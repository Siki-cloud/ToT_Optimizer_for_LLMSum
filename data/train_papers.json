[
  {
    "paper_id": "wunWpzNKfl",
    "title": "Attention-Guided Masking and Neighbor-Informed Reconstruction for Tabular Anomaly Detection",
    "domain": "self-supervised",
    "content": "One-class classification for tabular anomaly detection remains challenging due to the scarcity of labeled anomalies and the absence of explicit structural relationships among samples. Existing approaches have largely focused on intra-instance modeling, such as masking or reconstruction, while inter-sample modeling has received comparatively little attention. We propose AGNI (Attention-Guided Masking and Neighbor-Informed Reconstruction), a self-supervised framework that reimagines attention as a dual supervisory signal unifying these two perspectives. Specifically, Attention-Guided Masking leverages attention to identify and hide salient features, enforcing the learning of fine-grained intra-instance dependencies. At the same time, Neighbor-Informed Reconstruction repurposes the same attention scores to retrieve structurally similar neighbors, whose representations provide contextual support during reconstruction. By tightly coupling intra-instance and inter-sample objectives within a single attention space, AGNI transforms attention from a representational tool into a coordinating structural signal. Extensive experiments on 47 real-world datasets from ADBench demonstrate that AGNI achieves the best overall ranking among 15 classical and deep-learning baseline. Code is available in the supplementary material.",
    "key_points": [
      "tabular anomaly detection",
      "one-class classification"
    ],
    "gold_summary": "The proposed AGNI framework presents a novel approach that couples intra-instance and inter-sample modeling through an attention-guided mechanism. Its strong performance across numerous datasets demonstrates significant practical value."
  },
  {
    "paper_id": "WO6ngOsEL3",
    "title": "Test-Time Scaling via Metric Geometry for LLM Reasoning",
    "domain": "self-supervised",
    "content": "Test-Time Scaling (TTS) methods improve the reasoning capability of large language models (LLMs) by generating multiple independent Chain-of-Thoughts (CoTs) and aggregating them via designed policies. \nDespite effective, this ensemble approach incurs expensive inference costs due to the repeated model calls. \nIn this paper, we propose a physics-inspired framework that achieves the accuracy gains of multi-calls TTS within a single or few LLM calls. \nIt conceptualizes LLM reasoning as navigating through a maze, a complex puzzle through which one has to find a path to achieve specific goals.\nThe proposed \\emph{Maze} paradigm embeds candidate exemplars and domain knowledge into a multiplex latent manifold and learns a high-dimensional metric space.\nIn inference, \\emph{Maze} metrics can identify a single or a few optimal paths;\neach path refers to an ordered sequence of exemplars, forming a few-shot prompt that guides the LLM to the correct answer. \nEmpirically, in reasoning benchmarks including GPQA, MMLU-pro, GSM8K, and MATH-500, \\emph{Maze} matches or exceeds the accuracy of the Best-of-$N$ strategies while reducing the computational cost by 60$\\sim$80\\%. \nThese results support \\emph{Maze} to be a principled geometric alternative to brute-force TTS, enabling low-latency, interpretable, and computation-efficient reasoning for complex tasks.\nWe also advocate for an interesting width-depth equivalence in LLM reasoning under the \\emph{Maze} framework: any solution achievable by many shallow trials can be attained by a suitably planned sequence of reasoning steps.",
    "key_points": [
      "test-time scaling",
      "large language model",
      "reasoning"
    ],
    "gold_summary": "This paper proposes a test-time scaling method for LLMs leveraging the signals from hidden representations of LLMs' internal layers. The proposed method is physics-inspired and learnable."
  },
  {
    "paper_id": "XFrCbkHM8C",
    "title": "Random Feature Mean-Shift",
    "domain": "self-supervised",
    "content": "Locating the modes of a probability density function is a fundamental problem in many areas of machine learning. However, classical mode-seeking algorithms such as mean-shift and its variants exhibit quadratic complexity with respect to the number of data points due to exhaustive pairwise kernel computation - a well-known bottleneck that severely restricts the applicability. In this paper, we propose Random Feature mean-shift (RFMS), a novel linear complexity mode-seeking algorithm. We give a sampling-based estimator using random feature kernel approximation and zeroth-order gradient method that allows us to provably achieve linear runtime per iteration, with comprehensive theoretical guarantees for mode estimation and convergence behavior. Empirical evaluations on clustering and pixel-level image segmentation tasks show RFMS is up to 12x faster when compared with other mean-shift variants, offering substantial efficiency gains while producing near-optimal results.",
    "key_points": [
      "machine learning",
      "mode-seeking",
      "kernel density estimation",
      "random feature method",
      "zeroth-order optimization"
    ],
    "gold_summary": "This paper proposes a new algorithm named Random Feature Mean-Shift (RFMS) for mode-seeking. This paper solved the poor scalability of the traditional mean-shift algorithm. RFMS successfully reduces the computational complexity from $O(n^2)$ to $O(n)$."
  },
  {
    "paper_id": "6bt4Ej7tO7",
    "title": "HyperKAN: A Plug-and-Play Tool for Personalized Weights Generation",
    "domain": "self-supervised",
    "content": "Personalized weight generation is vital for adapting models to tailored patterns in real-world applications. However, existing methods struggle to capture nuanced feature variations across heterogeneous data distributions, resulting in suboptimal personalization performance. In this paper, we introduce HyperKAN, a plug-and-play personalized weights generator that integrates Kolmogorov-\nArnold Networks (KANs) for capturing feature variations among clients and enhancing personalization capacity. We design a novel\nPersonalized Federated Learning (pFL) framework that embed HyperKAN, enabling tailored model aggregation for each client with faster convergence. Our evaluations on four datasets present HyperKAN’s versatility and effectiveness, achieving up to 48% higher ac-\ncuracy than state-of-the-art methods. In a nutshell, HyperKAN offers a highly adaptable solution for enhancing model personalization, par-\nticularly in non-IID scenarios that challenge traditional weight generation approaches.",
    "key_points": [
      "personalized weight generation",
      "kolmogorov- arnold networks",
      "personalized federated learning"
    ],
    "gold_summary": "The paper introduces HyperKAN, a KAN-based personalized weight generator for federated learning that captures client-specific feature variations, achieving higher accuracy than prior methods on four datasets under non-IID settings."
  },
  {
    "paper_id": "lWIl9D1zPn",
    "title": "Hyperbolic Residual Quantization: Discrete Representations for Data with Latent Hierarchies",
    "domain": "self-supervised",
    "content": "Hierarchical data arise in countless domains, from biological taxonomies and organizational charts to legal codes and knowledge graphs. Residual Quantization (RQ) is widely used to generate discrete, multitoken representations for such data by iteratively quantizing residuals in a multilevel codebook. However, its reliance on Euclidean geometry can introduce fundamental mismatches that hinder modeling of hierarchical branching, necessary for faithful representation of hierarchical data. In this work, we propose Hyperbolic Residual Quantization (HRQ), which embeds data natively in a hyperbolic manifold and performs residual quantization using hyperbolic operations and distance metrics. By adapting the embedding network, residual computation, and distance metric to hyperbolic geometry, HRQ imparts an inductive bias that aligns naturally with hierarchical branching. We claim that HRQ in comparison to RQ can generate more useful for downstream tasks discrete hierarchical representations for data with latent hierarchies. We evaluate HRQ on two tasks: supervised hierarchy modeling using WordNet hypernym trees, where the model is supervised to learn the latent hierarchy - and hierarchy discovery, where, while latent hierarchy exists in the data, the model is not directly trained or evaluated on a task related to the hierarchy. Across both scenarios, HRQ hierarchical tokens yield better performance on downstream tasks compared to Euclidean RQ with gains of up to 20% for the hierarchy modeling task. Our results demonstrate that integrating hyperbolic geometry into discrete representation learning substantially enhances the ability to capture latent hierarchies.",
    "key_points": [
      "residual quantization",
      "hyperbolic space",
      "semantic tokens",
      "latent hierarchies"
    ],
    "gold_summary": "This paper proposes HRQ, a method for learning discrete multitoken representations for hierarchical data structures."
  },
  {
    "paper_id": "zM1JvKOdWT",
    "title": "GraphDenoiser: An Unsupervised Iterative Framework for Node Label Denoising in Graph-Structured Data",
    "domain": "self-supervised",
    "content": "Data annotation errors have always been one of the core challenges in the field of supervised learning: such noise not only interferes with the model's effective learning of the patterns of data distribution, but also directly leads to the model's discriminative bias in target tasks, significantly reducing the predictive accuracy of supervised learning systems. For graph-structured data, due to the uniqueness of the associative relationships between data points, traditional denoising methods struggle to adapt to the noise distribution patterns in this scenario. To address this issue, this paper focuses on the denoising problem of node type labels in graph data and proposes a denoising framework based on unsupervised learning called GraphDenoiser. Through multiple rounds of iteration between the node label noise prediction model and the synthetic data generation model, this framework can quantitatively output the noise probability of each node label and accurately locate mislabeled nodes in graph data. This provides a reliable noise diagnosis basis for subsequent label correction and robust graph model training, thereby alleviating the constraints of node mislabeling in graph data on supervised learning performance. Experiments show that under eight different noise injection methods across three datasets, compared with previous methods, the metrics of MCC, and F1 have increased by 22.81%, and 30.51% respectively.",
    "key_points": [
      "graph",
      "unsupervised learning",
      "node label denoising",
      "iterative optimization"
    ],
    "gold_summary": "This paper proposes an unsupervised graph denoising method, GraphDenoiser, which trains the noise prediction model through noise data sampling and iterative training. It claims to outperform multiple baselines on symmetric/asymmetric noise-injected graph datasets."
  },
  {
    "paper_id": "DealNNlz94",
    "title": "Are Object-Centric Representations Better At Compositional Generalization?",
    "domain": "self-supervised",
    "content": "Compositional generalization -- the ability to reason about novel combinations of familiar concepts -- is fundamental to human cognition and a critical challenge for machine learning. Object-centric learning, representing a scene as a set of objects, has been proposed as a promising approach for achieving this capability. However, systematic evaluation of these methods in visually complex settings remains limited. In this work, we introduce a Visual Question Answering benchmark consisting of three different visual worlds to measure how well vision encoders, with and without object-centric biases, generalize to unseen combinations of object properties. To ensure a fair and comprehensive comparison, we carefully account for the capacity of the image representation, training data diversity, downstream compute, and sample size. In this study, we use DINOv2 and SigLIP2, two widely used vision encoders, as the foundation models and their object-centric counterparts. Our key findings reveal that (1) object-centric approaches are superior in harder compositional generalization settings; (2) original dense representations surpass OC only on easier settings and typically require substantially more downstream compute; and (3) OC models are more sample-efficient, achieving stronger generalization with fewer images, whereas dense encoders catch up or surpass them only with sufficient data and diversity. Overall, object-centric representations offer stronger compositional generalization when any one of training data diversity, sample size, or downstream compute is constrained.",
    "key_points": [
      "compositional generalization",
      "object-centric learning",
      "visual question answering"
    ],
    "gold_summary": "This study focuses on whether object-centric (OC) representations are more conducive to compositional generalization. By constructing a VQA benchmark and comparing mainstream visual encoders with their OC variants."
  },
  {
    "paper_id": "J01ZhCGT2k",
    "title": "From Atoms to Chains: Divergence-Guided Reasoning Curriculum for Unlabeled LLM Domain Adaptation",
    "domain": "self-supervised",
    "content": "Adapting Large Language Models (LLMs) to specialized domains without human-annotated data is a crucial yet formidable challenge. Widely adopted  knowledge distillation methods often devolve into coarse-grained mimicry, where the student model inefficiently targets its own weaknesses and risks inheriting the teacher's reasoning flaws. This exposes a critical pedagogical dilemma: how to devise a reliable curriculum when the teacher itself is not an infallible expert. Our work resolves this by capitalizing on a key insight: while LLMs may exhibit fallibility in complex, holistic reasoning, they often exhibit high fidelity on focused, atomic sub-problems. Based on this, we propose Divergence-Guided Reasoning Curriculum (DGRC), which constructs a learning path from atomic knowledge to reasoning chains by dynamically generating two complementary curricula from model disagreements. When a student and a teacher arrive at conflicting results for the same problem, DGRC tasks the teacher with a diagnostic process: it analyzes both reasoning paths to formulate atomic, root-cause queries targeting the specific steps where their reasoning diverged, and then provides the answers itself to create high-confidence atomic question-answer pairs. These pairs then serve a dual purpose: (1) providing an atomic curriculum to rectify the student's knowledge gaps, and (2) serving as factual criterion to filter the teacher's original reasoning chains, yielding a verified CoT curriculum that teaches the student how to integrate atomic knowledge into complete reasoning paths. Experiments on specialized domains demonstrate the effectiveness of DGRC. Notably, our method achieves a 7.76\\% relative improvement for the 1.5B student model in the medical domain over strong unlabeled baseline.",
    "key_points": [
      "large language models",
      "unlabeled llm adaptation",
      "knowledge distillation",
      "learning from disagreement",
      "reasoning curriculum"
    ],
    "gold_summary": "This paper proposes the Divergence-Guided Reasoning Curriculum (DGRC) framework to address the challenge of adapting Large Language Models (LLMs) to specialized domains (e.g., medical and legal) without human-annotated data."
  },
  {
    "paper_id": "K5tcKEQaUr",
    "title": "Frequency-Balanced Retinal Representation Learning with Mutual Information Regularization",
    "domain": "self-supervised",
    "content": "We propose a frequency-oriented perspective on retinal representation learning by analyzing masked autoencoders (MAE) through the lens of spatial frequency. Our analysis shows that MAE favors low-frequency content while under-encoding diagnostically critical high-frequency structures in retinal images. Because retinal pathology often manifests in high-frequency detail, this bias limits diagnostic performance and motivates frequency-balanced representations. Within a mutual-information (MI) formulation of MAE, we introduce the \\emph{Frequency-Balanced Retinal Masked Autoencoder (RetMAE)}, which augments the reconstruction objective with a MI regularizer that suppresses low-frequency redundancy and accentuates clinically salient high-frequency information. Without altering architecture, RetMAE learns frequency-balanced features that surpass those of MAE-based retinal encoders in both quantitative and qualitative evaluations. These results suggest that a frequency-oriented view provides a principled foundation for future advances in ophthalmic modeling.",
    "key_points": [
      "masked image modeling",
      "masked autoencoders",
      "representation learning",
      "mutual information",
      "retinal imaging",
      "medical imaging"
    ],
    "gold_summary": "This paper proposes a frequency-balanced masked autoencoder framework (RetMAE) that enhances retinal representation learning by introducing a high-frequency mutual information regularizer to emphasize clinically critical high-frequency structures while suppressing redundant low-frequency content."
  },
  {
    "paper_id": "D7i6BIbCz0",
    "title": "UniBP: Toward Universal Backdoor Purification via Fine-Tuning",
    "domain": "self-supervised",
    "content": "Deep neural networks (DNNs) remain vulnerable to backdoor attacks, perpetuating an arms race between attacks and defenses. Despite their efficacy against classical threats, mainstream defenses often fail under more advanced, defense-aware attacks, particularly clean-label variants that can evade decision-boundary shifting and neuron-pruning defenses. We present UniBP, a universal post-training defense that operates with only 1\\% of the original training data and unveils the relationship between batch normalization (BN) behavior and backdoor effects. \nAt a high level, UniBP scrutinizes BN layers’ affine parameters and statistics using a small clean subset (i.e., as small as 1\\% of the training data) to find the most impactful affine parameters for reactivating the backdoor, then prunes them and applies masked fine-tuning to remove the backdoor effects. We compare our method against 5 SOTA defenses, 5 backdoor attacks, and various attack/defense conditions, and show that UNBP consistently reduces the attack success rate from more than 90\\% to less than 5\\% while preserving clean performance, whereas other baselines degrade under smaller fine-tuning sets or stronger poisoning techniques.",
    "key_points": [
      "backdoor attack",
      "backdoor defense",
      "adversarial ml"
    ],
    "gold_summary": "The paper adjusts the parameters of batch normalization layers to mitigate backdoor poisoning."
  },
  {
    "paper_id": "XQv3jegXqt",
    "title": "Grokked Models are Better Unlearners",
    "domain": "self-supervised",
    "content": "The phenomenon of $\\textbf{grokking}$, where deep neural networks achieve delayed but strong generalization long after fitting training data, challenges traditional views of model generalization. While previous work has shown that grokked models exhibit enhanced robustness, we establish a novel connection: grokked models are fundamentally better at machine unlearning—the process of removing specific data influences without full retraining. We provide comprehensive empirical evidence across CNNs and ResNets on CIFAR datasets, and transformers on text datasets. State-of-the-art unlearning algorithms (gradient ascent, SCRUB, Fisher forgetting, and fine-tuning) achieve significantly more efficient data removal when applied to grokked models. Critically, unlearned grokked models retain higher performance on remaining data and exhibit enhanced robustness compared to non-grokked counterparts. Our analysis reveals that grokking restructures internal representations, creating more disentangled knowledge that facilitates selective forgetting with minimal collateral damage. These findings establish the first systematic connection between grokking and machine unlearning, suggesting that grokking-induced training dynamics can be leveraged for more practical and robust privacy-preserving unlearning methods.",
    "key_points": [
      "machine unlearning",
      "grokking",
      "deep learning",
      "generalization"
    ],
    "gold_summary": "The authors demonstrate that grokking machine learning models leads to better unlearning without changing the unlearning methods."
  },
  {
    "paper_id": "ARDsBYnarO",
    "title": "Exact Online Learning with Gamma-memory delays for Accurate Feedforward SNNs",
    "domain": "self-supervised",
    "content": "Spiking Neural Networks (SNNs) promise energy-efficient, low-latency AI through sparse, event-driven computation. Neuromorphic hardware can realize this efficiency by exploiting high temporal resolution, as precise spike timing supports compact and sparse information processing. Yet, training SNNs under fine temporal discretization remains a major challenge. In state-of-the-art approaches, spiking neurons are modeled as self-recurrent units, embedded into recurrent networks to maintain state, and trained with BPTT or RTRL variants based on surrogate gradients. We show that these methods scale poorly with temporal resolution, while online approximations methods are inherently unstable. We solve this problem by developing recursive memory structures combined with a linear–nonlinear interpretation of spike-train generation in spiking neurons: the SpikingGamma model. We show that SpikingGamma models support direct error backpropagation without surrogate gradients, can learn fine temporal patterns with minimal spiking in an online manner, and scale feedforward SNNs to complex tasks with competitive accuracy, all while being insensitive to the temporal precision of the model. Our approach offers both an alternative to current recurrent SNNs trained with surrogate gradients, and a direct route for mapping SNNs to neuromorphic hardware.",
    "key_points": [
      "spiking neural network",
      "online learning",
      "delay learning",
      "energy-efficiency",
      "feedforward"
    ],
    "gold_summary": "The authors of this paper present a new approach/or spiking model called SpikingGamma, which they claim is able to produce better results than the standard spiking models trained with BPTT."
  },
  {
    "paper_id": "DRqmwamsD8",
    "title": "WHY TEACHER–STUDENT SELF-SUPERVISED LEARNING WORKS: A MUTUAL INFORMATION PERSPECTIVE",
    "domain": "self-supervised",
    "content": "We study teacher-student (TS) self-supervised learning methods (e.g., BYOL, SimSiam), which learn strong representations without relying on negative samples but currently lack a clear information-theoretic explanation. Building on the InfoMax perspective that unifies many multi-view SSL families, we show that TS-SSL implicitly maximizes a variational lower bound on the mutual information \\(I(Z_\\theta; X)\\) between inputs and the teacher representations \\(Z_\\theta\\). Concretely, we prove that the predictor yields an implicit variational estimate of \\(I(Z_\\theta; (Z_\\phi, X))\\), the mutual information between teacher and student representations, and that the alternating optimization—student prediction (with stop-gradient) followed by teacher updates—implicitly maximizes a lower bound on \\(I(Z_\\theta; X)\\). Then, we derive convergence results characterizing the evolution of the teacher representation’s entropy and alignment during training. Eventually, motivated by these theoretical insights, we introduce a simple mutual-information–based regularizer on the student latent space that enforces monotonic growth of \\(I(Z_\\theta; X)\\) and yields consistent downstream improvements on both natural-image and medical-imaging benchmarks.",
    "key_points": [
      "representation learning",
      "non-contrastive learning",
      "mutual information",
      "teacher-student framework"
    ],
    "gold_summary": "The paper looks to understand Teacher-Student SSL methods from an information theoretic perspective to justify their performance, analogously to the mutual information maximisation perspectives of other SSL methods, such as infoNCE."
  },
  {
    "paper_id": "t7fnqseNvU",
    "title": "A Unified Approach to Universal Domain Adaptation with Single and Multiple Source Domains",
    "domain": "self-supervised",
    "content": "Universal domain adaptation (UniDA) imposes no constraints on the label sets of the source and target domains, aiming to transfer knowledge from source to target domains. Existing works typically target either single-source or multi-source UniDA, rarely both. Naively merging multi-source data into a single source domain may lead to negative transfer and performance degradation. Moreover, since multi-source models are often equipped with modules tailored for multi-source data, they are usually not directly applicable to single-source tasks. These challenges hinder the development of a unified framework. In this paper, we propose a unified model based on multi-modal and uncertainty estimation, termed MUEUDA, to address this issue. Our model is capable of effectively handling both single-source and multi-source settings with outstanding performance. First, we incorporate multi-modal information, enabling class-level feature alignment between source and target domains using fine-tuning and prompt learning techniques. Second, we extract class-level image feature prototype from the source domain and progressively update them during training. Finally, we introduce a novel uncertainty estimation method that determines whether an image in the target domain belongs to a known or unknown class through a learnable threshold. Extensive experiments are conducted on both single-source and multi-source benchmarks, and our model achieved state-of-the-art performance. The method demonstrates strong performance across both scenarios, balancing effectiveness and generality. The code is available at https://github.com/jstree365/MUEUDA.",
    "key_points": [
      "universal domain adaptation",
      "multi-modal",
      "uncertainty estimation"
    ],
    "gold_summary": "In the paper, a unified model based on multi-modal and uncertainty estimation, termed MUEUDA, is proposed to address the development of a unified framework."
  },
  {
    "paper_id": "HYmaZwoyZr",
    "title": "Mixing Configurations for Downstream Prediction",
    "domain": "self-supervised",
    "content": "Humans possess an innate ability to group objects by similarity—a cognitive mechanism that clustering algorithms aim to emulate. Recent advances in community detection have enabled the discovery of configurations—valid hierarchical clusterings across multiple resolution scales—without requiring labeled data. In this paper, we formally characterize these configurations and identify similar emergent structures in register tokens within Vision Transformers. Unlike register tokens, configurations exhibit lower redundancy and eliminate the need for ad hoc selection. They can be learned through unsupervised or self-supervised methods, yet their selection or composition remains specific to the downstream task and input. Building on these insights, we introduce GraMixC, a plug-and-play module that extracts configurations, aligns them using our novel Reverse Merge/Split (RMS) technique, and fuses them via attention heads before forwarding them to any downstream predictor. On the DSNI 16S rRNA cultivation-media prediction task, GraMixC improves the R$^2$\n from 0.6 to 0.9 on various methods, setting a new state-of-the-art. We further validate GraMixC across standard tabular benchmarks, where it consistently outperforms single-resolution and static-feature baselines.",
    "key_points": [
      "unsupervised learning",
      "hierarchical clustering",
      "16s rrna",
      "cultivation media",
      "multi-resolution configurations",
      "tabular benchmarks"
    ],
    "gold_summary": "The paper introduces a hierarchical configuration learning module GraMixC as part of a prediction pipeline. It is evaluated on a bacterial species prediction task. The authors provide extensive experimentation and evaluation procedure"
  },
  {
    "paper_id": "woJuNveik3",
    "title": "Hidden units for tabular data representing intervals",
    "domain": "self-supervised",
    "content": "Tree-based boosting remains a strong baseline for tabular data, partly because standard neural units impose overly smooth inductive biases. We revisit exponential-centered units (ExU) through the lens of Lipschitz bounds and introduce Double-centered Units (DcU), which parameterize soft intervals via learnable left/right centers and preserve informative gradients outside the interval. Building on DcU, we propose the Soft Interval Neural Network (SINN)—an encoder-MLP architecture with max pooling and interval sparsity regularization.\nAcross 15 public datasets, SINN delivers competitive or superior accuracy to XGBoost on classification, while performance on regression is more mixed; we hypothesize that this gap reflects the implicit bias of neural networks. We further examine common generalization proxies—spectral/Lipschitz bounds, Hessian-based flatness, and dropout-based ensembling—and find that smoothness-oriented regularization is not consistently predictive of tabular performance. These results suggest that non-affine, interval-like representations provide a useful inductive bias for tabular classification, and motivate theoretical analyses beyond affine assumptions.",
    "key_points": [
      "neural network",
      "hidden units",
      "tabular data",
      "generalization"
    ],
    "gold_summary": "This paper proposes Double-centered Units (DcU) and the Soft Interval Neural Network (SINN), a new neural architecture for tabular data that aims to mimic the discrete, interval-based inductive biases of tree models."
  },
  {
    "paper_id": "0KeKeXK8Hv",
    "title": "Self-Supervised Dynamical System Representations for Physiological Time-Series",
    "domain": "self-supervised",
    "content": "The effectiveness of self-supervised learning (SSL) for physiological time series depends on the ability of a pretraining objective to preserve information about the underlying physiological state while filtering out unrelated noise. However, existing strategies are limited due to reliance on heuristic principles or poorly constrained generative tasks. To address this limitation, we propose a pretraining framework that exploits the information structure of a dynamical systems generative model across multiple time-series. This framework reveals our key insight that  class identity can be efficiently captured by extracting information about the generative variables related to the system parameters shared across similar time series samples, while noise unique to individual samples should be discarded. Building on this insight, we propose PULSE, a cross-reconstruction-based pretraining objective for physiological time series datasets that explicitly extracts system information while discarding non-transferrable sample-specific ones. We establish theory that provides sufficient conditions for the system information to be recovered, and empirically validate it using a synthetic dynamical systems experiment. Furthermore, we apply our method to diverse real-world datasets, demonstrating that PULSE learns representations that can broadly distinguish semantic classes, increase label efficiency, and improve transfer learning.",
    "key_points": [
      "self-supervised learning",
      "dynamical systems",
      "physiological time-series"
    ],
    "gold_summary": "PULSE introduces a self-supervised pretraining method grounded in a dynamical-systems generative model."
  },
  {
    "paper_id": "P4M6TkaU7Q",
    "title": "HashPose: Memory-Efficient Human Pose Estimation via Progressive Hash Codes",
    "domain": "self-supervised",
    "content": "Real-time human pose estimation on edge devices demands memory-efficient, high-precision methods. The dominant heatmap approaches, however, scale quadratically with input size, waste computation on background regions, and require slow post-processing. We propose HashPose, a framework replacing heatmaps with progressive hash codes: each keypoint is a binary sequence where successive bits refine localization, cutting memory complexity from $\\Theta(HW)$ to $\\Theta(log(HW))$. This direct bit prediction avoids dense heatmap-style background computations and removes the need for argmax or non-maximum suppression to decode coordinates. Furthermore, HashPose utilizes image classification backbones without upsampling layers to achieve high accuracy while significantly boosting its speed. We validate HashPose's performance envelope across a wide range of model sizes, ranging from an efficient 3.5M-parameter HashPose-XT model with 0.82 milliseconds frame latency and 85.9\\% $AP^{50}$ on the COCO, to a 196.8M Large model that achieves a state-of-the-art 91.9\\% $AP^{50}$ with 5.57 milliseconds frame latency using only the COCO training set. Simultaneously, HashPose has 510x lower output memory than heatmap configurations (0.48 MB vs 244.8 MB) for a typical $256 \\times 192$ input, enabling high-throughput pose analysis that maintains high practical precision for on-device applications. Furthermore, its discrete representation is inherently suited for integer-only quantization, offering a clear path to further hardware acceleration on edge devices. Code is provided as supplementary material.",
    "key_points": [
      "classification",
      "pose estimation",
      "memory-efficient",
      "hash codes",
      "progressive refinement"
    ],
    "gold_summary": "This paper proposes to encode keypoint positions with quadtree hash code. It removes the cost of upsampling head in conventional heatmap-based methods. Results on COCO and MPII are reported."
  },
  {
    "paper_id": "S0IIgb33fO",
    "title": "Gradient Fan-in Asymmetry: The Structural Cause of Layer Redundancy in Deep Transformers",
    "domain": "self-supervised",
    "content": "Deep Transformers are composed of uniformly stacked residual blocks, yet their deepest layers often add little value. Prevailing explanations attribute this to small gradients, treating a symptom rather than the cause. We identify Gradient Fan-in Asymmetry as the structural driver of redundancy. In Pre-LayerNorm residual stacks, the gradient at a layer is the sum of an identity path and all downstream functional paths, producing a gradient fan-in that decays linearly with depth (and quadratically under deep supervision), yielding rich signals early and sparse for later layers. Across Transformers and ResNets, accumulated training gradients follow the theoretical fan-in and predict post hoc layer importance. Two causal interventions isolate structure as the bottleneck: equalizing per-layer gradient norms does not restore late-layer value, whereas increasing downstream path counts via parameter-shared repetition restores and elevates their impact. Building on this mechanism, we propose CascadeFlow Pruning, which removes layers using accumulated training gradients and outperforms standard heuristics without expensive post hoc analysis. We also introduce CascadeFormer, which tapers width with depth to match the natural information flow, achieving comparable perplexity to a uniform baseline at the same training budget while reducing latency by 8.6\\% and increasing throughput by 9.4\\%.",
    "key_points": [
      "transformers",
      "representation learning",
      "gradient dynamics",
      "pruning",
      "architectural efficiency",
      "causal inference"
    ],
    "gold_summary": "The paper claims to have uncovered the true reason, why deep layers add little value in transformers being Gradient-Fan-in Asymmetry."
  },
  {
    "paper_id": "dtl4IcoQpp",
    "title": "F6-Net: Algorithmic Reasoning through Gated Pathways and Min-Reduction",
    "domain": "self-supervised",
    "content": "Neural Algorithmic Reasoning (NAR) is the research area that aims to build artificial neural networks that can mimic (classical) algorithms, reproducing intermediary steps from their execution traces.\nNAR expects to enhance neural network generalization and help to develop more efficient, adaptable, and faster algorithms. \nThis capability makes it a highly promising approach for dynamic systems in unpredictable, real-world environments.\nAmong the existing methods for algorithm reproduction, the Message Passing Neural Network (MPNN) architecture and its variations, such as Triplet-GMPNN, stand out.\nThis paper proposes a novel variant of Triplet-GMPNN, characterized by three key modifications: a streamlined message-passing process, a new gating-type activation mechanism, and the use of a minimum-type function for embedding reduction.\nTo ascertain the individual contribution of each component, a comprehensive ablative analysis was conducted. This study evaluates each architectural modification through the lens of algorithmic alignment.\nThis work advances the understanding of these systems and opens up new design possibilities for future Neural Algorithmic Reasoning architectures.",
    "key_points": [
      "neural algorithmic reasoning; graph neural networks; graph reasoning; algorithms."
    ],
    "gold_summary": "This paper proposes an improved version of Triplet-GMPNN, the previous state of the art for Neural Algorithmic Reasoning (NAR). Specifically, it improves message-passing, gating, and aggregation."
  },
  {
    "paper_id": "XfLvGIFmAN",
    "title": "Spectral Attention Steering for Prompt Highlighting",
    "domain": "self-supervised",
    "content": "Steering a large language model's attention towards user-specified highlighted text is a critical capability. Existing prompt highlighting methods are incompatible with modern efficient attention mechanisms like Flash Attention due to their reliance on post-hoc matrix editing. We introduce Spectral Editing Key Amplification (SEKA), a training-free steering method that tackles this by directly editing key embeddings before attention computation. SEKA learns universal relevance subspaces offline via spectral decomposition. We extend this to Adaptive SEKA (AdaSEKA), a query-adaptive variant that uses a training-free routing mechanism to dynamically combine multiple expert subspaces based on the prompt's semantic intent. Our experiments show both methods significantly outperform strong baselines on standard steering benchmarks while adding much lower latency and memory overhead, ensuring full compatibility with optimised attention.",
    "key_points": [
      "spectral learning",
      "attention steering",
      "large language models"
    ],
    "gold_summary": "The paper proposes a training-free attention–steering method and a query-adaptive variant to highlight user-specified spans by intervening on the attention inputs rather than post-hoc editing attention matrices."
  },
  {
    "paper_id": "c4r7iLhGcQ",
    "title": "Fitting Feature Norm to Confidence: A Regularization Approach for Robust Out-of-Distribution Detection",
    "domain": "self-supervised",
    "content": "We propose a novel framework for robust out-of-distribution (OOD) detection by explicitly designing the feature space. Our approach aligns feature norm with model confidence by enforcing a zero-confidence baseline—defined as the feature norm at which the softmax output is uniform—and deriving an upper bound on the feature norm through softmax sensitivity analysis. This strategy enables in-domain samples to exhibit high confidence while ensuring that OOD samples, which naturally possess lower feature norms, yield near-uniform predictions. Unlike existing methods that simply modify the feature norm without optimizing the underlying embedding space, our method learns an optimal feature space via density ratio estimation using Kernel Logistic Regression and feature space augmentation. Our theoretical analysis shows that the risk difference between the true data distribution (comprising both known and unknown samples) and an auxiliary domain—constructed from augmented OOD samples drawn from the inner region of the feature space—is bounded. Extensive experiments show that our approach significantly enhances OOD detection performance.",
    "key_points": [
      "out-of-distribution detection",
      "confidence calibration"
    ],
    "gold_summary": "this paper proposes a novel framework for robust out-of-distribution (OOD) detection by explicitly designing the feature space. \nExtensive experiments show that the proposed approach significantly enhances OOD detection performance."
  },
  {
    "paper_id": "pE7trvliXi",
    "title": "Correlation-based Self-Supervision for Few-shot Tabular Learning",
    "domain": "self-supervised",
    "content": "Despite its paramount importance in many real-world applications, e.g., few-shot learning, self-supervision for tabular data remains challenging. The inherently heterogeneous nature of tabular data substantially impedes the generation of pseudo-labels with high fidelity. The commonly utilized random-based selection methodology largely ignores the complex relationships among features and might induce substantial noise into the self-supervision process, especially when the selected features have little relations with others. To address this issue, this paper proposes a simple yet effective solution: utilizing the correlation among original features to qualitatively evaluate the possible quality of pseudo-labels. Accordingly, a correlation-based randomness, rather than pre-defined uniform randomness, is proposed to select features for pseudo-label generation according to their overall correlations towards others. We employ our design in VIME, SCARF, STUNT and SAINT. The experimental results in various few-shot classification tasks reveal significant performance improvements across 50 OpenML datasets, compared to the original design. Code and datasets are available at the supplemental file.",
    "key_points": [
      "tabular data",
      "self-supervision",
      "variable correlation",
      "few-shot learning"
    ],
    "gold_summary": "The paper proposes a correlation-guided feature selection strategy to replace uniform random sampling in self-supervised tabular learning."
  },
  {
    "paper_id": "3UDlRUf1es",
    "title": "DeCo-DETR: Decoupled Cognition DETR for efficient Open-Vocabulary Object Detection",
    "domain": "self-supervised",
    "content": "Open-Vocabulary Object Detection (OVOD) plays a critical role in autonomous driving and human-computer interaction by enabling perception beyond closed-set categories. However, current approaches predominantly rely on multimodal fusion, facing dual limitations: multimodal fusion methods incur heavy computational overhead from text encoders, while task-coupled designs compromise between detection precision and open-world generalization. To address these challenges, we propose Decoupled Cognition DETR, a vision framework featuring a three-stage cognitive distillation mechanism: Dynamic Hierarchical Concept Pool constructs self-evolving concept prototypes using LLaVA-generated region descriptions filtered by CLIP alignment, aiming to replace costly text encoders and reduce computational overhead; Hierarchical Knowledge Distillation decouples visual-semantic space mapping via prototype-centric projection, avoiding task coupling to enhance open-world generalization; Parametric Decoupling Training coordinates localization and cognition through dual-stream gradient isolation, further optimizing detection precision. Extensive experiments on the common OVOD evaluation protocol demonstrated that DeCo-DETR achieves state-of-the-art performance compared to existing OVOD methods. It provides a new paradigm for extending OVOD to more real-world applications.",
    "key_points": [
      "open-vocabulary object detection",
      "knowledge distillation",
      "multi-modal"
    ],
    "gold_summary": "This manuscript targets open-vocabulary object detection (OVOD) and proposes DeCo-DETR, a three-stage decoupled cognition pipeline."
  },
  {
    "paper_id": "iTaQmRWa7Y",
    "title": "KLAS: Using Similarity to Stitch Neural Networks for an Improved Accuracy-Efficiency Tradeoff",
    "domain": "self-supervised",
    "content": "Given the wide range of deployment targets, flexible model selection is essential for optimizing performance within a given compute budget.\nRecent work demonstrates that stitching pretrained models within a model family enables cost-effective interpolation of the accuracy-efficiency tradeoff space.\nStitching transforms intermediate activations from one pretrained model into another, producing a new interpolated stitched network.\nSuch networks provide a pool of deployment options along the accuracy-efficiency spectrum.\nHowever, existing stitching approaches often yield suboptimal tradeoffs and lack generalizability, as they primarily rely on heuristics to select stitch configurations.\nWe argue that constructing improved accuracy-efficiency tradeoffs requires explicitly capturing and leveraging the _similarity_ between pretrained models being stitched.\nTo this end, we introduce KLAS, a novel stitch selection framework that automates and generalizes stitch selection across model families by leveraging KL divergence between intermediate representations.\nKLAS identifies the most promising stitches from the $\\mathcal{O}(n^k)$ possibilities for $k$ pretrained models of depth $n$.\nThrough comprehensive experiments, we demonstrate that KLAS produces improved accuracy-efficiency curve of stitched models at the same cost as baselines.\nKLAS achieves up to $1.21\\%$ higher ImageNet-1K top-1 accuracy at the same computational cost, or maintains accuracy with a $1.33\\times$ reduction in FLOPs.",
    "key_points": [
      "representation learning",
      "neural networks",
      "deep learning"
    ],
    "gold_summary": "This paper proposes the use of inserted linear probes and KL divergence between them to find layers compatible for stitching between different networks."
  },
  {
    "paper_id": "abxVxyXNhW",
    "title": "MARS: Optimizing Dual-System Deep Research via Multi-Agent Reinforcement Learning",
    "domain": "self-supervised",
    "content": "Large Reasoning Models (LRMs) often exhibit a tendency for overanalysis in simple tasks, where the models excessively utilize System 2-type, deliberate reasoning, leading to inefficient token generation. \nFurthermore, these models face challenges in adapting their reasoning capabilities to rapidly changing environments due to the static nature of their pre-training data. \nTo address these issues, advancing Large Language Models (LLMs) for complex reasoning tasks requires innovative approaches that bridge intuitive and deliberate cognitive processes, akin to human cognition's dual-system dynamic. \nThis paper introduces a Multi-Agent System for Deep ReSearch (MARS) enabling seamless integration of System 1’s fast, intuitive thinking with System 2’s deliberate reasoning within LLMs. \nMARS strategically integrates multiple external tools—such as Google Search, Google Scholar, and Python Interpreter—to access up-to-date information and execute complex computations, while creating a specialized division of labor where System 1 efficiently processes and summarizes high-volume external information, providing distilled insights that expand System 2's reasoning context without overwhelming its capacity.\nFurthermore, we propose a multi-agent reinforcement learning framework extending Group Relative Policy Optimization to simultaneously optimize both systems with multi-turn tool interactions, bin-packing optimization, and sample balancing strategies that enhance collaborative efficiency.\nExtensive experiments demonstrate MARS achieves substantial improvements of 3.86\\% on the challenging Humanity's Last Exam (HLE) benchmark and an average gain of 8.9\\% across 7 knowledge-intensive tasks, validating the effectiveness of our dual-system paradigm for complex reasoning in dynamic information environments.",
    "key_points": [
      "deep research"
    ],
    "gold_summary": "MARS presents a dual-system multi-agent RL framework that unifies intuitive (System 1) and deliberate (System 2) reasoning within an LLM, jointly optimized via GRPO to improve deep research and reasoning performance across complex tasks."
  },
  {
    "paper_id": "jY21fwcrjr",
    "title": "GUIDE: Gated Uncertainty-Informed Disentangled Experts for Long-tailed Recognition",
    "domain": "self-supervised",
    "content": "Long-Tailed Recognition (LTR) remains a significant challenge in deep learning. While multi-expert architectures are a prominent paradigm, we argue that their efficacy is fundamentally limited by a series of deeply entangled problems at the levels of representation, policy, and optimization. These entanglements induce homogeneity collapse among experts, suboptimal dynamic adjustments, and unstable meta-learning. In this paper, we introduce GUIDE, a novel framework conceived from the philosophy of Hierarchical Disentanglement. We systematically address these issues at three distinct levels. First, we disentangle expert representations and decisions through competitive specialization objectives to foster genuine diversity. Second, we disentangle policy-making from ambiguous signals by using online uncertainty decomposition to guide a dynamic expert refinement module, enabling a differentiated response to model ignorance versus data ambiguity. Third, we disentangle the optimization of the main task and the meta-policy via a two-timescale update mechanism, ensuring stable convergence. Extensive experiments on four challenging LTR benchmarks, including  ImageNet-LT, iNaturalist 2018, CIFAR-100-LT and Places-LT, demonstrate that GUIDE establishes a new state of the art, validating the efficacy of our disentanglement approach. Code is available at Supplement.",
    "key_points": [
      "long-tailed recognition",
      "multi-expert learning",
      "hierarchical disentanglement"
    ],
    "gold_summary": "This paper introduces GUIDE, a novel framework conceived from the philosophy of Hierarchical Disentanglement."
  },
  {
    "paper_id": "i8b5T0ezsk",
    "title": "ProFit: Unsupervised Fine-Tuning of Tabular Models via  Proxy Tasks for Label-Scarce Anomaly Detection",
    "domain": "self-supervised",
    "content": "Anomaly detection in tabular data is crucial for applications such as fraud prevention and risk control, yet it remains challenging due to heterogeneous features, class imbalance, and limited labeled anomalies. Although pretrained tabular in context learning (TICL) models reduce label dependence, the inductive biases they develop on synthetic tasks are often misaligned with the actual data distributions encountered in downstream scenarios. Effective adaptation to new domains is thus difficult when labels are scarce. We propose **ProFiT**, an unsupervised fine-tuning framework that leverages only unlabeled target-domain data to adjust pretrained tabular models. ProFiT constructs a variety of proxy tasks by sampling different features as targets and using correlated features as inputs, encouraging the model to capture the underlying structure of the new data. To improve training effectiveness, we introduce a consistency regularizer that aligns the predictions from two different proxy views using Jensen–Shannon divergence. Experiments on tabular anomaly detection benchmarks show that ProFiT outperforms weakly-supervised and unsupervised methods, as well as vanilla TICL models. ProFiT offers a practical way to improve tabular anomaly detection under limited labeled data conditions and vast amounts of unlabeled data.",
    "key_points": [
      "anomaly detection",
      "unsupervised tabular learning"
    ],
    "gold_summary": "This paper focuses on the task of weak-supervised tabular anomaly detection. The proposed method ProFit, adapts tabular foundation model to downstream anomaly detection tasks via proxy-based fine-tuning."
  },
  {
    "paper_id": "RCtNvnifve",
    "title": "CLEAR: Consistent Labeling Enhanced by LLM-driven Automated Re-labeling for Improved Information Retrieval",
    "domain": "self-supervised",
    "content": "The performance of information retrieval (IR) systems is heavily influenced by the quality of training data. Manually labeled datasets often contain errors due to subjective biases of annotators, and limitations of retrieval models. To address these challenges, we propose CLEAR, a novel framework that leverages large language models (LLMs) to automatically correct incorrect labels and extract more accurate and true positive documents. CLEAR estimates the reliability of existing annotations using LLMs and rectifies potential labeling errors, thereby improving overall data quality. Furthermore, we conduct a systematic investigation of how utilizing true positive documents affects retrieval model performance. We evaluate CLEAR on several widely-used IR benchmarks, including MS MARCO Passage, MS MARCO Document, Natural Questions, and TriviaQA. Experimental results demonstrate that CLEAR consistently outperforms existing baseline models, validating the effectiveness of the proposed approach.",
    "key_points": [
      "information retrieval",
      "re-labeling",
      "large language models (llms)",
      "contrastive learning"
    ],
    "gold_summary": "The work proposes an LLM-based pipeline to relabel existing labels and find missing positives. Using this pipeline, a better dataset is constructed, and training on it results in better performance."
  },
  {
    "paper_id": "tooDJHBSvO",
    "title": "DiffSDA: Unsupervised Diffusion Sequential Disentanglement Across Modalities",
    "domain": "self-supervised",
    "content": "Unsupervised representation learning, particularly sequential disentanglement, aims to separate static and dynamic factors of variation in data without relying on labels. This remains a challenging problem, as existing approaches based on variational autoencoders and generative adversarial networks often rely on multiple loss terms, complicating the optimization process. Furthermore, sequential disentanglement methods face challenges when applied to real-world data, and there is currently no established evaluation protocol for assessing their performance in such settings. Recently, diffusion models have emerged as state-of-the-art generative models, but no theoretical formalization exists for their application to sequential disentanglement. In this work, we introduce the Diffusion Sequential Disentanglement Autoencoder (DiffSDA), a novel, modal-agnostic framework effective across diverse real-world data modalities, including time series, video, and audio. DiffSDA leverages a new probabilistic modeling, latent diffusion, and efficient samplers, while incorporating a challenging evaluation protocol for rigorous testing. Our experiments on diverse real-world benchmarks demonstrate that DiffSDA outperforms recent state-of-the-art methods in sequential disentanglement.",
    "key_points": [
      "sequential disentanglement",
      "diffusion models",
      "unsupervised learning"
    ],
    "gold_summary": "DiffSDA is a modal-agnostic diffusion sequential disentanglement autoencoder that factorizes static and dynamic factors using a single, unified score-estimation loss."
  },
  {
    "paper_id": "dWeKnWqmMZ",
    "title": "HEART: Emotionally-driven test-time scaling of Language Models",
    "domain": "self-supervised",
    "content": "Test-time scaling has shown considerable success in improving the performance of language models on complex reasoning tasks without requiring fine-tuning. However, current strategies such as self-reflection primarily focus on logical or structural refinement. They do not leverage the guiding potential of affective feedback. Inspired by psychological research showing that emotions can modulate cognitive performance, we introduce \\textit{HEART}--a novel framework that uses emotionally-driven prompts for iterative self-correction. \\textit{HEART} provides feedback on a model's incorrect response using a curated set of concise, emotionally charged phrases based on the six universal emotion categorized by Dr. Paul Ekman. By systematically varying the emotional tone of the feedback across iterations, our method guides the model to escape flawed reasoning paths and explore more promising alternatives. We evaluate our framework on challenging reasoning benchmarks including OlympiadBench, Humanity's Last Exam, and SimpleQA. Our results reveal a significant new phenomenon: when guided by an oracle verifier, this affective iteration protocol unlocks significantly deeper reasoning, leading to consistent and substantial increases in accuracy over state-of-the-art baselines with the same verifier. However, we also identify a critical bottleneck for practical deployment. In a verifier-free setting, it struggles to harness these gains consistently, highlighting as a key challenge for future work. Our findings suggest that the next frontier in machine reasoning may lie not just in refining logic, but also in understanding and leveraging the `\\textit{HEART}' of the models.",
    "key_points": [
      "large language models",
      "prompt engineering",
      "reasoning",
      "affective computing",
      "iterative refinement"
    ],
    "gold_summary": "* self-reflection + emotional style prompting\n* setting 1: oracle verifier -> works\n* setting 2: no oracle -> doesn't work"
  },
  {
    "paper_id": "educGk5ykl",
    "title": "Flow-Based Alignment of Uni-Modal Vision and Text Encoders for Few-Shot Image Classification",
    "domain": "self-supervised",
    "content": "Few-shot classification with vision–language models remains challenging, particularly when relying on multi-modal encoders such as CLIP that are restricted to paired image–text data. We introduce FSF, a framework that leverages arbitrary uni-modal encoders—including vision or text models that were pretrained on broad or domain-specific corpora—and aligns them for cross-modal classification. FSF first applies a closed-form orthogonal Procrustes map to align image and text embeddings while preserving their geometry, and then trains a lightweight flow-matching prior that regularizes adaptation in the few-shot regime. At inference, images are classified by cosine similarity in the aligned feature space between query embeddings and mapped class prototypes. Experiments on standard benchmarks, ImageNet variants, and VinDr-CXR, a large-scale chest X-ray benchmark, show that FSF is able to leverage stronger or specialized encoders, achieving competitive or superior accuracy compared to recent adaptation methods.",
    "key_points": [
      "few-shot classification",
      "vision-language models",
      "clip adaptation",
      "alignment of uni-modal encoders",
      "flow matching"
    ],
    "gold_summary": "The paper proposes a flow-based model for multimodal few-shot classification. The approach is highly interesting, thoughtfully addresses various experimental settings, and is well-supported by comprehensive experiments that align closely with the proposed method."
  },
  {
    "paper_id": "8TWUi94k9u",
    "title": "acuSimNet: Multi-View Self-Occlusion-Awared Visibility Learning for Cranio-Cervical Acupuncture Points",
    "domain": "self-supervised",
    "content": "The localization of acupuncture points (acupoints) in Traditional Chinese Medicine (TCM) presents unique challenges since they are defined by abstract principles rather than distinct anatomical landmarks. Existing approaches are typically constrained to single view or rely on indirect calculations of relative positions with respect to other landmarks, thereby overlooking human anatomical variations. Furthermore, acupoint visibility assessment, which determins whether points are occluded by human itself, hair, clothing, or other objects, has received limited attention in practical applications. Acupoint localization itself does not require 3D reconstruction, but inferring their occlusion relationships with anatomical surfaces does, which adds computational cost and limits real-time inference. In this work, we introduce acuSimNet, an efficient hierarchical multi-task learning architecture for multi-view, self-occlusion-aware visibility prediction of acupoints, achieving 99.97% accuracy on the validation set. Our approach also addresses the challenges of high-dimensional classification (174 acupoints in cervicocranial region), negative convergence issues for visible acupoints, and inter-task scheduling optimization, resulting in substantially accelerated convergence. We improved the training efficiency from the exisiting methods of 3000 epochs to achieve 99% validation accuracy, to our optimized framework achieving 90% accuracy in 39 epochs and 99% accuracy in 86 epochs. This architecture overcomes the limitations of existing methods, could enable practical applications in acupoints detection and visualization, advancing the automation of TCM.",
    "key_points": [
      "traditional chinese medicine",
      "multi-task learning",
      "visibility prediction",
      "multi-view analysis",
      "deep learning",
      "computer vision",
      "medical imaging"
    ],
    "gold_summary": "The paper proposes a method called acuSimNet to accurately locate acupoints by designing an efficient hierarchical multi-task learning\narchitecture for multi-view and self-occlusion-aware visibility prediction. The approach is validated by comprehensive experiments in public dataset."
  },
  {
    "paper_id": "sJHf6crz89",
    "title": "A Bio-Inspired Sound Localization Spiking Neural Network with Unsupervised Local Plasticity and Proximity Learning",
    "domain": "self-supervised",
    "content": "In this paper, we propose an unsupervised learning principle that leverages the neuro-inspired local plasticity and biophysiological characteristics of the brain for the learning of spiking neural networks (SNNs) without labels. The learning principle synergistically combines morphological features and biochemical phenomena in the brain cortex, guiding networks to self-organize their connectivity without global error backpropagation. The learning principle is based on two local plasticity rules. One is latency-mediated spike timing-dependent plasticity, formulated by combining the original STDP with axonal latency. The other is proximity learning, mediated by the volume transmission of neurotransmitters among neurons. We successfully applied these plasticity rules to a spiking model of the avian auditory cortex and observed the self-organization of the network, which results in the accurate localization of sound sources. After being trained using interaural time difference (ITD)-encoded spike trains, the network converged to synaptic connectivity resembling the famous Jeffress model. The performance evaluation results presented demonstrate that the proposed learning principle enables the SNN to localize sound sources with accuracy and resolution higher than those achieved by supervised learning rules.",
    "key_points": [
      "unsupervised learning",
      "spike-timing-dependent plasticity (stdp)",
      "spiking neural network (snn)",
      "neuromorphic system",
      "self-organization",
      "sound source localization (ssl)"
    ],
    "gold_summary": "This paper aims to provide a bio-inspired solution to sound location via two main ideas: a latency-mediated spike timing-dependent plasticity rule, and the volume transmission of neurotransmitters."
  },
  {
    "paper_id": "9LFvRkJwtV",
    "title": "Source-Free Test-Time Adaptation for Diffusion-based Virtual Try-On",
    "domain": "self-supervised",
    "content": "The rapid growth of e-commerce has driven notable advancements in diffusion-based virtual try-on models. Virtual try-on models, however, suffer significant quality degradation when deployed on real-world data that differs from their source (training) distribution. To address challenges in quality degradation due to domain shifts, we introduce a test-time adaptation framework that enhances try-on quality during diffusion denoising (inference time) without requiring model retraining or updates to the original network parameters. We introduce statistical distribution matching across complementary domains during the diffusion denoising process. Comprehensive evaluation across four state-of-the-art diffusion models (IDM-VTON, LaDI-VTON, Stable-VTON, TPD) and three datasets (VITON-HD, DressCode, DeepFashion) demonstrates notable improvements across multiple dataset-method combinations, with sharpness gains averaging 7.74\\% and distortion reduction of 0.95\\%. Our approach addresses important practical challenges in commercial virtual try-on deployment, enabling quality improvements across diverse domain conditions while preserving the original model's capabilities.",
    "key_points": [
      "test-time adaptation",
      "virtual try-on",
      "source-parameter-free adaptaion"
    ],
    "gold_summary": "The authors propose a test-time adaptation method for improving the performance of virtual try-on diffusion models, reducing distortion and increasing sharpness at a modest computational cost."
  },
  {
    "paper_id": "rwvTTjcuHv",
    "title": "Disentangled Skill Representations for Predictive Human Modeling",
    "domain": "self-supervised",
    "content": "Understanding human skill is essential for AI systems that collaborate with, coach, or assist people. Unlike typical latent variable estimation problems—which rely on single observations or explicit labels—skill is a persistent, compositional, and behaviorally grounded construct that must be inferred from patterns over time. We introduce Skill Abstraction with Interpretable Latents (SAIL), a method for learning disentangled skill representations from naturalistic behavioral data. Our approach produces a skill embedding that is robust to spurious performance fluctuations and captures core, transferable representation of human subskills. Furthermore, SAIL supports skill-informed behavior prediction that generalizes across a variety of contexts. We represent each individual with a persistent skill embedding that controls a blend between expert and novice behavior bases and is trained using counterfactual subskill swaps for disentanglement. This design yields a representation that is both robust to performance variation and structured for interpretability. We demonstrate that SAIL outperforms prior methods across two domains—high-performance driving and baseball batting—producing skill representations that are stable, predictive, and interpretable.",
    "key_points": [
      "representation learning",
      "human skill modeling",
      "interpretable latents",
      "counterfactual training"
    ],
    "gold_summary": "This paper models human skill as \"disentangled skill representations\" and represents individuals with skill embeddings that are blends between experts and novices. It evaluates in driving and baseball batting."
  },
  {
    "paper_id": "Hmnh6UhDp6",
    "title": "Layer-Based 3D Gaussian Splatting for Sparse-View CT Reconstruction",
    "domain": "self-supervised",
    "content": "We introduce a dynamic framework for 3D sparse-view Gaussian Splatting that learns scene representations through layerwise, iterative refinement of the Gaussian primitives. Conventional methods typically rely on dense, one-time initialization, where the placement of Gaussians is guided by 2D projection supervision and density control. However, such strategies can lead to misalignment with the true 3D structure, particularly in regions with insufficient projection information due to sparse-view acquisition. In contrast, we adopt a coarse-to-fine approach beginning with a base representation and progressively expanding it by adding new layers of smaller Gaussians to accommodate finer-grained details. At each such iteration, the placement of new primitives is guided by a 3D error map, obtained by the back projection of 2D projections' residuals. This process acts as adaptive importance sampling in 3D space, directing model capacity to regions with high error. We evaluate our approach on sparse-view computed tomography reconstruction tasks, demonstrating improved performance over existing methods.",
    "key_points": [
      "ct scan",
      "gaussian splatting",
      "3d reconstruction",
      "computer vision"
    ],
    "gold_summary": "This paper proposed a hierarchical approach to 3D gaussian splatting for sparse-view CT reconstruction, first introducing large-scale Gaussians, and then refining in later steps. Refinement choices are based on reconstruction of the residual error."
  },
  {
    "paper_id": "TB0Pdvxpm8",
    "title": "BioTamperNet: Affinity-Guided State-Space Model Detecting Tampered Biomedical Images",
    "domain": "self-supervised",
    "content": "We propose BioTamperNet, a novel framework for detecting duplicated regions in tampered biomedical images, leveraging affinity-guided attention inspired by State Space Model (SSM) approximations. Existing forensic models, primarily trained on natural images, often underperform on biomedical data where subtle manipulations can compromise experimental validity. To address this, BioTamperNet introduces an affinity-guided self-attention module to capture intra-image similarities and an affinity-guided cross-attention module to model cross-image correspondences. Our design integrates lightweight SSM-inspired linear attention mechanisms to enable efficient, fine-grained localization. Trained end-to-end, BioTamperNet simultaneously identifies tampered regions and their source counterparts. Extensive experiments on the benchmark bio-forensic datasets demonstrate significant improvements over competitive baselines in accurately detecting duplicated regions. All source code and dataset will be publicly available.",
    "key_points": [
      "generative local forgery detection",
      "information-theoretic gradient fingerprints"
    ],
    "gold_summary": "This article provides an original and empirically validated method for biomedical image tampering detection. But its clarity, interpretability, and wider comparability need to be further improved to enhance its readability and credibility."
  },
  {
    "paper_id": "zj9Mm4bCAo",
    "title": "HieraTok: Multi-Scale Visual Tokenizer Improves Image Reconstruction and Generation",
    "domain": "self-supervised",
    "content": "In this work, we present HieraTok, a novel multi-scale Vision Transformer (ViT)-based tokenizer that overcomes the inherent limitation of modeling single-scale representations. This is realized through two key designs: (1) multi-scale downsampling applied to the token map generated by the tokenizer encoder, producing a sequence of multi-scale tokens, and (2) a scale-causal attention mechanism that enables the progressive flow of information from low-resolution global semantic features to high-resolution structural details. Coupling these designs, HieraTok achieves significant improvements in both image reconstruction and generation tasks. Under identical settings, the multi-scale visual tokenizer outperforms its single-scale counterpart by a 27.2\\% improvement in rFID ($1.47 \\rightarrow 1.07$). When integrated into downstream generation frameworks, it achieves a $1.38\\times$ faster convergence rate and an 18.9\\% boost in gFID ($16.4 \\rightarrow 13.3$), which may be attributed to the smoother and more uniformly distributed latent space. To the best of our knowledge, we are the first to introduce multi-scale ViT-based tokenizer in image reconstruction and image generation. We hope our findings and designs advance the ViT-based tokenizers in visual generation tasks.",
    "key_points": [
      "visual tokenizer",
      "multi-scale design",
      "latent representation"
    ],
    "gold_summary": "This paper presents HieraTok, a novel multi-scale Vision Transformer tokenizer, and conducts experiments demonstrating that the hierarchical tokenizer indeed improves model performance."
  },
  {
    "paper_id": "SF8NYACPfb",
    "title": "Learning Convolutional Representations via Generalized Stein’s Method: A Training-Free Approach",
    "domain": "self-supervised",
    "content": "Convolutional Neural Networks (CNNs) have revolutionized computer vision, with the convolution operation serving as a cornerstone that enables the extraction of abstract features and the discovery of hidden structures in image data. However, CNNs training typically relies on gradient descent, which can be computationally expensive and unstable, particularly in high-dimensional, small-sample settings such as medical imaging analysis. This paper presents an efficient statistical approach to learn convolutional representations without training a CNN. We reformulate CNNs into a general index model with matrix-valued inputs, interpreting convolution filters as index vectors while absorbing subsequent layers into the link function. Through a generalized version of the first-order Stein's formula, we develop a novel singular value decomposition (SVD) based approach to estimate the convolution filters directly. Theoretical analysis suggests that our estimation achieves an optimal convergence rate, comparable to that of generalized linear models where the link function is known. Extensive simulations and medical imaging experiments demonstrate the effectiveness of our approach, providing a viable pathway for representation learning.",
    "key_points": [
      "representation learning",
      "convolutional neural networks",
      "multi-index model",
      "score function",
      "singular value decomposition"
    ],
    "gold_summary": "The authors introduce a new algorithm for learning convolutional layer parameters outside of gradient descent, based on SVD and Stein's method. They evaluate it on simulation experiments and on Alzheimer's disease prediction from brain MRI."
  },
  {
    "paper_id": "5JwUWsewWH",
    "title": "PRISM: Progressive Robust Learning for Open-World Continual Category Discovery",
    "domain": "semi-supervised",
    "content": "Continual Category Discovery (CCD) aims to leverage models trained on known categories to automatically discover novel category concepts from continuously arriving streams of unlabeled data, while retaining the ability to recognize previously known classes. Despite recent progress, existing methods often assume that data across all stages are drawn from a single, stationary distribution—a condition rarely satisfied in open-world scenarios. In this paper, we challenge this stationary-distribution assumption by introducing the Open-World Continual Category Discovery (OW-CCD) setting. We address this challenge with PRISM (\\underline{P}rogressive \\underline{R}obust d\\underline{I}scovery under \\underline{S}trea\\underline{M}ing data), an adaptive continual discovery framework consisting of three key components. First, inspired by spectral properties, we develop a high-frequency-driven category separation technique that exploits high-frequency components—preserving more global information—to distinguish known from unknown categories. Second, for known categories, we design a sparse assignment matching strategy, which performs proximal sparse sample-to-label matching to assign reliable cluster labels to known-class samples. Finally, to better recognize novel categories, we propose an invariant knowledge transfer module that enforces domain-invariant category relation consistency, thereby facilitating robust knowledge transfer from known to unknown classes under domain shifts. Extensive experiments on the SSB-C and DomainNet benchmarks demonstrate that our method significantly outperforms state-of-the-art CCD approaches, highlighting its effectiveness and superiority.",
    "key_points": [
      "continual category discovery",
      "generalized category discovery",
      "domain shift"
    ],
    "gold_summary": "This paper introduces a new category discovery task: Open-World Continual Category Discovery (OW-CCD), which challenges the single-domain data assumption in the previous CCD task."
  },
  {
    "paper_id": "8Bs3mz49Gp",
    "title": "Lighter is Better: Boost Your ViT in Person Re-Identification via Spatial-Aware Token Merging",
    "domain": "semi-supervised",
    "content": "Vision Transformers (ViTs) have significantly advanced person re-identification (ReID) by providing strong global modeling, but their high computational cost hinders deployment in real-time applications. Existing lightweight ReID methods mostly use token pruning, which can discard discriminative contextual information. Token merging is a moderate alternative, yet existing merging methods target image classification and overlook the local cues that ReID requires. This paper proposes STM-ReID, a spatial-aware and training-free token merging framework tailored for ViT-based lightweight ReID. STM-ReID injects information-enhanced spatial awareness into token assessment and uses the resulting scores to guide token matching and fusion, preserving identity-relevant local details while reducing computation. The framework comprises three key components: (i) DSE-Assess, a dynamic spatial-aware entropy weighting for token importance; (ii) CCF-Match, a correlation-guided matching scheme for precise pair selection; (iii) PNR-Fuse, a position response-driven computation strategy for feature aggregation. Extensive experiments on standard ReID benchmarks and general classification datasets show that STM-ReID cuts GFLOPs of the base ViT model by about 24\\% while keeping accuracy comparable to state-of-the-art methods, yielding a superior accuracy–efficiency trade-off.",
    "key_points": [
      "person re-identification",
      "vision transformer",
      "token merging",
      "lightweight"
    ],
    "gold_summary": "This paper proposes STM-ReID, a lightweight pedestrian re-identification (ReID) method based on Vision Transformer (ViT), which employs a token merging strategy to reduce computational overhead."
  },
  {
    "paper_id": "D4CH3hCNdb",
    "title": "Flow-Guided Neural Operator For Self- Supervised Learning On Time Series Data",
    "domain": "semi-supervised",
    "content": "Self-supervised learning (SSL) is a powerful paradigm for learning from unlabeled time-series data. However, popular methods such as masked autoencoders (MAEs) rely on reconstructing inputs from a fixed, predetermined masking ratio. \nInstead of this static design, we propose treating the corruption level as a new degree of freedom for representation learning, enhancing flexibility and performance.\nTo achieve this, we introduce the Flow-Guided Neural Operator (FGNO), a novel framework combining operator learning with flow matching for SSL training.\nBy leveraging Short-Time Fourier Transform (STFT) to enable computation under different time resolutions, our approach effectively learns mappings in functional spaces.\nWe extract a rich hierarchy of features by tapping into different network layers ($l$) and flow times ($s$) that apply varying strengths of noise to the input data. \nThis enables the extraction of versatile representations, from low-level patterns to high-level semantics, using a single model adaptable to specific tasks.\nUnlike prior generative SSL methods that use noisy inputs during inference, we propose using clean inputs for representation extraction while learning representations with noise; this eliminates randomness and boosts accuracy.\nWe evaluate FGNO across three biomedical domains, where it consistently outperforms established baselines. Our method yields up to 35\\% AUROC gains in neural signal decoding (BrainTreeBank), 16\\% RMSE reductions in skin temperature prediction (DREAMT), and over 20\\% improvement in accuracy and macro-F1 on SleepEDF under low-data regimes. These results highlight FGNO’s robustness to data scarcity and its superior capacity to learn expressive representations for diverse time-series applications.",
    "key_points": [
      "flow matching",
      "self-supervised learning",
      "time series data",
      "short time fourier transform",
      "neural operator"
    ],
    "gold_summary": "The paper presents a self-supervised method for time-series data based on flow-matching pre-training and short-term Fourier transform (STFT). The method is evaluated on multiple tasks on medical data, with good results at low-label settings."
  },
  {
    "paper_id": "DcHGEcqdFf",
    "title": "Disentanglement of Variations with Multimodal Generative Modeling",
    "domain": "semi-supervised",
    "content": "Multimodal data are prevalent across various domains, and learning robust representations of such data is paramount to enhancing generation quality and downstream task performance. To handle heterogeneity and interconnections among different modalities, recent multimodal generative models extract shared and private (modality-specific) information with two separate variables. Despite attempts to enforce disentanglement between these two variables, these methods struggle with challenging datasets where the likelihood model is insufficient. In this paper, we propose Information-disentangled Multimodal VAE (IDMVAE) to explicitly address this issue, with rigorous mutual information-based regularizations, including cross-view mutual information maximization for extracting shared variables, and a cycle-consistency style loss for redundancy removal using generative augmentations. We further introduce diffusion models to improve the capacity of latent priors. These newly proposed components are complementary to each other. Compared to existing approaches, IDMVAE shows a clean separation between shared and private information, demonstrating superior generation quality and semantic coherence on challenging datasets.",
    "key_points": [
      "multimodal variational autoencoder",
      "disentanglement",
      "multi-view information bottleneck",
      "diffusion models"
    ],
    "gold_summary": "This paper introduces Information-Disentangled Multimodal VAE (IDMVAE), a new multimodal generative framework designed to improve disentanglement between shared and modality-specific representations."
  },
  {
    "paper_id": "koKWoKaMrE",
    "title": "Tversky Neural Networks: Psychologically Plausible Deep Learning with   Differentiable Tversky Similarity",
    "domain": "semi-supervised",
    "content": "Work in psychology has highlighted that the geometric model of similarity standard in deep learning is not psychologically plausible because its metric properties such as symmetry do not align with human perception of similarity.\n    In contrast, (Tversky,1977) proposed an axiomatic theory of similarity with psychological plausibility based on a representation of objects as sets of features, and their similarity as a function of their common and distinctive features.\n    This model of similarity has not been used in deep learning before, in part because of the challenge of incorporating discrete set operations. \n    In this paper, we develop a differentiable parameterization of Tversky's similarity that is learnable through gradient descent, and derive basic neural network building blocks such as the \\emph{Tversky projection layer}, which unlike the linear projection layer can model non-linear functions such as  {\\sc xor}.\n    Through experiments with image recognition and language modeling neural networks, we show that the Tversky projection layer is a beneficial replacement for the linear projection layer.    For instance, on the NABirds image classification task, a frozen ResNet-50 adapted with a Tversky projection layer achieves a 24.7\\% relative accuracy improvement over the linear layer adapter baseline.\n    With Tversky projection layers, GPT-2's perplexity on PTB decreases by 7.8\\%, and its parameter count by 34.8\\%.\n    Finally, we propose a unified interpretation of both types of projection layers as computing similarities of input stimuli to learned prototypes for which we also propose a novel visualization technique highlighting the interpretability of Tversky projection layers. Our work offers a new paradigm for thinking about the similarity model implicit in modern deep learning, and designing neural networks that are interpretable under an established theory of psychological similarity.",
    "key_points": [
      "machine learning",
      "psychology",
      "neural networks"
    ],
    "gold_summary": "The authors propose how to use Tversky similarity (from cognitive psychology) instead of the geometric model of similarity, which is usually used in deep learning. They perform experiments on text and image domains."
  },
  {
    "paper_id": "JKAe94hv25",
    "title": "PRISM: Pareto-Responsive Iterative Sampling with DPO for Multi-objective Planning",
    "domain": "semi-supervised",
    "content": "Many planning-style applications of large language models are inherently multi-objective. Beyond correctness, users care about efficiency and the avoidance of irrelevant or unsafe actions. Yet most alignment pipelines optimize a single scalar reward, which hides trade-offs and offers little control when secondary objectives have uncertain or deployment-specific weights. We present PRISM, a Pareto responsive framework that integrates Direct Preference Optimization. PRISM adds three components designed for offline, several convergence toward balanced solutions. First, it uses golden comparisons that isolate per-objective preferences. Second, it computes attention-style weights from deficiency diagnostics that combine loss and gradient information. Third, it applies Pareto guided sampling that orients preference pairs by cosine alignment with the current weight direction.This loop performs common-descent updates for a vector of objective deficiencies and stops at a certificate of first-order Pareto stationarity. It removes the need for online reinforcement learning, reward sweeps, or families of specialist models. On six benchmarks in question answering, coding, and mathematical reasoning, PRISM improves accuracy over strong baselines while simultaneously reducing latency and step count and driving off-domain actions to near zero. PRISM provides a principled and compute efficient recipe for robust multi-objective alignment of LLM-based planners.",
    "key_points": [
      "dpo",
      "multi-objective optimization",
      "planner"
    ],
    "gold_summary": "This paper presents a framework named PRISM, a preference fine-tuning framework that jointly improves accuracy, efficiency, and error avoidance. It also introduces deficiency-aware weighting and Pareto Pareto-guided sampling mechanism."
  },
  {
    "paper_id": "pbMzwCnGpq",
    "title": "Gestalt Generalized Category Discovery",
    "domain": "semi-supervised",
    "content": "Human cognitive science discovers new categories by first grouping percepts under simple organizing principles and only then abstracting them into concepts. Generalized category discovery (GCD) seeks the same ability, yet most pipelines still map discrete tokens directly to category decisions, concentrating on objectives or prototypes while overlooking the relational organization that precedes induction. We present GesGCD, a cognition-inspired paradigm that progressively aligns GCD with human discovery. First, we insert a compact Hyper-Relation Construction stage between the backbone and the classifier so that tokens are organized as groups rather than isolated atoms, enabling evidence to be pooled before any category decision. Second, we inject Gestalt Psychology Calibration by synthesizing memberships that favor proximity, similarity, and continuity, bringing human-like perceptual grouping into the relational stage without extra supervision. These two steps form a simple perception-to-induction bridge that is orthogonal to prevailing objectives and prototype designs, and that preserves efficiency and reproducibility. Across fine-grained and coarse-grained benchmarks, GesGCD improves all-class metrics while offering intuitive visual evidence and more informative representations. We view GesGCD as a step toward closing the structural gap between machine pipelines and human discovery in open worlds.",
    "key_points": [
      "generalized category discovery",
      "cognitive science",
      "open-world learning"
    ],
    "gold_summary": "This paper proposes GesGCD, a GCD framework inspired by cognitive science that inserts a hyper-relation construction stage between backbone and classifier to group tokens before category decisions."
  },
  {
    "paper_id": "zfruJR2oxw",
    "title": "CLPO: Curriculum Learning meets Policy Optimization for LLM Reasoning",
    "domain": "semi-supervised",
    "content": "Recently, online Reinforcement Learning with Verifiable Rewards (RLVR) has become a key paradigm for enhancing the reasoning capabilities of Large Language Models (LLMs). However, existing methods typically treat all training samples uniformly, overlook the vast differences in problem difficulty relative to the model's current capabilities. This uniform training strategy leads to inefficient exploration of problems the model has already mastered, while lacking effective guidance on the problems that are challenging its abilities the most, limiting both learning efficiency and the performance upper-bound. To address this, we propose \\textbf{CLPO (Curriculum-guided Learning for Policy Optimization)}, a novel algorithm that creates a dynamic pedagogical feedback loop within the policy optimization process. The core of CLPO is to leverage the model's own rollout performance to conduct real-time difficulty assessment, thereby constructing an \\textbf{Online Curriculum}. This curriculum then guides an \\textbf{Adaptive Problem Restructuring} mechanism, where the model acts as its own teacher: it diversifies medium-difficulty problems to promote generalization and simplifies hard problems to make them more accessible. Our approach transforms the static training procedure into a dynamic process that co-evolves with the model's capabilities. Experiments show that CLPO achieves \\textbf{state-of-the-art (SOTA)} performance across eight challenging mathematical and general reasoning benchmarks, with an average \\textbf{pass@1} improvement of \\textbf{6.96\\%} over ohter methods, demonstrating its potential for more efficiently training more capable reasoning models.",
    "key_points": [
      "large language models; llm reasoning;curriculum learning"
    ],
    "gold_summary": "CLPO (Curriculum-guided Learning for Policy Optimization) is proposed to create a dynamic pedagogical feedback loop within the policy optimization process."
  },
  {
    "paper_id": "Y4xzgpLrWc",
    "title": "Online-Optimized RAG for Tool Use and Function Calling",
    "domain": "semi-supervised",
    "content": "In many applications, retrieval-augmented generation (RAG) drives tool use and function calling by embedding the (user) queries and matching them to pre-specified tool/function descriptions. In this paper, we address an embedding misalignment issue that often arises in practical applications due to imperfect embedding models or noisy descriptions; such misalignment may lead to incorrect retrieval and task failure. We introduce Online-Optimized RAG, a deployment-time framework that continually adapts retrieval embeddings from live interactions using minimal feedback (e.g., task success). Online-Optimized RAG applies lightweight online gradient updates with negligible per-query latency and requires no changes to the underlying LLM. The method is plug-and-play: it supports both single- and multi-hop tool use, dynamic tool inventories, and $K$-retrieval with re-ranking. We provide a problem-dependent theoretical analysis that quantifies how the method's performance depends on the initialization quality of the embeddings and other related quantities. Across diverse tool-use and document-retrieval scenarios, our Online-Optimized RAG consistently improves tool selection accuracy and end-task success, thus providing a simple, practical path to robust, self-improving RAG systems.",
    "key_points": [
      "retrieval augmented generation",
      "tool use",
      "agentic ai",
      "online optimization"
    ],
    "gold_summary": "This paper proposes an online learning framework that updates retrieval embeddings during deployment to improve tool selection in RAG."
  },
  {
    "paper_id": "nraPBoEJfU",
    "title": "LoRA-Ensemble: Efficient Uncertainty Modelling for Self-Attention Networks",
    "domain": "semi-supervised",
    "content": "Numerous real-world decisions rely on machine learning algorithms and require calibrated uncertainty estimates. However, modern methods often yield overconfident, uncalibrated predictions. The dominant approach to quantifying the uncertainty inherent in the model is to train an ensemble of separate predictors and measure their empirical variance. In an explicit implementation the ensemble has high computational cost and memory footprint, especially if the base model itself is already large, like modern transformers. This motivates efforts to develop implicit ensemble methods that emulate the ensemble without explicitly instantiating all its members. We introduce LoRA-Ensemble, a parameter-efficient ensembling method for self-attention networks. It is based on Low-Rank Adaptation (LoRA), originally developed for efficient LLM fine-tuning, and extends it into an implicit ensembling scheme, where all ensemble members share the same, pre-trained self-attention network, but have individual low-rank matrices for the attention projections. The resulting method not only outperforms state-of-the-art implicit techniques like BatchEnsemble, but even matches or exceeds the accuracy of an Explicit Ensemble, while at the same time achieving superior calibration.",
    "key_points": [
      "uncertainty",
      "ensemble",
      "implicit ensemble",
      "calibration",
      "self-attention",
      "transformer"
    ],
    "gold_summary": "The paper presents a lora-driven ensemble to generate uncertainty estimates for a large LLM model."
  },
  {
    "paper_id": "9IzfArmoHq",
    "title": "Unlearning Evaluation through Subset Statistical Independence",
    "domain": "semi-supervised",
    "content": "Evaluating machine unlearning remains challenging, as existing methods typically require retraining reference models or performing membership inference attacks—both rely on prior access to training configuration or supervision label, making them impractical in realistic scenarios. Motivated by the fact that most unlearning algorithms remove a small, random subset of the training data, we propose a subset-level evaluation framework based on statistical independence. Specifically, we design a tailored use of the Hilbert–Schmidt Independence Criterion to assess whether the model outputs on a given subset exhibit statistical dependence, without requiring model retraining or auxiliary classifiers. Our method provides a simple, standalone evaluation procedure that aligns with unlearning workflows. Extensive experiments demonstrate that our approach reliably distinguishes in-training from out-of-training subsets and clearly differentiates unlearning effectiveness, even when existing evaluations fall short.",
    "key_points": [
      "machine unlearning"
    ],
    "gold_summary": "This paper proposes to use Hilbert–Schmidt Independence Criterion to evaluate the effectiveness of unlearning methods. This novel, statistic-based method facilitates evaluation without a retrained reference model or shadow models."
  },
  {
    "paper_id": "H0bcEdPCoc",
    "title": "Let's (not) just put things in Context: Test-time Training for Long-context LLMs",
    "domain": "semi-supervised",
    "content": "Advances in training and architectural design have enabled LLMs with million-token context windows, yet in practice these models often read far more than they can reliably use. While inference-time compute scaling—typically via “thinking tokens”—can help on short multi-step reasoning tasks, our controlled long-context experiments show rapidly diminishing returns that collapse as context grows. We trace this to score dilution in static self-attention and prove that, in such regimes, decoding more tokens cannot reliably recover buried evidence. We propose query-only test-time training (qTTT): a cache-preserving adaptation that performs a single prefill to fix keys/values and then applies a handful of gradient updates to the query projections. qTTT provably increases the target–distractor margin and, empirically, delivers consistent gains across model sizes and benchmarks. On Qwen3-4B, qTTT improves average accuracy by +12.6 and +14.1 absolute points on LongBench-v2 and ZeroSCROLLS, respectively. The practical takeaway is simple: for long contexts, spending a small inference-time budget on context-specific adaptation is a more effective use of compute than generating additional thinking tokens.",
    "key_points": [
      "long-context language models",
      "test-time training",
      "inference-time scaling"
    ],
    "gold_summary": "The author proposes a test-time learning method for long context handling with ICL examples."
  },
  {
    "paper_id": "eR7E4LMPtR",
    "title": "Beyond Greedy: Towards Optimal Deep Classification Trees",
    "domain": "semi-supervised",
    "content": "Decision trees are central to interpretable machine learning but face severe scalability challenges. Existing global optimal methods are limited by binary feature selection and shallow tree depths, while traditional heuristic approaches often sacrifice accuracy. To overcome these limitations, this paper introduces a moving-horizon approximate branch-and-reduce method for constructing near-optimal deep classification trees on large-scale datasets with continuous features. This method is based on a bilevel optimization framework, where the upper-level problem is addressed using a branch-and-reduce method, while the lower-level problem is solved recursively. Although the underlying framework guarantees global optimality, we enhance its efficiency for deeper trees by introducing an approximate solution for the lower-level problem, which can be viewed as a lookahead rollout in reinforcement learning. The accuracy is further refined using a low-cost moving-horizon strategy. Extensive experiments demonstrate that the proposed method consistently outperforms existing heuristic baselines in testing accuracy, while maintaining scalability on large datasets compared to global optimal methods.",
    "key_points": [
      "decision tree.+cart.+optimal classification trees"
    ],
    "gold_summary": "This paper developed a hybrid approach to learning decision trees that attempts to bridge the gap between fast, greedy heuristics (like CART) and computationally intractable optimal methods (like MIP or full dynamic programming)."
  },
  {
    "paper_id": "SbahKA6FTf",
    "title": "HybridSB-MoE: Dual-Domain Schrödinger Bridges with Scene-Adaptive Expert Routing for Speech Enhancement",
    "domain": "semi-supervised",
    "content": "Single-domain generative speech enhancement methods fail to exploit complementary acoustic representations. Despite recent advances in Schr\\\"{o}dinger Bridge (SB) formulations, existing approaches remain constrained by homogeneous architectures and prohibitively high sampling costs. We propose \\textbf{HybridSB-MoE}, a framework that integrates SB with a heterogeneous mixture-of-experts (MoE) for parallel dual-domain processing. Our framework uniquely combines temporal coherence modeling via enhanced SB in the waveform domain with scene-adaptive spectral processing through five architecturally distinct experts (Home, Nature, Office, Transport, Public), automatically selected via sparse Top-$k$ routing without scene labels. By implementing trajectory regularization that incorporates optimal transport and path consistency, we reduce the required number of sampling steps from 40-50 to just 8, while maintaining quality. An uncertainty-aware fusion unifies these complementary representations using calibrated weights derived from epistemic (MoE) and aleatoric (SB) uncertainties. On the VoiceBank+DEMAND dataset, HybridSB-MoE achieves PESQ $3.88\\pm0.25$ and STOI $0.96$, surpassing methods that require $5\\times$ more sampling steps. Ablation studies confirm the necessity of each component, with the PESQ dropping to 3.45 without SB and 3.25 without MoE.",
    "key_points": [
      "speech enhancement",
      "schrödinger bridge",
      "mixture-of-experts",
      "dual-domain processing"
    ],
    "gold_summary": "This work proposes HybridSB-MoE, a dual-domain speech enhancement framework that integrates Schrödinger Bridge modeling with a heterogeneous Mixture-of-Experts for scene-adaptive processing. It reduces sampling steps from 40–50 to 8 while improving performance on VoiceBank+DEMAND."
  },
  {
    "paper_id": "e8bWf8old1",
    "title": "Topological Alignment: A Universal Framework for Anomaly Detection",
    "domain": "semi-supervised",
    "content": "Zero-Shot Anomaly Detection (ZS-AD) methods based on Vision-Language Models face a critical vulnerability: a paradoxical performance collapse when trained on large-scale, diverse data. We identify this phenomenon as {Negative Transfer in Domain Generalization (NTDG)} and diagnose its root cause as a {Domain Conflict}: a fundamental structural incompatibility where a single, rigid geometric decision boundary fails to separate topologically complex data manifolds from multiple domains. To escape this trap, we propose a paradigm shift from geometric separation to robust topological separability, actualized in our {TDA-CLIP} framework. The framework introduces two general-purpose, plug-and-play topological tools: (1) a macro-level {Homology Consistency Loss ($\\mathcal{L}_{\\text{HC}}$)} that acts as a structural regularizer to enforce a globally consistent feature space, and (2) a micro-level {Topology-Guided Attention (TGA)} module that purifies features by amplifying salient local evidence. Crucially, these topological components are active only during training and are completely pruned at inference time, delivering substantial performance gains while introducing absolutely no extra cost at inference. Extensive experiments demonstrate that our framework is the first to overcome this negative transfer, consistently benefiting from large-scale Domain Generalization where all baselines fail. TDA-CLIP not only establishes a new state-of-the-art across 11 industrial and medical benchmarks but also proves its generalizability by enhancing existing SOTA methods, offering a validated and principled pathway toward building truly universal anomaly detection models.",
    "key_points": [
      "anomaly detection",
      "robustness",
      "topology",
      "zero-shot"
    ],
    "gold_summary": "This paper tackles an important and recognized problem in ZS-AD: the severe performance collapse (termed Negative Transfer in Domain Generalization), where SOTA models like AnomalyCLIP and AA-CLIP suffer when trained on large-scale, diverse data."
  },
  {
    "paper_id": "hZENSn2miK",
    "title": "Optimizing What Matters: AUC-Driven Learning for Robust Neural Retrieval",
    "domain": "semi-supervised",
    "content": "Dual‑encoder retrievers depend on the principle that relevant documents should score higher than irrelevant ones for a given query. Yet the dominant Noise Contrastive Estimation (NCE) objective, which underpins Contrastive Loss, optimizes a softened ranking surrogate that we rigorously prove is fundamentally oblivious to score separation quality and unrelated to AUC. This mismatch leads to poor calibration and suboptimal performance in downstream tasks like retrieval‑augmented generation (RAG). To address this fundamental limitation, we introduce the MW loss, a new training objective that maximizes the Mann‑Whitney U statistic, which is mathematically equivalent to the Area under the ROC Curve (AUC). MW loss encourages each positive-negative pair to be correctly ranked by minimizing binary cross entropy over score differences.  We provide theoretical guarantees that MW loss directly upper-bounds the AoC, better aligning optimization with retrieval goals. We further promote ROC curves and AUC as natural threshold‑free diagnostics for evaluating retriever calibration and ranking quality. Empirically, retrievers trained with MW loss consistently outperform contrastive counterparts in AUC and standard retrieval metrics. Our experiments show that MW loss is an empirically superior alternative to Contrastive Loss, yielding better-calibrated and more discriminative retrievers for high-stakes applications like RAG.",
    "key_points": [
      "dense retrieval",
      "auc",
      "mann-whitney",
      "rag"
    ],
    "gold_summary": "It introduces a Mann–Whitney (MW) loss and proves an upper bound on the Area-over-ROC, so minimizing MW encourages higher AUC"
  },
  {
    "paper_id": "JQR8OCptcG",
    "title": "Improving Set Function Approximation with Quasi-Arithmetic Neural Networks",
    "domain": "semi-supervised",
    "content": "Sets represent a fundamental abstraction across many types of data. To handle the unordered nature of set-structured data, models such as DeepSets and PointNet rely on fixed, non-learnable pooling operations (e.g., sum or max) -- a design choice that can hinder the transferability of learned embeddings and limits model expressivity. In this work, we break from this paradigm by introducing the Neuralized Kolmogorov Mean (NKM) -- a novel, trainable framework for learning a generalized measure of central tendency through an invertible neural function. We further propose quasi-arithmetic neural networks (QUANNs), which incorporate the NKM as a learnable aggregation function. We provide a theoretical analysis showing that, QUANNs are universal approximators for a broad class of common set-function decompositions and, thanks to their invertible neural components, learn more structured latent representations. Empirically, QUANNs outperform state-of-the-art baselines across diverse benchmarks, while learning embeddings that transfer effectively even to tasks that do not involve sets.",
    "key_points": [
      "representation learning",
      "set function learning"
    ],
    "gold_summary": "The paper presents QUANNs, a learnable aggregation function, for (deep) set models. The learned aggregation is favorable over fixed aggregators in terms of performance."
  },
  {
    "paper_id": "CSUqM5uNCC",
    "title": "Structuring Semantic Embeddings for Principle Evaluation: A Kernel-Guided Contrastive Learning Approach",
    "domain": "semi-supervised",
    "content": "Evaluating principle adherence in high-dimensional text embeddings is challenging because principle-specific signals are often entangled with general semantic content. Our kernel-guided contrastive learning framework learns to disentangle these signals by projecting embeddings into a structured subspace. In this space, each principle is centered on a learnable **prototype kernel**---an optimized vector that embodies its core meaning---while a jointly learned **semantic basis** preserves context. A novel **offset penalty**, a loss term designed to create structure, then enforces a margin around each prototype. This ensures that even semantically similar principles are clearly separated while capturing their inherent contextual variability. Experiments show our optimized embeddings significantly improve performance on principle classification and ordinal regression, outperforming few-shot Large Language Models and demonstrating the value of specialized representations for reliable principle evaluation.",
    "key_points": [
      "contrastive learning",
      "semantic embeddings",
      "principle alignment",
      "structured representation",
      "prototype learning"
    ],
    "gold_summary": "This paper introduces a kernel-guided contrastive learning framework that uses learnable prototype kernels and a novel offset penalty to restructure fixed embeddings, forcing disentanglement of principle-specific features for post-hoc evaluation"
  },
  {
    "paper_id": "ivaIwRZvTT",
    "title": "Disentangled Pseudo-Labeling and Classification for Class-Imbalanced Semi-Supervised Learning",
    "domain": "semi-supervised",
    "content": "Although significant improvements have been made in addressing class-imbalanced semi-supervised learning (CISSL), many algorithms still suffer from confirmation bias. Inaccurate pseudo-labels hinder the learning of the classifier, which in turn leads to further inaccurate pseudo-labels—creating a self-reinforcing loop that amplifies bias, particularly toward majority classes. This bias arises because the classifier that generates pseudo-labels is simultaneously trained on the unlabeled data it labels. To address this issue, we propose a novel CISSL algorithm, Disentangled Pseudo-Labeling and Classification (DPC). DPC introduces an auxiliary classifier, dedicated solely to generating pseudo-labels, called a pseudo-labeler, which is attached to the representation layer of the backbone semi-supervised learning algorithm. To prevent confirmation bias, the pseudo-labeler is trained exclusively on labeled data, ensuring that pseudo-label generation remains unaffected by noisy unlabeled samples. Furthermore, to mitigate imbalanced feature representations—which are often biased toward majority classes and exacerbate confirmation bias—DPC propagates the classifier’s training loss to the shared representation layer to encourage balanced feature learning. Benefiting from high-quality pseudo-labels and balanced feature representations, DPC achieves state-of-the-art classification performance on CISSL benchmark datasets.",
    "key_points": [
      "class-imbalanced semi-supervised learning",
      "pseudo-labeling"
    ],
    "gold_summary": "This paper introduces Disentangled Pseudo-Labeling and Classification (DPC) for class-imbalanced semi-supervised learning. DPC separates pseudo-label generation from classifier training to reduce confirmation bias and employs reweighted and feature-level losses to handle imbalance."
  },
  {
    "paper_id": "sSJLsphFyC",
    "title": "Maximum Variance Unfolding on Disjoint Manifolds",
    "domain": "semi-supervised",
    "content": "An assumption underlying much of machine learning is that observed data are often sampled from a manifold of much lower dimension than the data space itself. While linear methods such as PCA can often be used to perform dimensionality reduction, they fail to capture nonlinear relationships in the data, which are often present in natural datasets. Maximum variance unfolding is an established and well-studied neighborhood graph-based method for nonlinear dimensionality reduction with the unique property of retaining exact local isometry. However, its applicability on real-world data is limited due to its dependence on the connectivity of the underlying neighborhood graph: in natural datasets, data are often multimodal and lie on disjoint manifolds, giving rise to clusters of points that are distant in the data space. In this work, we present a method that extends maximum variance unfolding to the common case where data lie on disjoint manifolds. We show that it decreases both computation time and memory requirements, and that it improves performance in standard metrics that assess the extent to which the local structure of the data is preserved.",
    "key_points": [
      "nonlinear dimensionality reduction; maximum variance unfolding; neighborhood graph; disjoint manifolds; manifold learning"
    ],
    "gold_summary": "This paper proposes Maximum Variance Unfolding on Disjoint Manifolds (MVU-DM), an extension of the classic nonlinear dimensionality reduction method Maximum Variance Unfolding (MVU), specifically designed to handle data that lies on disconnected manifolds."
  },
  {
    "paper_id": "uRA9cT4MK6",
    "title": "Relationship Alignment for View-aware Multi-view Clustering",
    "domain": "semi-supervised",
    "content": "Multi-view clustering improves clustering performance by integrating complementary information from multiple views. However, existing methods often suffer from two limitations: i) the neglect of preserving sample neighborhood structures, which weakens the consistency of inter-sample relationships across views; and ii) inability to adaptively utilize inter-view similarity, resulting in representation conflicts and semantic degradation. To address these issues, we propose a novel framework named Relationship Alignment for View-aware Multi-view Clustering (RAV). Our approach first constructs a sample relation matrix for each view using deep features and aligns it with a global relation matrix to enhance neighborhood consistency across views. Furthermore, we introduce a view-aware adaptive weighting mechanism for label contrastive learning. This mechanism dynamically adjusts the contrastive intensity between view pairs based on the similarity of their deep features: higher similarity leads to stronger label alignment, while lower similarity reduces the weighting to prevent forcing inconsistent views into agreement. This strategy effectively promotes cluster-level semantic consistency while preserving natural inter-view relationships. Extensive experiments demonstrate that our method consistently outperforms state-of-the-art approaches on multiple benchmark datasets.",
    "key_points": [
      "relationship alignment; view-aware contrastive learning; multi-view clustering"
    ],
    "gold_summary": "The approach is well-motivated, combining relation alignment with view similarity measurement to offer a novel perspective for addressing semantic degradation caused by view discrepancies in multi-view clustering."
  },
  {
    "paper_id": "mm0ghNJIXo",
    "title": "Kernel Complexity Reduced Graph Contrastive Learning for Noisy Node Classification",
    "domain": "semi-supervised",
    "content": "Graph Neural Networks (GNNs) have achieved remarkable success in learning node representations and have demonstrated strong performance on node classification. However, their effectiveness can be substantially compromised by noise in real-world graph data. To address this challenge, we propose Kernel Complexity Reduced Graph Contrastive Learning (KCR-GCL), a principled framework for noisy node classification with a provable transductive generalization guarantee. KCR-GCL introduces a novel KCR-GCL encoder, which incorporates a new KCR self-attention layer that adaptively balances different frequency components of the graph inspired by generalized graph convolution and reduces the kernel complexity for provably improved generalization for transductive learning. The KCR-GCL encoder is optimized with a low-rank regularization term through the truncated nuclear norm (TNN) on the gram matrix of the learned features. The learned low-rank representations are then used to train a linear  classifier for transductive node classification in noisy graph data.\nThe design of KCR-GCL is inspired by the Low Frequency Property (LFP)  widely studied in general deep learning and node-level graph learning, and is further supported by a sharp generalization bound for transductive learning. To the best of our knowledge, KCR-GCL is among the first to theoretically reveal the benefits of low-rank regularization in transductive settings for noisy graph data. Experiments on standard benchmarks highlight the effectiveness and robustness of KCR-GCL in learning node representations under noisy conditions.\nThe code of KCR-GCL is available at \\url{https://anonymous.4open.science/status/KCR-GCL}.",
    "key_points": [
      "kernel complexity reduced graph contrastive learning",
      "generalization bound",
      "noisy node classification"
    ],
    "gold_summary": "This paper introduces KCR-GCL, which learns robust node representations and tackles noisy node classification. Experiments on various benchmarks highlight the effectiveness and robustness in learning node representations under noisy conditions."
  },
  {
    "paper_id": "azBKlwMKIa",
    "title": "Supermodel: Rethinking DNN Training and Testing with Open-style Skill Acquisition and Dynamic Inference",
    "domain": "semi-supervised",
    "content": "Current DNN model building suffers from two serious problems: forgetting and doomed test cases. In this paper, we propose an open-style skill acquisition approach, which is the opposite of a currently closed-style training scheme with recent features/patterns often overwriting previous ones to minimize the overall loss in backpropagation (the forgetting problem). Testing is also drastically different and is conducted as optimally selecting the best available skills (nodes and connections in DNNs) from the training model specific to a testing sample in order to maximize its probability to be correctly processed (the doomed test case problem). We validate our approach with multiple datasets and achieve significant performance improvement over SOTA methods.",
    "key_points": [
      "machine learning",
      "generalization",
      "deep neural network",
      "continual learning",
      "lifelong learning",
      "catastrophic forgetting",
      "ensemble modeling"
    ],
    "gold_summary": "The paper proposes \"Supermodel\": a collection of skills (defined as nodes and their incoming connections). During inference the model tries to optimally use a subset of the skills while maximizing the confidence."
  },
  {
    "paper_id": "3axAvkv3ef",
    "title": "ARC-Encoder: learning compressed text representations for large language models",
    "domain": "semi-supervised",
    "content": "Recent techniques such as retrieval-augmented generation or chain-of-thought reasoning have led to longer contexts and increased inference costs. Context compression techniques can reduce these costs, but the most effective approaches require fine-tuning the target model or even modifying its architecture. This can degrade its general abilities when not used for this specific purpose. Here we explore an alternative approach: an encoder that compresses the context into continuous representations which replace token embeddings in decoder LLMs. First, we perform a systematic study of training strategies and architecture choices for the encoder. Our findings led to the design of an Adaptable text Representations Compressor, named ARC-Encoder, which outputs $x$-times fewer continuous representations (typically $x \\in $ {4,8}) than text tokens. We evaluate ARC-Encoder across a variety of LLM usage scenarios, ranging from in-context learning to context window extension, on both instruct and base decoders. Results show that ARC-Encoder achieves state-of-the-art performance on several benchmarks while improving computational efficiency at inference. Finally, we demonstrate that our models can be adapted to multiple decoders simultaneously, allowing a single encoder to generalize across different decoder LLMs. This makes ARC-Encoder a flexible and efficient solution for portable encoders that work seamlessly with multiple LLMs.",
    "key_points": [
      "llm",
      "context compression",
      "auto-encoder",
      "nlp"
    ],
    "gold_summary": "The authors proposed a new context compressor, ARC-Encoder to reduce the size of context representations. ARC-Encoder can generalize to many LLMs and show advanced performance on downstream tasks."
  },
  {
    "paper_id": "ooiR5tMN3J",
    "title": "DDI-Gaussian: Distributed Dynamic Instance Gaussian for Autonomous Driving",
    "domain": "semi-supervised",
    "content": "Current dynamic 3D Gaussian approaches are still limited to surface and appearance modeling and lack fine-grained, instance-level scene understanding. Such capability is not only essential for downstream applications but also facilitates scene reconstruction, such as capturing transient objects, modeling dynamic appearance changes, and decomposing scenes and motions. To bridge this gap, we propose Distributed Dynamic Instance Gaussians (DDIG), a novel framework for instance-aware reconstruction in urban street scenes. Our key innovation lies in assigning each Gaussian a compact multi-hot instance feature, enabling direct differentiation without relying on additional network. To model transient motions, we initialize sparse control points at the instance level and construct the motion field from coarse to fine by leveraging temporal and spatial positional relationships. Additionally, we introduce two novel loss functions: an instance-level region loss and an instance-semantic loss. The instance-level region loss, combined with the opacity rendering pipeline, enables precise instance-level rendering and suppresses ghosting artifacts. The instance-semantic loss enforces cross-view feature consistency. The entire framework operates in a distributed manner. Notably, our framework avoids costly 3D instance annotations by instead utilizing 2D pseudo-labels generated by Segment Anything Model (SAM) for supervision. Extensive experiments on both public datasets and real-world collected data demonstrate that our approach achieves state-of-the-art rendering quality and accurate instance-level understanding. Our demo video and code are available in the anonymous repository at  https://anonymous.4open.science/r/DDI-GS-750E/.",
    "key_points": [
      "3d gaussian、autonomous driving、instance-level、dynamic scene reconstruction"
    ],
    "gold_summary": "DDIG assigns a compact multi-hot instance feature to each Gaussian, enabling self-supervised modeling of different instances within a scene without requiring 3D instance annotations. Additionally, distributed training is employed to accelerate the overall training process."
  },
  {
    "paper_id": "gUXKz2PwQb",
    "title": "Simulator‑Based Synthetic ECGs for Self-Supervised Pretraining",
    "domain": "semi-supervised",
    "content": "Medical data remain scarce and sensitive despite rich domain knowledge. \nWe test whether knowledge‑driven parametric ECG generators can supply scalable pretraining signals without using patient records during pretraining.\nUsing two established simulator-based ECG generator, we synthesize 10‑s, 500‑Hz signals to pretrain a Transformer with masked autoencoding and compare against pretraining on real PTB‑XL and VAE/GAN‑generated ECG. \nWe fine‑tune on 26 abnormal‑ECG classification tasks across PTB‑XL, G12EC, and CPSC2018 and benchmark against five supervised baselines. \nThe Transformer pretrained on simulator‑based synthetic ECG performs comparably to real‑data pretraining and outperforms supervised baselines on 24 tasks, yielding a mean +5.49% improvement over the strongest baseline. \nWith reduced labeled data and across patient demographics, it preserves the advantages of real‑data pretraining and shows robust performance across all 12 single leads, while avoiding patient‑data exposure during pretraining. \nThese results indicate that knowledge‑driven synthetic ECG corpora can deliver practical, privacy‑enhancing initialization for downstream ECG models at scale.",
    "key_points": [
      "simulator synthesized ecg",
      "self‑supervised pretraining",
      "knowledge‑driven simulators"
    ],
    "gold_summary": "This paper investigates whether simulator-generated ECG signals can serve as effective pretraining data for self-supervised learning and subsequently benefit downstream ECG classification tasks."
  },
  {
    "paper_id": "L4cQ2Btscv",
    "title": "Autoencoder with Distribution Preservation",
    "domain": "semi-supervised",
    "content": "This paper proposes an improved autoencoder method. On the basis of maintaining the reconstruction accuracy, we introduce a data distribution preservation mechanism to improve the performance of the dimensionality reduction of the model. Traditional autoencoders only focus on the point-to-point distance between the input sample and its reconstruction result, ignoring the preservation of the overall distribution structure of the data. To solve this problem, we introduced the Kernel Mean Embedding (KME) term based on a kernel function with good topological properties into the loss function to measure the difference between the original data distribution and the reconstructed data distribution. This method effectively maintains the topological features and distribution characteristics of the global data. Experimental results show that compared with traditional autoencoders and existing topological autoencoders, our method performs better on multiple datasets, especially in terms of dimensionality reduction quality and structural preservation of latent representations.",
    "key_points": [
      "auto-encoder",
      "dimensionality reduction",
      "distribution preservation"
    ],
    "gold_summary": "This paper presents a novel approach to improving autoencoder-based dimensionality reduction by introducing a distribution preservation mechanism. The work addresses a significant limitation of traditional autoencoders and shows promising results."
  },
  {
    "paper_id": "cDL8r7Ua01",
    "title": "SeVA: Learning to Ask Discriminative Queries for Fine-Grained Visual Recognition",
    "domain": "semi-supervised",
    "content": "Fine-grained visual recognition (FGVR) aims to distinguish categories based on subtle, localized cues. Recent methods use vision–language models to ask questions for visual hints, but typically rely on fixed templates that yield static attributions rather than adaptive, informative queries. This limits their ability to reveal discriminative features critical to fine-grained categorization. In this work, we ask a key question: how can we ask better questions that are context aware, targeted, and dynamically guide visual reasoning? We propose the Anchored Self-Questioning Vision Agent (SeVA), an iterative reasoning framework that combines a visual–question-answering model with two large language models acting as a Questioner and a Reasoner. Rather than extracting surface-level attributions, SeVA begins with a coarse prediction and then actively interrogates the image by generating discriminative, context-sensitive sub-questions. A Verifier highlights relevant regions, and the Reasoner integrates accumulated evidence to refine the prediction over multiple rounds. To ensure stable and effective interaction between these components, SeVA introduces two complementary types of semantic anchors: (i) explicit anchors from prior category names that guide early attention, and (ii) implicit anchors from previous predictions that provide a language-based gradient for progressive reasoning. Experiments on standard FGVR benchmarks demonstrate the importance of asking good questions, enabling SeVA to outperform state-of-the-art methods.",
    "key_points": [
      "fine-grained vision recognition",
      "iterative reasoning",
      "self-questioning",
      "semantic anchors."
    ],
    "gold_summary": "The paper proposes an agent workflow combining a multimodal large language model and two large language model (three roles) to improve the accuracy of fine-grained classification tasks."
  },
  {
    "paper_id": "9gvUS0ewHm",
    "title": "Fair Out-of-Distribution Detection",
    "domain": "semi-supervised",
    "content": "Out-of-Distribution (OOD) detection prevents models from misclassifying OOD data that fall outside the in-distribution (ID) classes as ID categories. However, existing OOD detection methods ignore a critical metric, i.e., fairness metric. This oversight could result in unreliable predictions due to sensitive attributes in the data. To fill this gap, we introduce a novel and challenging problem termed \\textit{Fair OOD Detection} in this paper, which simultaneously considers OOD detection and bias induced by Fairness Confusion (FC) caused by sensitive attributes and their induced Feature Shifts (FS). Furthermore, we propose a novel metric termed Fair-OOD to identify FC phenomena in OOD detection, and a theoretically guaranteed semi-supervised solution named Predictive Adaptive Calibration (PACT) to simultaneously enhance OOD detection capability, ensure fairness, and mitigate FC without requiring the label of sensitive attribute for OOD data. Extensive experiments demonstrate that: (a) Fair-OOD can identify FC issues in models that existing fairness metrics fail to detect; (b) PACT effectively improves OOD detection performance while eliminating both FC and unfairness issues.",
    "key_points": [
      "out-of-distribution",
      "trustworthy machine learning"
    ],
    "gold_summary": "The paper shows how to make OOD detection fair: it adds a new score and a training method so models catch unseen data without treating any group worse."
  },
  {
    "paper_id": "1dNbK58bB9",
    "title": "Physics-Informed Neural Networks with Learnable Loss Balancing and Transfer Learning",
    "domain": "semi-supervised",
    "content": "We propose a self-supervised physics-informed neural network (PINN) framework that adaptively balances physics-based and data-driven supervision for scientific machine learning under data scarcity. Unlike prior PINNs that rely on fixed or heuristic weighting of physics residuals and data loss, our approach introduces a learnable blending neuron that dynamically adjusts the relative contribution of each term based on their uncertainties. This mechanism enables stable training and improved generalization without manual tuning. To further enhance efficiency, we integrate a transfer learning strategy that reuses representations from related domains and adapts them to new physical systems with limited data. We validate the framework for the prediction of heat transfer in liquid-metal miniature heat sinks using only 87 CFD datapoints, where the adaptive PINN achieves an error $<8\\%$, outperforming shallow neural networks, kernel methods, and physics-only baselines. Our framework provides a general recipe for embedding physics adaptively into neural networks, offering a robust and reproducible approach for data-scarce problems across various scientific domains, including fluid dynamics and material modeling.",
    "key_points": [
      "physics-informed neural networks",
      "self-supervised learning",
      "transfer learning",
      "scientific machine learning",
      "heat transfer",
      "computational fluid dynamics"
    ],
    "gold_summary": "This paper proposes a self-supervised physics-informed neural network (PINN) framework that adaptively balances physics-based and data-driven supervision for scientific machine learning under data scarcity."
  },
  {
    "paper_id": "ShEDWasmDG",
    "title": "HARP: Hallucination Detection via Reasoning Subspace Projection",
    "domain": "semi-supervised",
    "content": "Hallucinations in Large Language Models (LLMs) pose a major barrier to their reliable use in critical decision-making. Although existing hallucination detection methods have improved accuracy, they still struggle with disentangling semantic and reasoning information and maintaining robustness. To address these challenges, we propose HARP (Hallucination detection via reasoning subspace projection), a novel hallucination detection framework. HARP establishes that the hidden state space of LLMs can be decomposed into a direct sum of a semantic subspace and a reasoning subspace, where the former encodes linguistic expression and the latter captures internal reasoning processes. Moreover, we demonstrate that the Unembedding layer can disentangle these subspaces, and by applying Singular Value Decomposition (SVD) to its parameters, the basis vectors spanning the semantic and reasoning subspaces are obtained.\nFinally, HARP projects hidden states onto the basis vectors of the reasoning subspace, and the resulting projections are then used as input features for hallucination detection in LLMs. By using these projections, HARP reduces the dimension of the feature to approximately 5% of the original, filters out most noise, and achieves enhanced robustness. Experiments across multiple datasets show that HARP achieves state-of-the-art hallucination detection performance; in particular, it achieves an AUROC of 92.8% on TriviaQA, outperforming the previous best method by 7.5%.",
    "key_points": [
      "hallucination detection",
      "subspace",
      "projection",
      "svd"
    ],
    "gold_summary": "This paper proposes HARP (Hallucination Detection via Reasoning Subspace Projection), a framework for detecting hallucinations in Large Language Models (LLMs)."
  },
  {
    "paper_id": "Z0r8NHSKvO",
    "title": "An Uncertainty-guided Manifold Smoothing Method for Non-Ideal Measurement Computed Tomography Reconstruction",
    "domain": "semi-supervised",
    "content": "Non-ideal measurement computed tomography (NICT) reduces the need for extensive data sampling, accelerating scanning and mitigating radiation exposure risks. However, the reconstructed images often suffer from artifacts and noise. While enormous deep learning (DL) methods have been developed to improve image quality, most rely on paired data, which is challenging to obtain due to physiological motion. Unsupervised reconstruction methods is a possible solution to address this issue, but they typically assume homogeneous noise distributions and ignore distinct noise characteristics arising from different sampling strategies, which may cause model collapse under certain conditions. We observe that NICT images form discrete sub-manifolds in feature space due to varying physical scanning processes, which contradicts the assumption of unsupervised methods and consequently limits their effectiveness. To address this, we propose an Uncertainty-Guided Manifold Smoothing (UMS) framework to bridge the gaps between sub-manifolds. In UMS, a classifier is first trained to identify the sub-manifold associated with each feature representation. The predicted uncertainty scores are then used to guide the generation of diverse samples across the entire manifold. By leveraging the classifier’s capability, UMS effectively fills the gaps between discrete sub-manifolds, and promotes a more continuous and dense feature space. Furthermore, due to the complexity of the global manifold, it's hard to directly model the manifold. Therefore, we propose to dynamically incorporate the global- and sub-manifold-specific features. Specifically, we design a global- and sub-manifold-driven architecture guided by the classifier, which enables dynamic adaptation to subdomain variations. This dynamic mechanism improves the network’s capacity to capture both shared and domain-specific features, thereby improving reconstruction performance. Extensive experiments on the public datasets are conducted to validate the effectiveness and generalizability of our method.",
    "key_points": [
      "ct reconstruction",
      "image synthesis",
      "unsupervised learning"
    ],
    "gold_summary": "The paper proposes a  uncertainty-guided manifold smoothing framework to bridge the gap between the sub-manifolds associated with different non-ideal CT measurements. This is used for CT reconstruction."
  },
  {
    "paper_id": "lcrFXKWzF7",
    "title": "$\\textit{All the World's a Sphere}$: Learning Expressive Hierarchical Representations with Isotropic Hyperspherical Embeddings",
    "domain": "semi-supervised",
    "content": "Most existing embedding frameworks rely on Euclidean geometry, which, while effective for modeling symmetric similarity, struggle to represent richer relational structures such as asymmetry, hierarchy, and transitivity. Although alternatives like hypercubes and ellipsoids introduce containment-based semantics, they often suffer from axis-aligned rigidity, anisotropic bias, and high parameter overhead. To address these limitations, we propose SpheREx ($\\textbf{Sphe}$rical $\\textbf{R}$epresentations for Hierarchical $\\textbf{Ex}$pressiveness), a geometric embedding framework that utilizes isotropic hyperspheres for hierarchical and asymmetrical relation representation. By representing entities as hyperspheres, SpheREx naturally models containment, intersection, and mutual exclusion while maintaining rotational invariance and closed-form inclusion criteria. We formally characterize the geometric and probabilistic properties of hyperspherical interactions and show that they capture desirable logical structures. To ensure stable optimization and prevent uncontrolled radius growth, we introduce a volume clipping and radius regularization strategy tailored for asymmetric tasks. We conduct extensive evaluations across four diverse real-world benchmarks, spanning both text and vision modalities. SpheREx consistently outperforms twelve competitive baselines, achieving statistically significant improvements across key evaluation measures. Ablations supported by qualitative analysis across benchmarks demonstrate the efficacy of hyperspheres over state-of-the-art geometric baselines.",
    "key_points": [
      "hierarchical representation",
      "hyperspherical embeddings",
      "geometrical optimization"
    ],
    "gold_summary": "The authors present a method that uses isotrophic hyperspheres to embed hierarchical knowledge.\nthis could be seen as a simplification from earlier methods that used hyperellipsoids."
  },
  {
    "paper_id": "buCyma5zsQ",
    "title": "ParaRater: Enhancing Cross-Lingual Transfer in Large Langauge Models with Meta-Learning",
    "domain": "semi-supervised",
    "content": "Multilingual LLMs are rapidly emerging, accompanied by claims of supporting an ever-increasing number of languages. However, significant gaps remain between their performance in English and in other languages. Due to the limited quantity and quality of low-resource language data, independently improving these languages is a tough route. A natural alternative is to transfer the capabilities learned in English to low-resource languages. Parallel corpora play a key role in such transfer, and some prior works have conducted empirical studies. Yet, which types of parallel corpora contribute most effectively to cross-lingual transfer has not been systematically explored.\nTo address this, we propose ParaRater, a corpus selection method designed to identify the most valuable English data to be translated into target languages, thereby constructing high-quality parallel corpora that efficiently boost performance in those languages. ParaRater leverages meta-learning to directly align corpus selection with model performance on native target-language data. It further employs a two-stage filtering process to pinpoint data that is only effective when both language versions appear in training—i.e., truly impactful parallel corpora.\nWe demonstrate the effectiveness of this approach across multiple languages and provide detailed qualitative analyses, offering new insights into cross-lingual transfer in large language models. Our rater, datasets, and code are all released open-source.",
    "key_points": [
      "llm",
      "multilinguistic"
    ],
    "gold_summary": "This work focuses on selecting parallel data used for pre-training of LLMs for facilitating their cross-lingual transfer capabilities.\nGiven a set of corpora, a two-stage filtering strategy is applied.\nFirst,"
  },
  {
    "paper_id": "stMX9KBhUI",
    "title": "Towards Improved Sentence Representations using Token Graphs",
    "domain": "semi-supervised",
    "content": "Obtaining a single-vector representation from a Large Language Model's (LLM) token-level outputs is a critical step for nearly all sentence-level tasks. However, standard pooling methods like mean or max aggregation treat tokens as an independent set, discarding the rich relational structure captured by the model's self-attention layers and making them susceptible to signal dilution. To address this, we introduce GLOT, a lightweight, structure-aware pooling module that reframes pooling as relational learning followed by aggregation. Operating on the outputs of a frozen LLM, GLOT first constructs a latent token-similarity graph, then refines token representations with a graph neural network, and finally aggregates them using a readout layer. Experimentally, our approach is remarkably robust and efficient: on a diagnostic stress test where 90% of tokens are random distractors, GLOT maintains over 97% accuracy while baseline methods collapse. Furthermore, it achieves state-of-the-art performance on benchmarks like GLUE and MTEB with 20x fewer trainable parameters and speeds up the training time by over 100x compared with parameter-efficient fine-tuning methods. Supported by a theoretical analysis of its expressive power, our work shows that learning over token graphs is a powerful paradigm for the efficient adaptation of frozen LLMs.",
    "key_points": [
      "graph-based token pooling; sentence embeddings"
    ],
    "gold_summary": "The paper proposes a lightweight structure-aware pooling module that reframes pooling as relational learning followed by aggregation, dubbed GLOT. The method is remarkably robust and efficient, as demonstrated by extensive experiments."
  },
  {
    "paper_id": "oKmnyMNLGT",
    "title": "Scaling Language Model Reliability via Determinantal Point Process Prompt Sampling",
    "domain": "semi-supervised",
    "content": "Language models achieve stronger performance when given multiple opportunities to solve a task, as in best-of-$N$ inference. However, naive approaches to scaling at test time—such as high-temperature sampling or random prompt ensembling—suffer from correlated failures, where many attempts repeat the same mistakes. We argue that improving pass@$k$ performance requires selecting prompts that are individually strong at eliciting correct answers while also nudging the model toward semantically distinct reasoning paths. To this goal, we introduce a lightweight, query-conditioned framework for prompt selection based on Determinantal Point Processes (DPPs). We build an accuracy–diversity target kernel by combining accuracy labels with hidden-activation similarities, and train a small encoder to approximate this target kernel. The encoder is optimized via a Kullback-Leibler divergence objective, which admits an unbiased gradient estimator. Given the compute budget of $k$ generations at inference, the encoder alone is used to generate the test-time DPP and sample a diverse subset of $k$ prompts that maximize coverage of complementary paths. Experiments on multiple benchmarks demonstrate that our approach outperforms competitive baselines.",
    "key_points": [
      "language model reliability",
      "prompt sampling",
      "determinantal point process"
    ],
    "gold_summary": "The paper proposes a novel method for selecting effective, diverse prompts for sampling, with"
  },
  {
    "paper_id": "cFhcd4WGjO",
    "title": "Beyond Instance-Level Alignment: Dual-Level Optimal Transport for Audio-Text Retrieval",
    "domain": "semi-supervised",
    "content": "Cross-modal matching tasks have achieved significant progress, yet remain limited by mini-batch subsampling and scarce labelled data. Existing objectives, such as contrastive losses, focus solely on instance-level alignment and implicitly assume that all feature dimensions contribute equally. Under small batches, this assumption amplifies noise, making alignment signals unstable and biased. We propose DART (Dual-level Alignment via Robust Transport), a framework that augments instance-level alignment with feature-level regularization based on the Unbalanced Wasserstein Distance (UWD). DART constructs reliability-weighted marginals that adaptively reweight channels according to their cross-modal consistency and variance statistics, highlighting stable and informative dimensions while down-weighting noisy or modality-specific ones. From a theoretical perspective, we establish concentration bounds showing that instance-level objectives scale with the maximum distance across presumed aligned pairs, while feature-level objectives are governed by the Frobenius norm of the transport plan. By suppressing unmatched mass and sparsifying the transport plan, DART reduces the effective transport diameter and tightens the bound, yielding greater robustness under small batches. Empirically, DART achieves state-of-the-art retrieval performance on three audio-text benchmarks, with particularly strong gains under scarce labels and small batch sizes.",
    "key_points": [
      "audio-text retrieval",
      "cross-modal matching"
    ],
    "gold_summary": "This paper presents a dual-level alignment via robust transport (DART) method for audio-text retrieval. The proposed method has been explained in detail and experiments have been condudcted for evaluation."
  },
  {
    "paper_id": "8B1vsFiLin",
    "title": "CoT-PL: Visual Chain-of-Thought Reasoning Meets Pseudo-Labeling for Open-Vocabulary Object Detection",
    "domain": "semi-supervised",
    "content": "Open-vocabulary object detection (OVD) seeks to recognize and localize object categories beyond those seen during training. Recent approaches typically leverage vision-language models (VLMs) to generate pseudo-labels using image-text alignment, allowing detectors to generalize to unseen classes without explicit supervision. However, these methods depend heavily on direct image–text matching, neglecting the intermediate reasoning steps essential for interpreting semantically complex scenes. This results in limited robustness when confronted with crowded or occluded visual contexts. In this paper, we introduce CoT-PL, a new framework that employs structured visual chain-of-thought (CoT) reasoning into the pseudo-labeling process. CoT-PL decomposes object understanding into three interpretable steps: (1) region perception even for unseen objects, (2) category recognition via zero-shot reasoning, and (3) background grounding to separate semantically complex objects. Crucially, the third step naturally motivates our contrastive background learning (CBL) that uses the pre-computed background cues as negatives to promote feature disentanglement between objects and background. In this way, CoT reasoning and CBL form an integrated pipeline tailored to robust pseudo-labeling in crowded or occluded scenes. Notably, in these two settings, our novel-class pseudo-label quality achieves relative improvements of 103.4% and 168.4% over the best prior, respectively. Our extensive experiments demonstrate that CoT-PL achieves +7.7 AP50 on open-vocabulary COCO and +2.9 mask AP on LVIS for novel classes, setting a new state of the art.",
    "key_points": [
      "open-vocaburary object detection",
      "pseudo-labeling",
      "chain-of-thought reasoning"
    ],
    "gold_summary": "This paper introduces a three-step pipeline—comprising pseudo-box generation, pseudo-label assignment, and background extraction—to improve pseudo-label quality for open-vocabulary object detection. The method demonstrates strong results on the OV-COCO and OV-LVIS benchmarks."
  },
  {
    "paper_id": "htIO088ZZF",
    "title": "SURE: Shift-aware, User-adaptive, Risk-controlled Recommendations",
    "domain": "semi-supervised",
    "content": "Although Sequential Recommender Systems (SRS) have been well developed to capture temporal dynamics in user behavior, they face a critical gap in formal performance guarantees under preference shifts. When preferences change, predictions often become unreliable, undermining user trust and threatening long-term platform success. To address this challenge, we introduce **SURE** (**S**hift-aware, **U**ser-adaptive, **R**isk-controlled R**E**commendations), a dataset- and model-agnostic framework that provides adaptive recommendation sets with formal coverage guarantees while remaining compact under preference shifts. Specifically, SURE (i) ensures validity through a loss-based change-point mechanism that adaptively updates calibration thresholds upon detecting preference shift, (ii) maintains compact recommendation sets by stabilizing predictions with a Hedge-weighted ensemble of bootstrapped experts, preventing validity from degenerating into impractically large outputs, and (iii) guarantees robustness under non-stationarity by deriving finite-sample bounds that ensure the ensemble’s expected set size remains close to the best expert while controlling the utility-based risk in recommendation. Extensive experiments across multiple datasets and base models validate the effectiveness of the proposed framework, which aligns with our theoretical analysis.",
    "key_points": [
      "dynamic prediction sets"
    ],
    "gold_summary": "This paper formulates the sequential recommender systems problem as an SURE framework and then proposes the DAUO algorithm, with a Hedge component, to address it. Theoretical and empirical results were also presented."
  },
  {
    "paper_id": "327o4QYRoO",
    "title": "Measuring Invariance in Representation Learning: A Robust Evaluation Framework",
    "domain": "semi-supervised",
    "content": "Distribution shifts challenge reliable deployment even when in-distribution accuracy is high. Invariant representation learning aims to mitigate this challenge by learning feature spaces that remain invariant across diverse out-of-distribution (OOD) scenarios.  However, a critical gap exists in directly and efficiently evaluating the true invariance of learned representations across varied environments. To address this, we introduce DRIC, a novel and computationally efficient criterion designed for the direct assessment of invariant representation performance. DRIC establishes a formal link between the conditional expectation of invariant predictors and environmental diversity through the density ratio, providing a theoretically sound and practical evaluation framework. We validate the effectiveness and robustness of DRIC through extensive numerical experiments on both synthetic and real-world datasets, demonstrating its utility in quantifying and comparing the invariance of learned representations, ultimately contributing to the development of more robust machine learning models.",
    "key_points": [
      "invariant representation learning",
      "domain generalization"
    ],
    "gold_summary": "This paper introduces **DRIC**, a measure for assessing invariance in representation learning across environments. The measure is computationally efficient and easy to estimate."
  },
  {
    "paper_id": "9rSrF0MMpO",
    "title": "Enhancing Open-Vocabulary Object Detection through Multi-Level Fine-Grained Visual-Language Alignment",
    "domain": "applications to computer vision",
    "content": "Traditional object detection systems are typically constrained to predefined categories, limiting their applicability in dynamic environments. In contrast, open-vocabulary object detection (OVD) enables the identification of objects from novel classes not present in the training set. Recent advances in visual-language modeling have led to significant progress of OVD. However, prior works face challenges in either adapting the single-scale image backbone from CLIP to the detection framework or ensuring robust visual-language alignment. We propose Visual-Language Detection (VLDet), a novel framework that revamps feature pyramid for fine-grained visual-language alignment, leading to improved OVD performance. With the VL-PUB module, VLDet effectively exploits the visual-language knowledge from CLIP and adapts the backbone for object detection through feature pyramid. In addition, we introduce the SigRPN block, which incorporates a sigmoid-based anchor-text contrastive alignment loss to improve detection of novel categories. Through extensive experiments, our approach achieves 58.72 AP for novel classes on COCO2017 and 24.83 AP on LVIS, surpassing all state-of-the-art methods and achieving significant improvements of 28.8% and 7.03%, respectively. Furthermore, VLDet also demonstrates superior zero-shot performance on closed-set object detection.",
    "key_points": [
      "vision language model",
      "open-vocabulary object detection"
    ],
    "gold_summary": "This paper identifies that previous open-vocabulary object detection methods face challenges in adapting single-scale image backbones for object detection tasks. It further introduces a fine-grained visual-language alignment framework to bridge the image-region gap."
  },
  {
    "paper_id": "btWHQoSZZ1",
    "title": "Rex-Thinker: Grounded Object Referring via Chain-of-Thought Reasoning",
    "domain": "applications to computer vision",
    "content": "Object referring aims to detect all objects in an image that match a given natural language description. We argue that a robust object referring model should be grounded, meaning its predictions should be both explainable and faithful to the visual content. Specifically, it should satisfy two key properties: 1) Verifiable, by producing interpretable reasoning that justifies its predictions and clearly links them to visual evidence; and 2) Trustworthy, by learning to abstain when no object in the image satisfies the given expression. However, most methods treat referring as a direct bounding box prediction task, offering limited interpretability and struggling to reject expressions with no matching object. In this work, we propose Rex-Thinker, a model that formulates object referring as an explicit CoT reasoning task. Given a referring expression, we first identify all candidate object instances corresponding to the referred object category. Rex-Thinker then performs step-by-step reasoning over each candidate to assess whether it matches the given expression, before making a final prediction. To support this paradigm, we construct a large-scale CoT-style referring dataset named HumanRef-CoT by prompting GPT-4o on the HumanRef dataset. Each reasoning trace follows a structured planning, action, and summarization format, enabling the model to learn decomposed, interpretable reasoning over object candidates. We then train Rex-Thinker in two stages: a cold-start supervised fine-tuning phase to teach the model how to perform structured reasoning, followed by GRPO-based RL learning to improve accuracy and generalization. Experiments show that our approach outperforms standard baselines in both precision and interpretability on in-domain evaluation, while also demonstrating improved ability to reject hallucinated outputs and strong generalization in out-of-domain settings.",
    "key_points": [
      "object referring",
      "reasoning"
    ],
    "gold_summary": "This paper proposes to induce or enhance chain-of-thought reasoning of VLMs, with an application on Referring Expression Comprehension  (REC). The training recipe is standard practice, i.e., SFT+RL (GRPO)."
  },
  {
    "paper_id": "eZZDbYR3RH",
    "title": "SaLon3R: Structure-aware Long-term Generalizable 3D Reconstruction from Unposed Images",
    "domain": "applications to computer vision",
    "content": "Recent advances in 3D Gaussian Splatting (3DGS) have enabled generalizable, on-the-fly reconstruction of sequential input views.\nHowever, existing methods often predict per-pixel Gaussians and combine Gaussians from all views as the scene representation, leading to substantial redundancies and geometric inconsistencies in long-duration video sequences. To address this, we propose SaLon3R, a novel framework for Structure-aware, Long-term 3DGS Reconstruction. To our best knowledge, SaLon3R is the first online generalizable GS method capable of reconstructing over 50 views in over 10 FPS, with 50% to 90% redundancy removal. Our method introduces compact anchor primitives to eliminate redundancy through differentiable saliency-aware Gaussian quantization, coupled with a 3D Point Transformer that refines anchor attributes and saliency to resolve cross-frame geometric and photometric inconsistencies. Specifically, we first leverage a 3D reconstruction backbone to predict dense per-pixel Gaussians and a saliency map encoding regional geometric complexity. Redundant Gaussians are compressed into compact anchors by prioritizing high-complexity regions. The 3D Point Transformer then learns spatial structural priors in 3D space from training data to refine anchor attributes and saliency, enabling regionally adaptive Gaussian decoding for geometric fidelity. Without known camera parameters or test-time optimization, our approach effectively resolves artifacts and prunes the redundant 3DGS in a single feed-forward pass. Experiments on multiple datasets demonstrate our state-of-the-art performance on both novel view synthesis and depth estimation, demonstrating superior efficiency, robustness, and generalization ability for long-term generalizable 3D reconstruction. Code will be released.",
    "key_points": [
      "3d gaussian splatting",
      "3d reconstruction",
      "generalizable gaussian"
    ],
    "gold_summary": "This paper proposes SaLon3R for online generalizable 3D Gaussian Splatting (3DGS) reconstruction from unposed image sequences. The method achieves redundancy removal and performs well on novel view synthesis tasks."
  },
  {
    "paper_id": "Tp70ig4iKN",
    "title": "Seeing Before Reasoning: A Unified Framework for Generalizable and Explainable Fake Image Detection",
    "domain": "applications to computer vision",
    "content": "Detecting AI-generated images with multimodal large language models (MLLMs) has gained increasing attention, due to their rich world knowledge, common-sense reasoning, and potential for explainability.\nHowever, naively applying those MLLMs for detection often leads to suboptimal performance.\nWe argue that the root of this failure lies in a fundamental mismatch: *MLLMs are asked to reason about fakes before they can truly see them.*\nFirst, **they do not really see**: existing MLLMs' vision encoders are primarily optimized for semantic-oriented recognition rather than the perception of low-level signals, leaving them insensitive to subtle forgery traces. Without access to reliable perceptual evidence, the model grounds its judgment on incomplete and limited visual observations.\nSecond, existing finetuning data for detection typically uses narrow, instruction-style formats, which diverge sharply from the diverse, heterogeneous distributions seen in pretraining.\nIn the absence of meaningful visual cues, the model therefore exploits these linguistic shortcuts, resulting in catastrophic forgetting of pretrained knowledge (even the basic dialogue capabilities).\nIn response, we advocate for a new paradigm: *seeing before reasoning*. We propose that MLLMs should first be trained to perceive artifacts—strengthening their artifact-aware visual perception—so that subsequent reasoning is grounded in actual observations. \nWe therefore propose **Forensic-Chat**, a generalizable, explainable, and still-conversational (for multi-round dialogue) assistant for fake image detection.\nSpecifically, we first refine the vision encoder only via self-reconstruction while freezing the LLM, sensitizing it to artifacts without sacrificing pretrained knowledge (Stage 1).\nThen, we construct a multi-round dialogue finetuning data for detection, which is designed to progressively guide the model from artifact perception to common-sense reflection, enabling dialectical reasoning about *why an image is fake* and *what a real version should look like* (Stage 2).\nWe also propose **ExplainFake-Bench**, a benchmark tailored for the evaluation of the MLLM's explainability for image forensics from five key aspects.\nExtensive experiments show the superiority of generalization and genuinely reliable explainability.",
    "key_points": [
      "ai-generated image detection",
      "mllm",
      "media forensics"
    ],
    "gold_summary": "The paper introduces Forensic-Chat and ExplainFake-Bench. Forensic-Chat is a MLLM-based DeepFake reasoning model that makes use the ExplainFake-Bench data for supervised fine-tuning. ExplainFake-bench was curated by generating explanations from large MLLMs (proprietary models) like Gemini-2.5-Pro."
  },
  {
    "paper_id": "d7YpJuV64J",
    "title": "Two are Better than One: Uncertainty-Aware Vision-Language Models for Video Anomaly Detection",
    "domain": "applications to computer vision",
    "content": "Vision-language models (VLMs) have demonstrated impressive reasoning capability in visual understanding tasks. One recent highlight of VLMs is their success in generating human-understandable explanations in video anomaly detection (VAD), which is an advanced video understanding task requiring delicate judgment on context-dependent and ambiguous video content. Representative works mainly formulate this problem as a natural language generation task conditioned on task-related prompts and visual inputs. However, under this paradigm, the input is processed segment by segment, and VLMs generate a response for each segment independently, which inevitably leads to uncertainty in their reasoning with a limited context. To bridge this fundamental gap, we propose an uncertainty-aware VLM framework named Una for VAD to objectively identify the reasoning-level uncertainty in VLMs and correspondingly mitigate it: Firstly, Una obtains relevant scenes by temporal and semantic relevance and determines the existence of uncertainty by the prediction consistency across relevant scenes. After that, collective intelligence via the cooperation of VLMs is introduced to address the uncertainty. With Una, VLMs can achieve remarkable performance and advanced explainability, surpassing task-specific methods in challenging benchmarks in the most difficult setting where instruction tuning is not allowed for the first time.",
    "key_points": [
      "video anomaly detection",
      "vision-language models",
      "uncertainty-aware mechanism"
    ],
    "gold_summary": "The paper introduces UNA, an uncertainty-aware framework, for video anomaly detection (VAD) using vision-language models (VLMs). Experiments on UCF-Crime and XD-Violence datasets show UNA achieves superior scores (Tables 1–2) without instruction tuning, surpassing existing baselines."
  },
  {
    "paper_id": "zbHpRwzrq5",
    "title": "Motion-Aligned Word Embeddings for Text-to-Motion Generation",
    "domain": "applications to computer vision",
    "content": "Existing text-to-motion (T2M) generation models typically rely on pretrained large language models to encode textual inputs. However, these models, trained on generic text corpora, lack explicit alignment between motion-related words (e.g., \"clockwise'', \"quickly'') and human skeletal movements. This misalignment, fundamentally rooted in the word embedding layers, severely limits the ability of T2M models to understand and generalize fine-grained motion semantics. To tackle this issue, we propose Motion-Aligned Text Encoding (MATE), a novel framework that explicitly incorporates motion semantics into the word embedding layers of large language models to enhance text-motion alignment for motion generation. To address the challenge of inherent semantic entanglement in motion sequences, MATE introduces two key components: 1) a motion localization strategy that establishes localized correspondences between sub-texts and motion segments, enabling soft attention guidance for semantic localization; and 2) a motion disentanglement module that isolates word-specific motion semantics via contrastive kinematic prototypes, ensuring word-level alignment between linguistic and kinematic representations. Remarkably, language models enhanced with MATE can be seamlessly integrated into existing T2M methods, significantly surpassing state-of-the-art performance on two standard benchmarks with minimal modifications. Codes and pretrained models will be released upon acceptance.",
    "key_points": [
      "text-to-motion generation",
      "large language model fine-tuning",
      "word embeddings"
    ],
    "gold_summary": "This paper proposes MATE, a novel framework that explicitly incorporates motion semantics into the word embedding layers of large language models to enhance text-motion alignment for motion generation."
  },
  {
    "paper_id": "0TV81QK0l8",
    "title": "3D-CoS: A New 3D Reconstruction Paradigm Based on VLM Code Synthesis",
    "domain": "applications to computer vision",
    "content": "Most recent 3D reconstruction and editing systems operate on implicit and explicit representations such as NeRF, point clouds, or meshes. While these representations enable high-fidelity rendering, they are inherently low-level and hard to control automatically.\nIn contrast, we advocate a new \\bfunderline{3D} reconstruction paradigm based on vision-language-models (VLMs) \\bfunderline{Co}de \\bfunderline{S}ynthesis (\\bfunderline{3D-CoS}), where 3D assets are constructed as executable Blender code, a programmatic and interpretable medium.\nTo assess how well current VLMs can use code to represent 3D objects, we evaluate leading open-source and closed-source VLMs in code-based reconstruction under a unified protocol. We further introduce two generic improvements: a planning stage that produces a ratio-based, part-level blueprint before code synthesis, and Retrieval-Augmented Generation (RAG) over well-organized Blender API documents.\nTo demonstrate the unique advantages of this representation, we also present an evaluation focused on localized, text-driven modifications, comparing our code-based edits to state-of-the-art mesh-editing methods. \nOur study shows that code as a 3D representation offers strong controllability and locality, exhibiting significant advantages in edit fidelity, identity preservation, and overall visual quality.\nOur work also analyzes the potential of this paradigm and specifically delineates the current capability frontier of VLMs for programmatic 3D modeling, demonstrating the promising future of reconstruction by code.",
    "key_points": [
      "3d reconstruction",
      "3d edition",
      "vlm",
      "code synthesis"
    ],
    "gold_summary": "This paper proposes a new 3D reconstruction method, by using blender code as unified representation, authors highlight the editability for this representation."
  },
  {
    "paper_id": "lCaU7NlZ1I",
    "title": "Self-Guidance: Training VQ-VAE Decoders to be Robust to Quantization Artifacts for High-Fidelity Neural Speech Codec",
    "domain": "applications to computer vision",
    "content": "Neural speech codecs, predominantly based on Vector-Quantized Variational Autoencoders (VQ-VAEs), serve as fundamental audio tokenizers for speech large language models (SLLMs). However, their reconstruction fidelity is limited by quantization errors introduced during latent space discretization. Existing solutions typically increase model complexity through larger codebooks or hierarchical quantization, which subsequently intensify the modeling challenge for downstream SLLMs. Inspired by the key insight that the codec decoder produces superior output from continuous pre-quantize embeddings, we propose a novel self-guided training mechanism that addresses this problem by enhancing decoder robustness rather than modifying the quantization process. Our method introduces an additional training objective that aligns the decoder's intermediate features when processing both quantized tokens and continuous pre-quantized embeddings through a feature-mapping loss. Extensive experiments on XCodec2 demonstrate that self-guidance consistently improves reconstruction quality across various codebook sizes and quantization techniques (FSQ, SimVQ), achieving state-of-the-art performance for low-bitrate speech codecs. The method requires minimal additional training cost and no inference-time modifications, offering an efficient solution for high-fidelity neural audio coding. Remarkably, our approach enables a 4× reduction in codebook size while maintaining comparable fidelity. Downstream text-to-speech experiments confirm that this reduction significantly improves LLM-based synthesis performance by simplifying the token modeling space.",
    "key_points": [
      "neural speech codec",
      "vq-vae",
      "speech large language models"
    ],
    "gold_summary": "This paper studies the audio tokenizer task, aiming to improve the quality of audio codecs. The authors propose an approach that aligns hidden embeddings to better reconstruct fine-grained audio information."
  },
  {
    "paper_id": "MLs6ThXmcz",
    "title": "From Sparse to Dense: Spatio-Temporal Fusion for Multi-View 3D Human Pose Estimation with DenseWarper",
    "domain": "applications to computer vision",
    "content": "In multi-view 3D human pose estimation, models typically rely on images captured simultaneously from different camera views to predict a pose at a specific moment. While providing accurate spatial information, this traditional approach often overlooks the rich temporal dependencies between adjacent frames. We propose a novel 3D human pose estimation input method: the sparse interleaved input to address this. This method leverages images captured from different camera views at various time points (e.g., View 1 at time $t$ and View 2 at time $t+\\delta$), allowing our model to capture rich spatio-temporal information and effectively boost performance. More importantly, this approach offers two key advantages: First, it can theoretically increase the output pose frame rate by N times with N cameras, thereby breaking through single-view frame rate limitations and enhancing the temporal resolution of the production. Second, using a sparse subset of available frames, our method can reduce data redundancy and simultaneously achieve better performance. We introduce the DenseWarper model, which leverages epipolar geometry for efficient spatio-temporal heatmap exchange. We conducted extensive experiments on the Human3.6M and MPI-INF-3DHP datasets. Results demonstrate that our method, utilizing only sparse interleaved images as input, outperforms traditional dense multi-view input approaches and achieves state-of-the-art performance.",
    "key_points": [
      "3d pose estimation; spatiotemporal; sparse interleaved input; epipolar geometry;"
    ],
    "gold_summary": "This paper introduces a novel input paradigm for 3D human pose estimation: sparse interleaved multi-view input."
  },
  {
    "paper_id": "EHGZhNWU10",
    "title": "All in One: Unified Pretraining of GUI Agents via Masked Trajectory Prediction",
    "domain": "applications to computer vision",
    "content": "Graphical User Interface (GUI) agents are intelligent systems that interact with software applications by perceiving visual elements and taking appropriate actions. Existing studies typically explore a wide range of pretraining strategies with heterogeneous corpora and directly unify these tasks through mixture training to enhance the generalization of GUI agents. However, the direct unification of existing pretraining strategies leads to inconsistent training objectives and data heterogeneity, preventing the full potential of each pretraining task from being realized. In this paper, we present a unified framework, \\textbf{M}asked \\textbf{T}rajectory \\textbf{P}rediction (MTP), which consolidates diverse pretraining strategies into a consistent training objective via a masking-based manner. Specifically, we collect open-source GUI corpora that encompass a broad range of logical and semantic coherence, including randomly generated action–screenshot pairs, GUI tutorial data, and human-annotated datasets. Then, MTP models each GUI multi-interaction as a trajectory and defines pretraining objectives through component masking and prediction. Furthermore, to handle the heterogeneity across open-source corpora, we design a role-aware adapter learning module that dynamically routes each token to an appropriate optimization path. Extensive experiments on four representative GUI navigation benchmarks (AndroidControl, GUI-Odyssey, AITZ, and Mind2Web) demonstrate the effectiveness and generalization ability of our framework. By unifying existing pretraining objectives, MTP significantly outperforms prior methods and achieves SOTA results. The code and dataset will be publicly released.",
    "key_points": [
      "gui agent"
    ],
    "gold_summary": "The paper proposes a new training paradigm which uses Masked Trajectory prediction to unify all the open-sourced datasets. It also proposes role-aware adapters to address the challenge of data heterogeneity."
  },
  {
    "paper_id": "Snf7vos1Xp",
    "title": "GR-Gaussian: Graph-Based Radiative Gaussian Splatting for Sparse-View Tomographic Reconstruction",
    "domain": "applications to computer vision",
    "content": "Computed tomography (CT) reconstruction under sparse-view settings remains highly challenging due to severe artifacts. Recently, 3D Gaussian Splatting (3DGS) has shown promise for this task, but existing methods often rely on view-averaged gradient magnitudes, which easily cause needle-like artifacts in sparse views. To overcome this limitation, we propose GR-Gaussian, a graph-based 3DGS framework. It explicitly leverages a CT-specific prior, where regions of the same tissue or material have similar attenuation coefficients, forming a natural structural relationship among neighboring points. This structure motivates a graph-based representation, which guides gradient refinement to suppress needle-like artifacts. To exploit this structure, GR-Gaussian introduces (1) a Denoised Point Cloud Initialization strategy that mitigates initialization errors, and (2) a Pixel-Graph-Aware Gradient strategy that leverages graph-based density differences to refine gradient computation, improving splitting accuracy and density representation. Experiments on X-3D and real-world datasets validate the effectiveness of GR-Gaussian, achieving PSNR improvements of 0.67 dB and 0.92 dB, and SSIM gains of 0.011 and 0.021. These results highlight the importance of embedding domain-specific structural priors for accurate CT reconstruction under challenging sparse-view conditions.",
    "key_points": [
      "3d gaussian splatting ; ct reconstruction ; graph-based radiative gaussian splatting ;"
    ],
    "gold_summary": "This paper proposes a graph-based gaussian splatting method for CT reconstruction, outperforming previous methods or other INR methods. It is self-supervised and does not require large amount of training data."
  },
  {
    "paper_id": "EbjbESm8MD",
    "title": "Revisit Visual Prompt Tuning: The Expressiveness of Prompt Experts",
    "domain": "applications to computer vision",
    "content": "Visual Prompt Tuning (VPT) has proven effective for parameter-efficient adaptation of pre-trained vision models to downstream tasks by inserting task-specific learnable prompt tokens. Despite its empirical success, a comprehensive theoretical understanding of VPT remains an active area of research. Building on the recently established connection between Mixture of Experts (MoE) and prompt-based methods, wherein each attention head can be conceptualized as a composition of multiple MoE models, we reinterpret VPT as the introduction of new *prompt experts* into these MoE structures. We identify a key limitation in existing VPT frameworks: the *restricted functional expressiveness* of prompt experts, which remain static and thus limited in their adaptability. To address this, we propose **Visual Adaptive Prompt Tuning (VAPT)**, a novel method that endows prompt experts with enhanced expressiveness while preserving parameter efficiency. Empirical evaluations on VTAB-1K and FGVC demonstrate that VAPT achieves *substantial performance improvements*, surpassing fully fine-tuned baselines by **7.34%** and **1.04%**, respectively. Moreover, VAPT consistently outperforms VPT while *requiring fewer additional parameters*. Furthermore, our theoretical analysis indicates that VAPT achieves optimal sample efficiency. Collectively, these results underscore the theoretical grounding and empirical advantages of our approach.",
    "key_points": [
      "mixture of experts",
      "visual prompt tuning",
      "theory",
      "parameter-efficient fine-tuning",
      "pre-trained model"
    ],
    "gold_summary": "The paper reinterprets VPT as the introduction of new prompt experts into these MoE structures, solving the current limitation in existing VPT frameworks: the restricted functional expressiveness of prompt experts."
  },
  {
    "paper_id": "y3073f59bH",
    "title": "DOES THE DEFINITION OF DIFFICULTY MATTER ? SCORING FUNCTIONS AND THEIR ROLE FOR CURRICULUM LEARNING",
    "domain": "applications to computer vision",
    "content": "Curriculum learning (CL) relies on the simple and intuitive assumption that the non-uniform sampling of training instances based on some measure of sample difficulty is beneficial for learning, with the postulated benefits being faster convergence and improved test-set performance. The motivation for CL is oftentimes grounded on anthropomorphisation – humans, it is argued, often rely on curricula for their learning. However, this simple premise hinges on the notion of sample difficulty for which there is no established definition. Previous research on the benefits of CL begins by settling on a specific definition of difficulty, without questioning the potential bias that this a priori definition introduces. In the present contribution, we conduct an extensive experimental study on the robustness and similarity of the most common scoring functions for sample difficulty estimation on two benchmark datasets from the vision and audio domains. We report a strong dependence of scoring functions on the training hyperparameters, including randomness, which can partly be mitigated through ensemble scoring. While we do not find a general advantage of CL over uniform sampling, we observe that the ordering in which data is presented for CL-based training plays an important role in model performance. Furthermore, we find that the robustness of scoring functions across random seeds positively correlates with CL performance. Finally, we uncover that models trained with different CL strategies complement each other by boosting predictive power through late fusion, likely due to differences in the learnt concepts. Alongside our findings, we release a toolkit implementing sample difficulty and CL-based training in a modular fashion.",
    "key_points": [
      "curriculum learning",
      "sample difficulty",
      "scoring function similarity",
      "computer vision",
      "computer audition",
      "deep learning"
    ],
    "gold_summary": "This paper proposes to study the role of scoring function and pacing function in curriculum learning. It aims to answer several questions such as *How do different SFs affect model performance*?"
  },
  {
    "paper_id": "PmK4IIf1q0",
    "title": "TAS-GS: Integrating Topology, Appearance and Semantics for Sparse-View 3D Gaussian Splatting",
    "domain": "applications to computer vision",
    "content": "We present TAS-GS, a  framework that extends 3D Gaussian Splatting (3DGS) to sparse-view reconstruction by integrating topology, appearance and semantic priors.  TAS-GS addresses key challenges of sparse-view 3DGS, including structural fragility, texture incoherency, and loss of fine details, through three modules: (i) a topology-aware graph regularizer that prunes floaters and bridges structural gaps, (ii) a GNN-based appearance propagation module that refines textures in weakly supervised regions, and (iii) a semantic-rarity and boundary-aware modulator that preserves fine details and underrepresented categories. All modules are applied only during training, and the final representation remains fully compatible with the standard 3DGS rasterizer. Extensive experiments on LLFF and Mip-NeRF 360 show that TAG-GS consistently outperforms state-of-the-art NeRF- and Gaussian-based methods across a wide range of sparsity levels. Ablation studies further confirm the effectiveness of each component in improving both quantitative metrics and perceptual quality. Our code is available at https://anonymous.4open.science/r/56165123.",
    "key_points": [
      "sparse-view novel view synthesis、3d gaussian splatting"
    ],
    "gold_summary": "This work focuses on sparse-view 3D Gaussian Splatting reconstruction. By introducing topology, appearance, and semantic priors, the authors claim that this method achieves better performance."
  },
  {
    "paper_id": "s35Jvv0a4d",
    "title": "3D-ATRES: Ambiguity-Tolerant Learning for 3D Referring Expression Segmentation",
    "domain": "applications to computer vision",
    "content": "3D Referring Expression Segmentation (3D-RES) is an emerging yet challenging task at the interaction of 3D vision and language, which aims to precisely segment a target instance within a 3D point cloud based on a given natural language referring expression. However, most previous methods overlook multi-source ambiguities that are prevalent in real-world scenarios, including prompt, spatial, and annotation ambiguities. Prompt ambiguity arises from confusion between referent and target instances due to ambiguous language, spatial ambiguity results from viewpoint variations causing incomplete segmentation, and annotation ambiguity stems from inconsistent or noisy labeling in training data. In this paper, we propose a novel 3D Ambiguity-Tolerant Referring Expression Segmentation (3D-ATRES), which explicitly models and mitigates multi-source ambiguities in 3D-RES. Specifically, we employ $\\text{TR}^{2}$ Semantic Structurizer to transform free-form natural language into structured Target-Relation-Referent triples, thereby eliminating referential ambiguity. For spatial ambiguity, we introduce a Normal‑Aware Spatial Alignment that leverages surface normal cues to achieve viewpoint-consistent geometry alignment. To mitigate annotation ambiguity, we introduce an Annotation Ambiguity Penalty, which enables the network to adaptively learn from noisy or inconsistent annotations through confidence evaluation. Experiments on ScanRefer and Multi3DRefer show that 3D-ATRES achieves state-of-the-art performance, confirming the effectiveness of modeling ambiguity in 3D-RES.",
    "key_points": [
      "3d referring expression segmentation",
      "ambiguity"
    ],
    "gold_summary": "This manuscript identify three types of ambiguity in the 3D referring expression segmentation task and propose three corresponding modules to address these issues, ultimately achieving state-of-the-art performance on both the ScanRefer and Multi3DRef datasets."
  },
  {
    "paper_id": "RpBnG6f4Re",
    "title": "Graph Linearization Methods for Reasoning on Graphs with Large Language Models",
    "domain": "applications to computer vision",
    "content": "Large language models have evolved to process multiple modalities beyond text, such as images and audio, which motivates us to explore how to effectively leverage them for graph reasoning tasks. The key question, therefore, is how to transform graphs into linear sequences of tokens -a process we term graph linearization}-so that LLMs can handle graphs naturally. We consider that graphs should be linearized meaningfully to reflect certain properties of natural language text, such as local dependency and global alignment, in order to ease contemporary LLMs, trained on trillions of textual tokens, better understand graphs. To achieve this, we developed several graph linearization methods based on graph centrality and degeneracy. These methods are further enhanced using node relabeling techniques. The experimental results demonstrate the effectiveness of our methods compared to the random linearization baseline.\nOur work introduces novel graph representations suitable for LLMs, contributing to the potential integration of graph machine learning with the trend of multimodal processing using a unified transformer model.",
    "key_points": [
      "graph linearization",
      "large language models",
      "graph reasoning",
      "token sequences",
      "edge ordering",
      "centrality",
      "degeneracy"
    ],
    "gold_summary": "The paper explores how to make large language models (LLMs) reason over graph-structured data by linearizing graphs into token sequences."
  },
  {
    "paper_id": "uKF4aOvThW",
    "title": "UTFC-DiffTracker: Short- and Long-Range Temporal Feature Consistency Diffusion for Underwater Object Tracking",
    "domain": "applications to computer vision",
    "content": "Underwater object tracking (UOT) plays a significant role in marine animal protection, underwater search and rescue, and maritime security, yet faces distinctive challenges including color distortion, low visibility, similar distractors, and occlusion in complex environments. Existing approaches include frame-level trackers that employ enhancement-based or adaptation strategies, processing frames independently and leading to inconsistent feature styles and weakened temporal correlations.  Video-level trackers leverage autoregressive mechanisms for temporal consistency but still struggle with persistent feature degradation and tracking drift in underwater environments. To overcome these limitations, this paper proposes UTFC-DiffTracker, the feature \\& video-level tracker that achieves spatiotemporal feature alignment. The framework integrates two core innovations: the Short-Range Temporal Feature Consistency integrates diffusion-based correction and dynamic style memory retention to resolve underwater feature degradation while maintaining temporal coherence; the Long-Range Temporal Feature Consistency enhances discrimination against distractors and occlusion through wavelet decomposition that separates historical tokens into stable structures and transient details. UTFC-DiffTracker achieves state-of-the-art performance on four UOT benchmarks while preserving semantic integrity and ensuring tracking reliability.",
    "key_points": [
      "underwater object tracking",
      "feature correction",
      "temporal consistency"
    ],
    "gold_summary": "The paper proposes a new tracking framework designed to address the unique challenges of underwater object tracking, such as color distortion, low visibility, similar distractors, and occlusion."
  },
  {
    "paper_id": "x6IS5VnT3j",
    "title": "Composing Human Object Interaction with Decoupled Prototype for Zero-shot Learning",
    "domain": "applications to computer vision",
    "content": "Zero-shot Human-Object Interaction (HOI) detection is a daunting problem, largely stemming from the combinatorial explosion of potential action-object pairs. \nCurrent studies predominantly address this issue by transferring knowledge from large-scale pre-trained models (e.g., CLIP), yet ignore a more straightforward idea, i.e., mimic the powerful compositional generalization ability of human intelligence based on past cases. \nBesides, they simplify this combinatorial challenge by operating under the assumption that knowledge about unseen compositions is accessible, which is usually impractical in reality.\nIn this work, we extend prior Closed-World zero-shot setting to an Open-World scenario, where the search space for HOI compositions is entirely unrestricted.\nFor this challenging task, we introduce ProtoHOI, a fresh prototype-based framework for zero-shot HOI detection, which consists of: \ni) distill a set of prototypes from HOI proposal embeddings to model the inherent properties of objects and actions in the context of HOI.\nii) recalibrate the representation space learned by the HOI detector based on these derived prototypes in a decoupled manner, thereby facilitating the prediction of unseen HOI compositions. \nExtensive experiments on two standard benchmarks demonstrate the superiority of ProtoHOI over the state-of-the-art methods across all zero-shot settings. The source code will be released.",
    "key_points": [
      "human object detection",
      "zero-shot learning"
    ],
    "gold_summary": "The authors proposed ProtoHOI as a prototype-based framework for zero-shot HOI detection. It first distills a set of prototypes, then calibrates these prototypes. Extensive experiments and positive results are demonstrated."
  },
  {
    "paper_id": "kvEGQWemVx",
    "title": "PANICL: Mitigating Over-Reliance on Single Prompt in Visual In-Context Learning",
    "domain": "applications to computer vision",
    "content": "Visual In-Context Learning (VICL) uses input-output image pairs, referred to as in-context pairs (or examples), as prompts alongside query images to guide models in performing diverse vision tasks. However, VICL often suffers from over-reliance on a single in-context pair, which can lead to biased and unstable predictions. We introduce PAtch-based $k$-Nearest neighbor visual In-Context Learning (PANICL), a general training-free framework that mitigates this issue by leveraging multiple in-context pairs. PANICL smooths assignment scores across pairs, reducing bias without requiring additional training. Extensive experiments on a variety of tasks, including foreground segmentation, single object detection, colorization, multi-object segmentation, and keypoint detection, demonstrate consistent improvements over strong baselines. Moreover, PANICL exhibits strong robustness to domain shifts, including dataset-level shift (e.g., from COCO to Pascal) and label-space shift (e.g., FSS-1000), and generalizes well to other VICL models such as SegGPT, Painter, and LVM, highlighting its versatility and broad applicability.",
    "key_points": [
      "visual in-context learning"
    ],
    "gold_summary": "PANICL introduces a technically simple but novel inference-time strategy to mitigate over-reliance on single prompts in Visual In-Context Learning."
  },
  {
    "paper_id": "4oA5xPOTmy",
    "title": "Multimodal Cancer Survival Analysis with Learnable Queries",
    "domain": "applications to computer vision",
    "content": "Leveraging multimodal data, particularly the integration of whole-slide histology images (WSIs) and transcriptomic profiles, holds great promise for improving cancer survival prediction. However, excessive redundancy in multimodal data poses a critical challenge for model optimization and can become prohibitive. Thus, methods that effectively reduce redundancy are highly desirable. While previous approaches have achieved impressive results by clustering redundant representations, they still rely on additional prior knowledge, which limits their flexibility in capturing dynamic data changes and emerging patterns. To resolve this drawback, we propose a novel and effective approach, SurvQ, for multimodal cancer survival analysis with learnable queries, which adaptively learns representative features in a data-driven manner, reducing redundancy while preserving critical information. Our method employs two sets of learnable query vectors that serve as a bridge between high-dimensional representations and survival prediction, capturing task-relevant features. Additionally, we introduce a multimodal mixed self-attention mechanism to enable cross-modal interactions, further enhancing information fusion. Extensive experiments on five benchmark cancer datasets demonstrate that our method consistently outperforms state-of-the-art approaches, achieving the best average performance.",
    "key_points": [
      "survival analysis",
      "multimodal learning",
      "learnable queries"
    ],
    "gold_summary": "This work proposes to utilize two sets of learnable queries to extract representative features via cross-attention, while multimodal mixed self-attention is leveraged to model cross-modal interactions."
  },
  {
    "paper_id": "Chn50flK4X",
    "title": "Rethinking Predictive LLM Routing: When Simple KNN Beats Complex Learned Routers",
    "domain": "applications to computer vision",
    "content": "As large language models (LLMs) grow in scale and specialization, routing—selecting the best model for a given input—has become essential for efficient and effective deployment. While recent methods rely on increasingly complex learned routing strategies, their dependence on disparate training data and evaluation setups makes comparison and generalization difficult. In this work, we fundamentally rethink LLM routing by questioning whether such complexity is necessary. We show that a well-tuned k-Nearest Neighbors (kNN) approach not only matches but often outperforms state-of-the-art learned routers while being significantly more efficient. To support systematic evaluation, we introduce a suite of standardized routing benchmarks spanning instruction-following, question-answering, and reasoning tasks, as well as the first multi-modal routing dataset involving visual inputs. Our theoretical analysis reveals that the strong locality properties of model performance in embedding space enable simple non-parametric methods to achieve superior routing decisions with lower sample complexity than parametric approaches. These findings challenge the prevailing trend toward sophisticated architectures and demonstrate that simple, interpretable approaches can be surprisingly effective for LLM routing.",
    "key_points": [
      "llm routing"
    ],
    "gold_summary": "The paper contributes two benchmarks and validate the effectiveness of non-parametric KNN rather than complex networks in LLM routing."
  },
  {
    "paper_id": "OgDa8T3XDb",
    "title": "Deformable Contact-Aware 3D Object Placement",
    "domain": "applications to computer vision",
    "content": "We study language-guided object placement in real 3D scenes when contact is \\emph{deformable and frictional}. Rather than guessing a rigid pose that “looks right,” we cast placement as a \\emph{drop-to-equilibrium} problem: if the support, scale, and a reasonable pre-drop pose are provided, physics should determine where the object actually rests. Our pipeline, \\textbf{DCAP}, couples language/vision priors with simulation. An LLM extracts the intended support and a realistic size prior; a minimal three-view VLM query returns a single rotation; and a sub-part–aware LLM selects the exact target region, after which we raycast to place the object 1cm above it—no “upward-facing” constraint required. We assign per-part materials by \\emph{hard} mapping of semantic labels to a curated library, split parts into rigid vs.\\ MPM by stiffness, fill soft parts with particles, and then drop to equilibrium with a corotated-elastic MPM solver. To evaluate deformable placement, we convert 186 high-fidelity indoor scenes to watertight meshes by rendering multi-view images from InteriorGS and extracting surfaces with SuGaR. We score methods along two axes—\\emph{Right Place} and \\emph{Physics \\& Naturalness}—using both a human-aligned VLM protocol and forced-choice human studies. DCAP substantially outperforms language-only and rigid-constraint baselines on both axes, produces visible, material-consistent deformations, and correctly flags infeasible instructions. Finally, using DCAP’s settled geometry as conditioning improves downstream 2D insertions, indicating that physically justified final states are valuable beyond simulation.",
    "key_points": [
      "3d vision"
    ],
    "gold_summary": "Uses segmentation and VLM queries to try and solve object placement in the problem of 2D image editing, trying to simulate properties of the different objects to give good contacts and realistic deformations."
  },
  {
    "paper_id": "Fxz0aaGSNY",
    "title": "Efficient Multi-modal Dataset Distillation via Analytic Parameter Matching",
    "domain": "applications to computer vision",
    "content": "Multi-modal dataset distillation (MDD) seeks to compress the large-scale multi-modal data, \\eg, images and text, into a compact set of synthetic pairs. Existing methods typically employ a bi-trajectory distillation framework to align the trajectories of expert and student models within each modality. Although effective, this paradigm incurs significant storage and computational overhead due to the large number of checkpoints and the need for double backpropagation, limiting its efficiency and scalability. To overcome these limitations, we propose analytic parameter matching (APM), which directly matches the analytic parameters of the modal projectors rather than the entire trajectory, offering two key advantages: First, instead of storing multiple checkpoints, APM only caches two matrices, which significantly reduces the storage budget. Second, APM avoids the bi-level optimization, as the analytic parameters can be computed in a single forward pass. Theoretically, we establish the connection between these analytic parameters and matrix whitening, clarifying their benefits for MDD.\nEmpirically, APM achieves up to 65$\\times$ storage reduction, 9.6$\\times$ distillation speedup, and scales to 2000 synthetic pairs. Extensive experiments on Flickr30k and MS-COCO demonstrate the effectiveness of APM in cross-modal retrieval tasks, \\eg, 12.8 IR@1 and 17.8 TR@1 under 100-pairs, outperforming existing MDD methods in most scenarios.",
    "key_points": [
      "dataset distillation",
      "multi-modal"
    ],
    "gold_summary": "This paper proposes an efficient method for multimodal dataset distillation by bypassing double backpropagation computation. This was achieved by leveraging an analytic solution of the image/text projection head of the vision-language model."
  },
  {
    "paper_id": "08pxmTLKTT",
    "title": "SmartSAM: Segment Ambiguous Objects like Smart Annotators",
    "domain": "applications to computer vision",
    "content": "Segment Anything Model (SAM) often encounters ambiguity in interactive segmentation, where insufficient user interaction leads to inaccurate segmentation of the target object. Existing approaches primarily address ambiguity through repeated human-model interactions, which are time-consuming due to the inherent latency of human responses. To reduce human efforts, we propose a novel interactive segmentation framework that leverages the model’s inherent capabilities to effectively segment ambiguous objects.\nOur key idea is to create an annotator-like agent to interact with the model. The resulting SmartSAM method mimics intelligent human annotators, resolving ambiguity with a single click and one reference instance. The agent generates multiple prompts around the initial click to simulate diverse annotator behaviors and refines the output masks by iteratively adding click chains in uncertain regions, thereby producing a set of candidate masks. Finally, the agent selects the mask that most closely aligns with the user’s intent, as indicated by the reference instance. Furthermore, we formalize the agent’s behavior as a fuzzy regression problem by quantifying ambiguity using fuzzy entropy. We demonstrate that our agent yields lower entropy than traditional methods, and we establish robustness and sufficiency theorems to ensure effective, human-like decision-making within a bounded range of actions. We evaluate our approach on multiple segmentation benchmarks and demonstrate its superiority over state-of-the-art methods.",
    "key_points": [
      "ambiguity",
      "segment anything model",
      "interactive segmentation"
    ],
    "gold_summary": "This paper proposes a novel interactive segmentation framework that utilizes the model's intrinsic knowledge to segment ambiguous objects effectively."
  },
  {
    "paper_id": "dS9nGa5Mun",
    "title": "Reproducing and Dissecting Denoising Language Models for Speech Recognition",
    "domain": "applications to computer vision",
    "content": "Denoising language models (DLMs) have been proposed\nas a powerful alternative to traditional autoregressive language models (LMs)\nfor automatic speech recognition (ASR),\nmotivated by their ability to use bidirectional context\nand adapt to a specific ASR model's error patterns.\nHowever, the complexity of the DLM training pipeline has hindered wider investigation.\nThis paper presents the first independent, large-scale empirical study of the DLMs paradigm.\nWe build and release a complete, reproducible pipeline to systematically investigate the impact of key design choices.\nWe evaluate dozens of configurations across multiple axes, including various data augmentation techniques\n(e.g., SpecAugment, dropout, mixup),\ndifferent text-to-speech systems,\nand multiple decoding strategies.\nOur comparative analysis in a common subword vocabulary setting\ndemonstrates that our best DLM outperforms our best traditional LM.\nHowever, we observe smaller improvements than those reported in prior character-based work,\nwhich indicates that the DLM's performance is highly conditional on factors such as the vocabulary.\nOur analysis reveals that a key factor for improving performance\nis to condition the DLM on richer information from the ASR's hypothesis space,\nrather than just a single best guess.\nTo this end, we introduce DLM-sum, a novel method for decoding from multiple ASR hypotheses,\nwhich consistently outperforms the previously proposed DSR decoding method.\nWe believe our findings and public pipeline provide a crucial foundation for the community\nto better understand, improve, and build upon this promising class of models.\nThe code is publicly available at https://anonymous.4open.science/r/2025-dlm/.",
    "key_points": [
      "speech recognition",
      "denoising language model",
      "data augmentation",
      "decoding strategies",
      "reproducibility"
    ],
    "gold_summary": "The paper proposes a dataset and method to post-edit ASR output with a denoising non-autoregressive language model."
  },
  {
    "paper_id": "NteaYNay7g",
    "title": "RobuQ: Pushing DiTs to W1.58A2 via Robust Activation Quantization",
    "domain": "applications to computer vision",
    "content": "Diffusion Transformers (DiTs) have recently emerged as a powerful backbone for image generation, demonstrating strong scalability and superior performance compared to U-Net architectures. However, their deployment remains hindered by substantial computational and memory costs. While quantization-aware training (QAT) has shown promise for U-Net architectures, its application to DiTs introduces unique challenges, primarily due to activation sensitivity and distributional complexity. In this work, we identify activation quantization as the principal bottleneck in pushing DiTs to extreme low-bit settings, and present a systematic QAT study of quantization for DiTs, namely RobuQ. We first establish a strong ternary-weight (W1.58A4) DiT baseline. To achieve robust activation quantization, we then propose RobustQuantizer, supported by theoretical analysis showing the Hadamard transform converts unknown per-token distributions into known normal distributions. In addition, we introduce AMPN, the first Activation-only Mixed-Precision Network pipeline for DiTs, which distributes mixed-precision activation to eliminate information bottlenecks, achieves state-of-the-art performance at W1.58A3, and stably supports average precision as low as W1.58A2 without collapse. Extensive experiments on unconditional and conditional image generation show that our framework consistently outperforms prior state-of-the-art quantization methods, achieving highly efficient DiT quantization while preserving generative fidelity. Together, these contributions substantially advance the practical deployment of DiTs in challenging ultra-low bit quantization scenarios.",
    "key_points": [
      "ternarization",
      "diffusion transformer",
      "mixed-precision quantization",
      "quantization"
    ],
    "gold_summary": "This paper focuses on ultra-low-bit quantization for diffusion transformer models. It applies ternary weights across the entire network while assigning different activation precisions to each layer to mitigate information bottlenecks."
  },
  {
    "paper_id": "FStqfhYUSI",
    "title": "Atoms to Events: Categorical Evidence Composition for Video Anomaly Detection",
    "domain": "applications to computer vision",
    "content": "Video anomaly detection (VAD) seeks to identify events that deviate from learned normality. Current Vision–Language Models (VLMs) face significant challenges: anomalies are rare, labels are weak, and visual appearance varies drastically. Mainstream VLMs directly map visual features to events, they overfit to intermediate incidental cues which are present during training and generalize poorly. To address this issue, we propose a categorical view of anomaly understanding that replaces this \"visual features to event\" mapping with a \"visual features to learnable atoms, then to event\" framework that models direct, indirect, and counter evidence cues. Firstly, an Unsupervised Anomalous Period Detector (UAPD) is proposed to identify abnormal periods. Next, a Category-based Atom Miner (CAM) is proposed to map visual features to learned atoms in video segments, and learn the roles of atoms. In inference, CAM provides role-aware indications to VLM which maps meaningful atoms and visual features to event predictions. This framework harnesses meaningful evidence and preserves the generalization capacity of VLMs. Extensive experiments and ablations show consistent gains over strong vision‑only and fine‑tuned VLM baselines.",
    "key_points": [
      "video anomaly detection",
      "vision–language models (vlms)",
      "categorical view",
      "unsupervised anomalous period detector (uapd)",
      "category-based atom miner (cam)"
    ],
    "gold_summary": "The paper introduces an “atoms-to-events” framework that decomposes video anomalies into interpretable evidence atoms before event prediction. It improves both accuracy and interpretability over existing vision–language and vision-only baselines."
  },
  {
    "paper_id": "uYK6GPVg1O",
    "title": "Estimating Semantic Alphabet Size for LLM Uncertainty Quantification",
    "domain": "applications to computer vision",
    "content": "Many black-box techniques for quantifying the uncertainty of large language models (LLMs) rely on repeated LLM sampling, which can be computationally expensive. Therefore, practical applicability demands reliable estimation from few samples. Semantic entropy (SE) is a popular sample-based uncertainty estimator with a discrete formulation attractive for the black-box setting. Recent extensions of semantic entropy exhibit improved LLM hallucination detection, but do so with less interpretable methods that admit additional hyperparameters. For this reason, we revisit the canonical discrete semantic entropy estimator, finding that it underestimates the \"true\" semantic entropy, as expected from theory. We propose a modified semantic alphabet size estimator, and illustrate that using it to adjust discrete semantic entropy for sample coverage results in more accurate semantic entropy estimation in our setting of interest. Furthermore, our proposed alphabet size estimator flags incorrect LLM responses as well or better than recent top-performing approaches, with the added benefit of remaining highly interpretable.",
    "key_points": [
      "large language model",
      "uncertainty quantification",
      "hallucination",
      "entropy",
      "alphabet"
    ],
    "gold_summary": "Authors propose a better (less biased) estimator for semantic-alphabet-size in the semantic-entropy-related methods for UQ estimation in NLG tasks. \nThey show empirically that their semantic-alphabet-size is competitive with some of the SOTA methods."
  },
  {
    "paper_id": "jPFjUehx4i",
    "title": "EVTAR: End-to-End Try on with Additional Unpaired Visual Reference",
    "domain": "applications to computer vision",
    "content": "We propose EVTER, an end-to-end virtual try-on model that incorporates additional reference images. Most existing virtual try-on models rely on complex inputs, such as images with agnostic clothing areas, human pose, densepose, and body keypoints, making them labor-intensive and impractical for real-world applications. In contrast, EVTER addresses these challenges by adopting an end-to-end training strategy, allowing for simple inference with only the source image and target clothing as inputs. The model generates try-on images without the need for masking. Moreover, to enhance try-on quality, our model can utilize additional reference images, inspired by how humans typically select clothing. To enable this capability, we built a dataset with supplementary reference images for training. We evaluate our model on popular benchmarks, and the results validate the effectiveness of our proposed approach.",
    "key_points": [
      "virtual tryon"
    ],
    "gold_summary": "This paper introduces EVTAR, an end-to-end virtual try-on model designed to directly fit a target garment onto a person's image while incorporating additional visual reference images to enhance try-on accuracy and realism."
  },
  {
    "paper_id": "upMIVpe467",
    "title": "Equivariant Splitting: Self-supervised learning from incomplete data",
    "domain": "applications to computer vision",
    "content": "Self-supervised learning for inverse problems allows to train a reconstruction network from noise and/or incomplete data alone. These methods have the potential of enabling learning-based solutions when obtaining ground-truth references for training is expensive or even impossible. In this paper, we propose a new self-supervised learning strategy devised for the challenging setting where measurements are observed via a single incomplete observation model. We introduce a new definition of equivariance in the context of reconstruction networks, and show that the combination of self-supervised splitting losses and equivariant reconstruction networks results in unbiased estimates of the supervised loss. Through a series of experiments on image inpainting, accelerated magnetic resonance imaging, and compressive sensing, we demonstrate that the proposed loss achieves state-of-the-art performance in settings with highly rank-deficient forward models.",
    "key_points": [
      "inverse problems",
      "self-supervised imaging",
      "equivariant neural networks"
    ],
    "gold_summary": "This paper discusses a study of self-supervised method to solve inverse problems, with the approach as designing loss functions with the \"SPLIT\" technique."
  },
  {
    "paper_id": "ogKZnm8F7D",
    "title": "Future Policy Aware Preference Learning for Mathematical Reasoning",
    "domain": "applications to computer vision",
    "content": "Preference learning methods such as Direct Preference Optimization (DPO) have become standard for Large Language Model (LLM) post-training, yet they are often ineffective for mathematical reasoning. A key challenge is the large token overlap between preferred and dispreferred trajectories; lowering the probability of dispreferred trajectories also reduces the probability of shared useful tokens, leading to over-penalization and overall performance collapse. As a mitigation, existing algorithms include the probability of a trajectory under the current policy as a regularization term, which decreases the effect of the gradient when the probability is low. \nHowever, by the time this effect takes hold, useful tokens may have already been over-penalized as the model has begun to degrade.\nTo address this, we propose Future Policy Aware (FPA) preference learning, which replaces the current policy with a future policy in the regularization term. This future policy is estimated via lightweight, logit-space extrapolation from a reference model toward the current model. FPA enables safer training by preemptively regularizing potentially problematic gradients. We apply FPA to DPO, RPO, and SimPER and evaluate them on the MATH and GSM8K benchmarks. FPA yields consistent performance gains, with the largest improvements observed with SimPER, achieving gains of up to 5.75%. \nWe demonstrate that FPA provides proactive regularization while preserving the probability of shared, useful mathematical tokens, and enables longer, degradation-free training with negligible computational overhead. We will release our code publicly upon publication.",
    "key_points": [
      "preference learning",
      "large language models",
      "reasoning"
    ],
    "gold_summary": "This paper proposes Future Policy Aware (FPA) preference learning, as a plug-in weighting strategy of the preferred and dispreferred samples in DPO-style algorithms."
  },
  {
    "paper_id": "ZzH6xDdpTP",
    "title": "Learning on the Job: An Experience-Driven Self-Evolving Agent for Long-Horizon Tasks",
    "domain": "applications to computer vision",
    "content": "Large Language Models have demonstrated remarkable capabilities across diverse domains, yet significant challenges persist when deploying them as AI agents for real-world long-horizon tasks. Existing LLM agents suffer from a critical limitation: they are test-time static and cannot learn from experience, lacking the ability to accumulate knowledge and continuously improve on the job. To address this challenge, we propose MUSE, a novel agent framework that introduces an experience-driven, self-evolving system centered around a hierarchical Memory Module. MUSE organizes diverse levels of experience and leverages them to plan and execute long-horizon tasks across multiple applications. After each sub-task execution, the agent autonomously reflects on its trajectory, converting the raw trajectory into structured experience and integrating it back into the Memory Module. This mechanism enables the agent to evolve beyond its static pretrained parameters, fostering continuous learning and self-evolution. We evaluate MUSE on the long-horizon productivity benchmark TAC. It achieves new SOTA performance by a significant margin using only a lightweight Gemini-2.5 Flash model. Sufficient Experiments demonstrate that as the agent autonomously accumulates experience, it exhibits increasingly superior task completion capabilities, as well as robust continuous learning and self-evolution capabilities. Moreover, the accumulated experience from MUSE exhibits strong generalization properties, enabling zero-shot improvement on new tasks. MUSE establishes a new paradigm for AI agents capable of real-world productivity task automation.\nDemo videos can be found in our supplementary materials.",
    "key_points": [
      "agent framwork",
      "self-evolution",
      "memory mechanism"
    ],
    "gold_summary": "This paper proposes MUSE, an experience-driven agent framework with a hierarchical memory module for self-evolution in long-horizon tasks."
  },
  {
    "paper_id": "DCnYQ59zrt",
    "title": "MIND: Market Interpretation DSL for Unified Market Design and Simulation",
    "domain": "applications to computer vision",
    "content": "Market mechanisms such as auctions and matchings coordinate supply and demand at scale, yet their implementations remain locked in rigid procedural code that hinders iteration and auditing. We introduce the Market Interpretation DSL (MIND), a typed language and toolchain for declarative market specification to achieve unified market design and simulation. MIND comprises (i) a core grammar with a phased Intermediate Representation (IR) and economic safety checks, (ii) a natural language assistant that translates descriptions into DSL with automated diagnostics and safe rewrites, and (iii) rule-based simulation and convex optimization backends. Using synthetic specifications generated across 87 domains with held-out validation, our fine-tuned Llama-3-8B assistant achieves 96.33% semantic correctness, measured as IR equivalence to gold programs, surpassing few-shot GPT-4o at 91.41%. Across second-price auctions, multi-stage auctions, and matching markets, MIND reduces specification complexity by approximately 79% in lines of code compared to Python implementations. In a preregistered within-subjects study with 17 participants, mechanism modifications were completed 4 to 10 times faster using MIND. Code, dataset, and models will be released upon acceptance.",
    "key_points": [
      "market design",
      "domain-specific language",
      "dsl",
      "ai copilot",
      "auctions",
      "matching markets",
      "mechanism design",
      "code generation",
      "symbolic ai",
      "computational economics"
    ],
    "gold_summary": "The paper introduces a Market Interpretation DSL that allows LLM-based simulation to adhere to market-related constraints."
  },
  {
    "paper_id": "TJxRIsc1By",
    "title": "KAN-Semi: A Semi-Supervised Approach Combining Self-Supervised Pre-training, Hierarchical Priors, and Kolmogorov-Arnold Networks for Landmark-based Biometry Estimation",
    "domain": "applications to computer vision",
    "content": "Ultrasound (US)-based biometric estimation is crucial for monitoring labor progression and diagnosing fetal and maternal abnormalities. Reliable biometry estimation relies heavily on accurate landmark localization on standard planes, a process traditionally performed by sonographers. However, manual measurement is time-consuming, operator-dependent, and prone to variability. Although automated segmentation methods based on fully supervised models show promise, they often suffer from multi-stage error accumulation and a lack of expertly annotated data. To address these challenges, we introduce KAN-Semi, a semi-supervised network that combines self-supervised pre-training, hierarchical priors, and Kolmogorov-Arnold Networks (KANs). First, we utilize in-domain self-supervised pre-training with a Masked Autoencoder (MAE) to learn robust, domain-adapted representations for a novel CNN-ViT hybrid backbone. Next, we propose a Hierarchical Guidance Decoder, which encodes symbolic medical priors to regularize the model’s reasoning, progressively guiding it from stable to variable structures. Finally, we explore Kolmogorov-Arnold Network (KAN)-enhanced heads as an alternative to conventional predictors, demonstrating their efficacy in complex spatial regression tasks. We perform extensive experiments on three intrapartum ultrasound datasets collected from 24 medical centers and institutions, showing that our approach significantly outperforms fully supervised models in landmark detection performance. Our work offers a structured framework for designing effective learning systems that integrate self-supervision, knowledge-based architectural design, and emerging network paradigms.",
    "key_points": [
      "semi-supervised learning",
      "self-supervised learning",
      "medical image analysis",
      "landmark detection",
      "kolmogorov-arnold networks (kan)"
    ],
    "gold_summary": "The paper targets landmark localization and quantitative biometry in intrapartum ultrasound, and proposes a two-stage framework **KAN-Semi**. It also introduces two architectural designs: a **Hierarchical Guidance Decoder** and a **KAN-enhanced prediction head**."
  },
  {
    "paper_id": "9zVPsVWUY1",
    "title": "Octic Vision Transformers: Quicker ViTs Through Equivariance",
    "domain": "applications to computer vision",
    "content": "Why are state-of-the-art Vision Transformers (ViTs) not designed to exploit natural geometric symmetries such as 90-degree rotations and reflections? In this paper, we argue that there is no fundamental reason, and what has been missing is an efficient implementation. To this end, we introduce Octic Vision Transformers (octic ViTs) which rely on octic group equivariance to capture these symmetries. In contrast to prior equivariant models that increase computational cost, our octic linear layers achieve 5.33x reductions in FLOPs and up to 8x reductions in memory compared to ordinary linear layers. In full octic ViT blocks the computational reductions approach the reductions in the linear layers with increased embedding dimension. We study two new families of ViTs, built from octic blocks, that are either fully octic equivariant or break equivariance in the last part of the network. Training octic ViTs supervised (DeiT-III) and unsupervised (DINOv2) on ImageNet-1K, we find that they match baseline accuracy while at the same time providing substantial efficiency gains.",
    "key_points": [
      "vision transformers",
      "equivariance",
      "scaling",
      "image classification",
      "vision",
      "deep learning"
    ],
    "gold_summary": "The paper proposes a new, efficient D8 equivariant vision transformer. The authors report extensive experiments which supports their method."
  },
  {
    "paper_id": "KgyyIk59Nx",
    "title": "High-Fidelity and Long-Duration Human Image Animation with Diffusion Transformer",
    "domain": "applications to computer vision",
    "content": "Recent progress in diffusion models has significantly advanced the field of human image animation. While existing methods can generate temporally consistent results for short or regular motions, significant challenges remain, particularly in generating long-duration videos. Furthermore, the synthesis of fine-grained facial and hand details remains under-explored, limiting the applicability of current approaches in real-world, high-quality applications. To address these limitations, we propose a diffusion transformer (DiT)-based framework which focuses on generating high-fidelity and long-duration human animation videos. First, we design a set of hybrid implicit guidance signals, enabling our framework to additionally incorporate detailed face and hand features as guidance. Next, we incorporate the time-aware position shift fusion module, modify the input format within the DiT backbone, and refer to this mechanism as the Position Shift Adaptive Module, which enables video generation of arbitrary length. Finally, we introduce a novel data augmentation strategy and a skeleton alignment model to reduce the impact of human shape variations across different identities. Experimental results demonstrate that our method outperforms existing state-of-the-art approaches, achieving superior performance in both high-fidelity and long-duration human image animation.",
    "key_points": [
      "human image animation",
      "diffusion model",
      "video generation"
    ],
    "gold_summary": "This paper proposes a Diffusion Transformer (DiT) framework for long-duration human image animation. Authors design three modules to stress fidelity (hands/faces), temporal consistency, and cross-identity robustness."
  },
  {
    "paper_id": "BqLGlQF46f",
    "title": "Beyond the Known: An Unknown-Aware Large Language Model for Open-Set Text Classification",
    "domain": "applications to computer vision",
    "content": "Open-set text classification (OSTC) requires models to correctly classify in-distribution (ID) samples while reliably rejecting out-of-distribution (OOD) inputs—an essential capability for real-world NLP systems. Most OSTC methods train on ID data under the closed assumption that all outputs belong to the known label space and then perform OOD detection with the biased representations, which inherently lack awareness of unknowns and thus yield overconfident predictions on OOD inputs. In this work, we present UnLLM, an Unknown-aware Large Language Model for OSTC. Instead of fixing classification to the entire known label space, we reformulate it into a subset-conditioned text generation task: the LLM is prompted with sampled subsets of known labels, and any instance outside the candidate set is explicitly assigned as “unknown”. This reformulation transforms OOD detection from a post-hoc procedure into an intrinsic modeling capability. More importantly, our approach is the first to explicitly incorporate the unknown into classification, enabling systematic modeling of unknowns through a unified representation–logits–inference optimization, which progressively strengthens the model’s capacity to capture open-set risk. Extensive experiments across six benchmarks show that UnLLM consistently outperforms state-of-the-art (SOTA) baselines. Code is available in an anonymous repository: https://anonymous.4open.science/r/UnLLM-03C2.",
    "key_points": [
      "large language models",
      "open-set text classification"
    ],
    "gold_summary": "The paper tackles open-set text classification (OSTC) by making “unknown-class” awareness an explicit, trainable behavior for LLMs via UnLLM, a three-stage pipeline."
  },
  {
    "paper_id": "2EQPpEZtEK",
    "title": "DiSTAR: Diffusion over a Scalable Token Autoregressive Representation for Speech Generation",
    "domain": "applications to computer vision",
    "content": "Recent attempts to interleave autoregressive (AR) sketchers with diffusion-based refiners over continuous speech representations have shown promise, but they remain brittle under distribution shift and offer limited levers for controllability. We introduce DiSTAR, a zero-shot text-to-speech framework that operates entirely in a discrete residual vector quantization (RVQ) code space and tightly couples an AR language model with a masked diffusion model, without forced alignment or a duration predictor. Concretely, DiSTAR drafts block-level RVQ tokens with an AR language model and then performs parallel masked-diffusion infilling conditioned on the draft to complete the next block, yielding long-form synthesis with blockwise parallelism while mitigating classic AR exposure bias. The discrete code space affords explicit control at inference: DiSTAR produces high-quality audio under both greedy and sample-based decoding using classifier-free guidance, supports trade-offs between robustness and diversity, and enables variable bit-rate and controllable computation via RVQ layer pruning at test time. Extensive experiments and ablations demonstrate that DiSTAR surpasses state-of-the-art zero-shot TTS systems in robustness, naturalness, and speaker/style consistency, while maintaining rich output diversity. Audio samples are provided on \\url{https://anonymous.4open.science/w/DiSTAR_demo}.",
    "key_points": [
      "text-to-speech",
      "residual vector quantization",
      "masked diffusion model",
      "autoregressive language model"
    ],
    "gold_summary": "The paper extends DiTAR by replacing continuous code with RVQ codes and use a LLaDA style masked diffusion transformer to predict the next code patch."
  },
  {
    "paper_id": "RDOlvzwSyF",
    "title": "Salient Object Ranking via Cyclical Perception-Viewing Interaction Modeling",
    "domain": "applications to computer vision",
    "content": "Salient Object Ranking (SOR) aims to predict human attention shifts across different salient objects in a scene. Although a number of methods have been proposed for the task, they typically rely on modeling the bottom-up influences of image features on attention shifts. In this work, we observe that when free-viewing an image, humans instinctively browse the objects in such a way as to maximize contextual understanding of the image. This implies a cyclical interaction between content (or story) understanding of the image and attention shift over it. Based on this observation, we propose a novel SOR approach that models this explicit top-down cognitive pathway with two novel modules: a story prediction (SP) module and a guided ranking (GR) module. By formulating content understanding as the image caption generation task, the SP module learns to generate and complete the image captions conditioned on the salient object queries of the GR module, while the GR module learns to detect salient objects and their viewing orders guided by the SP module. Extensive experiments on SOR benchmarks demonstrate that our approach outperforms state-of-the-art SOR methods.",
    "key_points": [
      "saliency ranking",
      "human attention shift modeling"
    ],
    "gold_summary": "The authors propose a Salient Object Ranking (SOR) approach that consists of two modules: the Guided Ranking (GR) module and the Story Prediction (SP) module, whose interaction enhances the overall performance of SOR."
  },
  {
    "paper_id": "3GNaNi9xnt",
    "title": "MIRRORMARK: A Distortion-Free Multi-Bit Watermark for Large Language Models",
    "domain": "applications to computer vision",
    "content": "As large language models (LLMs) become increasingly integral to broad applications such as question answering and content creation, reliable content attribution and accountability have grown increasingly urgent. Watermarking offers a promising approach to identifying AI-generated text. However, existing approaches either provide only a binary provenance signal or perturb the sampling distribution, degrading the text quality; approches that preserve text quality, in turn, often exhibit weak detectability and little robustness. We propose MirrorMark, a multi-bit and distortion-free watermark for LLMs. By mirroring the sampling randomness in a measure-preserving way, MirrorMark embeds multi-bit messages without altering the token probability distribution during generation, and thus text quality is maintained by design. For robustness, we employ a content-based scheduler that partitions the messages into per-position symbols and allocates tokens to each symbol nearly uniformly, allowing limited tokens to carry more symbols while keeping assignments stable under insertions and deletions. We also present a theoretical analysis that models detection error versus the number of pseudorandom draws per generation step, offering interpretability to our empirical results and insights on the design of high-detectability multi-bit watermarks. In our comparisons with state-of-the-art multi-bit baselines, MirrorMark preserves the text quality comparable with non-watermarked text while delivering superior detectability: with 54 bits embedded in 300 tokens, it improves bit accuracy by 8–12\\% and correctly identifies up to 11\\% more watermarked texts when the false positive rate is fixed at 1\\%. These results show that MirrorMark enables practical attribution, offering a scalable path to provenance and accountability in LLM deployment.",
    "key_points": [
      "llm watermark",
      "bias",
      "llm security"
    ],
    "gold_summary": "Dear Area Chair,\n\nThis paper does not use the ICLR official template and should be desk reject. The margin is significant wider than the offical template.\n\nBest regards,\nReviewer"
  },
  {
    "paper_id": "9WtgapSaCv",
    "title": "Beyond Reward Margin: Rethinking and Resolving Likelihood Displacement in Diffusion Models via Video Generation",
    "domain": "applications to computer vision",
    "content": "Direct Preference Optimization (DPO) has shown promising results in aligning generative outputs with human preferences by distinguishing between chosen and rejected samples. However, a critical limitation of DPO is likelihood displacement, where the probabilities of chosen samples paradoxically decrease during training, undermining the quality of generation. Although this issue has been investigated in autoregressive models, its impact within diffusion-based models remains largely unexplored. This gap leads to suboptimal performance in tasks involving video generation. To address this, we conduct a formal analysis of DPO loss through updating policy within the diffusion framework, which describes how the updating of specific training samples influences the model's predictions on other samples. Using this tool, we identify two main failure modes: (1) Optimization Conflict, which arises from small reward margins between chosen and rejected samples, and (2) Suboptimal Maximization, caused by large reward margins. Informed by these insights, we introduce a novel solution named Policy-Guided DPO (PG-DPO), combining Adaptive Rejection Scaling (ARS) and Implicit Preference Regularization (IPR) to effectively mitigate likelihood displacement. Experiments show that PG-DPO outperforms existing methods in both quantitative metrics and qualitative evaluations, offering a robust solution for improving preference alignment in video generation tasks.",
    "key_points": [
      "video generation; reinforcement learning; direct preference optimization; diffusion models"
    ],
    "gold_summary": "The paper provides the analysis of likelihood displacement in diffusion models and introduces Policy-Guided DPO (PG-DPO) — a theoretically grounded, empirically validated method that stabilizes preference alignment for video generation."
  },
  {
    "paper_id": "sL0NpgJRMs",
    "title": "Advancing Sparse Attention in Spiking Neural Networks via Spike-Timing-Based Prioritization",
    "domain": "applications to computer vision",
    "content": "Current Spiking Neural Networks (SNNs) underutilize the temporal dynamics inherent in spike-based processing, relying primarily on rate coding while overlooking precise timing information that provides rich computational cues. We address this by proposing \\textbf{SPARTA} (Spiking Priority Attention with Resource-Adaptive Temporal Allocation), which leverages heterogeneous neuron dynamics and spike-timing information to enable sparse attention mechanisms. SPARTA extracts temporal cues—including firing patterns, spike timing, and inter-spike intervals—to prioritize tokens for processing, achieving 65.4% sparsity through competitive gating. By selecting only the most salient tokens, SPARTA reduces attention complexity from (O(N^{2})) to (O(K^{2})), where (k!\\ll!n). Our approach achieves state-of-the-art accuracy on DVS-Gesture (98.78%) and competitive performance on CIFAR10-DVS (83.06%) and CIFAR-10 (95.3%), demonstrating that spike-timing utilization enables both computational efficiency and competitive accuracy.",
    "key_points": [
      "spiking neural networks",
      "neuromorphic computing",
      "transformer",
      "energy efficiency",
      "sparse attention",
      "temporal coding",
      "event-based vision"
    ],
    "gold_summary": "This paper proposed the Spiking Priority Attention with Resource Adaptive Temporal Allocation (SPARTA) to enable sparse attention mechanisms."
  },
  {
    "paper_id": "gCUW1T9scF",
    "title": "LLM2Token: Distilling Large Language Models into Task-Specific Tokenizer",
    "domain": "applications to computer vision",
    "content": "We present LLM to Tokenizer, a new distrilling method that preserves the prior knowledge from LLMs in the form of tokenizer, diverging from neural network based methods. This simple, intuitive method allows strong performance even only using one-hot encoding and a simgle-layer logistic regression. Based on the generated tokenizer, without any pre-training, surpressing GPT-2 with just 0.01\\% parameters. On event recognition tasks, the L2T method achieves an F1 score of 0.408 while using only 0.1\\% of the parameters compared to previous models. We also observed that stronger foundation models lead to improved tokenizer performance. And long tokenizers can harm the performance since the capacity of single-layer logistic regression is limited. This demonstrates a zero-shot capability of LLMs--through training on internet-scale corpora, they can recognize words that are important for specific tasks. We released all models, codes and the dataset to promote the furture exploration.",
    "key_points": [
      "tokenizer",
      "distrill",
      "large language models (llms)"
    ],
    "gold_summary": "This paper presents LLM2Token (L2T), a novel knowledge distillation paradigm that departs from traditional neural network-based methods by distilling the knowledge of Large Language Models (LLMs) into task-specific tokenizers instead of smaller neural networks."
  },
  {
    "paper_id": "aAyONRMcdB",
    "title": "Search-on-Graph: Iterative Informed Navigation for Large Language Model Reasoning on Knowledge Graphs",
    "domain": "applications to computer vision",
    "content": "Large language models (LLMs) have demonstrated impressive reasoning abilities yet remain unreliable on knowledge-intensive, multi-hop questions---they miss long-tail facts, hallucinate when uncertain, and their internal knowledge lags behind real-world change. Knowledge graphs (KGs) offer a structured source of relational evidence, but existing KGQA methods face fundamental trade-offs: compiling complete SPARQL queries without knowing available relations proves brittle, retrieving large subgraphs introduces noise, and complex agent frameworks with parallel exploration exponentially expand search spaces. To address these limitations, we propose Search-on-Graph (SoG), a simple yet effective framework that enables LLMs to perform iterative informed graph navigation using a single, carefully designed \\textsc{Search} function. Rather than pre-planning paths or retrieving large subgraphs, SoG follows an ``observe, then navigate'' principle: at each step, the LLM examines actual available relations from the current entity before deciding on the next hop. This approaches further adapts seamlessly to different KG schemas and handles high-degree nodes through adaptive filtering. Across six KGQA benchmarks spanning Freebase and Wikidata, SoG achieves state-of-the-art performance using off-the-shelf LLMs without fine-tuning. We demonstrate particularly strong gains on Wikidata benchmarks (+15\\% improvement over previous best methods) alongside consistent improvements on Freebase benchmarks.",
    "key_points": [
      "large language models",
      "reasoning",
      "knowledge graphs"
    ],
    "gold_summary": "The paper “Search-on-Graph: Iterative Informed Navigation for Large Language Model Reasoning on Knowledge Graphs” proposes a novel framework that allows large language models (LLMs) to reason over knowledge graphs through step-by-step navigation."
  },
  {
    "paper_id": "yFaIaj40Fr",
    "title": "Sample Margin-Aware Recalibration of Temperature Scaling",
    "domain": "applications to computer vision",
    "content": "Deep neural networks often exhibit overconfidence despite their high accuracy. Such miscalibration limits reliability in safety-critical domains where trustworthiness are crucial. Post-hoc calibration methods offer a practical solution where popular approaches like Temperature Scaling (TS) apply a single corrective parameter to all samples, failing to address the sample-dependent nature of miscalibration. While more advanced methods attempt to adapt to sample difficulty, they often rely on complex and indirectly learned proxies.\nIn this work, we first identify the \\emph{logit margin} as a direct, simple, and principled indicator of sample hardness. We provide substantial empirical and theoretical evidence that it serves as a more effective indicator of sample hardness than existing proxies. Meanwhile, we identify a fundamental flaw in current methods that optimizing Negative Log-Likelihood can paradoxically degrade calibration. To resolve this, we introduce Huber–SoftECE, a novel and theoretically guaranteed objective that directly minimizes calibration error.\nBuilding on these insights, we propose Sample Margin-Aware Recalibration of Temperature (SMART), a lightweight post-hoc method that learns a minimalistic sample-wise mapping from the logit margin to an optimal temperature, guided by our calibration-centric objective. Extensive experiments show state-of-the-art performance for calibration across diverse architectures and datasets with a minimal inference-time data consumption. The code is available at: \\url{https://anonymous.4open.science/r/SMART-8B11}.",
    "key_points": [
      "confidence calibration",
      "temperature scaling",
      "logit margin",
      "out-of-distribution detection",
      "deep neural networks",
      "deep learning"
    ],
    "gold_summary": "The paper proposed a temperature scaling (TS) calibration method which utilizes the margin between the first and second largest logits as input to a per-sample parameterization of temperature. A soft ECE calibration objective is proposed."
  },
  {
    "paper_id": "aKCYSL14HX",
    "title": "DiskHIVF: Disk-Resident Hierarchical Inverted File Index For Billion-scale Approximate Nearest Neighbor Search",
    "domain": "applications to computer vision",
    "content": "The in-memory algorithms for approximate nearest neighbor search (ANNS) has demonstrated remarkable success. However, as the scale of vector data grows, the memory demands of in-memory indexing become increasingly prohibitive. A promising solution lies in hybrid memory-disk implementations, which offload the bulk of data storage to cost-efficient devices such as Solid State Drives (SSDs) while retaining only frequently accessed data in memory. \nDespite this, existing hybrid memory-disk indexing methods suffer from memory overheads that scale proportionally with the number and dimensionality of the vectors, limiting their memory savings to a modest 5–20$\\times$.\nIn this paper, we introduce the Disk-Resident Hierarchical Inverted File Index (DiskHIVF), a novel hybrid memory-disk indexing algorithm with a memory space complexity of ${O(\\sqrt{N} \\cdot d + N)}$, where ${N}$ is the number of vectors and ${d}$ is their dimensionality. Leveraging its superior space complexity, DiskHIVF achieves several hundred times memory savings compared to the original vectors, and 10–30$\\times$ reduction compared to state-of-the-art methods. \nExperimental results on four different datasets demonstrate that DiskHIVF is 1.2-2.3$\\times$ faster than the state-of-the-art hybrid indexing solutions at achieving the same recall quality of 90\\%. These results indicate that our approach can significantly reduce the overhead of machine resources while maintaining high search performance.",
    "key_points": [
      "billion-scale;disk-resident;approximate nearest neighbor search;"
    ],
    "gold_summary": "The paper proposes a two-layer hierarchical inverted index for billion-scale approximate nearest neighbor (ANN) search, aiming to reduce memory consumption. Experimental results indicate a 10–30× memory reduction compared to state-of-the-art methods."
  },
  {
    "paper_id": "d2Bx55mOgh",
    "title": "TerraCodec: Compressing Earth Observations",
    "domain": "applications to computer vision",
    "content": "Earth observation (EO) satellites produce massive streams of multispectral image time series, posing pressing challenges for storage and transmission. Yet, learned EO compression remains fragmented, lacking publicly available pretrained models and misaligned with advances in compression for natural imagery. Image codecs overlook temporal redundancy, while video codecs rely on motion priors that fail to capture the radiometric evolution of largely static scenes. We introduce TerraCodec (TEC), a family of learned codecs tailored to EO. TEC includes efficient image-based variants adapted to multispectral inputs, as well as a Temporal Transformer model (TEC-TT) that leverages dependencies across time. To overcome the fixed-rate setting of today's neural codecs, we present Latent Repacking, a novel method for training flexible-rate transformer models that operate on varying rate-distortion settings. Trained on Sentinel-2 data, TerraCodec outperforms classical codecs, achieving 3-10x stronger compression at equivalent image quality. Beyond compression, TEC-TT enables zero-shot cloud inpainting, surpassing state-of-the-art methods on the AllClear benchmark. Our results establish bespoke, learned compression algorithms as a promising direction for Earth observation. Code and model weights will be released under a permissive license.",
    "key_points": [
      "earth observation",
      "compression",
      "pretraining"
    ],
    "gold_summary": "TerraCodec targets EO compression with three models (FP/ELIC/TT) and a single-checkpoint variable-rate variant (FlexTEC) via Latent Repacking. Experiments on Sentinel-2 show RD gains vs. JPEG/JPEG2000/WebP/HEVC, plus zero-shot cloud removal and downstream robustness."
  },
  {
    "paper_id": "zW1U6SW9ra",
    "title": "Compressed Map Priors for 3D Perception",
    "domain": "applications to computer vision",
    "content": "Human drivers rarely travel where no person has gone before.\nAfter all, thousands of drivers use busy city roads every day, and only one can claim to be the first.\nThe same holds for autonomous computer vision systems.\nThe vast majority of the deployment area of an autonomous vision system will have been visited before.\nYet, most autonomous vehicle vision systems act as if they are encountering each location for the first time.\nIn this work, we present Compressed Map Priors, a simple but effective framework to learn spatial priors from historic traversals.\nThe map priors use a binarized hashmap that requires only 32 KB/sq km, a 20x reduction compared to storing features densely.\nCompressed Map Priors easily integrate into leading 3D perception systems at little to no extra computational costs, and lead to a significant and consistent improvement in 3D object detection on the nuScenes dataset across several architectures.",
    "key_points": [
      "3d perception",
      "autonomous driving"
    ],
    "gold_summary": "This paper presents a framework for incorporating historical context into perception models with Compressed Map Priors, which employs a multi-resolution hash-based spatial encoding with binary quantization to efficiently store and retrieve prior spatial information."
  },
  {
    "paper_id": "4WU3cG29Qp",
    "title": "AnyMS: Bottom-up Attention Decoupling for Layout-guided and Training-free Multi-subject Customization",
    "domain": "applications to computer vision",
    "content": "Multi-subject customization aims to synthesize multiple user-specified subjects into a coherent image. To address issues such as subjects missing or conflicts, recent works incorporate layout guidance to provide explicit spatial constraints. However, existing methods still struggle to balance three critical objectives: text alignment, subject identity preservation, and layout control, while the reliance on additional training further limits their scalability and efficiency. In this paper, we present AnyMS, a novel training-free framework for layout-guided multi-subject customization. AnyMS leverages three input conditions: text prompt, subject images, and layout constraints, and introduces a bottom-up dual-level attention decoupling mechanism to harmonize their integration during generation. Specifically, global decoupling separates cross-attention between textual and visual conditions to ensure text alignment. Local decoupling confines each subject’s attention to its designated area, which prevents subject conflicts and thus guarantees identity preservation and layout control. Moreover, AnyMS employs pre-trained image adapters to extract subject-specific features aligned with the diffusion model, removing the need for subject learning or adapter tuning. Extensive experiments demonstrate that AnyMS achieves state-of-the-art performance, supporting complex compositions and scaling to a larger number of subjects.",
    "key_points": [
      "computer vision",
      "diffusion model",
      "multi-subject customization"
    ],
    "gold_summary": "This paper proposes a multi-subject customization method that designs global and local decoupling mechanisms to ensure both text alignment and spatial control."
  },
  {
    "paper_id": "NpkI32QYTI",
    "title": "A Step towards Efficient Waste Segmentation for Automated Waste Recycling in Cluttered Background",
    "domain": "applications to computer vision",
    "content": "Rapid expansion of urban areas and population growth is causing an immense increase in waste production, which demands the need for efficient and automated waste management. In this scenario, automated waste recycling that utilizes deep learning methods to separate the recyclable waste objects may emerge as a savior to humanity. Recent deep learning approaches for automated waste recycling provide promising waste segmentation performance in cluttered scenarios. However, these methods rely on large backbone networks that are inefficient for automated waste recycling systems. To this end, we propose an efficient waste segmentation network, where the spatial context module enhances localized structural dependencies in the spatial domain, and the spectral context module subsequently captures global contextual relationships in the frequency domain. This cascaded design allows the network to progressively leverage both local and global representations across complementary domains to highlight the semantic information necessary for effective segmentation of waste objects in cluttered scenes. \nFurthermore, our auxiliary feature enhancement focuses on structural information to enhance the target objects' boundaries and blob amplification for better segmentation.\nExtensive experimentation on two challenging waste segmentation datasets including ZeroWaste-f and SpectralWaste reveals the merits of the proposed method.",
    "key_points": [
      "waste recycling",
      "multi-scale feature aggregation",
      "spectral domain",
      "difference of gaussian",
      "feature enhancement",
      "semantic segmentation"
    ],
    "gold_summary": "This work focuses on the task of waste segmentation. Instead of using large vision foundation models, the authors propose a new architecture, EWSegNet, for efficient waste segmentation. Experiments are conducted on waste datasets."
  },
  {
    "paper_id": "gLCKZEjmWg",
    "title": "Sample by Step, Optimize by Chunk: Chunk-Level GRPO for Text-to-Image Generation",
    "domain": "applications to computer vision",
    "content": "Group Relative Policy Optimization (GRPO) has shown strong potential for flow-matching-based text-to-image (T2I) generation, but it suffers from two key limitations: inaccurate advantage assignment, and the neglect of temporal dynamics of generation. In this work, we argue that shifting the optimization paradigm from the step level to the chunk level can effectively alleviate these issues. Building on this idea, we propose Chunk-GRPO, the first chunk-level GRPO-based approach for T2I generation. The central insight is to group consecutive steps into coherent 'chunk’s that capture the intrinsic temporal dynamics of flow matching, and to optimize policies at the chunk level. In addition, we introduce an optional weighted sampling strategy to further enhance performance. Extensive experiments show that Chunk-GRPO achieves superior results in both preference alignment and image quality, highlighting the promise of chunk-level optimization for GRPO-based methods.",
    "key_points": [
      "grpo",
      "text-to-image generation",
      "reinforcement learning",
      "flow matching"
    ],
    "gold_summary": "This paper proposes a method that involves fine-tuning the image generation process at the chunk level instead of at separate timesteps. Furthermore, it introduces a weighted sampling strategy derived from the proposed chunk split design."
  },
  {
    "paper_id": "hESsatbRee",
    "title": "Mitigating Catastrophic Forgetting in Target Language Adaptation of LLMs via Source-Shielded Updates",
    "domain": "applications to computer vision",
    "content": "Expanding the linguistic diversity of instruct large language models (LLMs) is crucial for global accessibility but is often hindered by the reliance on costly specialized target language labeled data and catastrophic forgetting during adaptation. We tackle this challenge under a realistic, low-resource constraint: adapting instruct LLMs using only unlabeled target language data. We introduce **S**ource-**S**hielded **U**pdates (**SSU**), a selective parameter update strategy that proactively preserves source knowledge. Using a small set of source data and a parameter importance scoring method, SSU identifies parameters critical to maintaining source abilities. It then applies a column-wise freezing strategy to protect these parameters before adaptation. Experiments across five typologically diverse languages and 7B and 13B models demonstrate that SSU successfully mitigates catastrophic forgetting. It reduces performance degradation on monolingual source tasks to just 3.4% (7B) and 2.8% (13B) on average, a stark contrast to the 20.2% and 22.3% from full fine-tuning. SSU also achieves target-language performance highly competitive with full fine-tuning, outperforming it on all benchmarks for 7B models and the majority for 13B models.",
    "key_points": [
      "cross-lingual transfer",
      "language adaptation",
      "continual pre-training",
      "multilinguality",
      "catastrophic forgetting",
      "instruct llm",
      "llm"
    ],
    "gold_summary": "The paper aims to mitigate catastrophic forgetting in LLM adaptation by identifying and freezing a subset of the parameters during adaptation. Empirically, the proposed approach has better performance than some existing adaptation methods."
  },
  {
    "paper_id": "mUIGdUTtk2",
    "title": "Cross-Domain Lossy Compression via Rate- and Classification-Constrained Optimal Transport",
    "domain": "applications to computer vision",
    "content": "We study cross-domain lossy compression, where the encoder observes a degraded source while the decoder reconstructs samples from a distinct target distribution. The problem is formulated as constrained optimal transport with two constraints on compression rate and classification loss. With shared common randomness, the one-shot setting reduces to a deterministic transport plan, and we derive closed-form distortion-rate-classification (DRC) and rate-distortion-classification (RDC) tradeoffs for Bernoulli sources under Hamming distortion. In the asymptotic regime, we establish analytic DRC/RDC expressions for Gaussian models under mean-squared error. The framework is further extended to incorporate perception divergences (Kullback-Leibler and squared Wasserstein), yielding closed-form distortion-rate-perception-classification (DRPC) functions. To validate the theory, we develop deep end-to-end compression models for super-resolution (MNIST), denoising (SVHN, CIFAR-10, ImageNet, KODAK), and inpainting (SVHN) problems, demonstrating the consistency between the theoretical results and empirical performance.",
    "key_points": [
      "lossy compression",
      "image compression",
      "image restoration",
      "image inpainting",
      "optimal transport",
      "multi-task learning",
      "rate-distortion-perception tradeoff",
      "rate-distortion-classification tradeoff",
      "deep learning",
      "unsupervised learning"
    ],
    "gold_summary": "The paper models \"cross-domain lossy compression\" as a Constrained Optimal Transport problem. It derives closed-form expressions for the tradeoffs between Distortion-Rate-Classification (DRC) and Rate-Distortion-Classification (RDC)."
  },
  {
    "paper_id": "ZAwqNXc2V5",
    "title": "Forging a Masterpiece from Any Face: A Universal Framework for Face Stylization",
    "domain": "applications to computer vision",
    "content": "The canonical challenge in face stylization lies in disentangling high-level semantic\ncontent, such as identity, from low-level stylistic attributes. Prevailing methods,\nincluding recent diffusion-based models, often fail to achieve a robust separation,\nresulting in an undesirable trade-off between style fidelity and content preservation.\nTo address these challenges, we introduce **StyleFace**, a novel framework that\ntreats face stylization as a targeted statistical transfer within a disentangled feature\nspace. Our approach is a cohesive pipeline that begins with a disentangled attention\nmodule, which orthogonally projects content and style information into separate,\ncontrollable embeddings. This separation is critical, enabling our method’s core:\na statistical style injection layer that manipulates feature distributions to preserve\nidentity while implanting style. To guide this transfer and ensure global coherence,\nthe entire process is optimized using a perceptually-aligned adversarial objective\nthat operates not on raw pixels, but on the high-level feature manifold of a Vision\nTransformer (ViT), enforcing perceptual and stylistic consistency. This synergistic\ndesign allows StyleFace to achieve an unprecedented balance between identity\npreservation and style fidelity, with comprehensive experiments demonstrating that\nour model consistently outperforms state-of-the-art methods",
    "key_points": [
      "face stylization",
      "diffusion model",
      "identity preservation"
    ],
    "gold_summary": "This paper introduces StyleFace, a new framework that treats face stylization as a targeted statistical transfer within a disentangled feature space. Experiments demonstrating that the proposed model outperforms state-of-the-art methods"
  },
  {
    "paper_id": "PJH4DhtksK",
    "title": "EgoExo-Con: Exploring View-Invariant Video Temporal Understanding",
    "domain": "applications to computer vision",
    "content": "Can Video-LLMs achieve consistent temporal understanding when videos capture the same event from different viewpoints? To study this, we introduce EgoExo-Con (Consistency), a benchmark of comprehensively synchronized egocentric and exocentric video pairs with human-refined queries in natural language. EgoExo-Con emphasizes two temporal understanding tasks: Temporal Verification and Temporal Grounding. It evaluates not only correctness but consistency across viewpoints. Our analysis reveals two critical limitations of existing Video-LLMs: (1) models often fail to maintain consistency, with results far worse than their single-view performances. (2) When naively finetuned with synchronized videos of both viewpoints, the models show improved consistency but often underperform those trained on a single view. For improvements, we propose View-GRPO, a novel reinforcement learning framework that effectively strengthens view-specific temporal reasoning while encouraging consistent comprehension across viewpoints. Our method demonstrates its superiority over naive SFT and GRPO, especially for improving cross-view consistency. All resources will be made publicly available.",
    "key_points": [
      "video large language models;"
    ],
    "gold_summary": "The paper introduces evaluation benchmark EgoExo-Con to evaluate cross-view video temporal understanding. The authors propose View-GRPO and construct View30K, to explicitly enhance temporal reasoning."
  },
  {
    "paper_id": "ZOuU0udyA4",
    "title": "MedAgent-Pro: Towards Evidence-based Multi-modal Medical Diagnosis via Reasoning Agentic Workflow",
    "domain": "applications to computer vision",
    "content": "Modern clinical diagnosis relies on the comprehensive analysis of multi-modal patient data, drawing on medical expertise to ensure systematic and rigorous reasoning. Recent advances in Vision–Language Models (VLMs) and agent-based methods are reshaping medical diagnosis by effectively integrating multi-modal information. However, they often output direct answers and empirical-driven conclusions without clinical evidence supported by quantitative analysis, which compromises their reliability and hinders clinical usability. \nHere we propose MedAgent-Pro, an agentic reasoning paradigm that mirrors modern diagnosis principles via a hierarchical diagnostic workflow, consisting of disease-level standardized plan generation and patient-level personalized step-by-step reasoning. To support disease-level planning, a retrieval-augmented generation agent is designed to access medical guidelines for alignment with clinical standards.  For patient-level reasoning, MedAgent-Pro leverages professional tools such as visual models to take various actions to analyze multi-modal input, and performs evidence-based reflection to iteratively adjust memory, enforcing rigorous reasoning throughout the process. Extensive experiments across a wide range of anatomical regions, imaging modalities, and diseases demonstrate the superiority of MedAgent-Pro over mainstream VLMs, agentic systems and leading expert models. Ablation studies and expert evaluation further confirm its robustness and clinical relevance. Anonymized code link is available in the reproducibility statement.",
    "key_points": [
      "medical ai",
      "agentic ai"
    ],
    "gold_summary": "The paper introduces MedAgent-Pro, an agentic reasoning workflow designed to emulate evidence-based clinical diagnosis. The system operates on a hierarchical structure, using planning, RAG and reasoning agents to ensure reliability."
  },
  {
    "paper_id": "RTTYGeC2Io",
    "title": "STream3R: Scalable Sequential 3D Reconstruction with Causal Transformer",
    "domain": "applications to computer vision",
    "content": "We present STream3R, a novel approach to 3D reconstruction that reformulates pointmap prediction as a decoder-only Transformer problem. Existing state-of-the-art methods for multi-view reconstruction either depend on expensive global optimization or rely on simplistic memory mechanisms that scale poorly with sequence length. In contrast, STream3R introduces a streaming framework that processes image sequences efficiently using causal attention, inspired by advances in modern language modeling. By learning geometric priors from large-scale 3D datasets, STream3R generalizes well to diverse and challenging scenarios, including dynamic scenes where traditional methods often fail. Extensive experiments show that our method consistently outperforms prior work across both static and dynamic scene benchmarks. Moreover, STream3R is inherently compatible with LLM-style training infrastructure, enabling efficient large-scale pretraining and fine-tuning for various downstream 3D tasks. Our results underscore the potential of causal Transformer models for online 3D perception, paving the way for real-time 3D understanding in streaming environments.",
    "key_points": [
      "monocular and video 3d reconstruction"
    ],
    "gold_summary": "This paper introduces a streaming version of VGGT, which can process image sequences efficiently using causal attention.\nThe authors conduct extensive experiments to show the effectiveness and advantages of their method on various tasks."
  },
  {
    "paper_id": "SxjWFRmFT2",
    "title": "MaskCaptioner: Learning to jointly segment and caption object trajectories in videos",
    "domain": "applications to computer vision",
    "content": "Dense Video Object Captioning (DVOC) is the task of jointly detecting, tracking, and captioning object trajectories in a video, requiring the ability to understand spatio-temporal details and describe them in natural language.\nDue to the complexity of the task and the high cost associated with manual annotation, previous approaches resort to disjoint training strategies, potentially leading to suboptimal performance.\nTo circumvent this issue, we propose to generate captions about spatio-temporally localized entities leveraging a state-of-the-art VLM. \nBy extending the LVIS and LV-VIS datasets with our synthetic captions (LVISCap and LV-VISCap), we train MaskCaptioner, an end-to-end model capable of jointly detecting, segmenting, tracking and captioning object trajectories. \nMoreover, with pretraining on LVISCap and LV-VISCap, MaskCaptioner achieves state-of-the-art DVOC results on three existing benchmarks, VidSTG, VLN and BenSMOT.",
    "key_points": [
      "computer vision",
      "video instance segmentation",
      "multi-object tracking",
      "video captioning",
      "video understanding"
    ],
    "gold_summary": "This paper proposes to generate spatio-temporally localized entity captions with VLM for the task of dense video object captioning, thereby jointly detecting, segmenting, tracking and captioning object trajectories."
  },
  {
    "paper_id": "ZgCCDwcGwn",
    "title": "AgentGym-RL: An Open-Source Framework to Train LLM Agents for Long-Horizon Decision Making via Multi-Turn RL",
    "domain": "applications to computer vision",
    "content": "Training LLM agents for complex multi-turn decision-making tasks requires extensive exploration within their environment, with reinforcement learning (RL) as a natural way. However, the open-source community currently lacks a unified RL framework capable of training agents from scratch across diverse and realistic environments. To bridge this gap, we introduce AgentGym-RL, a modular and decoupled framework specifically designed for RL-based agent in multi-turn decision-making tasks. It offers high flexibility and extensibility, supports mainstream RL algorithms, and spans a broad range of real-world scenarios. To effectively train agents for challenging tasks, we argue that they are required to expand external interactions with the environment, rather than relying solely on internal reasoning. Nevertheless, training agents for long-horizon interaction with vanilla methods often faces challenges like training instability. To this end, we propose ScalingInter-RL, a staged training approach for stable long-horizon RL training. It starts with short-horizon interaction to establish foundational policies and progressively expands them to encourage deeper exploration. Extensive experiments show that agents trained with our method achieve performance on par with—or even surpass—commercial counterparts like OpenAI o3 and Gemini-2.5-Pro across 27 tasks in diverse environments. We share key insights and will release the full framework, including code and datasets, to empower the community in building the next generation of intelligent agents.",
    "key_points": [
      "large language model",
      "llm-based agent",
      "decision-making"
    ],
    "gold_summary": "This work introduces a new framework for multi-turn LLM RL and a multi-staged training approach for long-horizon RL by progressively scaling interaction lengths. The results are strong relative to baselines, often outperforming much larger models."
  },
  {
    "paper_id": "EdQzLC0Zra",
    "title": "MetaSpatial: Reinforcing 3D Spatial Reasoning in VLMs for the Metaverse",
    "domain": "applications to computer vision",
    "content": "We present MetaSpatial, the first reinforcement learning (RL) framework for enhancing 3D spatial reasoning in vision-language models (VLMs), enabling real-time 3D scene layout generation without post-processing. MetaSpatial addresses two key challenges: (i) the need for extensive post-processing, as existing VLMs lack inherent 3D spatial reasoning to generate realistic layouts; and (ii) the inefficiency of supervised fine-tuning (SFT) for layout generation due to scarcity of perfect annotations. Our core contribution is the 3D Spatial Policy Optimization (3D-SPO) algorithm, which incorporates physics-aware modulation into advantage estimates at the object level and trajectory-level reward from a training-only multi-turn refinement pipeline. This design enhances temporal credit assignment and encourages spatially consistent policy learning. Empirical evaluations across models of varying scales demonstrate that MetaSpatial improves spatial coherence, physical plausibility, and formatting stability, leading to more realistic and functionally coherent object placements applicable to metaverse environments.",
    "key_points": [
      "spatial reasoning",
      "vision language model"
    ],
    "gold_summary": "This paper introduces a novel RL framework for layout generation from vision-language models. It outperforms several existing VLLMs including both open-weight and API-based and training paradigms over one layout generation benchmark."
  },
  {
    "paper_id": "nBCApflsHM",
    "title": "RegMean++: Enhancing Effectiveness and Generalization of Regression Mean for Model Merging",
    "domain": "applications to computer vision",
    "content": "Model merging aims to combine task-specific models into a unified model that is capable of multi-tasking, without any computational overhead of re-training. Regression Mean (RegMean), an approach that formulates model merging as a linear regression problem, aims to find the optimal weights for each linear layer in the merge model by minimizing the discrepancy in predictions between the merge and candidate models. RegMean provides a precise closed-form solution for the merging problem; therefore, it offers explainability and computational efficiency. However, RegMean merges each linear layer independently, overlooking how the features and information in the earlier layers propagate through the layers and influence the final prediction in the merge model. In this paper, we introduce RegMean++, a simple yet effective alternative to RegMean, that explicitly incorporates both intra- and cross-layer dependencies between merge models' layers into RegMean's objective. By accounting for these dependencies, RegMean++ better captures the behaviors of the merge model. Extensive experiments demonstrate that RegMean++ consistently outperforms RegMean across diverse settings, including in-domain (ID) and out-of-domain (OOD) generalization, sequential merging, large-scale tasks, and robustness under several types of distribution shifts. Furthermore, RegMean++ achieves competitive or state-of-the-art performance compared to various recent advanced model merging methods.",
    "key_points": [
      "model merging",
      "image classification",
      "regression mean for model mering"
    ],
    "gold_summary": "This paper proposes a method called RegMean++ for multi-task model merging, which is built upon the previous RegMean work."
  },
  {
    "paper_id": "FAgro0MDDp",
    "title": "High-Fidelity Human Motion Generation with Motion Quality Feedbacks",
    "domain": "applications to computer vision",
    "content": "Text-to-motion generation aims to synthesize realistic human motions from natural language descriptions. Prevailing approaches typically condition generative models on embeddings from the pre-trained CLIP text encoder. However, a fundamental discrepancy exists: CLIP's embeddings are optimized for static visual semantics, failing to capture the dynamic nuances essential for motion, consequently leading to suboptimal generation quality. To bridge this semantic gap, we propose AdaQF, a novel diffusion-based framework that enables the autonomous and efficient adaptation of the CLIP text encoder through feedback-driven co-optimization. AdaQF introduces a quality feedback loop, where semantic consistency constraints, between the generated motion, the conditioning text, and the ground truth motion, guide the fine-tuning of the CLIP encoder via low-rank adaptation. This process yields AdaCLIP, a motion-specialized text encoder that produces semantically rich and  dynamic-aware embeddings. Our framework delivers advantages from three perspectives: it achieves state-of-the-art performance on standard benchmarks, achieving state-of-the-art results with an FID of 0.039 and an R-Precision of 0.888 on the HumanML3D database; it facilitates dramatically faster convergence (up to 8x); moreover, the resulting AdaCLIP module demonstrates remarkable transferability, serving as a versatile drop-in replacement that elevates the performance of various motion generation models including the VQ-VAE-based and latent diffusion-based ones, thus presenting a general and efficient solution for high-fidelity text-to-motion synthesis. The code of this paper will be released.",
    "key_points": [
      "human motion generation; text-to-motion generation"
    ],
    "gold_summary": "This paper introduces an innovative framework for human motion generative model, which mainly focuses on text embedding. The proposed method achieves noticeable improvement while significantly reduces the time cost of covergence."
  },
  {
    "paper_id": "3eN8zaMN8G",
    "title": "DeepPersona: A Generative Engine for Scaling Deep Synthetic Personas",
    "domain": "applications to computer vision",
    "content": "Simulating human profiles by instilling personas into large language models (LLMs) is rapidly transforming research in personalization, social simulation, and human-AI alignment. However, most existing synthetic personas remain shallow and simplistic, capturing minimal attributes and failing to reflect the rich complexity and diversity of real human identities. We introduce DeepPersona, a scalable generative engine for synthesizing narrative-complete synthetic personas through a two-stage, taxonomy-guided method. First, we algorithmically construct the largest-ever human-attribute taxonomy, comprising over hundreds of hierarchically-organized attributes, by systematically mining thousands of real user-ChatGPT conversations. Second, we progressively sample attributes from this taxonomy, conditionally generating coherent and realistic personas, averaging hundreds of structured attributes and roughly 1 MB of narrative text, two orders of magnitude deeper than prior works. Intrinsic evaluations confirm significant improvements in attribute diversity (32% higher coverage) and profile uniqueness (44% greater) compared to state-of-the-art baselines. Extrinsically, our personas enhance GPT-4.1-mini’s personalized Q&A accuracy by 11.6% average on ten metrics, and substantially narrow (by 32%) the gap between simulated LLM ``citizens'' and authentic human responses in social surveys. DeepPersona thus provides a rigorous, scalable, and privacy-free platform for high-fidelity human simulation and personalized AI research.",
    "key_points": [
      "synthetic data generation",
      "synthetic personas",
      "persona generation",
      "human simulation",
      "llm personalization",
      "social simulation",
      "large language models"
    ],
    "gold_summary": "This paper introduces DEEPPERSONA, a two-stage generative framework for creating synthetic personas."
  },
  {
    "paper_id": "tlM5H8wyhc",
    "title": "Attention Misalignment Attacks: Targeting Cross-Modal Attention in Multimodal Large Language Models for Adversarial Examples",
    "domain": "applications to computer vision",
    "content": "Multimodal large language models (MLLMs) have achieved impressive performance across a wide range of multimodal understanding tasks. However, their growing deployment raises concerns about robustness under adversarial conditions. Existing adversarial attacks on MLLMs predominantly focus on disrupting the global semantic alignment between image and text by optimizing over joint embeddings or globally aggregated image/text token representations. We observe that such methods often fail to generate effective adversarial examples for fine-grained tasks such as VQA (Visual Question Answering), especially when the questions aim at detailed understanding of particular regions in the image, which requires precise alignment between image regions and textual answers for MLLMs. To address this, we propose Attention Misalignment Attack (AMA), a novel plug-and-play attack method that is highly compatible with existing attack objectives—it can be easily integrated by combining its attention misalignment loss with other attack losses. AMA operates by extracting attention maps from each decoding step of the MLLM and optimizing the divergence between target and adversarial attention patterns, guided by semantic similarity. This forces the model to attend to irrelevant regions, effectively misguiding its answer generation process even towards fine-grained questions. To improve efficiency, we further introduce FastAMA, a lightweight variant that avoids autoregressive decoding and instead uses a single forward pass to extract self-attention from the input tokens. Experiments show that our method significantly enhances the performance of existing attack methods across multiple tasks, especially on the more challenging instances within VQA datasets.",
    "key_points": [
      "adversarial attack",
      "multimodal large language model",
      "attention mechanism"
    ],
    "gold_summary": "The paper focuses on adversarial attacks of MLLMs, and it proposes a mis-alignment adversarial attack to perturb MLLM hidden embeddings for generating better attack performance."
  },
  {
    "paper_id": "DLqs8GnD96",
    "title": "VoxelPrompt: A Vision Agent for End-to-End Medical Image Analysis",
    "domain": "applications to computer vision",
    "content": "We present VoxelPrompt, an end-to-end image analysis agent that tackles free-form radiological tasks. Given any number of volumetric medical images and a natural language prompt, VoxelPrompt integrates a language model that generates executable code to invoke a jointly-trained, adaptable vision network. This code further carries out analytical steps to address practical quantitative aims, such as measuring the growth of a tumor across visits. The pipelines generated by VoxelPrompt automate analyses that currently require practitioners to painstakingly combine multiple specialized vision and statistical tools. We evaluate VoxelPrompt using diverse neuroimaging tasks and show that it can delineate hundreds of anatomical and pathological features, measure complex morphological properties, and perform open-language analysis of lesion characteristics. VoxelPrompt performs these objectives with an accuracy similar to that of specialist single-task models for image analysis, while facilitating a broad range of compositional biomedical workflows.",
    "key_points": [
      "vision-language agent",
      "medical image analysis",
      "neuroimaging"
    ],
    "gold_summary": "This paper presents VoxelPrompt, a system that combines a language model agent with a jointly-trained vision network to perform complex neuroimaging analysis tasks."
  },
  {
    "paper_id": "5i6eu9w6aw",
    "title": "Understanding-in-Generation: Reinforcing Generative Capability of Unified Model via Infusing Understanding into Generation",
    "domain": "applications to computer vision",
    "content": "Recent works have made notable advancements in enhancing unified models for text-to-image generation through the Chain-of-Thought (CoT). However, these reasoning methods separate the processes of understanding and generation, which limits their ability to guide the reasoning of unified models in addressing the deficiencies of their generative capabilities. To this end, we propose a novel reasoning framework for unified models, **Understanding-in-Generation (UiG)**, which harnesses the robust understanding capabilities of unified models to reinforce their performance in image generation. The core insight of our UiG is to **integrate generative guidance by the strong understanding capabilities during the reasoning process, thereby mitigating the limitations of generative abilities**. To achieve this, we introduce \"*Image Editing*\" as a bridge to infuse understanding into the generation process. Initially, we verify the generated image and incorporate the understanding of unified models into the editing instructions. Subsequently, we enhance the generated image step by step, gradually infusing the understanding into the generation process. Our UiG framework demonstrates a significant performance improvement in text-to-image generation over existing text-to-image reasoning methods, *e.g.*, a **3.92% gain** on the long prompt setting of the TIIF benchmark. *The project code is available in the Supplementary Materials.*",
    "key_points": [
      "text-to-image reasoning",
      "unified model"
    ],
    "gold_summary": "The paper proposes Understanding-in-Generation, an effective reasoning framework designed to mitigate the limitations of generative capabilities by infusing understanding guidance."
  },
  {
    "paper_id": "fJY2fKDqJM",
    "title": "Interactive Multi-event Video Retrieval with Context Integration and Position Constraint",
    "domain": "applications to computer vision",
    "content": "Interactive video retrieval aims to progressively refine queries through multi-round interactions between the user and the system. Existing methods focus on pre-trimmed videos that provide captions that well describe the gist of the video content. In real-world scenarios, however, videos typically contain a sequence of unrelated and discontinuous events, while a query usually refers to a single event. This mismatch introduces significant challenges, including sensitivity to irrelevant content, lack of context exploitation, and insufficient position exploration. \nMotivated by this, we propose **CIPC**, a tailored interactive video retrieval framework with Context Integration and Position Constraint for multi-event videos. CIPC adaptively segments videos into event-consistent units, supports progressive interactions that exploit contextual information, and incorporates a position constraint to re-weight candidate segments by temporal distance, promoting better temporal alignment with the query. Extensive experiments and a user simulation study demonstrate the effectiveness and robustness of our approach, yielding 4.1\\%–6.7\\% R@1 improvements on three widely used benchmarks.",
    "key_points": [
      "interactive retrieval",
      "text-to-video retrieval",
      "multi-event video retrieval"
    ],
    "gold_summary": "This paper proposes CIPC, a framework for interactive video retrieval over multi-event/untrimmed videos. CIPC segments videos into semantically coherent events adaptively, enables progressive multi-round interaction with context integration, and introduces a position constrain."
  },
  {
    "paper_id": "uKPdSZuvUJ",
    "title": "I$^2$C: Intra- and Inter-modality Consistency Learning for Multimodal Sentiment Analysis",
    "domain": "applications to computer vision",
    "content": "Multimodal sentiment analysis (MSA) aims to predict human sentiments by integrating signals from different modalities such as text, video, and audio. However, sentiment cues are often semantically inefficient—exhibiting inconsistency within and across modalities—that hinders robust understanding and inflates computation. In this paper, we propose I$^2$C, a framework that explicitly models Intra- and Inter-modality Consistency to guide effective and efficient sentiment prediction. I$^2$C first projects token-level features into a shared sentiment space and computes intra- and inter-modality consistency scores (I$^2$CS). The I$^2$CS serves three functions: (1) as a consistency loss for regularizing training; (2) as token-wise weights for reweighting features; and (3) as a compression signal for eliminating redundant or conflicting tokens. Extensive experiments are conducted on the CMU-MOSI and CMU-MOSEI datasets, and the results show that I$^2$C outperforms previous state-of-the-art models. Despite removing 90\\% of tokens, I$^2$C maintains comparable performance, exhibiting remarkable robustness across varying token budgets. All results highlight consistency-aware learning as an effective strategy to improve the accuracy and efficiency of sentiment prediction.",
    "key_points": [
      "multimodal learning",
      "multimodal sentiment analysis"
    ],
    "gold_summary": "This paper proposes a method to address both intra-modal and inter-modal semantic conflicts."
  },
  {
    "paper_id": "GAjGFZPcf8",
    "title": "SegRGB-X: General RGB-X Semantic Segmentation Model",
    "domain": "applications to computer vision",
    "content": "Semantic segmentation across multiple sensor modalities involves leveraging both shared and modality-specific cues. Existing approaches often rely on modality-specific specialist models, which can result in redundancy and suboptimal results. In this work, we propose SegRGB-X, a general model designed to jointly address semantic segmentation across five diverse multi-modal datasets. Our framework incorporates three key components: (1) Modality-Aware CLIP (MA-CLIP), fine-tuned with LoRA to extract modality-specific features; (2) a modality-aligned embedding mechanism that introduces modality-aligned prompts to mitigate the feature gap between input embeddings and control prompts; and (3) a Domain-Specific Refinement Module (DSRM) at the final stage of the backbone to adaptively refine modality-specific features. Extensive experiments on five datasets encompassing event, thermal, depth, polarization, and light field modalities demonstrate the effectiveness of SegRGB-X. Our model achieves an average mIoU of 65.03%, outperforming previous specialist models. The codes will be available.",
    "key_points": [
      "general model",
      "semantic segmentation",
      "multimodal fusion",
      "vision-language model"
    ],
    "gold_summary": "This paper proposed a universal arbitrary-modality semantic segmentation method using modality-aware CLIP, complementary learnable prompts, and a modality-aware selective adapter. The experimental results demonstrate the effectiveness of the proposed on different multimodal segmentation benchmarks."
  },
  {
    "paper_id": "6fsOkjGGUz",
    "title": "HART: Human Aligned Reconstruction Transformer",
    "domain": "applications to computer vision",
    "content": "We introduce HART, a unified framework for sparse-view human reconstruction. Given a small set of uncalibrated RGB images of a person as input, it outputs a watertight clothed mesh, the aligned SMPL-X body mesh, and a Gaussian-splat representation for photorealistic novel-view rendering. Prior methods for clothed human reconstruction either optimize parametric templates, which overlook loose garments and human-object interactions, or train implicit functions under simplified camera assumptions, limiting applicability in real scenes. In contrast, HART predicts per-pixel 3D point maps, normals, and body correspondences, and employs an occlusion-aware Poisson reconstruction to recover complete geometry, even in self-occluded regions. These predictions also align with a parametric SMPL-X body model, ensuring that reconstructed geometry remains consistent with human structure while capturing loose clothing and interactions. These human-aligned meshes initialize Gaussian splats to further enable sparse-view rendering. While trained on only 2.3K synthetic scans, HART achieves state-of-the-art results: Chamfer Distance improves by 18–23% for clothed-mesh reconstruction, PA-V2V drops by 6–27% for SMPL-X estimation, LPIPS decreases by 15–27% for novel-view synthesis on a wide range of datasets. These results suggest that feed-forward transformers can serve as a scalable model for robust human reconstruction in real-world settings. Code and models will be released.",
    "key_points": [
      "human reconstruction",
      "computer vision",
      "computer graphics"
    ],
    "gold_summary": "The paper introduces HART, a transformer-based framework for sparse-view human reconstruction (clothed mesh, SMPL-X estimation, novel-view synthesis) with occlusion-aware DPSR and residual normal learning."
  },
  {
    "paper_id": "SJL09XqcX1",
    "title": "Less Data Less Tokens: Multilingual Unification Learning for Efficient Test-Time Reasoning in LLMs",
    "domain": "applications to computer vision",
    "content": "This paper explores the challenges of test-time scaling of large language models (LLMs), regarding both the data and inference efficiency. We highlight the diversity of multi-lingual reasoning based on our pilot studies, and then introduce a novel approach, $L^2$ multi-lingual unification learning with a decoding intervention strategy for further investigation. The basic idea of $L^2$ is that the reasoning process varies across different languages, which may be mutually beneficial to enhance both model performance and efficiency. In specific, there are two types of multi-lingual data: the entire long chain-of-thought annotations in different languages and the step-wise mixture of languages. By further tuning based on them, we show that even small amounts of data can significantly improve reasoning capabilities. Our findings suggest that multilingual learning reduces both the required data and the number of inference tokens while maintaining a comparable performance. Furthermore, $L^2$ is orthogonal to other data efficient methods. Thus, we also emphasize the importance of diverse data selection. The $L^2$ method offers a promising solution to the challenges of data collection and test-time compute efficiency in LLMs.",
    "key_points": [
      "test‑time scaling; token/compute efficiency; data‑efficient reasoning; low‑resource multilingual nlp; small‑data fine‑tuning;"
    ],
    "gold_summary": "The paper introduces a novel technique for data augmentation for LLM finetuning using multiple languages for generation.\n\nOverall, I like the idea, but I have some comments provided below."
  },
  {
    "paper_id": "VHNzDcJKU3",
    "title": "FakeMark: Deepfake Speech Attribution With Watermarked Artifacts",
    "domain": "applications to computer vision",
    "content": "Deepfake speech attribution remains challenging for existing solutions. Classifier-based solutions often fail to generalize to domain-shifted samples, and watermarking-based solutions are easily compromised by distortions like codec compression or malicious removal attacks. To address these issues, we propose FakeMark, a novel watermarking framework that injects artifact-correlated watermarks associated with deepfake systems rather than predefined bitstring messages. This design allows a detector to attribute the source system by leveraging both injected watermark and intrinsic deepfake artifacts, remaining effective even if one of these cues is elusive or removed. Experimental results show that FakeMark improves generalization to cross-dataset samples where classifier-based solutions struggle and maintains high accuracy under various distortions where conventional watermarking-based solutions fail. Speech samples are available at https://fakemark-demo.github.io/fakemark-demo/.",
    "key_points": [
      "deepfake attribution",
      "deepfake speech",
      "audio watermarking",
      "synthetic artifacts",
      "source tracing"
    ],
    "gold_summary": "This submission proposes a post-hoc watermarking technique dedicated to audio GenAI.\nThe idea is to make the watermark signal reinforcing the audio cues characterizing a particular GenAI model.\nThe application is data provenance."
  },
  {
    "paper_id": "JwJiDLvJWm",
    "title": "Position-Aware Singular Value Shrinkage for Unfolded Dynamic MRI Reconstruction",
    "domain": "applications to computer vision",
    "content": "Dynamic MRI reconstruction benefits from low-rank priors to exploit spatiotemporal redundancy. Recent deep unfolding networks (DUNs) often adopt Singular Value Thresholding (SVT) to apply low-rank constraints. However, most methods apply uniform or globally scaled thresholds, ignoring the unequal importance of singular values and the resolution-dependent nature of dynamic MR images. This leads to suboptimal shrinkage and poor generalization across anatomical variations. Existing adaptive shrinkage techniques in classical models are not trainable and incompatible with end-to-end learning. To address these challenges, we propose a Position-Aware Adaptive Singular-Value Shrinkage (PASS) module that learns to perform context-aware SVT using spectral positional encoding and a neural gating mechanism. This enables selective preservation of important components while suppressing noise and redundancy. We integrate PASS into a deep unfolding network based on low-rank plus sparse decomposition, and introduce a multi-resolution training strategy to improve the adaptivity of PASS across varying anatomical scales and acquisition settings. Experimental results on two dynamic cardiac MRI datasets demonstrate that our method achieves superior reconstruction quality and generalization compared to existing SVT-based baselines. Our code will be available after acceptance.",
    "key_points": [
      "mri reconstruction",
      "singular value shrinkage"
    ],
    "gold_summary": "The paper proposes a Position-Aware Adaptive Singular-Value Shrinkage (PASS) module and embeds it into an L+S-unfolding framework to enhance the discriminative ability of singular-value thresholding."
  },
  {
    "paper_id": "nCqjDPTYUE",
    "title": "Med3D-JADE: 3D Joint Attentive Diffusion Engine for Volumetric Medical CT and Mask Co-generation",
    "domain": "applications to computer vision",
    "content": "Data scarcity is a critical bottleneck for training robust 3D medical image segmentation models. Current generative approaches for paired data synthesis are often limited to conditional generation (e.g., mask-to-image), which cannot produce novel anatomical structures and thus fail to address the lack of structural diversity in training data. To overcome this, we introduce Med3D-JADE, the first diffusion-based framework, to our knowledge, that learns the true joint distribution p(image, mask) to simultaneously generate entirely new 3D CT volumes and their corresponding segmentation masks. Our method adapts a pre-trained 3D medical generation foundation model (MAISI) into a dual-branch latent diffusion architecture. We preserve the foundation model's high-fidelity image synthesis by freezing its original branch and training a new, parallel branch for segmentation. Our proposed Volumetric Joint Attention (VJA) modules enforce coherence between the modalities, while the reuse of the model's powerful Volumetric Compression Network (VCN) facilitates efficient, high-resolution generation for both domains without needing to train a new encoder from scratch. We rigorously validate our approach by using the generated pairs for data augmentation across four datasets, including public benchmarks like SegTHOR and challenging MSD tumor datasets. Augmenting with our synthetic data leads to significant performance gains for diverse segmentation models like nnU-Net, SwinUNETR, and SegResNet, establishing Med3D-JADE as a generalizable and practical solution for overcoming 3D data scarcity in medical imaging.",
    "key_points": [
      "medical imaging",
      "data augmentation",
      "joint generation",
      "diffusion model",
      "3d"
    ],
    "gold_summary": "The paper introduces Med3D-JADE, which is aiming to generate 3D paired image-mask pairs. The paper performs evaluation on both generation and segmentation, demonstrating the effectiveness of using Med3D-JADE as an augmentation tool."
  },
  {
    "paper_id": "oKy58UqRLW",
    "title": "An Efficient Global-Local Feature Extraction Architecture for 3D Point Clouds",
    "domain": "applications to computer vision",
    "content": "Accurate 3D object detection and segmentation from LiDAR point clouds require both global context and fine-grained local features. Sparse convolutions capture local geometry efficiently but have limited receptive fields, while transformers model long-range context at high memory and runtime costs and often miss fine detail. We introduce Dilated Uniform Attention with 3D Sparse Convolution (DUA-SConv), a building block that integrates attention and sparse convolution in a complementary way. Each block applies self-attention over a uniformly dilated neighborhood spanning a large, fixed region to provide coarse global context, followed by sparse convolution to recover fine-grained local features. Stacked DUA-SConv blocks form a compact backbone that achieves high accuracy in 3D detection and segmentation with low runtime and parameter count.",
    "key_points": [
      "detection",
      "lidar",
      "point-clouds"
    ],
    "gold_summary": "The paper presents an efficient transformer design that unifies global-local LiDAR perception through uniform grouping, localized attention, and implicit relative positional encoding—achieving strong accuracy with scalable computation."
  },
  {
    "paper_id": "TPJEZDn5zo",
    "title": "Constructing a 3D Scene from a Single Image",
    "domain": "applications to computer vision",
    "content": "Acquiring detailed 3D scenes typically demands costly equipment, multi-view data, or labor-intensive modeling. Therefore, a lightweight alternative, generating complex 3D scenes from a single top-down image, plays an essential role in real-world applications. While recent 3D generative models have achieved remarkable results at the object level, their extension to full-scene generation often leads to inconsistent geometry, layout hallucinations, and low-quality meshes.\nIn this work, we introduce SceneFuse-3D, a training-free framework designed to synthesize coherent 3D scenes from a single top-down view. Our method is grounded in two principles: region-based generation to improve image-to-3D alignment and resolution, and spatial-aware 3D inpainting to ensure global scene coherence and high-quality geometry generation. Specifically, we decompose the input image into overlapping regions and generate each using a pretrained 3D object generator, followed by a masked rectified flow inpainting process that fills in missing geometry while maintaining structural continuity. This modular design allows us to overcome resolution bottlenecks and preserve spatial structure without requiring 3D supervision or fine-tuning.\nExtensive experiments across diverse scenes show that SceneFuse-3D outperforms state-of-the-art baselines, including Trellis, Hunyuan3D-2, TripoSG, and LGM, in terms of geometry quality, spatial coherence, and texture fidelity. Our results demonstrate that high-quality unstructured 3D scene-level asset generation is achievable from a single top-down image using a principled, training-free pipeline.",
    "key_points": [
      "image-to-3d generation",
      "3d scene generation"
    ],
    "gold_summary": "This paper tackles the problem of scene-level 3D generation from (bird-eye-view) images. The motivation and contribution is clear."
  },
  {
    "paper_id": "kyLS9EhPhY",
    "title": "Threading Keyframe with Narratives: MLLMs as Strong Long Video Comprehenders",
    "domain": "applications to computer vision",
    "content": "Employing Multimodal Large Language Models (MLLMs) for long video understanding remains a challenging problem due to the dilemma between the substantial number of video frames (i.e., visual tokens) versus the limited context length of language models. Traditional uniform sampling often leads to selection of irrelevant content,  while post-training MLLMs on thousands of frames imposes a substantial computational burden. In this paper, we propose _Narrating KeyFrames Capturing_ (Nar-KFC), a plug-and-play module to facilitate effective and efficient long video perception. Nar-KFC generally involves two collaborative steps. First, we formulate the _keyframe_ selection process as an integer quadratic programming problem, jointly optimizing query-relevance and frame-diversity. To avoid its computational complexity, a customized greedy search strategy is designed as an efficient alternative. Second, to mitigate the temporal discontinuity caused by sparse keyframe sampling, we further introduce interleaved textual _narratives_ generated from non-keyframes using off-the-shelf captioners. These narratives are inserted between keyframes based on their true temporal order, forming a coherent and compact representation. Nar-KFC thus serves as a temporal- and content-aware compression strategy that complements visual and textual modalities. Experimental results on multiple long-video benchmarks demonstrate that Nar-KFC significantly improves the performance of popular MLLMs. Code will be made publicly available.",
    "key_points": [
      "multimodal large language models",
      "long video understanding",
      "keyframe selection",
      "keyframe narratives"
    ],
    "gold_summary": "This paper introduces Nar-KFC, a novel and practical training-free framework designed to enhance long-video comprehension for existing Multimodal Large Language Models (MLLMs) constrained by limited context windows."
  },
  {
    "paper_id": "y6XJZlEC2x",
    "title": "Mixture of Contexts for Long Video Generation",
    "domain": "applications to computer vision",
    "content": "Long video generation is fundamentally a long context memory problem: models must retain and retrieve salient events across a long range without collapsing or drifting. However, scaling diffusion transformers to generate long-context videos is fundamentally limited by the quadratic cost of self-attention, which makes memory and computation intractable and difficult to optimize for long sequences. We recast long-context video generation as an internal information retrieval task and propose a simple, learnable sparse attention routing module, Mixture of Contexts (MoC), as an effective long-term memory retrieval engine. In MoC, each query dynamically selects a few informative chunks plus mandatory anchors (caption, local windows) to attend to, with causal routing that prevents loop closures. As we scale the data and gradually sparsify the routing, the model allocates compute to salient history, preserving identities, actions, and scenes over minutes of content. Efficiency follows as a byproduct of retrieval (near-linear scaling), which enables practical training and synthesis, and the emergence of memory and consistency at the scale of minutes.",
    "key_points": [
      "video generation"
    ],
    "gold_summary": "This paper proposes a sparse attention-based method to alleviate the excessive computational cost in long-context learning for long video generation. The main experimental results are conducted in a multi-shot setting."
  },
  {
    "paper_id": "pJUQ5YA98Z",
    "title": "Collaborative Memory: Multi-User Memory Sharing in LLM Agents with Dynamic Access Control",
    "domain": "applications to computer vision",
    "content": "Complex tasks are increasingly delegated to ensembles of specialized LLM-based agents that reason, communicate, and coordinate actions—both among themselves and through interactions with external tools, APIs, and databases. While persistent memory has been shown to enhance single-agent performance, most approaches assume a monolithic, single-user context—overlooking the benefits and challenges of knowledge transfer across users under dynamic, asymmetric permissions. We introduce Collaborative Memory, a framework for multi-user, multi-agent environments with asymmetric, time-evolving access controls encoded as bipartite graphs linking users, agents, and resources. Our system maintains two memory tiers: (1) private memory—private fragments visible only to their originating user; and (2) shared memory—selectively shared fragments. Each fragment carries immutable provenance attributes (contributing agents, accessed resources, and timestamps) to support retrospective permission checks. Granular read policies enforce current user–agent–resource constraints and project existing memory fragments into filtered transformed views. Write policies determine fragment retention and sharing, applying context-aware transformations to update the memory. Both policies may be designed conditioned on system, agent, and user-level information. Our framework enables safe, efficient, and interpretable cross-user knowledge sharing, with provable adherence to asymmetric, time-varying policies and full auditability of memory operations.",
    "key_points": [
      "collaborative memory",
      "multi-agent systems",
      "multi-user collaboration",
      "asymmetric permissions",
      "shared memory"
    ],
    "gold_summary": "This paper introduces a framework that enables multi-user, multi-agent LLM systems to efficiently manage memories while ensuring safety and adhering to dynamic and asymmetric access policies."
  },
  {
    "paper_id": "l1MQVgIKEU",
    "title": "CoAct-1: Computer-using Multi-agent System with Coding Actions",
    "domain": "applications to computer vision",
    "content": "Autonomous agents that operate computers via Graphical User Interfaces (GUIs) often struggle with efficiency and reliability on complex, long-horizon tasks. While augmenting these agents with planners can improve task decomposition, they remain constrained by the inherent limitations of performing all actions through GUI manipulation, leading to brittleness and inefficiency. In this work, we introduce a more robust and flexible paradigm: enabling agents to use coding as an enhanced action. We present CoAct-1, a novel multi-agent system that synergistically combines GUI-based control with direct programmatic execution. CoAct-1 features an Orchestrator that dynamically delegates subtasks to either a conventional GUI Operator or a specialized Programmer agent, which can write and execute Python or Bash scripts. This hybrid approach allows the agent to bypass inefficient GUI action sequences for tasks like file management and data processing, while still utilizing visual interaction when necessary. We evaluate our system on the challenging OSWorld and WindowsAgentArena benchmark, where CoAct-1 achieves a new state-of-the-art success rate of 60.8% on OSWorld and 52.5% on WindowsAgentArena, significantly outperforming prior methods. Furthermore, our approach dramatically improves efficiency, reducing the average number of steps required to complete a task to just 10.15 on OSWorld, compared to 15 for leading GUI agents. Our results demonstrate that integrating coding as a core action provides a more powerful, efficient, and scalable path toward generalized computer automation.",
    "key_points": [
      "computer-using agent",
      "multi-gent system",
      "llm agent"
    ],
    "gold_summary": "This paper presents CoAct-1, a multi-agent framework to tackle long-horizon computer-use tasks. By combining an orchestrator, a GUI agent, and a programming agent, this work achieves state-of-the-art results on OSWorld and WindowsAgentArena."
  },
  {
    "paper_id": "92dDR0sUYI",
    "title": "Bidirectional Collaborative Medical Report Generation via Concept-level Interaction",
    "domain": "applications to computer vision",
    "content": "We introduce the first bidirectional collaborative medical report generation framework to reduce physicians' workload and enhance trustworthiness through targeted physician-AI interaction, where physicians provide feedback only on the most critical parts, and the Vision-Language Model (VLM) propagates these to finalize the full report. The core challenge lies in defining the optimal unit of interaction. We propose the Anatomy-Finding Concept Unit (AFCU), a minimal, clinically grounded semantic statement (e.g., ``left lobe: hypoechoic nodule''), satisfying three key principles: atomicity, lack of ambiguity, and anatomical anchoring. To extract AFCU, we use a Large Language Model (LLM) guided by predefined clinical templates followed by information bottleneck clustering to group lexically diverse but semantically equivalent anatomical concepts (e.g., “left and right lobe” to “both lobes of the thyroid gland”), eliminating redundancy while preserving diagnostic fidelity. To prioritize physician intervention, we introduce the Concept Risk Score (CRS), quantifying behavioral inconsistency (concepts generated regardless of image content) and semantic instability (inconsistent associated findings under image perturbations) via occlusion-based visual grounding. Finally, we propose Holistic Semantic Match (HSM), a concept-based metric that correlates strongly with human judgment (Pearson’s r = 0.846, $p < 0.05$). Experiments show our framework improves semantic quality by 9.13\\% HSM across four organs by correcting only one AFCU with high error risk per report -- a minimal, clinically feasible intervention, enabling efficient and trustworthy physician-AI collaboration.",
    "key_points": [
      "medical report generation",
      "human-ai collaboartion"
    ],
    "gold_summary": "This paper proposes a new interactive medical report generation method. Intuitively, authors reduce physician workload in medical report generation by identifying areas of uncertainty in images. To some extent, this is reasonable."
  },
  {
    "paper_id": "Sfv7l4GuAi",
    "title": "Visual Autoregressive Models Beat Diffusion Models on Inference Time Scaling",
    "domain": "applications to computer vision",
    "content": "While inference-time scaling through search has revolutionized Large Language Models, translating these gains to image generation has proven difficult. Recent attempts to apply search strategies to continuous diffusion models show limited benefits, with simple random sampling often performing best. We demonstrate that the discrete, sequential nature of visual autoregressive models enables effective search for image generation. We show that beam search substantially improves text-to-image generation, enabling a 2B parameter autoregressive model to outperform a 12B parameter diffusion model across benchmarks. Systematic ablations show that this advantage comes from the discrete token space, which allows early pruning and computational reuse, and our verifier analysis highlights trade-offs between speed and reasoning capability. These findings suggest that model architecture, not just scale, is critical for inference-time optimization in visual generation.",
    "key_points": [
      "autoregressive models",
      "inference-time scaling",
      "beam search",
      "image generation",
      "compositional generation",
      "verifiers",
      "computational efficiency"
    ],
    "gold_summary": "This paper proposes a new test-time search method, beam search, to enhance autoregressive T2I models. The paper demonstrates the effectiveness and scalability of the proposed approach."
  },
  {
    "paper_id": "00F7BfXLYJ",
    "title": "CyberV: A Cybernetic Framework for Enhancing Logical Reasoning in Video Understanding",
    "domain": "applications to computer vision",
    "content": "Current Multimodal Large Language Models (MLLMs) may struggle with tasks requiring deep logical reasoning about video content, primarily stemming from the feed-forward processing nature, which limits their ability for self-correction and iterative refinement. To address these limitations, we propose a novel framework inspired by cybernetic principles, redesigning video MLLMs as adaptive systems capable of self-monitoring, self-correction, and dynamic resource allocation during inference. Our approach, CyberV, introduces a cybernetic loop consisting of an MLLM Inference System, a Sensor, and a Controller. Specifically, the sensor monitors MLLM forward processes. It collects intermediate interpretations, such as attention drift, then the controller determines when and how to trigger self-correction and generate feedback to guide the next round. This test-time adaptive scaling framework enhances frozen MLLMs without requiring training or additional components. Experiments demonstrate significant improvements on complex reasoning benchmarks: CyberV boosts Qwen2.5-VL-7B by 8.3% and InternVL3-8B by 5.5% on VideoMMMU, surpassing the competitive proprietary model GPT-4o. When applied to Qwen2.5-VL-72B, it yields a 10.0% improvement, achieving performance even comparable to human experts. Furthermore, on other reasoning-focused benchmarks, our method shows consistent gains of 4.6% on the multiple-choice question section of MMVU and 2.4% on MMR-V, highlighting its robustness in enhancing logical reasoning for video understanding. The code will be released to support further research.",
    "key_points": [
      "video understanding",
      "multimodal large language models",
      "test-time scaling"
    ],
    "gold_summary": "This paper introduces **CyberV**, an approach that leverages cybernetic structures to enhance the reasoning performance of Multi-Modal Large Language Models (MLLMs)."
  },
  {
    "paper_id": "zrH2A1upAo",
    "title": "GuirlVG: Incentivize GUI Visual Grounding via Empirical Exploration on Reinforcement Learning",
    "domain": "applications to computer vision",
    "content": "Graphical user interface visual grounding (GUI-VG)—a core capability for GUI agents—has primarily relied on supervised fine-tuning (SFT) of multimodal large language models (MLLMs), demanding extensive data curation and significant training costs. However, as MLLMs continue to advance and even cover GUI domains during pretraining, the necessity of exhaustive SFT post-training becomes increasingly questionable. Meanwhile, the recent successes of rule-based reinforcement fine-tuning (RFT) suggest a more efficient alternative. However, despite its promise, the optimal manner of RFT for GUI-VG remains unexplored. To bridge this gap, we introduce GuirlVG, a reinforcement learning–based GUI-VG method built on a systematic empirical study and a novel stabilization technique. Preliminarily, we find that naive application of RFT underperforms the SFT baseline, motivating a deeper exploration of RFT. First, we decompose RFT into its core components and analyze the optimal formulation of each. Second, as part of this exploration, we propose a novel Adversarial KL Factor that dynamically stabilizes training to mitigate reward over-optimization. Third, we further explore the training configurations of RFT to enhance the effectiveness. Extensive experiments show that GuirlVG, with only 5.2K training samples, outperforms SFT methods trained on over 10M samples, achieving a +7.7% improvement on ScreenSpot, a +17.2% improvement on ScreenSpotPro and 91.9% accuracy on ScreenSpotV2.",
    "key_points": [
      "gui visual grounding",
      "reinforcement fine-tuning"
    ],
    "gold_summary": "The authors applied RFT to the GUI-agent which is underexplored. the study step-by-step analyze the intermediate resutls and propose an efficient way that outperforms SFT on the tasks of interest."
  },
  {
    "paper_id": "Ly6NP07Rw5",
    "title": "Back to Basics: Motion Representation Matters for Human Motion Generation Using Diffusion Model",
    "domain": "applications to computer vision",
    "content": "Diffusion models have emerged as a widely utilized and successful methodology in human motion synthesis. Task-oriented diffusion models have significantly advanced action-to-motion, text-to-motion, and audio-to-motion applications. In this paper, we investigate fundamental questions regarding motion representations and loss functions in a controlled study, and we enumerate the impacts of various decisions in the workflow of the generative motion diffusion model. To answer these questions, we conduct empirical studies based on a proxy motion diffusion model (MDM). We apply $v$ loss as the prediction objective on MDM ($v$MDM), where $v$ is the weighted sum of motion data and noise. We aim to enhance the understanding of latent data distributions and provide a foundation for improving the state of conditional motion diffusion models. First, we evaluate the six common motion representations in the literature and compare their performance in terms of quality and diversity metrics. Second, we compare the training time under various configurations to shed light on how to speed up the training process of motion diffusion models. Finally, we also retarget a large motion dataset to the SMPL skeleton for evaluation. The results of our experiments indicate clear performance differences across motion representations in diverse datasets. Our results also demonstrate the impacts of distinct configurations on model training and suggest the importance and effectiveness of these decisions on the outcomes of motion diffusion models.",
    "key_points": [
      "motion generation",
      "diffusion model",
      "motion representation",
      "biped animation"
    ],
    "gold_summary": "This paper revisits motion representation for diffusion-based motion generation: starting from MDM/vMDM, they plug in six encodings (JP, RP6JR, RPQJR, RPAJR, RPEJR, RPMJR) and run a series of comparisons on HumanAct12 and 100STYLE."
  },
  {
    "paper_id": "42gPoLZLQB",
    "title": "$\\text{S}^{3}$Mamba: Arbitrary-Scale Super-Resolution via Scaleable State Space Model",
    "domain": "applications to computer vision",
    "content": "Arbitrary scale super-resolution (ASSR) aims to super-resolve low-resolution images to high-resolution images at any scale using a single model, addressing the limitations of traditional super-resolution methods that are restricted to fixed-scale factors (e.g., ( $\\times$2 ), ( $\\times$4 )). The advent of Implicit Neural Representations (INR) has brought forth a plethora of novel methodologies for ASSR, which facilitate the reconstruction of original continuous signals by modeling a continuous representation space for coordinates and pixel values, thereby enabling arbitrary-scale super-resolution. Consequently, the primary objective of ASSR is to construct a continuous representation space derived from low-resolution inputs. However, existing methods, primarily based on CNNs and Transformers, face significant challenges such as high computational complexity and inadequate modeling of long-range dependencies, which hinder their effectiveness in real-world applications. To overcome these limitations, we propose a novel arbitrary-scale super-resolution method, called $\\text{S}^{3}$Mamba, to construct a scalable continuous representation space. Specifically, we propose a Scalable State Space Model (SSSM) to modulate the state transition matrix and the sampling matrix of step size during the discretization process, achieving scalable and continuous representation modeling with linear computational complexity. Additionally, we propose a novel scale-aware self-attention mechanism to further enhance the network's ability to perceive global important features at different scales, thereby building the \nMamba to achieve superior arbitrary-scale super-resolution. Extensive experiments on both synthetic and real-world benchmarks demonstrate that our method achieves state-of-the-art performance and superior generalization capabilities at arbitrary super-resolution scales. The code will be publicly available.",
    "key_points": [
      "super resolution",
      "arbitrary scale super resolution",
      "implicit neural representation"
    ],
    "gold_summary": "This paper proposes a novel arbitrary-scale super-resolution method, called $\\text{S}^3$Mamba, to construct a scalable continuous representation space, achieving state-of-the-art (SOTA) performance."
  },
  {
    "paper_id": "1RgXNloctI",
    "title": "CoT-RVS: Zero-Shot Chain-of-Thought Reasoning Segmentation for Videos",
    "domain": "applications to computer vision",
    "content": "Reasoning Video Object Segmentation is a challenging task, aiming at  generating a mask sequence from an input video given a complex and implicit text query. While existing works finetune Multimodal Large Language Models (MLLM) for the task, they still fail in video inputs given complex temporally-sensitive queries, indicating their lack of temporal and spatial integration in complex scenarios. In this paper, we propose **CoT-RVS**, a novel framework employing the zero-shot Chain-of-Thought (CoT) capability of MLLM to address these complex challenges by **temporal-semantic reasoning**: CoT-RVS analyzes the visible objects within a given frame that possibly match the language query (semantic), and chooses a corresponding keyframe for each object that can be observed effortlessly among all frames (temporal). Notably, the CoT-RVS framework is training-free and compatible with closed-source MLLMs, which can be applied to Reasoning Video Instance Segmentation. Our framework's training-free feature further allows its extension to process online video streams, where the CoT  is used at test time to update the object of interest when  a better target starts to emerge and becomes visible. We conduct extensive experiments on video object segmentation with explicit and implicit queries. The results show that CoT-RVS significantly outperforms previous works in both cases, qualitatively and quantitatively.",
    "key_points": [
      "multimodal large language model",
      "reasoning video object segmentation"
    ],
    "gold_summary": "This paper proposed a novel training-free framework called CoT-RVS. This method leverages the zero-shot CoT capability of MLLM to select the optimal keyframes for segmentation. This framework outperforms existing methods both qualitatively and quantitatively."
  },
  {
    "paper_id": "QGejSAi7U4",
    "title": "Prompt-Guided Low-Level Recovery and High-Level Fusion for Incomplete Multimodal Sentiment Analysis",
    "domain": "applications to computer vision",
    "content": "Multimodal Sentiment Analysis seeks to understand emotions by combining language, audio, and visual signals, but its real challenge lies in building models that stay robust when one or more modalities are missing or corrupted. Recent studies attempted to leverage available embedding to complement missing regions by single-level feature reconstruction or cross-modal fusion. However, both reconstruction-only and fusion-only pipelines are limited: the former amplifies noise from imperfect recovery, while the latter overlooks semantic restoration, leaving cross-modal gaps and complex intermodal relationships inadequately captured for robust generalization. To overcome these limitations, we propose Prompt-Guided Low-level recovery and High-level fusion (PGLH)  for incomplete multimodal sentiment analysis, achieving deep cross-modal interactions from low-level semantic recovery to high-level semantic fusion through adaptive prompts. Specifically, PGLH mainly consists of Prompted Cross-Modal Masking (PCM2) and Unimodal-to-Bimodal Prompt Fusion (UBPF). First, PCM2 extends masked autoencoding to multimodal inputs by leveraging language-guided prompts to restore corrupted audio and visual tokens. This enables both structural fidelity and semantic grounding for low-level recovery. Secondly, in UBPF, self-guided prompts are introduced into each modality to extract fine-grained unimodal structures by selectively attending to informative regions. Next, they are progressively aligned with language-guided prompts for robust high-level fusion. Finally, PCM2 and UBPF realize the dual-level adaptation from low-level token reconstruction to high-level semantic integration, thereby effectively bridging modality gaps and more robust representations. Extensive experiments on MOSI, MOSEI, and SIMS demonstrate that PGLH consistently achieves impressive performance with missing data.",
    "key_points": [
      "multimodal learning",
      "sentiment analysis",
      "incomplete modalities",
      "cross-modal fusion",
      "modality reconstruction"
    ],
    "gold_summary": "This paper focuses on incomplete multimodal sentiment analysis and proposes PGLH, which leverages PCM2 for low-level recovery and UBPF for high-level integration. The reported results on three datasets demonstrate the effectiveness of the proposed approach."
  },
  {
    "paper_id": "wbqPX3jOS4",
    "title": "TVMamba:Towards Efficient Visual Mammba With Ternary Weights and Activations",
    "domain": "applications to computer vision",
    "content": "Visual Mambas based on state space models have recently emerged as strong vision backbones. To improve efficiency on resource-constrained devices, many studies explore quantization to represent weights and activations at low precision. However, most state-of-the-art methods reach ternary weights while activations stay at 8 bits or higher, which limits practical efficiency gains. We present TVMamba, to our knowledge the first approach that achieves ternary weights and ternary activations. Our analyses show that uneven channel distributions make ternary activations difficult, leading to unstable optimization and amplified spectral distortions. To address this, TVMamba introduces two components: (1) a staged codebook that trains with five level activations for stability and collapses to ternary at deployment, and (2) a lightweight quantization aware frequency routing module that preserves high frequency detail while maintaining the low pass behavior of the SSM core. Empirically, on two mainstream Visual Mamba backbones, VMamba and Vim, our method delivers competitive accuracy. Wall clock measurements across devices show matrix multiplication at various sizes accelerated between 17 times and 87 times with joint ternarization of both weights and activations.",
    "key_points": [
      "ternary quantization",
      "visual mamba",
      "quinary-to-ternary annealing",
      "frequency-aware routing",
      "edge inference"
    ],
    "gold_summary": "The paper proposes a two-stage quantization method. Firstly, the activations are quantized to quinary, and secondly, they are quantized to ternary using a step-wise approach."
  },
  {
    "paper_id": "lDA2C9nJg6",
    "title": "Fire on Motion: Optimizing Video Pass-bands for Efficient Spiking Action Recognition",
    "domain": "applications to computer vision",
    "content": "Spiking neural networks (SNNs) have gained traction in vision due to their energy efficiency, bio-plausibility, and inherent temporal processing. Yet, despite this temporal capacity, most progress concentrates on static image benchmarks, and SNNs still underperform on dynamic video tasks compared to artificial neural networks (ANNs). In this work, we diagnose a fundamental pass-band mismatch: Standard spiking dynamics behave as a temporal low pass that emphasizes static content while attenuating motion bearing bands, where task relevant information concentrates in dynamic tasks. This phenomenon explains why SNNs can approach ANNs on static tasks yet fall behind on tasks that demand richer temporal understanding.To remedy this, we propose the Pass-Bands Optimizer (PBO), a plug-and-play module that optimizes the temporal pass-band toward task-relevant motion bands. PBO introduces only two learnable parameters, and a lightweight consistency constraint that preserves semantics and boundaries, incurring negligible computational overhead and requires no architectural changes.\nPBO deliberately suppresses static components that contribute little to discrimination, effectively high passing the stream so that spiking activity concentrates on motion bearing content. On UCF101, PBO yields over ten percentage points improvement. On more complex multi-modal action recognition and weakly supervised video anomaly detection, PBO delivers consistent and significant gains, offering a new perspective for SNN based video processing and understanding.",
    "key_points": [
      "spiking neural networks; dynamic vision sensor; action recognition; frequency analysis"
    ],
    "gold_summary": "This paper proposed a Pass-Bands Optimizer to optimize the temporal pass-band toward task-relevant motion bands."
  },
  {
    "paper_id": "7poaGCcesq",
    "title": "Are Medical Vision–Language Foundation Models Ready for Dermatology",
    "domain": "applications to computer vision",
    "content": "Medical Vision-Language models (VLMs) show significant promise for clinical image understanding, offering the promise of greater medical accessibility and interpretability. However, a critical performance gap in diagnostic accuracy exists between their strong vision encoders and the full multimodal model. This performance gap suggests that such VLM fails to make full use of the strength of its vision branch. Such misalignment also implies that these models often over-rely on their language priors, producing plausible-sounding diagnoses without sufficiently grounding their reasoning in visual evidence. Focusing on dermatology, we systematically investigate the root causes of this phenomenon. While fine-tuning can improve accuracy, it often compromises the model's essential reasoning capabilities. To address these challenges, we introduce a training-free inference pipeline designed to close the performance gap while preserving the model's reasoning abilities. Our pipeline enhances diagnostic accuracy and faithfulness without requiring additional training. These strategies are readily extensible, suggesting a path toward more reliable and interpretable VLMs in medicine and beyond.",
    "key_points": [
      "skin imaging analysis",
      "machine learning for healthcare",
      "medical foundation models"
    ],
    "gold_summary": "This paper investigates the performance gap between the vision encoder capabilities and end-to-end diagnostic accuracy of MedGemma-4B in dermatology."
  },
  {
    "paper_id": "0oXyMbPMtP",
    "title": "MambaVoiceCloning: Efficient and Expressive Text-to-Speech via State-Space Modeling and Diffusion Control",
    "domain": "applications to computer vision",
    "content": "\\begin{abstract}\n\\noindent We present MambaVoiceCloning (MVC), a text-to-speech framework whose encoder/conditioning path is SSM-only at inference: no attention modules and no recurrent units remain at deployment. MVC comprises three linear-time components—a bidirectional Mamba text encoder, a temporal Bi-Mamba for rhythm/duration (with a lightweight training-only aligner), and a prosody predictor with gated AdaLN conditioning. To our knowledge, prior Mamba-in-speech systems (e.g., hybrids) retain inference-time attention or recurrence in duration/prosody, whereas MVC is the first to eliminate them across the entire conditioning stack. Our aim is not end-to-end speed (the diffusion decoder still dominates latency), but bounded activation memory, stable long-form synthesis, and streaming with bounded look-ahead. On LibriTTS, LJSpeech, and stress tests on VCTK/CSS10 (ES/DE/FR), MVC delivers modest but statistically significant gains in MOS/CMOS, F0~RMSE, MCD, and WER versus StyleTTS2 and Mamba–attention hybrids, while reducing conditioning parameters to 21M and improving encoder-side throughput by $1.6\\times$. A runtime breakdown confirms the diffusion decoder as the primary bottleneck, whereas SSM-only conditioning lowers peak memory and enables longer inputs and larger batches in practice. Source code: \\url{https://github.com/aiai-9/MVC}.\n\\end{abstract}",
    "key_points": [
      "text-to-speech (tts)",
      "speech synthesis",
      "voice cloning",
      "mamba",
      "state space models (ssm)",
      "diffusion tts",
      "prosody modeling",
      "streaming/low-latency"
    ],
    "gold_summary": "The paper proposed to use MAMBA style SSM blocks in all conditioning encoders of a diffusion-based TTS model."
  },
  {
    "paper_id": "7EUYamNuJ9",
    "title": "MatchVIT: Light-weight Vision Transformer with Matching Separable Self-attention",
    "domain": "applications to computer vision",
    "content": "Vision Transformers (ViTs) have emerged as a powerful alternative to Convolutional Neural Networks (CNNs) in various vision tasks.\nViTs process images as sequences of patches and capture long-range dependencies through Multi-Head Self-Attention (MHSA). \nHybrid CNN-ViT architectures further enhance performance by integrating the local inductive bias of CNNs with the global contextual information of ViTs. \nHowever, the quadratic complexity of self-attention limits its efficiency as the number of tokens rises. \nSeparable Self-Attention (SSA) in MobileViTv2 reduces computational overhead by aggregating contextual information into a single vector and applying the vector to all tokens.\nDespite this improvement, SSA exhibits limitations compared to MHSA, including extracting only a single level of features, and lacking the ability for tokens to selectively acquire relevant information. These shortcomings further confine the performance of SSA.\n\nTo address these issues, we propose MatchViT as a novel hybrid CNN-ViT model.\nIn MatchViT, we introduce Matching Separable Self-Attention (MaSSA), which employs multi-head processing and matching mechanism to enable tokens to individually gather information across hidden tokens. \nMoreover, Context-gated FFNs in MatchViT leverage the information gathered in MaSSA for enhanced performance. \nBy adopting MaSSA and context-gated FFN, MatchViT achieves a 1\\%–3\\% accuracy improvement in Image Classification tasks compared to various other vision models with identical MACs.\nOther experimental results demonstrate that MatchViT overcomes shortcomings in MobileViTv2, achieving superior accuracy with low computational costs across diverse vision tasks.",
    "key_points": [
      "vision transformer",
      "light-weighted model",
      "computer vision"
    ],
    "gold_summary": "This paper presents MatchViT, a CNN–Transformer model to achieve MobileViT-level efficiency, the proposed network also recover representational power lost with a Matching Separable Self-Attention (MaSSA)."
  },
  {
    "paper_id": "ooYtHcj6LI",
    "title": "EarthMind: Leveraging Cross-Sensor Data for Advanced Earth Observation Interpretation with a Unified Multimodal LLM",
    "domain": "applications to computer vision",
    "content": "Earth Observation (EO) data analysis is vital for monitoring environmental and human dynamics. Recent Multimodal Large Language Models (MLLMs) show potential in EO understanding but remain restricted to single-sensor inputs, overlooking the complementarity across heterogeneous modalities. We propose EarthMind, *a unified vision-language framework* that handles both *single- and cross-sensor* inputs via an innovative hierarchical cross-modal attention (*i.e.*, HCA) design. Specifically, HCA hierarchically captures visual relationships across sensors and aligns them with language queries, enabling adaptive fusion of optical and Synthetic Aperture Radar (SAR) features. To support cross-sensor learning, we curate *FusionEO*, a 30K-pair dataset with diverse annotations, and establish *EarthMind-Bench*, a 2,841-pair benchmark with expert annotations for perception and reasoning tasks. Extensive experiments show that EarthMind achieves state-of-the-art results on EarthMind-Bench and surpasses existing MLLMs on multiple EO benchmarks.",
    "key_points": [
      "earth observation",
      "cross-sensor fusion",
      "multimodal llms"
    ],
    "gold_summary": "The paper introduces the first optical–SAR instruction fine-tuning benchmarks and the corresponding method EarthMind. Extensive experiments demonstrate the effectiveness of the proposed method. But there are some necessary concerns that should be addressed"
  },
  {
    "paper_id": "54BPFBsT2p",
    "title": "Dynamic Rank Adjustment for Accurate and Efficient Neural Network Training",
    "domain": "applications to computer vision",
    "content": "Low-rank training is a primary strategy for efficient deep learning, but it presents a fundamental challenge. It reduces computational cost, yet it permanently caps a model’s representational capacity and accelerates the rank collapse that diminishes its expressive power during training. We address this with dynamic-rank training, a framework built on the intuition that a model can temporarily escape its low-rank constraints to restore its full learning potential. Our approach strategically interleaves full-rank epochs within a low-rank schedule, with the timing of these restorative phases aligned with the learning rate’s noise regimes to maximize their effect. This enables the model to regain expressive power at critical stages of training by restoring the effective rank of its weights. Our extensive evaluations across various computer vision and natural language processing benchmarks show this method achieves the accuracy of full-rank models while retaining the computational advantages of low-rank training.",
    "key_points": [
      "low-rank training",
      "rank adjustment",
      "model reparameterization"
    ],
    "gold_summary": "This paper proposes a dynamic-rank training framework to address a key limitation of low-rank training, the permanent loss of representational capacity and rank collapse."
  },
  {
    "paper_id": "kwhk8o3k5O",
    "title": "Phys-Bench: A Physics-aware Benchmark with Multi-Body Interactions for 3D Dynamic Scene Understanding",
    "domain": "applications to computer vision",
    "content": "We introduce Phys-Bench, a novel physics-aware benchmark for 3D dynamic scene understanding. This benchmark is designed to evaluate methods for reconstructing 4D scenes and understanding underlying physics from given videos, with a main\nfocus on the Dynamic Novel View Synthesis (DyNVS) task. \nWhile existing algorithms and benchmarks primarily focus on photorealistic reconstruction, they largely overlook physics understanding. This neglect is a critical limitation, as a true understanding of dynamic scenes requires models to reason about physical interactions, not just appearance. \nOur benchmark provides complex dynamic scenarios with rich multi-object interactions, featuring realistic collisions and force exchanges that are faithfully generated to strictly adhere to physical laws. \nFurthermore, it contains a diverse range of physical materials, such as liquid, gas, rheological substances, and textiles, which move beyond the rigid bodies prevalent in existing benchmarks. \nTo enable quantitative evaluation, we provide essential ground-truth information such as 3D particle trajectories and physics parameters and propose two novel metrics tailored to assessing physical realism. \nWe further evaluate existing Dynamic Novel View synthesis and physics parameter estimation method on our benchmark and reveal their overlooked limitations in physics understanding and multi-body dynamics handling. \nWe believe Phys-Bench will serve as a crucial foundation for advancing research in dynamic view synthesis, physics-based scene understanding, and the integration of deep learning with physical simulation, ultimately enabling more faithful reconstruction and interpretation of complex 3D dynamic scenes.",
    "key_points": [
      "4d gaussian splatting",
      "physics",
      "dynamic novel view synthesis"
    ],
    "gold_summary": "A new benchmark for dynamic 3D scenes, with an emphasis on not just realism but physics since many of the benchmarks in existence don't put an emphasis on this facet of 3D dynamic reconstruction."
  },
  {
    "paper_id": "8xjCp4OA6k",
    "title": "Scene, Class, Signal: Tri‑Level Adaptation for Synthetic‑to‑Real LiDAR Segmentation",
    "domain": "applications to computer vision",
    "content": "Synthetic LiDAR datasets offer a scalable alternative to costly real-world annotations, but still exhibit a significant domain gap when applied to real-world data. Previous unsupervised domain adaptation (UDA) methods mainly rely on general adaptation strategies, without directly addressing the LiDAR-specific factors causing this gap. In this work, we analyze the synthetic-to-real domain gap from a root-cause-driven perspective. We decompose the components of this gap into three distinct granularities: scene-level, class-level, and signal-level. At the scene-level, we address the point structure distortions caused by real-world sensor effects, such as motion blur and rolling shutter. At the class-level, we consider that the domain gap varies depending on the structural complexity and dynamicity of each object class. Finally, at the signal-level, we tackle the lack of direct, realistic semantic information that corresponds to the synthetic input. To address these respective problems, we propose the following three methods. At the scene-level, we introduce a style embedding that captures point structure distortions and serves as a domain cue for adversarial learning. We then extend this scene-level style embedding to the class-level to address the class-dependent domain gap. To address the signal-level problem, we propose an intensity-guided self-training scheme, which enables the model to learn realistic, implicit semantic information from synthetic inputs. On SynLiDAR→SemanticKITTI, our method achieves 44.7 mIoU, and on SynLiDAR→SemanticPOSS, it reaches 51.1 mIoU, setting a new state of the art on both benchmarks. Extensive ablation studies validate each component, confirming our style embedding captures the structural domain gap while our self-training scheme significantly improves adaptation.",
    "key_points": [
      "lidar semantic segmentation",
      "unsupervised domain adaptation",
      "synthetic-to-real"
    ],
    "gold_summary": "This paper proposes a multi-level adaptation framework that addresses the synthetic-to-real domain gap in LiDAR segmentation by analyzing and mitigating scene-level, class-level, and signal-level factors, achieving state-of-the-art results on major benchmarks."
  },
  {
    "paper_id": "6UDRtcScwO",
    "title": "Harnessing the Power of Reinforcement Learning for Language-Model-Based Information Retriever via Query-Document Co-Augmentation",
    "domain": "applications to computer vision",
    "content": "Recent advances have explored the use of large language models (LLMs) as retrievers by rewriting user queries, while other work has focused on expanding or augmenting corpus documents. However, such unidirectional augmentation, applied to queries or documents in isolation, often fails to reconcile the lexical and stylistic mismatches between them, limiting recall and overall retrieval robustness.\n    To this end, we present an LLM-based retriever empowered to augment both user queries and corpus documents, with its policy fully explored via reinforcement learning (RL) and minimal human inductive bias. Notably, we find that simply training the LLM to augment queries and documents separately, even when combining both at inference, yields little benefit unless paired with our carefully designed bidirectional RL framework, which enables the LLM to simultaneously learn and collaborate on both query and document augmentation policies. A key technical challenge in realizing such a framework lies in jointly updating both policies during training, where the rewards for the two directions depend on each other, making their entangled reward intractable. Our approach addresses this by introducing a reward sampling strategy and a specifically designed RL algorithm that enables effective training with these sampled rewards. Experimental results demonstrate that our approach significantly enhances LLM-based retrieval performance in both sparse and dense settings, particularly in difficult retrieval domains, and achieves strong cross-benchmark generalization. Our code will be publicly released upon acceptance.",
    "key_points": [
      "information retrieval",
      "large language model"
    ],
    "gold_summary": "This paper proposes a reinforcement learning (RL)-based framework for improving large language model (LLM) retrievers through query-document co-augmentation."
  },
  {
    "paper_id": "ST0wOB1bdX",
    "title": "mR3: Multilingual Rubric-Agnostic Reward Reasoning Models",
    "domain": "applications to computer vision",
    "content": "Evaluation using Large Language Model (LLM) judges has been widely adopted in English and shown to be effective for automatic evaluation. However, their performance does not generalize well to non-English settings, and it remains unclear what constitutes effective multilingual training for such judges. In this paper, we introduce mR3, a massively multilingual, rubric-agnostic reward reasoning model trained on 72 languages, achieving the broadest language coverage in reward modeling to date. We present a comprehensive study of data and curriculum selection for training to identify effective strategies and data sources for building high-quality reward models, including the integration of target-language reasoning datasets. Our approach attains state-of-the-art performance on multilingual reward model benchmarks, surpassing much larger models (i.e., GPT-OSS-120B) while being up to nine times smaller, and its effectiveness is further confirmed through extensive ablation studies. We will release our models and datasets publicly upon acceptance.",
    "key_points": [
      "reward model",
      "reasoning",
      "rubric"
    ],
    "gold_summary": "The paper introduces MR3, a multilingual, rubric-agnostic reward reasoning model trained on 72 languages. It studies multilingual dataset curation, curriculum strategies, and the role of language in rubrics, reasoning, and evaluation."
  },
  {
    "paper_id": "CacTP7YoqG",
    "title": "Skeleton-to-Image Encoding: Enabling Skeleton Representation Learning via Vision-Pretrained Models",
    "domain": "applications to computer vision",
    "content": "Recent advances in large-scale pretrained vision models have demonstrated impressive capabilities across a wide range of downstream tasks, including cross-modal and multi-modal scenarios. However, their direct application to 3D human skeleton data remains challenging due to fundamental differences in data format. Moreover, the scarcity of large-scale skeleton datasets and the need to incorporate skeleton data into multi-modal action recognition without introducing additional model branches present significant research opportunities. To address these challenges, we introduce Skeleton-to-Image Encoding (S2I), a novel representation that transforms skeleton sequences into image-like data by partitioning and arranging joints based on body-part semantics and resizing to standardized image dimensions. This encoding enables, for the first time, the use of powerful vision-pretrained models for self-supervised skeleton representation learning, effectively transferring rich visual-domain knowledge to skeleton analysis. While existing skeleton methods often design models tailored to specific, homogeneous skeleton formats, they overlook the structural heterogeneity that naturally arises from diverse data sources. In contrast, our S2I representation offers a unified image-like format that naturally accommodates heterogeneous skeleton data. Extensive experiments on NTU-60, NTU-120, and PKU-MMD demonstrate the effectiveness and generalizability of our method for self-supervised skeleton representation learning, including under challenging cross-format evaluation settings.",
    "key_points": [
      "self-supervised skeleton representation learning",
      "uniform skeleton representation learning",
      "vision pretrained models"
    ],
    "gold_summary": "1. This paper introduces a skeleton-based image representation to leverage vision-pretrained models.\n\n2. To achieve this, the authors propose a skeleton-to-image encoding approach.\n\n3. The framework can be applied to heterogeneous skeleton representations."
  },
  {
    "paper_id": "7lddcnHLCI",
    "title": "MambaMatch: SLAM Front-End Feature Matching with State Space Models",
    "domain": "applications to computer vision",
    "content": "SLAM (Simultaneous Localization and Mapping) systems depend on front-end components for feature detection and matching. Traditional methods use handcrafted or learning-based features, but both have limitations in robustness and efficiency. We propose a new SLAM front-end framework that fuses recent State Space Models (SSMs), specifically the Mamba architecture, with transformer-based attention. Our method exploits the linear efficiency of SSMs for visual feature processing and the global modeling of attention. By integrating these techniques, we achieve better feature matching on challenging datasets while keeping computation efficient. The fusion strategy adaptively balances local relationships from Mamba and global dependencies from attention. Experiments show our approach surpasses state-of-the-art methods in feature matching precision and recall, especially in scenes with repetitive patterns, lighting and viewpoint shifts.",
    "key_points": [
      "slam",
      "feature matching",
      "state space models"
    ],
    "gold_summary": "See Questions"
  },
  {
    "paper_id": "FihSkzyxdv",
    "title": "VibeVoice: Expressive Podcast Generation with Next-Token Diffusion",
    "domain": "applications to computer vision",
    "content": "Generating long-form, multi-speaker conversational audio like podcasts poses significant challenges for traditional Text-to-Speech (TTS) systems, particularly in scalability, speaker consistency, and natural turn-taking. We present VibeVoice , a novel model designed to synthesize expressive, long-form speech with multiple speakers in a zero-shot manner. A core component of our approach is the continuous speech tokenizers operating at an ultra-low frame rate of 7.5. This tokenizer effectively preserves audio fidelity while significantly boosting computational efficiency for processing long sequences. To facilitate training on authentic conversational dynamics, we have developed an annotation pipeline that generates pseudo transcriptions and turn-taking labels for extensive podcast data. Leveraging this data and our efficient tokenizer, VibeVoice  employs the next-token diffusion framework. This enables VibeVoice  to: (1) synthesize long-form speech (up to 30 minutes) with up to 4 speakers, surpassing the typical 1-2 speaker limits of many prior models; and (2) achieve a high degree of naturalness in turn-taking, pacing, and the rendition of subtle non-lexical cues (such as breaths and lip smacks), which are crucial for listener immersion and capturing the authentic vibe of expressive conversations.",
    "key_points": [
      "text-to-speech; podcast generation"
    ],
    "gold_summary": "VibeVoice is a next-token diffusion multispeaker long-context TTS model that benefit from the following innovations: 1) a 7.5 Hz framerate tokenizer; 2) an annotation pipeline that generates pseudo transcription and turn-taking labels."
  },
  {
    "paper_id": "oTlIfmU1nf",
    "title": "Beyond Quantity: Distribution-Aware Labeling for Visual Grounding",
    "domain": "applications to computer vision",
    "content": "Visual grounding requires large and diverse region–text pairs. However, manual annotation is costly and fixed vocabularies restrict scalability and generalization. Existing pseudo-labeling pipelines often overfit to biased distributions and generate noisy or redundant samples. Through our systematic analysis of data quality and distributional coverage, we find that performance gains come less from raw data volume and more from effective distribution expansion. Motivated by this insight, we propose DAL, a distribution-aware labeling framework for visual grounding. The proposed method first employs a dual-driven annotation module, where a closed-set path provides reliable pseudo labels and an open-set path enriches vocabulary and introduces novel concepts; meanwhile, it further performs explicit out-of-distribution (OOD) expression expansion to broaden semantic coverage. We then propose a consistency- and distribution-aware filtering module to discard noisy or redundant region–text pairs and rebalance underrepresented linguistic content, thereby improving both data quality and training efficiency. Extensive experiments on three visual grounding tasks demonstrate that our method consistently outperforms strong baselines and achieves state-of-the-art results, underscoring the critical role of distribution-aware labeling in building scalable and robust visual grounding datasets.",
    "key_points": [
      "visual grounding; pseudo-labeling"
    ],
    "gold_summary": "See Questions."
  },
  {
    "paper_id": "qrCAGOE483",
    "title": "LucidFlux: Caption-Free Universal Image Restoration via a Large-Scale Diffusion Transformer",
    "domain": "applications to computer vision",
    "content": "Universal image restoration (UIR) aims to recover images degraded by unknown mixtures while preserving semantics—conditions under which discriminative restorers and UNet-based diffusion priors often oversmooth, hallucinate, or drift. We present LucidFlux, a caption-free UIR framework that adapts a large diffusion transformer (Flux.1) to restoration with minimal parameter overhead. LucidFlux introduces a lightweight \\emph{dual-branch conditioner} that injects signals from the degraded input and a lightly restored proxy to respectively anchor geometry and suppress artifacts. A timestep- and layer-adaptive modulation schedule routes these cues across the backbone’s hierarchy, yielding coarse-to-fine, context-aware updates that protect global structure while recovering texture. To avoid the latency and instability of text prompts or VLM captions, we enforce \\emph{caption-free semantic alignment} via SigLIP features extracted from the proxy. A scalable curation pipeline further filters large-scale data for structure-rich supervision. \n\nAcross synthetic and in-the-wild benchmarks, LucidFlux consistently surpasses strong open-source and commercial baselines across seven metrics, with clear visual gains in realism, detail, and artifact suppression. Ablations confirm that, for large DiTs, when, where, and what to condition—rather than scaling parameters or relying on text prompts—is the key lever for robust, prompt-free restoration.",
    "key_points": [
      "diffusion transformer; generative models; image restoration"
    ],
    "gold_summary": "This paper proposes LucidFlux, a caption-free UIR framework that adapts the large diffusion transformer Flux.1 without relying on image captions."
  },
  {
    "paper_id": "sa0udzVW4M",
    "title": "ShadowDraw: From Any Object to Shadow–Drawing Compositional Art",
    "domain": "applications to computer vision",
    "content": "We introduce *ShadowDraw*, a framework that transforms ordinary 3D objects into shadow–drawing compositional art. Given a 3D object, our system predicts scene parameters---including object pose and lighting---together with an incomplete line drawing, such that the cast shadow completes the drawing into a recognizable image. To this end, we optimize scene configurations to reveal meaningful shadows, employ shadow strokes to guide line drawing generation, and adopt automatic evaluation to enforce shadow-drawing coherence and visual quality. Experiments show that *ShadowDraw* produces compelling results across diverse inputs, from real-world scans and curated datasets to generative assets, and naturally extends to multi-object scenes, animations, and physical deployments. Our work provides a practical pipeline for creating shadow–drawing art and broadens the design space of computational visual art, bridging the gap between algorithmic design and artistic storytelling. Check out our anonymous [project page](https://anonymous.4open.science/w/ShadowDraw-anon-E584/) for more results.",
    "key_points": [
      "computational visual art",
      "computation art design",
      "shadow art"
    ],
    "gold_summary": "This paper proposes a method to create line drawings with an effect called \"shadow drawing\". The shadow is cast by an 3D object and becomes a part of the drawing."
  },
  {
    "paper_id": "2KKDWERRm3",
    "title": "DETR-ViP: Detection Transformer with Robust Discriminative Visual Prompts",
    "domain": "applications to computer vision",
    "content": "Visual prompted object detection enables interactive and flexible definition of target categories, thereby facilitating open-vocabulary detection. Since visual prompts are derived directly from image features, they often outperform text prompts in recognizing rare categories. Nevertheless, research on visual prompted detection has been largely overlooked, and it is typically treated as a byproduct of training text prompted detectors, which hinders its development. To fully unlock the potential of visual-prompted detection, we investigate the reasons why its performance is suboptimal and reveal that the underlying issue lies in the absence of global discriminability in visual prompts. Motivated by these observations, we propose DETR-ViP, a robust object detection framework that yields class-distinguishable visual prompts. On top of basic image-text contrastive learning, DETR-ViP incorporates global prompt integration and visual-textual prompt relation distillation to learn more discriminative prompt representations. In addition, DETR-ViP employs a selective fusion strategy that ensures stable and robust detection. Extensive experiments on COCO, LVIS, ODinW, and Roboflow100 demonstrate that DETR-ViP achieves substantially higher performance in visual prompt detection compared to other state-of-the-art counterparts. A series of ablation studies and analyses further validate the effectiveness of the proposed improvements and shed light on the underlying reasons for the enhanced detection capability of visual prompts.",
    "key_points": [
      "object detection",
      "prompt-based detection",
      "open-set object detection"
    ],
    "gold_summary": "This paper introduces a openset detection baseline model called DETR-ViP, The model aims to address a long-standing problem in open-vocabulary object detection: how to use visual prompts more effectively."
  },
  {
    "paper_id": "T4ipdPCY1d",
    "title": "UniFlow: Zero-Shot LiDAR Scene Flow via Cross-Domain Generalization",
    "domain": "applications to computer vision",
    "content": "Scene flow estimation is an important primitive for 3D motion understanding and dynamic scene reconstruction. Recent LiDAR-based methods have made significant progress in achieving centimeter-level accuracy on popular autonomous vehicle (AV) datasets. Notably, such methods typically only train and evaluate on the same dataset because each dataset has its own unique sensor setup. Motivated by recent work in zero-shot image-based scene flow, we argue that multi-dataset training is essential for scaling up LiDAR-based methods. However, prior work in LiDAR-based semantic segmentation and 3D object detection demonstrate that naively training on multiple datasets yields worse performance than single-dataset models. We re-examine this conventional wisdom in the context of LiDAR-based scene flow. Contrary to popular belief, we find that state-of-the-art scene flow methods greatly benefit from cross-dataset training. We posit that low-level tasks such as motion estimation may be less sensitive to sensor configuration than high-level tasks such as detection. Informed by our analysis, we propose UniFlow, a feedforward model that unifies and trains on multiple large-scale LiDAR scene flow datasets with diverse point density and velocity distributions. Our frustratingly simple solution establishes a new state-of-the-art on Waymo and nuScenes, improving over prior work by 16.4% and 34.5% respectively. Moreover, UniFlow achieves state-of-the-art zero-shot accuracy on TruckScenes, outperforming prior dataset-specific models by 38.4%!",
    "key_points": [
      "lidar scene flow",
      "zero-shot",
      "autonomous veicles"
    ],
    "gold_summary": "This paper proposed a multi-dataset training strategy for better performance and generalization ability in scene flow models. Although the multi-dataset training can improve the performance, I have concerns about the zero-shot ability and efficiency."
  },
  {
    "paper_id": "NaHzPMaCY9",
    "title": "Steering Autoregressive Music Generation with Recursive Feature Machines",
    "domain": "applications to computer vision",
    "content": "Controllable music generation remains a significant challenge, with existing methods often requiring model retraining or introducing audible artifacts. We introduce MusicRFM, a framework that adapts Recursive Feature Machines (RFMs) to enable fine-grained, interpretable control over frozen, pre-trained music models by directly steering their internal activations. RFMs analyze a model's internal gradients to produce interpretable \"concept directions\", or specific axes in the activation space that correspond to musical attributes like notes or chords. We first train lightweight RFM probes to discover these directions within MusicGen's hidden states; then, during inference, we inject them back into the model to guide the generation process in real-time without per-step optimization. We present advanced mechanisms for this control, including dynamic, time-varying schedules and methods for the simultaneous enforcement of multiple musical properties. Our method successfully navigates the trade-off between control and generation quality: we can increase the accuracy of generating a target musical note from 0.23 to 0.82, while text prompt adherence remains within approximately 0.02 of the unsteered baseline, demonstrating effective control with minimal impact on prompt fidelity.",
    "key_points": [
      "music generation",
      "probing",
      "interpretability",
      "music ai",
      "multimodal llms",
      "steering",
      "inference"
    ],
    "gold_summary": "This paper presents a training-free method to steer MusicGen with RFMs. The controllable features include tempo, chords, notes, time signatures etc."
  },
  {
    "paper_id": "cZFgsLq8Gs",
    "title": "DeepScientist: Advancing Frontier-Pushing Scientific Findings Progressively",
    "domain": "applications to computer vision",
    "content": "While previous AI Scientist systems can generate novel findings, they often lack the focus to produce scientifically valuable contributions that address pressing human-defined challenges. We introduce DeepScientist, a system designed to overcome this by conducting goal-oriented, fully autonomous scientific discovery over month-long timelines. It formalizes discovery as a Bayesian Optimization problem, using a cumulative Findings Memory to intelligently balance the exploitation of promising avenues with the exploration of novel hypotheses. Consuming over 20,000 GPU hours, the system generated about 5,000 unique ideas and experimentally validated approximately 1100, ultimately surpassing human-designed 2025 state-of-the-art (SOTA) methods on three frontier AI tasks by 183.7\\%, 1.9\\%, and 7.9\\%. Crucially, this was achieved by autonomously redesigning core methodologies, not merely recombining existing techniques. In a striking demonstration, the system achieved progress on AI text detection in just two weeks that is comparable to three years of cumulative human research. This work provides the first large-scale evidence of an AI achieving discoveries that progressively surpass human SOTA on scientific tasks, producing valuable findings that genuinely push the frontier forward. To facilitate further research into this process, we will open-source all experimental logs and system code.",
    "key_points": [
      "automated scientific discovery",
      "large language models (llms)",
      "ai scientist"
    ],
    "gold_summary": "The paper introduces DeepScientist, a system designed to automate goal-oriented scientific discovery. Experimental results suggest that DeepScientist can identify novel methods that outperform state-of-the-art (SOTA) approaches across three frontier AI tasks."
  },
  {
    "paper_id": "vIecIscDJf",
    "title": "HiTeA: Hierarchical Temporal Alignment for Training-Free Long-Video Temporal Grounding",
    "domain": "applications to computer vision",
    "content": "Temporal grounding in long, untrimmed videos is critical for real-world video understanding, yet it remains a challenging task owing to complex temporal structures and pervasive visual redundancy. Existing methods rely heavily on supervised training with task-specific annotations, which inherently limits their scalability and adaptability due to the substantial cost of data collection and model retraining. Although a few recent works have explored training-free or zero-shot grounding, they seldom address the unique challenges posed by long videos. In this paper, we propose HiTeA (Hierarchical Temporal Alignment), a novel, training-free framework explicitly designed for long-video temporal grounding. HiTeA introduces a hierarchical temporal decomposition mechanism that structures videos into events, scenes, and actions, thereby aligning natural language queries with the most appropriate temporal granularity. Candidate segments are then matched with queries by leveraging pre-trained vision–language models (VLMs) to directly compute segment–text similarity, thereby obviating the need for any task-specific training or fine-tuning. Extensive experiments on both short- and long-video benchmarks show that HiTeA not only substantially outperforms all existing training-free methods (e.g., achieving 44.94% R\\@0.1 on TACoS, representing an absolute gain of 12.4%) but also achieves competitive performance against state-of-the-art supervised baselines under stricter metrics. The code is available at https://anonymous.4open.science/r/HiTeA_code.",
    "key_points": [
      "video temporal grounding;training-free;long-video understanding;vision-language models"
    ],
    "gold_summary": "This paper introduces HiTeA, a training-free framework for long-video temporal grounding. The method tackles the challenge of locating temporal segments in long, untrimmed videos corresponding to natural language queries—without requiring any supervised training."
  },
  {
    "paper_id": "hsBBYOqph2",
    "title": "Fixing the Broken Compass: Diagnosing and Improving Inference-Time Reward Modeling",
    "domain": "applications to computer vision",
    "content": "Inference-time scaling techniques have shown promise in enhancing the reasoning capabilities of large language models (LLMs). While recent research has primarily focused on training-time optimization, our work highlights inference-time reward model (RM)-based reasoning as a critical yet overlooked avenue. In this paper, we conduct a systematic analysis of RM behavior across downstream reasoning tasks, revealing three key limitations: (1) RM can impair performance on simple questions, (2) its discriminative ability declines with increased sampling, and (3) high search diversity undermines RM performance. To address these issues, we propose CRISP (Clustered Reward Integration with Stepwise Prefixing), a novel inference-time algorithm that clusters generated reasoning paths by final answers, aggregates reward signals at the cluster level, and adaptively updates prefix prompts to guide generation. Experimental results demonstrate that CRISP significantly enhances LLM reasoning performance, achieving up to 5% accuracy improvement over other RM-based inference methods and an average of 10% gain over advanced reasoning models.",
    "key_points": [
      "model analysis & interpretability",
      "reasoning",
      "inference-time scaling"
    ],
    "gold_summary": "This paper identifies several issues in RM-based inference-time scaling, proposes a new scaling algorithm, and validates its effect through empirical studies."
  },
  {
    "paper_id": "2Un2KLQXir",
    "title": "Taming Data Chaos: Agentic Knowledge Warehousing for Contextual Intelligence",
    "domain": "applications to computer vision",
    "content": "Information seeking can be viewed as bridging the knowledge gap between a query and its answer. While large language models (LLMs) perform strongly across diverse tasks, their capacity to fill this gap is bounded by pretraining data and deteriorates on queries requiring specialized or up-to-date knowledge. A common solution is to augment LLMs with external knowledge, either by injecting retrieved evidence into the context or by interleaving retrieval with reasoning. The former restricts exploration of layered dependencies, whereas the latter is constrained by context length, limiting both efficiency and scalability. Yet complex tasks often involve intricate dependencies and may require processing large volumes of raw text, under which both strategies become inadequate.\n\nTo tackle this bottleneck, we present Agentic Knowledge Warehouse (AWARE), a retrieval paradigm that transforms vast unstructured data into minimal, task-specific knowledge consumable by LLMs. Rather than simply returning raw information, AWARE curates knowledge through an agentic process that plans, explores, and synthesizes evidence into coherent context. Specifically, it organizes raw corpora with document-level gist memory for global coverage, applies diffusion-based exploration with vertical exploitation to recover layered dependencies, and employs map–reduce inspired synthesis to integrate large-scale evidence into a compact, LLM-ready context. This design enables both in-depth exploration and scalable integration, reconstructing the knowledge space needed to address task-specific knowledge gaps. Experiments on GAIA, WebWalker, and BrowseComp show that AWARE outperforms baselines, validating its effectiveness and generality.",
    "key_points": [
      "complex knowledge discovery",
      "contextual intelligence",
      "large language models"
    ],
    "gold_summary": "This paper proposes AWARE, which refines the indexing of corpora to be retrieved and leverages diffusion-search to augment the reasoning process of LLMs to solve complex problems."
  },
  {
    "paper_id": "6mrtHalbuh",
    "title": "Evaluating the use of large language models for post optical character recognition correction in Brazilian Portuguese",
    "domain": "applications to computer vision",
    "content": "In recent decades digital media have taken precedence over printed media, firmly establishing themselves in everyday life. Optical Character Recognition (OCR) technology facilitates the digitization of printed text but frequently introduces errors during the process. This study investigates the effectiveness of generative Large Language Models (LLMs), like the model Gemma 3, in correcting OCR outputs in Brazilian Portuguese. Using the ESTER-Pt dataset, we assess the models' ability to leverage contextual information to identify and correct OCR-induced errors. The results demonstrate that LLMs can significantly outperform existing methods, achieving an improvement in character error rate (CER) over the current state of the art in Portuguese, reducing it from 5.12 to 1.69.",
    "key_points": [
      "post-ocr error correction",
      "brazilian portuguese"
    ],
    "gold_summary": "This paper evaluates LLM for post-OCR correction, specifically for Brazilian Portuguese.  Results show better performance using an LLM versus other tested alternatives."
  },
  {
    "paper_id": "qkKUG56s5r",
    "title": "Automatic Complementary-Separation Pruning for Efficient CNNs",
    "domain": "applications to computer vision",
    "content": "Reducing the complexity of neural networks without sacrificing performance is a critical challenge for deploying models in real-world, resource-constrained environments. We introduce Automatic Complementary Separation Pruning (ACSP), a novel and fully automated method for pruning convolutional neural networks that focuses on accelerating inference time. ACSP combines structured and activation-based pruning to remove redundant neurons and channels while preserving essential components. Tailored for supervised learning tasks, ACSP constructs a graph space that encodes the separation capabilities of each component across all class pairs. By leveraging complementary selection principles and clustering techniques, ACSP ensures that the selected components maintain diverse and complementary separation capabilities, reducing redundancy and maintaining high network performance. The pruning volume is determined automatically, removing the need for manual tuning. This approach significantly reduces the number of FLOPs (floating-point operations) and results in faster inference time without compromising accuracy.",
    "key_points": [
      "neural network pruning",
      "model compression",
      "layer pruning",
      "computational efficiency"
    ],
    "gold_summary": "The paper proposes a pruning method for neural networks based on combining structured pruning with activation-based pruning, using graph representations that encode separation capabilities of each component across class pairs."
  },
  {
    "paper_id": "HHQjNDiWoR",
    "title": "Can LLMs Serve as Causal Inference Agents? A Study on Post-Training Methods",
    "domain": "applications to computer vision",
    "content": "Despite the potential of Large Language Models (LLMs) to democratize causal inference, they currently struggle with quantitative reasoning. This paper investigates whether post-training can transform an LLM into a practical and accessible causal inference agent for non-professionals. To facilitate this, we first introduce the DeepCausal dataset, a novel collection of seven computational causal inference tasks designed for both training and evaluation. We then propose DeepCausal, an LLM-based agent that enables users to perform complex causal analysis using natural language. Our core methodology involves a comprehensive comparison of online and offline post-training techniques. We find that while offline training equips LLMs with fundamental causal concepts, online post-training is crucial for teaching them how to apply these rules to solve problems, resulting in a significantly more effective, robust, and generalizable model. Our extensive experiments demonstrate that DeepCausal effectively performs causal effect estimation, providing clear, interpretable explanations in natural language. By lowering the technical barrier, our work makes complex causal analysis accessible to a broader audience and establishes the viability of using post-trained LLMs for sophisticated causal reasoning.",
    "key_points": [
      "large language models (llms)",
      "causal inference",
      "post-training"
    ],
    "gold_summary": "The author introduced the DeepCausa dataset (with variants) for training large language models in causal reasoning and evaluated the effectiveness of popular post-training methods in enabling models to perform this task."
  },
  {
    "paper_id": "0ZRne2Nt8t",
    "title": "MAIG: Multi-agent system for Academic Illustration Generation based on deep search and reflection",
    "domain": "applications to computer vision",
    "content": "While text-to-image models have revolutionized creative content generation, they fall short in the domain of academic illustration, which demands stringent scientific accuracy and informational completeness, creating a significant bottleneck in automated scientific communication. Existing models often produce illustrations that are factually incorrect, omit critical information, and are limited to simple structured diagrams, failing to render the complex, unstructured conceptual visuals common in science. To address these challenges, we introduce \\textbf{MAIG}, a novel multi-agent framework that mimics an expert's workflow. MAIG first employs a deep research agent to ground the generation process in a factual knowledge base, ensuring all necessary background information is available. Subsequently, reflection and editing agents iteratively verify the visual output against this knowledge, identifying and correcting scientific errors. In the meantime, evaluating scientific figures is a parallel challenge plagued by subjective and unscalable methods, we also propose a novel Question-Answering (QA) based Evaluator. This method leverages the strong reasoning capabilities of modern Multimodal Large Language Models (MLLMs) to quantitatively measure both informational completeness and factual correctness, providing an objective and scalable assessment of an illustration's quality. Extensive experiments across various scientific disciplines demonstrate the effectiveness of MAIG, which achieves minimal factual errors and the most complete knowledge coverage, significantly outperforming state-of-the-art models.Our results validate that the proposed research-reflect-edit loop is crucial for generating high-fidelity scientific illustrations and that our QA-based evaluator offers a reliable assessment methodology, together forming a comprehensive solution for advancing automated scientific visualization.",
    "key_points": [
      "image generation",
      "multi-agent",
      "academic illustration"
    ],
    "gold_summary": "Multi-agent pipeline (research → generate → reflect/edit) for scientific illustration; introduces an MLLM QA-based metric (ACC/NBR) for factuality/completeness; reports gains over GPT-4o/Qwen on small bespoke tasks."
  },
  {
    "paper_id": "LIG31I6ArY",
    "title": "IntE: Quantitative Framework for Qualitative Data Evaluation via Distributional Mining",
    "domain": "applications to computer vision",
    "content": "Evaluating the quality of qualitative datasets containing responses collected for semi-structured questions is a persistent challenge. Manual analysis is slow and subjective, while existing automated methods lack a holistic, dataset-level perspective crucial for mining insights. We introduce IntE, a novel framework for the quantitative assessment of qualitative response datasets. IntE evaluates dataset quality using the cluster distributions based on collected responses and the predefined demographic distributions based on user metadata. IntE is structured into a four-quadrant assessment that quantifies the potential of a dataset for revealing general patterns and unique insights. The four quadrants rely on the distributions reconstructed via metadata and intra-data distances. Therefore, we propose a content-aware multi-agent system that accurately computes inter-response dissimilarity. This system features a two-stage adversarial framework for generating domain-specific evaluation instructions and an adaptive anchor algorithm to ensure scoring consistency. \nWe validate IntE through controlled experiments on synthetic data, highlighting the effectiveness of its components. Additionally, a real-world social survey case study, validated by domain experts, demonstrates IntE's capability to enhance knowledge discovery by accurately evaluating dataset quality and identifying key responses for analysis.",
    "key_points": [
      "qualitative data evaluation",
      "semi-structured questions",
      "content-aware dissimilarity extraction",
      "multi-agent system"
    ],
    "gold_summary": "This paper introduce a framework for analysis of qualitative response datasets. The framework combine cluster analysis and multi-agent LLMs to evaluate the datasets."
  },
  {
    "paper_id": "ea1U1MgbdT",
    "title": "Pose-RFT: Aligning MLLMs for 3D Pose Generation via Hybrid Action Reinforcement Fine-Tuning",
    "domain": "applications to computer vision",
    "content": "Generating 3D human poses from multimodal inputs such as text or images requires models to capture both rich semantic and spatial correspondences. While pose-specific multimodal large language models (MLLMs) have shown promise, their supervised fine-tuning (SFT) paradigm struggles to resolve the task's inherent ambiguity. Its reliance on objectives like SMPL parameter regression creates a critical alignment gap, compromising the model's ability to achieve the required semantic and spatial fidelity. To close the gap, we propose Pose-RFT, a framework that shifts the learning paradigm from supervised imitation to reward-driven reinforcement fine-tuning (RFT). We address the core technical challenge of this task: a \nhybrid action space requiring joint optimization of discrete language and continuous pose outputs. To this end, we introduce HyGRPO, a hybrid reinforcement learning algorithm that enables stable optimization by performing group-wise reward normalization over sampled responses. Pose-RFT incorporates task-specific reward functions to guide optimization towards spatial alignment in image-to-pose generation and semantic consistency in text-to-pose generation.\nExtensive experiments on multiple pose generation benchmarks demonstrate that Pose-RFT significantly improves performance over existing pose-specific MLLMs, validating the effectiveness of our approach in closing the alignment gap for 3D pose generation.",
    "key_points": [
      "human pose estimation",
      "multimodal large language model",
      "reinforcement fine-tuning"
    ],
    "gold_summary": "Pose-RFT introduces a RL fine-tuning framework for MLLM-based 3D pose generation. This framework, HyGRPO, utilizes a mixed optimization strategy to optimize both discrete tokens (from the LLM) and continuous motion (SMPL params)."
  },
  {
    "paper_id": "Othf7vEtg7",
    "title": "MoCA: Mixture-of-Components Attention for Scalable Compositional 3D Generation",
    "domain": "applications to computer vision",
    "content": "Compositionality is critical for 3D object and scene generation, but existing part-aware 3D generation methods suffer from poor scalability due to quadratic global attention costs when increasing the number of components. In this work, we present MoCA, a compositional 3D generative model with two key designs: 1) importance-based component routing that selects top-k relevant components for sparse global attention, and 2) unimportant components compression that preserve contextual priors of unselected components while reducing computational complexity of global attention. With these designs, MoCA enables efficient, fine-grained compositional 3D asset creation with scalable number of components. Extensive experiments show MoCA outperforms baselines on both compositional object and scene generation tasks.",
    "key_points": [
      "compositional 3d generation",
      "latent diffusion models",
      "sparse attention"
    ],
    "gold_summary": "This paper introduces MoCA, a compositional 3D generative model for efficient, scalable, and accurate compositional modeling of 3D objects and scenes."
  },
  {
    "paper_id": "INnZIRw2XE",
    "title": "Scaling Open-world Multiple Object Tracking",
    "domain": "applications to computer vision",
    "content": "Multiple Object Tracking (MOT) has traditionally relied on expensive, exhaustively annotated datasets, limiting scalability and generalization.\nTo address these limitations, we propose \\textbf{\\ourmodel}, a transformer-based association module for MOT, explicitly designed to leverage large-scale, sparsely annotated video data. At the core of our approach is \\textit{Chain Contrastive Learning}, a novel contrastive strategy that maintains local discriminability while capturing long-range temporal coherence. Specifically, our approach constructs positive pairs in a chained manner across consecutive frames, promoting transitive consistency and local discriminability simultaneously. Our model additionally features a multi-scale spatiotemporal attention mechanism that effectively integrates contextual information across space and time, ensuring robust associations even in challenging scenarios. Notably, our method consistently improves performance as the amount of training video data increases, demonstrating robust scalability.\nOur tracker is designed as a plug-and-play module that seamlessly synergizes with any object detector, achieving state-of-the-art zero-shot performance across multiple large-scale MOT benchmarks, including TAO, BDD100K, SportsMOT and OVT-B. Code will be made public.",
    "key_points": [
      "open-vocabulary tracking",
      "multiple object tracking",
      "open-world"
    ],
    "gold_summary": "The paper proposes Chain Contrastive Learning to maintain local discriminability while capturing long-range temporal coherence. The performance seems good on many datasets."
  },
  {
    "paper_id": "WnRzN4U8Y8",
    "title": "WIMFRIS: WIndow Mamba Fusion and Parameter Efficient Tuning for Referring Image Segmentation",
    "domain": "applications to computer vision",
    "content": "Existing Parameter-Efficient Tuning (PET) methods for Referring Image Segmentation (RIS) primarily focus on layer-wise feature alignment, often neglecting the crucial role of a neck module for the intermediate fusion of aggregated multi-scale features, which creates a significant performance bottleneck. To address this limitation, we introduce WIMFRIS, a novel framework that establishes a powerful neck architecture alongside a simple yet effective PET strategy. At its core is our proposed HMF block, which first aggregates multi-scale features and then employs a novel WMF module to perform effective intermediate fusion. This WMF module leverages non-overlapping window partitioning to mitigate the information decay problem inherent in SSMs while ensuring rich local-global context interaction. Furthermore, our PET strategy enhances primary alignment with a MTA for robust textual priors, a MSA for precise vision-language fusion, and learnable emphasis parameters for adaptive stage-wise feature weighting. Extensive experiments demonstrate that WIMFRIS achieves new state-of-the-art performance across all public RIS benchmarks.",
    "key_points": [
      "referring image segmentation",
      "parameter efficient tuning",
      "computer vision"
    ],
    "gold_summary": "The paper presents a parameter-efficient framework that integrates a window-based intermediate fusion neck (HMF) and lightweight adapters (MTA, MSA, and emphasis parameters) to enhance vision–language alignment for referring image segmentation."
  },
  {
    "paper_id": "snbY9Uj0Gx",
    "title": "Plug-and-Play Retrieval-Augmented Active Test-Time Adaptation for VLMs",
    "domain": "applications to computer vision",
    "content": "Pre-trained vision-language models (VLMs) have demonstrated remarkable performance across various real-world benchmarks. In particular, CLIP, one of the famous VLMs, has achieved satisfactory performance on vision-language tasks without fine-tuning (\\ie zero-shot setting). Nevertheless, it is well-known that effectively leveraging a pre-trained model requires adaptation to the test distribution. Since the test distribution is typically unknown, test-time adaptation (TTA) has emerged as one of the solutions. However, existing TTA algorithms rely not on expert-provided ground-truth knowledge but on pseudo-labels derived from the knowledge of the pre-trained model itself. This undesirable reliance can lead to a cascade of incorrect knowledge propagation. To address this issue, we propose a novel framework, active test-time adaptation, which selectively queries human experts for ground-truth labels of uncertain samples and incorporates them for answering future queries. Then, we develop a novel algorithm, **RE**trieval-augmented **ACT**ive TTA (**REACT**), which is designed to be plug-and-play with any TTA algorithms. Through extensive experiments on ten real-world benchmarks commonly used in CLIP evaluation as well as a domain transfer benchmark based on ImageNet, the proposed algorithm is shown to effectively identify and query informative samples, leveraging them to enhance test-time inference capabilities.",
    "key_points": [
      "active test-time adaptation",
      "vision-language model",
      "retrieval-augmented"
    ],
    "gold_summary": "This paper introduces extra information from an external database during test-time adaptation via retrieval. The method is designed as a plug-and-play module for various  TTA methods."
  },
  {
    "paper_id": "LqrWNdceum",
    "title": "EMBridge: Enhancing Gesture Generalization from EMG Signals Through Cross-modal Representation Learning",
    "domain": "applications to computer vision",
    "content": "Hand gesture classification using high-quality structured data such as videos, images, and hand skeletons is a well-explored problem in computer vision. Alternatively, leveraging low-power, cost-effective bio-signals, e.g. surface electromyography (sEMG), allows for continuous gesture prediction on wearable devices. In this work, we aim to enhance EMG representation quality by aligning it with embeddings obtained from structured, high-quality modalities that provide richer semantic guidance, ultimately enabling zero-shot gesture generalization. Specifically, we propose EMBridge, a cross-modal representation learning framework that bridges the modality gap between EMG and pose. EMBridge learns high-quality EMG representations by introducing a Querying Transformer (Q-Former), a masked pose reconstruction loss, and a community-aware soft contrastive learning objective that aligns the relative geometry of the embedding spaces. We evaluate EMBridge on both in-distribution and unseen gesture classification tasks and demonstrate consistent performance gains over all baselines. To the best of our knowledge, EMBridge is the first cross-modal representation learning framework to achieve zero-shot gesture classification from wearable EMG signals, showing potential toward real-world gesture recognition on wearable devices.",
    "key_points": [
      "emg",
      "zero-shot gesture classification",
      "cross-modal",
      "representation learning"
    ],
    "gold_summary": "This paper presents a cross-modal framework that aligns EMG signals with hand pose embeddings to enable zero-shot gesture recognition. The approach is technically solid and yields consistent improvements."
  },
  {
    "paper_id": "E9n2OlNZCH",
    "title": "Verifying Out-of-Distribution Robustness in Multi-spectral Satellite Change Detection",
    "domain": "applications to computer vision",
    "content": "Reliable multi-spectral change detection on-board satellites requires robustness under distribution shifts. We address this challenge from both the certification and empirical perspectives.\n\nOn the certification side, we adapt neural verification to the unique structure of change detection, accounting for sensor noise, encoder–decoder heads, and semantic evaluation. We introduce a tail-tapped verifier that transports input intervals to the final decoder tap and applies $\\alpha$-CROWN solely to the decision head. This yields per-pixel logit-margin lower bounds, which we summarize through task-aligned predicates such as coverage, false positives, and minimum island size.\n\nOn the empirical side, we study out-of-distribution robustness across three representative backbones — U-Net style encoder–decoder (FresUNet), lightweight convolutional attention encoder–decoder (FALCONet), and transformer-inspired global attention encoder–decoder (AttU-Net) — on the Onera Satellite Change Detection (OSCD) dataset. We find that existing certificates vanish even for mild perturbations ($\\varepsilon \\ge 1/255$), while empirical robustness varies widely across architectures.\n\nOur results highlight both the difficulty of certifying change detection and the promise of architecture design for achieving practical robustness. This establishes a foundation for principled verification and stress-tested deployment of satellite-based change detection models",
    "key_points": [
      "change detection",
      "certified robustness",
      "out-of-distribution generalization",
      "multi-spectral remote sensing",
      "encoder–decoder architectures"
    ],
    "gold_summary": "This paper investigates robustness of multi-spectral satellite change detection on both certification and empirical perspectives."
  },
  {
    "paper_id": "v8md2B38MX",
    "title": "Rethinking Visual Information Processing in Multimodal LLMs",
    "domain": "applications to computer vision",
    "content": "Despite the remarkable success of the LLaVA architecture for vision-language tasks, its design inherently struggles to effectively integrate visual features due to the inherent mismatch between text and vision modalities. We tackle this issue from a novel perspective in which the LLM not only serves as a language model but also a powerful vision encoder. To this end, we present LLaViT–Large Language Models as extended Vision Transformers—which enables the LLM to simultaneously function as a vision encoder through three key modifications: (1) learning separate QKV projections for vision modality, (2) enabling bidirectional attention on visual tokens, and (3) incorporating both global and local visual representations. Through extensive controlled experiments on a wide range of LLMs, we demonstrate that LLaViT significantly outperforms the baseline LLaVA method on a multitude of benchmarks, even surpassing models with double its parameter count, establishing a more effective approach to vision-language modeling.",
    "key_points": [
      "multimodal",
      "llm",
      "vlm"
    ],
    "gold_summary": "This paper proposes a visual information re-weighting pipeline intended to emphasize key regions in image representations and improve downstream recognition tasks. The framework is evaluated across several benchmarks to demonstrate performance improvements."
  },
  {
    "paper_id": "DUpmBHZTmH",
    "title": "LacTok: Latent Consistency Tokenizer for High-resolution Image Reconstruction and Generation by 256 Tokens",
    "domain": "applications to computer vision",
    "content": "Image tokenization has significantly advanced visual generation and multimodal\nmodeling, particularly when paired with autoregressive models. However, current\nmethods face challenges in balancing efficiency and fidelity: high-resolution image\nreconstruction either requires an excessive number of tokens or compromises\ncritical details through token reduction. To resolve this, we propose Latent Consistency\nTokenizer (LacTok) that bridges discrete visual tokens with the compact\nlatent space of pre-trained Latent Diffusion Models (LDMs), enabling efficient\nrepresentation of 1024×1024 images using only 256 tokens—a 16× compression\nover VQGAN. LacTok integrates a transformer encoder, a quantized codebook,\nand a latent consistency decoder. Direct application of LDM as the decoder results\nin color and brightness discrepancies; thus, we convert it to latent consistency\ndecoder, reducing multi-step sampling to 1-2 steps for direct pixel-level supervision.\nExperiments demonstrate LacTok’s superiority in high-fidelity reconstruction,\nwith 10.8 reconstruction Frechet Inception Distance on MSCOCO-2017 5K\nbenchmark for 1024×1024 image reconstruction. We also extend LacTok to a textto-\nimage generation model, LacTokGen, working in autoregression. It achieves\n0.73 score on GenEval benchmark, surpassing current state-of-the-art methods.",
    "key_points": [
      "tokenizer",
      "consistency model",
      "image generation",
      "image reconstruction"
    ],
    "gold_summary": "This paper proposes LacTok, a discrete tokenizer for efficient compression of high-resolution images, achieving a 16x compression ratio compared with conventional VQGAN."
  },
  {
    "paper_id": "Aymp6MkZwn",
    "title": "JARA: Joint Alignment and Reconstruction Architecture for Region-Aware Vision-Language Pretraining",
    "domain": "applications to computer vision",
    "content": "Contrastive Language-Image Pretraining (CLIP) shows strong zero-shot transfer capabilities. However, it fails to capture the intrinsic semantic structure within images and performs weak on fine-grained retrieval and dense prediction. In this work, we propose Joint Alignment and Reconstruction Architecture (JARA), a unified framework that integrates region-aware learning into CLIP via self-supervised objectives. JARA employs a Spatially Balanced Masking (SBM) strategy to decouple each image into context and masked regions uniformly. On this basis, JARA firstly replaces vision-to-vision self-distillation with Cross-Modal Self-Distillation (CMSD) to align context region's \\texttt{[CLS]} tokens with paired captions. Secondly, JARA extends multi-view learning to semantic patch reconstruction to encourage the model to learn the intrinsic association across image regions, enabling region-level semantics to synchronously emerge during contrastive training. Both objectives are optimized in the same masked view, achiving an efficient single-pass training. Experiments on image-text retrieval and open-vocabulary segmentation show that JARA achieves state-of-the-art performance while remaining efficient. The code will be available after the review phase.",
    "key_points": [
      "vision language pretraining"
    ],
    "gold_summary": "This paper introduces a novel Vision-Language Pretraining approach that integrates the training methodologies of DINO and CLIP into a unified framework, thereby enhancing the model's performance in downstream applications."
  },
  {
    "paper_id": "B8nSGoGiJr",
    "title": "Noise and anatomy-guided diffusion model for realistic CT image synthesis",
    "domain": "applications to computer vision",
    "content": "Generative models, specifically Diffusion Models (DMs), have been quite successful in generating high-quality images. However, DMs rely on large-scale training data. In medical imaging, more specifically for computed tomography (CT), these models struggle in accurately reconstructing anatomical structures due to limited training data. This can cause the wrong depiction of organs, which can impact clinical treatment. Some existing models, although guided by anatomical structures, ignore dose-dependent noise, which is critical in real-world scenarios. To tackle this challenge, we propose a novel diffusion model, namely NA-Diff, which is guided by noise from different dose levels and anatomical structures, leveraging a dual conditional diffusion framework. To facilitate large-scale training of DMs on complex structured CT data, we transform natural images emulating realistic CT noises and leverage them for pre-training, followed by fine-tuning on small CT data. Extensive experimental results demonstrate that NA-Diff generates high-fidelity and noise-aware CT images, effectively delineating the organ-of-interest and bridging the gap between synthetic and real CT.",
    "key_points": [
      "ct image",
      "synthesis",
      "diffusion",
      "dual-conditioned"
    ],
    "gold_summary": "The paper introduces NA-Diff for CT image synthesis guided by both noise and anatomical conditions. NA-Diff leverages the emulated CT noise and natural-image pretrained weights to overcome limited CT data."
  },
  {
    "paper_id": "XroExfcQ5U",
    "title": "PointVLM: Multi-Modal Vision-Language Model for CAD Model Understanding via Point Cloud Integration",
    "domain": "applications to computer vision",
    "content": "In computer-aided design (CAD) and engineering, understanding complex CAD models remains a critical challenge. Existing methods struggle with integrating geometric features due to the lack of 3D modality and the difficulty of modal fusion. To address this, we introduce PointVLM, a novel multi-modal vision-language model that bridges 3D point cloud processing with vision and natural language understanding to enable precise CAD model interpretation. PointVLM leverages a 3D encoder to grasp 3D features from the point cloud of the object in addition to vision and language modalities. By combining Qwen2.5-VL architecture, PointVLM fuses three kinds of modality features using a learnable projector module, enabling context-aware interactions between geometric and semantic properties. We further build a pipeline which takes CAD file and instruction as input, automatically samples point clouds and renders multi-view images, and finally outputs responses. Experiments show that PointVLM outperforms existing methods on both generative 3D object classification and 3D object captioning tasks. The source code and pre-trained models will be available at MASKED_URL.",
    "key_points": [
      "point cloud",
      "3d understanding",
      "multi-modal llm"
    ],
    "gold_summary": "This paper presents  PointVLM, a multi-modal vision-language model that bridges 3D point cloud processing with vision and natural\nlanguage understanding. The proposed method is evaluated by 3D object classification and 3D object captioning tasks."
  },
  {
    "paper_id": "eLsEjjFODE",
    "title": "SpeechOp: Inference-Time Task Composition for Generative Speech Processing",
    "domain": "applications to computer vision",
    "content": "While generative Text-to-Speech (TTS) systems leverage vast \"in-the-wild\" data to achieve remarkable success, speech-to-speech processing tasks like enhancement face data limitations, which lead data-hungry generative approaches to distort speech content and speaker identity. To bridge this gap, we present SpeechOp, a multi-task latent diffusion model that transforms pre-trained TTS models into a universal speech processor capable of performing a wide range of speech tasks and composing them in novel ways at inference time. By adapting a pre-trained TTS model, SpeechOp inherits a rich understanding of natural speech, accelerating training and improving S2S task quality, while simultaneously enhancing core TTS performance. Finally, we introduce Implicit Task Composition (ITC), a novel pipeline where ASR-derived transcripts (e.g., from Whisper) guide SpeechOp's enhancement via our principled inference-time task composition. ITC achieves state-of-the-art content preservation by robustly combining web-scale speech understanding with SpeechOp's generative capabilities.",
    "key_points": [
      "speech generation",
      "tts",
      "enhancement",
      "diffusion",
      "latent diffusion"
    ],
    "gold_summary": "The paper proposes a multi-task training method that jointly learn on TTS and speech processing tasks. The paper also proposes a test time composition method using CFG to better guide the speech processing task."
  },
  {
    "paper_id": "9ttjYx3NJQ",
    "title": "Finding agreement in disagreement: Simultaneous label alignment and multi-dataset training with SLAMDUNKS",
    "domain": "applications to computer vision",
    "content": "Multi-dataset training is a key strategy for improving the versatility and robustness of deep models, but its effectiveness is often hindered by unaligned and contradictory dataset taxonomies. These inconsistencies introduce training noise and prevent effective knowledge sharing. To address this, we propose SLAMDUNKS, a framework for simultaneous multi-dataset training and label alignment. Its core is a shared feature extractor trained with two competing heads: a gating head that determines which dataset-specific classes should be shared, and a classification head that maps samples to the emerging shared taxonomy. To rigorously evaluate alignment quality, we introduce a synthetic benchmark where ground-truth relations are modeled as bipartite graphs. Our method demonstrates remarkable precision, perfectly recovering the true taxonomy (a Graph Edit Distance of 0) for same-domain datasets. Across more challenging cross-domain pairs, SLAMDUNKS achieves an Average Precision of 0.8, outperforming the state-of-the-art by 0.1 to 0.2 and validating its superior alignment capabilities.",
    "key_points": [
      "computer vision",
      "multi-dataset training",
      "image classification",
      "aligning taxonomies"
    ],
    "gold_summary": "The author proposed a framework for simultaneous multi-dataset training and label alignment and a synthetic benchmark to address the problem of the inconsistencies across the datasets."
  },
  {
    "paper_id": "Yzr27JSBiV",
    "title": "Knowledge distillation through geometry-aware representational alignment",
    "domain": "applications to computer vision",
    "content": "Knowledge distillation is a common paradigm for transferring capabilities from larger models to smaller ones. While traditional distillation methods leverage a probabilistic divergence over the output of the teacher and student models, feature-based distillation methods often minimize variants of Euclidean norms between the hidden layer representations. The main goal is for the student to mimic the structure of the feature space of the teacher. In this work, we theoretically show that existing feature distillation methods, such as projection based mean squared loss or Centered Kernel Alignment (CKA), cannot capture the feature structure, even under zero loss. We then motivate the use of \\textit{Procrustes distance} and the Frobenius norm of \\textit{Feature Gram Matrix}, distances already common in the context of measuring representational alignment, as distillation losses. We show that feature distillation through our method showcases statistically significant improvement in distillation performance across language models families (BERT and OPT) in classification and instruction-following tasks by up to 2 percentage points, showcasing the potential of integrating feature geometry into existing distillation methods.",
    "key_points": [
      "representation learning",
      "knowledge distillation",
      "large language models"
    ],
    "gold_summary": "This work tackles the conflict issues generated in graph manipulation steps of generated scene graphs for downstream tasks."
  },
  {
    "paper_id": "kBsBUqEVES",
    "title": "Track4Animate3D: Animating Any 3D Model via Multi-View Diffusion with Point-Tracking Motion Priors",
    "domain": "applications to computer vision",
    "content": "Generating 4D objects is challenging because it requires jointly maintaining appearance and motion consistency across space and time under sparse inputs, while avoiding artifacts and temporal drift. \nWe hypothesize that this view discrepancy stems from supervision that relies solely on pixel- or latent-space video-diffusion losses and lacks explicitly temporally aware tracking guidance at feature-level.\nTo address this issue, we introduce \\emph{Track4Animate3D}, a two-stage framework that unifies a multi-view video diffusion model with a foundation point tracker and a hybrid 4D Gaussian Splatting (4D-GS) reconstructor.\nThe core idea is to explicitly inject motion priors from a foundation point tracker into the feature representation for both video generation and 4D-GS.\nIn Stage One, we impose dense, feature-level point correspondences within the diffusion generator, enforcing temporally consistent feature representations that suppress appearance drift and strengthen cross-view coherence. \nIn Stage Two, we reconstruct a dynamic 4D-GS using a hybrid motion representation that concatenates co-located diffusion features (carrying tracking priors from Stage One) with Hex-plane features, and appends a 4D Spherical Harmonics modeling, improving higher-fidelity dynamics and illumination modeling.\n\\emph{Track4Animate3D} outperforms strong baselines (e.g., Animate3D, DG4D) across VBench metrics for multi-view video generation, CLIP-O/F/C metrics and user preference studies for 4D generation, producing temporally stable and text-editable 4D assets. \nFinally, we curate a new high-quality 4D dataset named \\emph{Sketchfab28}, to evaluate object-centric 4D generation for future research.",
    "key_points": [
      "4d reconstruction",
      "gaussian splatting"
    ],
    "gold_summary": "This paper introduces Track4Animate3D, a novel two-stage framework designed to solve the core challenges in 4D object generation—such as maintaining appearance and motion consistency over time and avoiding visual artifacts."
  },
  {
    "paper_id": "KdI9luPqaB",
    "title": "SeqRL: Sequence-Attentive Reinforcement Learning for LLM Jailbreaking",
    "domain": "applications to computer vision",
    "content": "Large Language Models (LLMs) have demonstrated remarkable capabilities across diverse domains, underscoring the importance of ensuring their safety and robustness. Recent work has examined jailbreaking attacks that bypass safeguards, but most methods either rely on access to model internals or depend on heuristic prompt designs, limiting general applicability. Reinforcement learning (RL)-based approaches address some of these issues, yet they often require many interaction steps and overlook vulnerabilities revealed in earlier turns. We propose a novel RL-based jailbreak framework that explicitly analyzes and reweights vulnerabilities from prior steps, enabling more efficient attacks with fewer queries. We first show that simply leveraging historical information already improves jailbreak success. Building on this insight, we introduce an attention-based reweighting mechanism that adaptively highlights critical vulnerabilities within the interaction history. Through comprehensive evaluations on the AdvBench benchmark, our method achieves state-of-the-art performance, demonstrating higher effectiveness in jailbreak success and greater efficiency in query usage. These findings emphasize the value of incorporating historical vulnerability signals into RL-driven jailbreak strategies, offering a general and effective pathway for advancing adversarial research on LLM safeguards.",
    "key_points": [
      "jailbreaking",
      "llm",
      "safety",
      "reinforcement learning"
    ],
    "gold_summary": "This paper proposes a sequence-aware reinforcement learning framework for LLM jailbreaking."
  },
  {
    "paper_id": "faYbbo1KsQ",
    "title": "HiCache: A Plug-in Scaled-Hermite Upgrade for Taylor-Style Cache-then-Forecast Diffusion Acceleration",
    "domain": "applications to computer vision",
    "content": "Diffusion models have achieved remarkable success in content generation but suffer from prohibitive computational costs due to iterative sampling. While recent feature caching methods tend to accelerate inference through temporal extrapolation, these methods still suffer from severe quality loss due to the failure in modeling the complex dynamics of feature evolution. To solve this problem, this paper presents HiCache (Hermite Polynomial-based Feature Cache), a training-free acceleration framework that fundamentally improves feature prediction by aligning mathematical tools with empirical properties. Our key insight is that feature derivative approximations in Diffusion Transformers exhibit multivariate Gaussian characteristics, motivating the use of Hermite polynomials, the potentially theoretically optimal basis for Gaussian-correlated processes. Besides, we introduce a dual-scaling mechanism that ensures numerical stability while preserving predictive accuracy, which is also effective when applied standalone to TaylorSeer. Extensive experiments demonstrate HiCache's superiority: achieving \\$5.55\\times\\$ speedup on FLUX.1-dev while exceeding baseline quality, maintaining strong performance across text-to-image, video generation, and super-resolution tasks. Moreover, HiCache can be naturally added to the previous caching methods to enhance their performance, e.g., improving ClusCa from \\$0.9480\\$ to \\$0.9840\\$ in terms of image rewards. Our code is included in the supplementary material, and will be released on GitHub.",
    "key_points": [
      "diffusion acceleration",
      "efficiency ml"
    ],
    "gold_summary": "This paper proposes HiCache, a training-free acceleration framework for diffusion transformers that replaces Taylor expansion with scaled Hermite polynomial-based feature caching, achieving more stable and accurate predictions across multiple generative tasks."
  },
  {
    "paper_id": "dpVx9wCXAg",
    "title": "Beyond Textual CoT: Interleaved Text-Image Chains with Deep Confidence Reasoning for Image Editing",
    "domain": "applications to computer vision",
    "content": "Image editing with natural language has gained significant popularity, yet existing methods struggle with intricate object intersections and fine-grained spatial relationships due to the lack of an explicit reasoning process. While Chain-of-Thought (CoT) has been explored to enhance reasoning, purely textual CoT or CoT augmented with coordinate information is fundamentally limited in its ability to represent intricate visual layouts and lacks the necessary visual cues to guide the generation of fine-grained, pixel-level details. To address these challenges, we propose $\\textbf{Mu}$ltimodal $\\textbf{R}$easoning $\\textbf{E}$dit ($\\textbf{MURE}$), a novel framework that $\\textit{shifts the visual editing process from purely text-based reasoning to a series of interleaved textual and visual rationales}$. Our framework performs image editing using a natively multimodal, interleaved text-image CoT. This approach generates a step-by-step chain of reasoning where a textual description is followed by a corresponding visual cue, such as a positional mask that defined intended edited regions or a representation of new content. Furthermore, to mitigate the hallucination phenomenon of large language models, we introduce $\\textbf{M}$ulti$\\textbf{m}$odal $\\textbf{D}$eep $\\textbf{C}$onfidence ($\\textbf{MMDC}$) reasoning paradigm. This paradigm explores a tree of visual reasoning paths at each step. By pruning low-quality branches using a deep confidence score from a reward model, it ensures the model consistently follows a high-quality trajectory towards the final edited result. The proposed method decomposes complex editing tasks into interdependent sub-tasks, achieving greater precision at each stage and yielding high-fidelity edited results. We define the formulation for interleaved text-image chains and release the first CoT-Edit-14K dataset, comprising 14K high-quality editing examples. Extensive experiments show that our method yields significant improvements across three image editing benchmarks, establishing a more effective reasoning framework for visual editing.",
    "key_points": [
      "image editing",
      "multi-modal chain-of-thought",
      "deep confidence reasoning."
    ],
    "gold_summary": "The paper proposes an interleaved CoT formation with confidence-based pruning, along with a new dataset CoT-Edit-14K to fine-tune an existing MLLM to enhance its image editing capability."
  },
  {
    "paper_id": "oxgcPoDkNv",
    "title": "Bridging Radiology and Pathology Foundation Models via Concept-Based Multimodal Co-Adaptation",
    "domain": "applications to computer vision",
    "content": "Pretrained medical foundation models (FMs) have shown strong generalization across diverse imaging tasks, such as disease classification in radiology and tumor grading in histopathology. While recent advances in parameter-efficient finetuning have enabled effective adaptation of FMs to downstream tasks, these approaches are typically designed for a single modality. In contrast, many clinical workflows rely on joint diagnosis from heterogeneous domains, such as radiology and pathology, where fully leveraging the representation capacity of multiple FMs remains an open challenge. To address this gap, we propose Concept Tuning and Fusing (CTF), a parameter-efficient framework that uses clinically grounded concepts as a shared semantic interface to enable cross-modal co-adaptation before fusion. By incorporating task-specific concepts that are relevant across modalities, CTF aligns radiology and pathology representations, thereby enhancing their complementarity and enabling interpretation. We further design a Global–Context–Shared Prompt (GCSP) mechanism, which employs a small set of learnable tokens to capture domain-specific priors, shared patient-level information, and cross-domain context. The resulting concept alignment scores from each modality are then fused to produce a final prediction. Extensive experiments demonstrate that CTF outperforms strong unimodal, latent-fusion, and adapter-based baselines (e.g., AUC 0.903 on TCGA-GBMLGG). Notably, CTF achieves these gains without finetuning the full FMs, requiring only 0.15\\% additional parameters, thus highlighting the effectiveness of concept-based multimodal co-adaptation. Our code is anonymously available at: https://anonymous.4open.science/r/CTF-27C2.",
    "key_points": [
      "multimodal learning",
      "concept-based learning",
      "foundation models",
      "parameter-efficient fine-tuning",
      "medical imaging",
      "survival analysis"
    ],
    "gold_summary": "This paper proposed a parameter-efficient framework that uses clinically grounded concepts to bridge radiology and pathology, where a set of learnable tokens is employed to learn modality-specific and common knowledge, as well as cross-modal interactions."
  },
  {
    "paper_id": "FBPuLChGNX",
    "title": "Learning to Generate Stylized Handwritten Text via a Unified Representation of Style, Content, and Noise",
    "domain": "applications to computer vision",
    "content": "Handwritten Text Generation (HTG) seeks to synthesize realistic and personalized handwriting by modeling stylistic and structural traits. While recent diffusion-based approaches have advanced generation fidelity, they typically rely on auxiliary style or content encoders with handcrafted objectives, leading to complex training pipelines and limited interaction across factors. In this work, we present InkSpire, a diffusion transformer based model that unifies style, content, and noise within a shared latent space. By eliminating explicit encoders, InkSpire streamlines optimization while enabling richer feature interaction and stronger in-context generation. To further enhance flexibility, we introduce a multi-line masked infilling strategy that allows training directly on raw text-line images, together with a revised positional encoding that supports arbitrary-length multi-line synthesis and fine-grained character editing. Moreover, InkSpire is trained on a bilingual Chinese–English corpus, enabling a single model to handle both Chinese and English handwriting generation with high fidelity and stylistic diversity, thereby overcoming the need for language-specific systems. Extensive experiments on IAM and ICDAR2013 demonstrate that InkSpire achieves superior structural accuracy and stylistic diversity compared to prior state-of-the-art methods.",
    "key_points": [
      "handwriting text generation",
      "flow matching",
      "in-contaext generation"
    ],
    "gold_summary": "This paper designs a unified diffusion model for processing style, content, and noise for the task of handwritten text generation, eliminating the need for additional style or content encoders and achieving performance improvements."
  },
  {
    "paper_id": "3m3E1TEjtb",
    "title": "MODE: Multi-Objective Dynamic Coreset Selection",
    "domain": "applications to computer vision",
    "content": "We present \\mode (Multi-Objective adaptive Data Efficiency), a framework that dynamically combines coreset selection strategies based on their evolving contribution to model performance. Unlike static methods, \\mode adapts selection criteria to training phases: \nemphasizing class balance early, diversity during representation learning, and uncertainty at convergence. We show that MODE achieves $(1-1/e)$-approximation with $O(n \\log n)$ complexity \nand demonstrate competitive accuracy while providing interpretable insights into data utility evolution. Experiments show \\mode reduces memory requirements \n%by 10× on ImageNet \nwhile providing actionable insights about which data types matter most during different training phases.",
    "key_points": [
      "coreset selection",
      "submodularity"
    ],
    "gold_summary": "This paper proposes a new method for coreset selection. It progressively selects training data based on model training results. Several strategies are introduced to boost efficiency."
  },
  {
    "paper_id": "bl3drImevi",
    "title": "Multimodal Dataset Distillation Made Simple by Prototype-guided Data Synthesis",
    "domain": "applications to computer vision",
    "content": "Recent advances in multimodal learning have achieved remarkable success across diverse vision–language tasks. However, such progress heavily relies on large-scale image–text datasets, making training costly and inefficient. \nPrior efforts in dataset filtering and pruning attempt to mitigate this issue, but still require relatively large subsets to maintain performance and fail under very small subsets.\nDataset distillation offers a promising alternative, yet existing multimodal dataset distillation methods require full-dataset training and joint optimization of pixel and text features, making them architecture-dependent and limiting cross-architecture generalization.\nTo overcome this, we propose a learning-free dataset distillation framework that eliminates the need for large-scale training and optimization while enhancing generalization across architectures. \nOur method uses CLIP to extract aligned image–text embeddings, obtains prototypes, and employs an unCLIP decoder to synthesize images, enabling efficient and scalable multimodal dataset distillation.\nExtensive experiments demonstrate that our approach consistently outperforms optimization-based dataset distillation and subset selection methods, achieving state-of-the-art cross-architecture generalization.",
    "key_points": [
      "dataset distillation",
      "dataset condensation",
      "vision-language models",
      "learning-free approach"
    ],
    "gold_summary": "The paper proposes a learning-free framework for multimodal dataset distillation, which avoids complex optimization by leveraging pre-trained models such as CLIP and unCLIP generation models, with new designs. The experiments validate the effectiveness."
  },
  {
    "paper_id": "PSixwg3wpL",
    "title": "RUSID: Robust Uncertainty-aware Single Image Deraining beyond Certainty",
    "domain": "applications to computer vision",
    "content": "Rainy weather induces rain streaks, blurs details, and reduces contrast, impairing image quality, making single image deraining a classic research topic. However, existing learning-based image restoration methods fail to account for uncertainties in both data and model dimensions, thus being unable to produce satisfactory results. To address this challenge, we introduce a novel framework called the Uncertainty-aware Visual-priors Prompt-interaction Network (UVPNet). UVPNet comprises three key modules: the Distribution-aware Visual Priors Learning (DVPL) module, which aims at data-wise aleatoric uncertainties, the Certainty-Uncertainty Prompt Fusion (CUPF) module, which tackles model-wise epistemic uncertainties, and the Channel Spatial Uncertainty Weighting Block (CSUWB). UVPNet leverages uncertainty modeling through visual semantic and depth priors and distributionally representative prompts by integrating data-wise and model-wise uncertainty learning. To the best of our knowledge, our UVPNet first utilizes uncertainty modeling with visual priors for single image deraining. Extensive experiment results demonstrate that our UVPNet outperforms state-of-the-art methods on both public synthetic datasets and real-world images while maintaining low complexity.",
    "key_points": [
      "image deraining",
      "visual priors",
      "uncertainty-modeling",
      "prompt learning",
      "sam"
    ],
    "gold_summary": "An uncertainty-aware work on image deraining with visual priors"
  },
  {
    "paper_id": "vFxYtiVhJR",
    "title": "DRO-Augment Framework: Robustness by Synergizing Wasserstein Distributionally Robust Optimization and Data Augmentation",
    "domain": "applications to computer vision",
    "content": "In many real-world applications, ensuring the robustness and stability of deep neural networks (DNNs) is crucial, particularly for image classification tasks that encounter various input perturbations. While data augmentation techniques have been widely adopted to enhance the resilience of a trained model against such perturbations, there remains significant room for improvement in robustness against corrupted data and adversarial attacks simultaneously. \nTo address this challenge, we introduce DRO-Augment, a novel framework that integrates Wasserstein Distributionally Robust Optimization (W-DRO) with various data augmentation strategies to improve the robustness of the models significantly across a broad spectrum of corruptions. \nOur method outperforms existing augmentation methods under severe data perturbations and adversarial attack scenarios while maintaining the accuracy on the clean datasets on a range of benchmark datasets, including but not limited to CIFAR-10-C, CIFAR-100-C, Tiny-ImageNet-C, and Fashion-MNIST.  \nOn the theoretical side, we establish novel generalization error bounds for neural networks trained using a computationally efficient, variation-regularized loss function with augmented data, closely related to the W-DRO problem. Furthermore, we introduce a refined CIFAR-C benchmark that corrects inconsistencies in corruption intensities, providing a more reliable evaluation for future robustness research.",
    "key_points": [
      "distributionally robust optimization；data augmentation；deep learning；multi-class classification"
    ],
    "gold_summary": "This work proposes a novel training framework that integrates Wasserstein Distributionally Robust Optimization (W-DRO) with data augmentation to improve robustness against both adversarial attacks and corrupted data."
  },
  {
    "paper_id": "pFxyiDo9dy",
    "title": "A LoD of Gaussians: Unified Training and Rendering for Ultra-Large Scale Reconstruction with External Memory",
    "domain": "applications to computer vision",
    "content": "Gaussian Splatting has emerged as a high-performance technique for novel view synthesis, enabling real-time rendering and high-quality reconstruction of small scenes. However, scaling to larger environments has so far relied on partitioning the scene into chunks---a strategy that introduces artifacts at chunk boundaries, complicates training across varying scales, and is poorly suited to unstructured scenarios such as city-scale flyovers combined with street-level views. Moreover, rendering remains fundamentally limited by GPU memory, as all visible chunks must reside in VRAM simultaneously.\nWe introduce A LoD of Gaussians, a framework for training and rendering ultra-large-scale Gaussian scenes on a single consumer-grade GPU---without partitioning. Our method stores the full scene out-of-core (e.g., in CPU memory) and trains a Level-of-Detail (LoD) representation directly, dynamically streaming only the relevant Gaussians. A hybrid data structure combining Gaussian hierarchies with Sequential Point Trees enables efficient, view-dependent LoD selection, while a lightweight caching and view scheduling system exploits temporal coherence to minimize the loading overhead. Together, these innovations enable seamless multi-scale reconstruction and interactive visualization of complex scenes---from broad aerial views to fine-grained ground-level details.",
    "key_points": [
      "gaussian splatting",
      "neural rendering",
      "level of detail",
      "city-scale",
      "sequential point trees"
    ],
    "gold_summary": "This work proposes a 3DGS pipeline that avoids scene partitioning by storing the full scene out-of-core (CPU RAM) and streaming view-relevant Gaussians to the GPU."
  },
  {
    "paper_id": "e4FqU4SyHL",
    "title": "Synthesizing Multimodal Verifiable Game Data to Boost VLMs' General Reasoning",
    "domain": "applications to computer vision",
    "content": "Vision-language reinforcement learning (RL) has primarily focused on narrow domains (e.g. geometry or chart reasoning). This leaves broader training scenarios and resources underexplored, limiting the exploration and learning of Vision Language Models (VLMs) through RL. We find video games inherently provide rich visual elements and mechanics that are easy to verify. To fully use the multimodal and verifiable reward in video games, we propose Game-RL, constructing diverse game tasks for RL training to boost VLMs general reasoning ability. To obtain training data, we propose Code2Logic, a novel approach that adapts game code to synthesize game reasoning task data, thus obtaining the GameQA dataset of 30 games and 158 tasks with controllable difficulty gradation. Unexpectedly, training solely on GameQA would help VLMs obtain better out of domain generalization, demonstrating the value of Game-RL for enhancing VLMs general reasoning. Furthermore, this suggets that RL can lead to generalizable improvements in VLMs' reasoning abilities, and notably, video games may serve as valuable scenarios and resources to bring this generalization.",
    "key_points": [
      "vision language model",
      "reasoning",
      "data synthesis",
      "game playing",
      "visual question answering",
      "data sets or data repositories",
      "benchmarks"
    ],
    "gold_summary": "The paper proposes a method for verifiable synthetic vision-language data generation with video games, by training VLMs on this synthetic data with GRPO, they get improvements in other benchmarks for vision language models."
  },
  {
    "paper_id": "34WC2yucLy",
    "title": "LyFormer: Context-aware feature fusion for industrial small-object detection",
    "domain": "applications to computer vision",
    "content": "Accurate detection of small electronic components, such as semiconductors and printed circuit board (PCB) elements, is crucial for maintaining product quality and operational efficiency in surface mount technology (SMT) assembly lines. However, existing YOLO-based detection frameworks, while effective in general scenarios, often struggle with small, visually ambiguous objects under complex backgrounds, variable illumination, and subtle visual distinctions. To address these challenges, we propose \\textbf{LyFormer}, a YOLOv8s-based framework that integrates four specialized modules: (1) an Adaptive Multi-level Preprocessing Module (AMPM) for dynamic image preprocessing, (2) a Spatial Relation-aware Image Segmentation Patch (SRISP) for precise object localization, (3) a Fine-grained Cue Extraction Module (FCEM) for amplifying subtle texture details, and (4) a Context-aware Transformer Module (CaT) for integrating global and local contextual information. This modular design significantly improves detection accuracy while maintaining real-time performance. Experiments on real-world SMT production line X-ray images of semiconductor reels demonstrate that LyFormer achieves a mean Average Precision (mAP@0.5) of 0.672, substantially outperforming the baseline YOLOv8s (mAP@0.5: 0.399). These results confirm LyFormer’s accuracy and robustness for small, densely packed components in challenging industrial environments.",
    "key_points": [
      "industrial vision",
      "pcb/smt inspection",
      "feature fusion",
      "transformer block",
      "yolo extension",
      "attention mechanism",
      "domain adaptation",
      "few-shot transfer",
      "class imbalance",
      "ablation study",
      "map",
      "density score",
      "counting accuracy",
      "robust preprocessing",
      "noise-resilience"
    ],
    "gold_summary": "This paper proposes LyFormer for industrial small-object detection. The paper demonstrates both engineering innovation and empirical rigor, offering a practically deployable system with measurable performance gains."
  },
  {
    "paper_id": "c7vpjzlDR9",
    "title": "Scale-Adapter: Reversed Distillation Adapter for Efficient Training of Large Video Diffusion Models",
    "domain": "applications to computer vision",
    "content": "We propose Scale-Adapter, a plug-and-play adapter designed to efficiently bridge conditional knowledge from small adapted models to large video diffusion transformers. Existing controllable video DiT methods face critical inefficiencies: full fine-tuning of billion-parameter models is prohibitively expensive, while cascaded ControlNets introduce significant parameter overhead and exhibit limited flexibility for novel multi-condition compositions. To overcome these issues, Scale-Adapter introduces a novel reversed distillation method that allows a large video diffusion model to inherit precise control capabilities from efficiently tuned small video diffusion models, completely avoiding full fine-tuning.  Moreover, recognizing the intrinsic relationships among different conditions, we replace the cascaded ControlNet design with a Mixture of Condition Experts (MCE) layer. This structure dynamically routes diverse conditional inputs within a unified architecture, thereby supporting both single condition control and multiple condition combinations without additional training cost. To achieve cross-scale knowledge transfer, we further develop a Feature Propagation Module to ensure efficient and temporally consistent feature propagation across video frames. Experiments demonstrate that Scale-Adapter enables high-fidelity multiple condition video synthesis, making advanced controllable video generation feasible on low-resource hardware and establishing a new efficiency standard for the field.",
    "key_points": [
      "adapter",
      "diffusion model",
      "controlnet",
      "video generation"
    ],
    "gold_summary": "This paper proposes an adapter-based architecture for structural control in video generation models."
  },
  {
    "paper_id": "TcyBURFQSq",
    "title": "Multi-Representation Attention Framework for Underwater Bioacoustic Denoising and Recognition",
    "domain": "applications to computer vision",
    "content": "Automated monitoring of marine mammals in the St. Lawrence Estuary faces extreme challenges: calls span low-frequency moans to ultrasonic clicks, often overlap, and are embedded in variable anthropogenic and environmental noise. We introduce a multi-representation, attention-guided framework that first segments spectrograms to generate soft masks of biologically relevant energy and then fuses these masks with the raw inputs for multi-band, denoised classification. Image and mask embeddings are integrated via mid-level fusion, enabling the model to focus on salient spectrogram regions while preserving global context. Using real-world recordings from the Saguenay–St. Lawrence Marine Park Research Station in Canada, we demonstrate that segmentation-driven attention and mid-level fusion improve signal discrimination, reduce false positive detections, and produce reliable representations for operational marine mammal monitoring across diverse environmental conditions and signal-to-noise ratios. Beyond in-distribution evaluation, we further assess the generalization of Mask-Guided Classification (MGC) under distributional shifts by testing on spectrograms generated with alternative acoustic transformations. While high-capacity baseline models lose accuracy in this Out-of-distribution (OOD) setting, MGC maintains stable performance, with even simple fusion mechanisms (gated, concat) achieving comparable results across distributions. This robustness highlights the capacity of MGC to learn transferable representations rather than overfitting to a specific transformation, thereby reinforcing its suitability for large-scale, real-world biodiversity monitoring. We show that in all experimental settings, the MGC framework consistently outperforms baseline architectures, yielding substantial gains in accuracy on both in-distribution and OOD data.",
    "key_points": [
      "bioacoustics",
      "underwater monitoring",
      "computer vision",
      "spectrogram analysis",
      "attention",
      "segmentation",
      "mask-guided classification",
      "denoising",
      "distribution shift",
      "generalization",
      "multi-band signals",
      "acoustic representation learning"
    ],
    "gold_summary": "The paper proposes an end-to-end multi-modal framework to represent bioacustic signals for monitoring. The study is done with data from the St. Lawrence Estuary habitat."
  },
  {
    "paper_id": "CqqjVO6efL",
    "title": "Cross-modal Transfer Through Time for Human Activity Recogntion",
    "domain": "applications to computer vision",
    "content": "Cross-modal knowledge transfer between time-series sensors remains a critical challenge for robust Human Activity Recognition (HAR) systems.\nEffective cross-modal transfer exploits knowledge from one modality to train models for a completely unlabeled target modality—a problem setting we refer to as Unsupervised Modality Adaptation (UMA).\nExisting methods typically compress continuous-time data samples into single latent vectors during alignment, limiting their ability to transfer temporal information through real-world temporal distortions.\nTo address this, we introduce Cross-modal Transfer Through Time (C3T), which preserves fine-grained temporal information during alignment to handle dynamic sensor data better.\nC3T achieves this by aligning a set of temporal latent vectors across sensing modalities.\nOur extensive experiments on various camera+IMU datasets demonstrate that C3T outperforms existing methods in UMA by over 8\\% in accuracy and shows superior robustness to temporal distortions such as time-shift, misalignment, and dilation.\nOur findings suggest that C3T has significant potential for developing generalizable models for time-series sensor data, opening new avenues for various multimodal applications.",
    "key_points": [
      "human activity recognition",
      "cross-modal transfer",
      "multimodal learning",
      "imu",
      "rgb videos"
    ],
    "gold_summary": "This paper presents a novel method (C3T) and tackles an important problem, namely Unsupervised Modality Adaptation for cross-modal human activity recognition."
  },
  {
    "paper_id": "kDsteyTMbd",
    "title": "Towards Generalizable LLM Multi-Agent System: Identifying Collective Intelligence Factor in LLM Agent Groups",
    "domain": "applications to computer vision",
    "content": "Large language models (LLM)-based multi-agent systems (MAS) have shown impressive performance in solving a wide range of complex problems. However, previous studies mainly focus on designing customized MAS for specific tasks, while a critical research problem remains unclear: Do LLM agent groups exhibit a form of ``general intelligence'' that reflects their general ability across various tasks?\nIn human cognitive psychology research, it has been established that the mental capabilities of a human group can be measured by a single statistical factor, known as the Collective Intelligence (CI) factor. This factor can capture the group's general capability and predict its performance on a wide range of tasks, much like how IQ scores capture the general cognitive ability of individuals.\nInspired by this, in this study, we aim to investigate whether an analogous CI factor also exists in LLM agent groups, which is crucial for building generalizable MAS.\nMotivated by human cognitive psychology experiments, we design experiments along three dimensions: group size, individual intelligence, and collaboration process. Specifically, we construct 108 LLM agent groups with diverse group sizes, LLM compositions, and communication topologies. These groups are systematically evaluated across a wide range of tasks, including commonsense reasoning, math, game, etc. \nOur results demonstrate that an Artificial Collective Intelligence (ACI) factor does exist in LLM agent groups, accounting for 66.3\\% of the variance in performance across different tasks, which is substantially higher compared with the 43\\% observed in human groups. Moreover, by analyzing the indicators of groups that affect ACI, we find similar patterns between the ACI of LLM agent and human groups, where the collaboration process is the most important indicator influencing ACI rather than the individual intelligence of group members. \nThis highlights that, for MAS design, the way agents are connected and interact has a greater impact on overall performance than the scale of individual models, offering practical guidance for building more efficient and generalizable MASs.\nOur code is open-source at \\url{https://anonymous.4open.science/r/LLM_Collective_Intelligence-71B3} for reproducibility.",
    "key_points": [
      "large language model",
      "multi-agent system",
      "collective intelligence",
      "cognitive psychology"
    ],
    "gold_summary": "This work shows that LLMs possess similar artificial collective intelligence(ACI) like human group. The authors also analyse indicators that affects the ACI and propose design principles to build stronger multi-agent networks."
  },
  {
    "paper_id": "31CznLfRIS",
    "title": "VideoJudge: Bootstrapping Enables Scalable Supervision of MLLM-as-a-Judge for Video Understanding",
    "domain": "applications to computer vision",
    "content": "Precisely evaluating video understanding models remains challenging: commonly used metrics such as BLEU, ROUGE, and BERTScore fail to capture the fineness of human judgment, while obtaining such judgments through manual evaluation is costly. Recent work has explored using large language models (LLMs) or multimodal LLMs (MLLMs) as evaluators, but their extension to video understanding remains relatively unexplored. In this work, we introduce VideoJudge, a 3B and 7B-sized MLLM judge specialized to evaluate outputs from video understanding models (\\textit{i.e.}, text responses conditioned on videos). To train VideoJudge, our recipe builds on the interplay between a generator and an evaluator: the generator is prompted to produce responses conditioned on a target rating, and responses not matching the evaluator's rating are discarded. Across three out of four meta-evaluation benchmarks, VideoJudge-7B outperforms larger MLLM judge baselines such as Qwen2.5-VL-32B and Qwen2.5-VL-72B. Notably, we find that LLM judges (Qwen3) models perform worse than MLLM judges (Qwen2.5-VL) and that long chain-of-thought reasoning does not improve performance, indicating that providing video inputs is crucial for evaluation of video understanding tasks.",
    "key_points": [
      "meta-evaluation",
      "llm-as-judge",
      "synthetic data",
      "self-refinement",
      "video understanding"
    ],
    "gold_summary": "The paper introduces VideoJudge, a framework that uses multi-language large language models (MLLMs) as judges for video understanding tasks. It employs bootstrapping to iteratively improve the model’s performance by generating scalable supervision signals."
  },
  {
    "paper_id": "Tq0oPUyVTz",
    "title": "PolyAudio: Advancing Multi-Audio Analysis & Reasoning in Large Audio Language Models",
    "domain": "applications to computer vision",
    "content": "While Large Audio Language Models (LALMs) have achieved superior performance on reasoning over single audio clips, their ability to understand and reason over multiple audio clips remains a significant challenge. In this paper, we introduce PolyAudio, a novel LALM specifically designed for this complex task. To systematically train and evaluate our model, we first identify and formalize eleven foundational multi-audio reasoning capabilities. These capabilities, spanning sound, music, and speech, are designed to represent a broad range of challenging real-world scenarios. To enhance these skills, we fine-tune the Qwen2-Audio-7B-Instruct model using Group Relative Policy Optimization (GRPO). This approach mitigates common issues associated with Supervised Fine-Tuning (SFT), such as catastrophic forgetting. Specifically, we construct preference data that explicitly rewards the model for correctly synthesizing information across multiple audio clips. Our model, PolyAudio, achieves 58.6% on the MMAU-Pro multi-audio subset and 71.2% on our PolyAudio-Bench, substantially outperforming baselines on multi-audio reasoning tasks while maintaining its performance on single-audio tasks. To promote research in this space, we will publicly release the model, data generators, evaluation scripts, and training recipes at the time of publication.",
    "key_points": [
      "large audio language model",
      "mult-audio",
      "audio understanding",
      "audio reasoning"
    ],
    "gold_summary": "The authors fine-tune Qwen2-Audio to tackle the \"reasoning over multiple audio clips\" task, achieving SOTA results for their proposed PolyAudio-Bench and the multi-audio subset of MMAU-Pro."
  },
  {
    "paper_id": "rWrr6EUKpm",
    "title": "Rethinking OOD Detection at Scale through Ensemble Diversity",
    "domain": "applications to computer vision",
    "content": "The common practice of equating in-distribution (ID) data with the training set is a flawed oversimplification for large-scale applications. A viable strategy for out-of-distribution (OOD) detection is to train an ensemble of models to disagree, a method proven effective at smaller scales. However, these approaches have been limited by their reliance on external OOD datasets for diversification. This work revisits the fundamental definition of OOD data based on data density. This perspective reveals that the low-density, “OOD-like” samples required for diversification are already present within large training sets, removing the need for external data. We introduce the loss-guided diversification regulariser (LDR) to operationalise this principle. LDR identifies these internal samples by targeting those with high cross-entropy loss and encourages the ensemble to disagree only on them, thereby learning diverse, generalisable hypotheses. To ensure scalability, LDR employs a stochastic pairing strategy which reduces computational complexity from quadratic to constant. The process also yields a new uncertainty metric, the predictive diversity score (PDS). Extensive evaluation on benchmarks like ImageNet shows that LDR, combined with PDS, achieves state-of-the-art performance in OOD detection. Our work demonstrates that sourcing disagreement from within the training set is a powerful and effective paradigm for building robust models at scale.",
    "key_points": [
      "ensemble diversification",
      "ood detection",
      "ood generalizatin",
      "disagreement regularizer"
    ],
    "gold_summary": "The paper proposes a unified pipeline that integrates label error detection [1] and ensemble diversification [2, 3, 7], leveraging automatically identified OOD-like data [4, 5, 6]."
  },
  {
    "paper_id": "2wSORykWAc",
    "title": "Prioritizing Faithfulness: Efficient Zero-Shot Novel View Synthesis with Adaptive Latent Modulation",
    "domain": "applications to computer vision",
    "content": "The challenge of camera-controlled novel view synthesis (NVS) lies in balancing high visual fidelity with strict faithfulness to the source scene. We argue that current dominant approaches, which rely on finetuning large-scale diffusion models, often over-emphasize fidelity while struggling with faithfulness due to their generative nature. To address this, we propose a zero-shot NVS pipeline that prioritizes faithfulness and efficiency. Our method introduces two key contributions applied during inference: (1) Test-time Latent Homography Deformation, an on-the-fly homography optimization to deform latents for global motion consistency, and (2) Spatially Adaptive RePaint (SA-RePaint), an extension to RePaint that achieves both structural consistency and texture fidelity by introducing a mathematically-grounded, region-wise balancing of these two objectives. Our evaluations demonstrate substantial improvements in faithfulness and camera accuracy with competitive perceptual scores, highlighting a successful integration of faithfulness, quality, and efficiency. This work offers a promising direction for NVS that rebalances the focus towards greater authenticity.",
    "key_points": [
      "nvs",
      "zero-shot"
    ],
    "gold_summary": "Based on the video diffusion model, the authors propose a training-free novel view synthesis method. Compared to previous state-of-the-art work, they introduce homography optimization and Spatially Adaptive RePaint, demonstrating their effectiveness on datasets."
  },
  {
    "paper_id": "IWer3Ciqkp",
    "title": "PG-VLM: A Multi-Stage Panoptic-Graph Architecture for Detailed Visual-Linguistic Grounding in Urban Scenes",
    "domain": "applications to computer vision",
    "content": "Describing complex urban scenes with coherent paragraphs that are both semantically rich and spatially grounded is a key challenge for vision–language research. We present PG-VLM, a modular framework that (i) builds a Hierarchical Panoptic Scene Graph (HPSG) from panoptic segmentation, (ii) distills the graph into semantic triplets using a local instruction model, and (iii) generates narratives with a structured-to-text T5 generator. We assess text quality with standard captioning metrics and grounding with a new Narrative Relevance Detection Score (NRDS) that ties detection correctness to textual mention quality. On Cityscapes, PG-VLM surpasses recent vision–language baselines (BLIP-2, LLaVA-1.5 7B, SpatialVLM) across all metrics: CIDEr 135.0 (vs. 88.0/104.5/118.2), SPICE 28.8 (vs. 19.5/21.2/23.6), and BERTScore-F1 92.5 (vs. 88.0/89.0/90.1). Hallucination is reduced, with CHAIR-s 7.2 and CHAIR-i 9.5 (vs. 16.8/20.5 for BLIP-2, 13.0/16.2 for LLaVA-1.5, 11.4/14.8 for SpatialVLM). PG-VLM achieves substantially higher grounding via NRDS 0.76 compared to BLIP-2 at 0.52. A zero-shot check on BDD100K (50 images) indicates cross-dataset generalization (CIDEr 108.4, SPICE 24.1, NRDS-ZS 0.68), maintaining margins over all baselines. These results show that enforcing a symbolic bottleneck (HPSG to triplets) before generation improves both descriptive quality and faithfulness, offering a reproducible and extensible route to interpretable visual–language grounding in urban scenes.",
    "key_points": [
      "panoptic scene graph",
      "vision-language model",
      "semantic triplets",
      "paragraph generation",
      "explainable ai",
      "spatial reasoning",
      "hallucination reduction",
      "urban scene understanding",
      "nrds"
    ],
    "gold_summary": "This paper designs a new framework that uses an intermediate graph structure to improve the accuracy of spatial information in VLM predictions."
  },
  {
    "paper_id": "A9Ha2CCGYt",
    "title": "DocReward: A Document Reward Model for Structuring and Stylizing",
    "domain": "applications to computer vision",
    "content": "Recent advances in agentic workflows have enabled the automation of tasks such as professional document generation. However, they primarily focus on textual quality, neglecting visual structure and style, which are crucial for readability and engagement. This gap arises mainly from the absence of suitable reward models to guide agentic workflows toward producing documents with stronger structural and stylistic quality. To address this, we propose DocReward, a document reward model that evaluates documents based on their structure and style. We construct a multi-domain dataset DocPair of 117K paired documents, covering 32 domains and 267 document types, each including a high- and low-professionalism document with identical content but different structure and style. This enables the model to evaluate professionalism comprehensively, and in a textual-quality- agnostic way. DOCREWARD is trained using the Bradley-Terry loss to score documents, penalizing predictions that contradict the annotated ranking. To assess the performance of reward models, we create a test dataset containing document bundles ranked by well-educated human evaluators. Notably, DocReward outperforms GPT-4o and GPT-5 in accuracy by 30.6 and 19.4 percentage points, respectively, demonstrating its superiority over baselines. In an extrinsic evaluation of document generation, DocReward achieves a significantly higher win rate of 60.8%, compared to GPT-5’s 37.7% win rate, demonstrating its utility in guiding generation agents toward producing human-preferred documents",
    "key_points": [
      "reward model",
      "document structure and style"
    ],
    "gold_summary": "The paper introduces a large-scale document preference dataset and proposes DocReward to evaluate the professionalism of documents. Experiments show that the trained model outperforms existing baselines."
  },
  {
    "paper_id": "73QNa7rAgm",
    "title": "Unsupervised Anomaly Detection in Tabular Data with Test-time Contrastive Learning",
    "domain": "applications to computer vision",
    "content": "Unsupervised anomaly detection methods typically learn the feature patterns of normal samples during training, subsequently identifying samples that deviate from the learned patterns as anomalies during testing. However, most existing methods assume that the normal patterns in the test set are similar to those in the training set, ignoring the fact that a limited number of training samples may not cover all possible normal patterns. As a result, when the normal patterns in the test set differ from those in the training set, the model may struggle to distinguish whether these samples are normal or anomalous, leading to incorrect predictions. To address this issue, we propose a novel Test-time Contrastive learning approach for unsupervised Anomaly Detection in tabular data (namely TCAD). Specifically, TCAD consists of two core stages: Collaborative Dual-task Training and Test-Time Contrastive Learning. In training, Collaborative Dual-task Training uses two self-supervised tasks to capture multi-level features of normal samples and model normal patterns. At test time, Test-Time Contrastive Learning assigns pseudo labels to high-confidence samples and updates the model in two ways: First, it facilitates model adaptation to pseudo-normal samples while preventing overfitting to pseudo-abnormal ones. Second, it employs a KNN-based contrastive strategy to align pseudo-normal samples with the training distribution while pushing pseudo-abnormal samples away. By combining robust normal pattern modeling with iterative test-time adaptation, TCAD improves anomaly discrimination, especially under distribution shifts between training and test sets. We construct distribution shifts on 15 widely used tabular datasets, and the results show that TCAD achieves state-of-the-art performance, outperforming the best baseline by 4.19% in AUC-ROC, 3.15% in AUC-PR, and 6.64% in F1 score.",
    "key_points": [
      "unsupervised anomaly detection",
      "data shift",
      "test-time training",
      "contrastive learning"
    ],
    "gold_summary": "TCAD offers a novel and effective strategy for handling distribution shifts in unsupervised tabular anomaly detection. By integrating dual-task training with test-time contrastive learning, it enhances model robustness and sets a new state-of-the-art benchmark."
  },
  {
    "paper_id": "LQSlLfKAoZ",
    "title": "Cocktail-Party at the MUSEUM: Referring Audio-Visual Segmentation requires Augmentation",
    "domain": "applications to computer vision",
    "content": "Recent advances in Referring Audio-Visual Segmentation (Ref-AVS) have significantly progressed, with the development of multimodal fusion methods and Multimodal Large Language Models (MLLM). However, their modality-specific performance is underexplored, and the effectiveness of audio perception remains unclear. We find that current methods often fail to identify the correct sounding object with audio expressions (e.g., $\\textit{loudest sounding object}$), especially at the cocktail-party (i.e., mixed audio source). In addition, MLLM methods tend to memorize through visual-text patterns due to their weaker audio understanding capabilities. To this end, we first propose $\\textbf{MISA}$: $\\textbf{M}$usical-audio $\\textbf{I}$nstructed $\\textbf{S}$egmentation $\\textbf{A}$ssistant, with an integration of specialized musical-audio encoder MERT, and a musical-specific dataset for alignment to enhance audio tokens' representation. To mitigate the lack of variation of mixed-source signals, we introduce $\\textbf{MUSEUM}$, a musical-audio augmentation pipeline consisting of three stages: $\\textbf{MU}$sical $\\textbf{S}$ourc$\\textbf{E}$, A$\\textbf{U}$gment, and $\\textbf{M}$ix, to respectively perform source separation, sampling from extra musical datasets, and audio augmentation. Our proposed augmentation enriches the mixture of audio signals in the existing training dataset, which facilitates the model learning with diverse samples. Moreover, we refine the existing benchmark as $\\textbf{C-Ref-AVSBench}$ that categorizes expressions into Audio-Centric (audio cues), AV-Grounded (audio and visual cues), and Visual-Centric (visual cues), in order to perform modality-specific evaluation. Our approach achieves state-of-the-art performance on both Ref-AVSBench and C-Ref-AVSBench, particularly with the Audio-Centric expressions.",
    "key_points": [
      "referring audio-visual segmentation",
      "data augmentation",
      "mllm"
    ],
    "gold_summary": "The authors propose an integration of the specialized musical-audio encoder and a musical-audio augmentation pipeline for Ref-AVS."
  },
  {
    "paper_id": "dHWtOTiceO",
    "title": "Text2Arch: A Dataset for Generating Scientific Architecture Diagrams from Natural Language Descriptions",
    "domain": "applications to computer vision",
    "content": "Communicating complex system designs or scientific processes through text alone is inefficient and prone to ambiguity. A system that automatically generates scientific architecture diagrams from text with high semantic fidelity can be useful in multiple applications like enterprise architecture visualization, AI-driven software design, and educational content creation. Hence, in this paper, we focus on leveraging language models to perform semantic understanding of the input text description to generate intermediate code that can be processed to generate high-fidelity architecture diagrams. Unfortunately, no clean large-scale open-access dataset exists, implying lack of any effective open models for this task. Hence, we contribute a comprehensive dataset, \\system, comprising scientific architecture images, their corresponding textual descriptions, and associated DOT code representations.  Leveraging this resource, we fine-tune a suite of small language models, and also perform in-context learning using GPT-4o. Through extensive experimentation, we show that \\system{} models significantly outperform existing baseline models like DiagramAgent and perform at par with in-context learning based generations from GPT-4o. We have added code and data as Supplementary material, and will make them (and models) publicly available on acceptance.",
    "key_points": [
      "nlp: generation",
      "nlp: applications"
    ],
    "gold_summary": "**TEXT2ARCH** introduces a 75K+ text–DOT–image dataset that fills a clear gap for text-to-architecture generation, compares **DOT1/2/3** variants, and adds **novel graph-level metrics**; fine-tuned 7B–8B models (notably DeepSeek-7B) beat DiagramAgent and few-shot baselines."
  },
  {
    "paper_id": "PNRGSW9jPz",
    "title": "EvA: An Evidence-First Audio Understanding Paradigm for LALMs",
    "domain": "applications to computer vision",
    "content": "While Large Audio Language Models (LALMs) have demonstrated remarkable capabilities in audio understanding tasks, their performance degrades sharply in complex acoustic scenes, revealing a fundamental limitation in their perceptual grounding. In this work, we first identify a critical failure mode that exposes this limitation: state-of-the-art LALMs paradoxically struggle more with simple evidence-extraction tasks than with complex reasoning ones. We diagnose this as a breakdown in acoustic evidence grounding, a problem rooted in systemic information loss during feature encoding and fusion. To address this, we introduce EvA (Evidence-First Audio), a new paradigm that prioritizes maximizing the fidelity of acoustic evidence. EvA's dual-encoder architecture combines Whisper with CED-Base, a ViT-based general audio encoder, and pioneers a structure-preserving, two-stage fusion process. First, it enriches evidence by hierarchically aggregating multi-level features from within the CED-Base encoder. Second, it integrates this representation with Whisper's output via a time-aligned, inject-and-add mechanism that guarantees perfect temporal integrity. To facilitate training for this paradigm, we co-develop EvA-Perception, a large-scale open-source dataset with high-temporal-precision annotations. Our resulting model establishes a new open-source state-of-the-art on multiple challenging benchmarks, including MMAU, MMAR, and MMSU. Crucially, EvA achieves its most significant gains on perception-heavy subsets, validating our hypothesis that addressing the evidence bottleneck is key to unlocking the next level of audio understanding.",
    "key_points": [
      "large audio language model",
      "audio understanding"
    ],
    "gold_summary": "This paper presents a good motivation and an interesting problem formulation, but the proposed approach relies heavily on previous works and employs a relatively simple fusion method, which limits its novelty."
  },
  {
    "paper_id": "57bSlUHBfV",
    "title": "AVRT: Audio-Visual Reasoning Transfer through Single-Modality Teachers",
    "domain": "applications to computer vision",
    "content": "While recent advances in reasoning models have shown remarkable progress in text-based domains, the development of effective reasoning capabilities in multimodal settings, particularly audio-visual, remains still a challenge, mainly because of the limited availability of high-quality reasoning data in target multimodal combinations. To address this problem, we introduce AVRT, a novel framework that generates high-quality audio-visual reasoning data by distilling knowledge from specialized single-modality teachers. To this end, we generate high-quality reasoning traces via a vision-reasoning and a audio-reasoning teacher and merge the resulting traces with an LLM merger model. This enables an two stage training with a supervised fine-tuning of student models as cold start followed by a reinforcement learning. The evaluation show that the resulting models achieves competitve performance on various datasets, i.a. OmniBench, DailyOmni, and MMAR, establishing a new pipeline for an effective training of audio-visual reasoning models.",
    "key_points": [
      "reasoning",
      "multi-modal learning",
      "audio-visual"
    ],
    "gold_summary": "This paper proposes a way to create audio-visual reasoning data from audio-only and visual-only models. The authors show the data created is helpful to achieve better performance in reasoning in a somewhat limited setup."
  },
  {
    "paper_id": "Y1Mo2RLon8",
    "title": "Recursive Autoregressive Depth Estimation with Continuous Token Modeling",
    "domain": "applications to computer vision",
    "content": "Monocular depth estimation is a cornerstone of robotic perception and computer vision, yet reconstructing 3-D structure from a single RGB image suffers from severe geometric ambiguity and uncertainty. Motivated by the recent success of autoregressive (AR) models in image generation, we introduce a Fractal Visual AR + Diffusion framework that predicts depth both accurately and efficiently. Conventional pixel-wise AR generation is too slow for robotic applications, so we design a coarse-to-fine, multi-scale autoregressive pipeline: the model first sketches a global depth map at low resolution and then refines it progressively to full pixel fidelity, greatly accelerating inference.\nTo bridge the RGB–Depth modality gap, each scale incorporates a Visual-Conditioned Feature Refinement (VCFR) module that fuses multi-scale image features with the current depth prediction, explicitly injecting geometric and textural cues. Because discretising continuous depth values can cause information loss and unstable training, we adopt a conditional denoising diffusion loss that models depth distributions directly in continuous latent space, fundamentally avoiding quantisation errors. Although the visual AR–diffusion paradigm boosts accuracy, its layer-by-layer generation still introduces latency. To reclaim speed, we abstract the Visual AR unit into a reusable base generator and invoke it recursively, forming a self-similar fractal architecture that preserves modelling power while cutting the inference path.",
    "key_points": [
      "autoregressive， depth estimation"
    ],
    "gold_summary": "This paper considers a task of single view depth estimation. A new autoregressive framework with diffusion loss on continuous tokens is proposed. SOTA results are demonstrated on several benchmarks."
  },
  {
    "paper_id": "mD3Peom6lN",
    "title": "AttMetNet: Attention-Enhanced Deep Neural Network for Methane Plume Detection in Sentinel-2 Satellite Imagery",
    "domain": "applications to computer vision",
    "content": "Methane is a powerful greenhouse gas that contributes significantly to global warming. Accurate detection of methane emissions is the key to taking timely action and minimizing their impact on climate change. We present AttMetNet, a novel attention-enhanced deep learning framework for methane plume detection with Sentinel-2 satellite imagery. The major challenge in developing a methane detection model is to accurately identify methane plumes from Sentinel-2's B11 and B12 bands while suppressing false positives caused by background variability and diverse land cover types. Traditional detection methods typically depend on the differences or ratios between these bands when comparing the scenes with and without plumes. However, these methods often require verification by a domain expert because they generate numerous false positives. Recent deep learning methods make some improvements using CNN-based architectures, but lack mechanisms to prioritize methane-specific features. AttMetNet introduces a methane-aware architecture that fuses the Normalized Difference Methane Index (NDMI) with an attention-enhanced U-Net. By jointly exploiting NDMI's plume-sensitive cues and attention-driven feature selection, AttMetNet selectively amplifies methane absorption features while suppressing background noise. This integration establishes a first-of-its-kind architecture tailored for robust methane plume detection in real satellite imagery. Additionally, we employ focal loss to address the severe class imbalance arising from both limited positive plume samples and sparse plume pixels within imagery. Furthermore, AttMetNet is trained on the real methane plume dataset, making it more robust to practical scenarios. Extensive experiments show that AttMetNet surpasses recent methods in methane plume detection with a lower false positive rate, better precision recall balance, and higher IoU.",
    "key_points": [
      "computer vision",
      "remote sensing",
      "methane detection",
      "multispectral imagery",
      "image segmentation",
      "attention mechansim"
    ],
    "gold_summary": "A novel attention-enhanced deep learning framework for methane plume detection with Sentinel-2 satellite imagery."
  },
  {
    "paper_id": "z5caL4aXLt",
    "title": "Take Another Look: Improving Information Extraction From Images With Multiple Encoders",
    "domain": "applications to computer vision",
    "content": "Unstructured image data are increasingly used across diverse applications, yet standard practices for extracting predictive features remain underexplored. We redefine encoder choice as an ensemble and present three strategies for leveraging multiple pre-trained encoders to mitigate model risk associated with using a single encoder. These strategies include: feature union, which concatenates encoder features before model training, and two forms of model averaging, which weight predictions from single encoders using either equal weights or weights chosen with regression. Across six prediction applications—house prices from exterior images, poverty rates from satellite imagery, breast cancer and pneumonia detection from chest X-rays, rice disease classification from leaf images, and facial age —our results show three key findings: (i) using multiple encoders consistently outperform single encoders, with out-of-sample $R^2$  for house prices, for example, increasing from 15.01\\% (best single encoder) to 24.1\\% with feature union;  (ii) model averaging reduces error rates across all classification tasks, for example from 13.31\\% to 8.68\\% offering consistent gains over both single encoders and feature union; and (iii) using multiple encoders methods mitigate model risk, as accuracy varies widely across individual encoders in different applications. These results demonstrate that using multiple encoders provides robust, high-performing pipelines for image-based prediction without requiring extensive task-specific fine-tuning.",
    "key_points": [
      "multi-encoder learning",
      "model averaging",
      "computer vision",
      "deep learning"
    ],
    "gold_summary": "The paper presents an empirical study on how to combine frozen predictions from one/multiple encoders and test this application on different datasets belonging to different domains."
  },
  {
    "paper_id": "wd3nWzmE7i",
    "title": "Multimodal Few-Shot Point Cloud Segmentation via Agent Adaptation and Discriminative Deconfusion",
    "domain": "applications to computer vision",
    "content": "Few-shot 3D point cloud segmentation (FS-PCS) aims to leverage a limited amount of annotated data to enable the segmentation of novel categories. Most existing studies rely on single-modal point cloud data and have not fully explored the potential of multimodal information. In this paper, we propose a novel FS-PCS framework, Multimodal Agent Adaptation and Discriminative Deconfusion (MAD).  MAD incorporates three modalities: images, point clouds, and category text embeddings. To fuse multimodal information, we propose the Multimodal Semantic Agents Correlation Aggregation (M-SACA) module, which fuses multimodal features through agent-level correlation and uses text affinity for category semantic learning. To alleviate semantic gaps between the support set and query set in multimodal features, we propose the Semantic Agents Prototypes Adaptation (SAPA) module, which generates multimodal agents for query and support sets, adjusting prototypes to adapt the query feature space. To alleviate intra-class confusion, we introduce the Discriminative Deconfusion (DD) module, which preserves intra-class consistency through residual adapters and generator weights. \nExperiments on the S3DIS and ScanNet datasets demonstrate that MAD attains state-of-the-art performance, improving mIoU by \n3%–7%. Our method can significantly improve segmentation results and suggest valuable insights for future studies. The code will be publicly available.",
    "key_points": [
      "few-shot 3d point cloud segmentation; multimodal data; semantic agents correlation aggregation; discriminative deconfusion; semantic agents prototypes adaptation"
    ],
    "gold_summary": "Authors present a method for few-shot point-cloud segmentation. As far\nas I can see, the contributions are the integration of textual\nguidance and joint embedding of query and support sets. Experiments on\ntwo datasets show very impressive results."
  },
  {
    "paper_id": "HreYquZ5xs",
    "title": "Teach2Eval: An Interaction-Driven LLMs Evaluation Method via Teaching Effectiveness",
    "domain": "applications to computer vision",
    "content": "Recent progress in large language models (LLMs) has outpaced the development of effective evaluation methods. Evaluating LLMs with static, task-specific benchmarks is increasingly fragile due to contamination and saturation, and it fails to capture interactive reasoning. We introduce Teach2Eval, which reframes evaluation as teaching: a candidate model guides weaker students, and the students’ gains constitute the score. This interaction yields robustness to contamination and exposes orthogonal abilities with fine-grained metrics across Application, Judgment, Guidance, and Reflection. The framework scales automatically by exploiting natural error distributions from weak students, requiring neither bespoke rubrics nor human graders. Across 30 LLMs and 60 datasets, Teach2Eval achieves Spearman above 0.95 with human-preference leaderboards (e.g., Chatbot Arena/LiveBench), surpassing direct baselines, while offering actionable training signals (capability hierarchies, early overfitting) at low cost.",
    "key_points": [
      "new evaluation method",
      "multi-dimensional evaluation",
      "large language models",
      "data contamination",
      "teach2eval"
    ],
    "gold_summary": "Teach2Eval reframes LLM evaluation as teaching: a candidate “teacher” guides weaker “students,” and the students’ multi-turn gains—factored into Application, Judgment, Guidance, and Reflection abilities become the score;"
  },
  {
    "paper_id": "xjCkwPhQWq",
    "title": "SceneTransporter: Optimal Transport-Guided Compositional Latent Diffusion for Single-Image  Structured 3D Scene Generation",
    "domain": "applications to computer vision",
    "content": "We introduce SceneTransporter, an end-to-end framework for structured 3D scene generation from a single image. While existing methods generate part-level 3D objects, they often fail to organize these parts into distinct instances in open-world scenes. Through a debiased clustering probe, we reveal a critical insight: this failure stems from the lack of structural constraints within the model's internal assignment mechanism. Based on this finding, we reframe the task of structured 3D scene generation as a global correlation assignment problem. To solve this, SceneTransporter formulates and solves an entropic Optimal Transport (OT) objective within the denoising loop of the compositional DiT model. This formulation imposes two powerful structural constraints. First, the resulting transport plan gates cross-attention to enforce an exclusive, one-to-one routing of image patches to part-level 3D latents, preventing entanglement. Second, the competitive nature of the transport encourages the grouping of similar patches, a process that is further regularized by an edge-based cost, to form coherent objects and prevent fragmentation.  Extensive experiments show that SceneTransporter outperforms existing methods on open-world scene generation, significantly improving instance-level coherence and geometric fidelity. Code and models will be publicly available at \\url{https://scenetransporter.github.io/}",
    "key_points": [
      "3d scene generation",
      "part-aware 3d generation"
    ],
    "gold_summary": "This paper introduces SceneTransporter by reformulating the task of structured 3D scene generation as a global correlation assignment problem."
  },
  {
    "paper_id": "sgvL0zuDeZ",
    "title": "OpenAVS: Training-Free Open-Set Audio Visual Segmentation with Foundational Models",
    "domain": "applications to computer vision",
    "content": "Audio-visual segmentation (AVS) aims to separate sounding objects from videos by predicting pixel-level masks based on audio signals. Existing methods primarily concentrate on closed-set scenarios and direct audio-visual alignment, which limits their capability to generalize to new, unseen situations. In this paper, we propose OpenAVS, a novel training-free language-based approach that, for the first time, effectively aligns audio and visual via text proxy for open-vocabulary AVS. Equipped with multimedia foundation models, OpenAVS directly infers masks through 1) audio-to-text description generation, 2) visual-to-text description generation, 3) LLM-guided prompt translation, and 4) text-to-visual sounding object segmentation. The objective of OpenAVS is to establish a simple yet flexible architecture that harnesses the strengths of appropriate foundation models, thereby maximizing their potential for effective knowledge transfer to downstream AVS tasks. Moreover, we present a model-agnostic framework OpenAVS-ST that enables the integration of OpenAVS with any advanced supervised AVS model via pseudo-label based self-training. This approach enhances performance by effectively utilizing large-scale unlabeled data when available.\nComprehensive experiments on four benchmark datasets demonstrate the superior performance of OpenAVS. It surpasses existing unsupervised, zero-shot, and few-shot AVS methods by a significant margin, achieving absolute performance gains of 3.9% ~ 6.7% and 2.2% ~ 4.9% in mIoU and F-score, respectively, in challenging scenarios.",
    "key_points": [
      "open-vocabulary audio-visual segmentation",
      "multimedia foundation models",
      "large language models"
    ],
    "gold_summary": "The authors propose OpenAVS, a novel training-free language-based approach that, for the first time, effectively aligns audio and visual via a text proxy for open-vocabulary AVS. But there is still work to do."
  },
  {
    "paper_id": "7fCwWFb3rt",
    "title": "Search-T2I: Internet-Augmented Text-to-Image Generation",
    "domain": "applications to computer vision",
    "content": "Current text-to-image (T2I) generation models achieve promising results, but they fail on the scenarios where the knowledge implied in the text prompt is uncertain. For example, a T2I model released in February would struggle to generate a suitable poster for a movie premiering in April, because the character designs and styles are uncertain to the model. To solve this problem, we propose an Internet-Augmented text-to-image generation framework (Search-T2I) to compel T2I models clear about such uncertain knowledge by providing them with reference images. Specifically, an active retrieval module is designed to determine whether a reference image is needed based on the given text prompt; a hierarchical image selection module is introduced to find the most suitable image returned by an image search engine to enhance the T2I model; a self-reflection mechanism is presented to continuously evaluate and refine the generated image to ensure faithful alignment with the text prompt. To evaluate the proposed framework's performance, we collect a dataset named Img-Ref-T2I, where text prompts include three types of uncertain knowledge: (1) known but rare. (2) unknown. (3) ambiguous. Moreover, we carefully craft a complex prompt to guide GPT-4o in making preference evaluation, which has been shown to have an evaluation accuracy similar to that of human preference evaluation. Experimental results demonstrate the effectiveness of our framework, outperforming GPT-4o by ∼30\\% in human evaluation.",
    "key_points": [
      "internet-augmented generation",
      "text-to-image generation"
    ],
    "gold_summary": "The papaer propose an Internet-Augmented text-to-image generation framework (Search-T2I) to compel T2I models clear about such uncertain knowledge by providing them with reference images. Experiments prove the effectiveness of the proposed framework."
  },
  {
    "paper_id": "LaIkPfPu9K",
    "title": "Efficient Audio-Visual Speech Separation with Discrete Lip Semantics and Multi-Scale Global-Local Attention",
    "domain": "applications to computer vision",
    "content": "Audio-visual speech separation (AVSS) methods leverage visual cues to extract target speech and have demonstrated strong separation quality in noisy acoustic environments. However, these methods usually involve a large number of parameters and require high computational cost, which is unacceptable in many applications where speech separation serves as only a preprocessing step for further speech processing. To address this issue, we propose an efficient AVSS method, named **Dolphin**. For visual feature extraction, we develop **DP‑LipCoder**, a dual‑path lightweight video encoder that transforms lip‑motion into discrete audio‑aligned semantic tokens. For audio separation, we construct a lightweight encoder–decoder separator, in which each layer incorporates a global–local attention (GLA) block to efficiently capture multi-scale dependencies. Experiments on three benchmark datasets showed that Dolphin not only surpassed the current state-of-the-art (SOTA) model in separation quality but also achieved remarkable improvements in efficiency: over 50\\% fewer parameters, more than 2.4$\\times$ reduction in MACs, and over 6$\\times$ faster GPU inference speed. These results indicate that Dolphin offers a practical and deployable solution for high-performance AVSS in real-world scenarios. Our code and demo page are publicly available at https://dolphin-avss.github.io/Dolphin.",
    "key_points": [
      "audio-video speech separation",
      "vector quantization",
      "lightweight network",
      "discrete semantic units"
    ],
    "gold_summary": "This paper presents an audio-visual model for speech separation. The main contribution is a model which achieves SOTA results and is also lightweight. Results on multiple datasets and an ablation study are presented."
  },
  {
    "paper_id": "RBuVfiOFvI",
    "title": "3D-LATTE: Latent Space 3D Editing from Textual Instructions",
    "domain": "applications to computer vision",
    "content": "Despite the recent success of multi-view diffusion models for text/image-based 3D asset generation, instruction-based editing of 3D assets lacks surprisingly far behind the quality of generation models. The main reason is that recent approaches using 2D priors suffer from view-inconsistent editing signals. Going beyond 2D prior distillation methods and multi-view editing strategies, we propose a training-free editing method that operates within the latent space of a native 3D diffusion model, allowing us to directly manipulate 3D geometry. We guide the edit synthesis by blending 3D attention maps from the generation with the source object. Coupled with geometry-aware regularization guidance, a spectral modulation strategy in the Fourier domain and a refinement step for 3D enhancement, our method outperforms previous 3D editing methods enabling high-fidelity, precise, and robust edits across a wide range of shapes and semantic manipulations.",
    "key_points": [
      "3d editing",
      "diffusion models",
      "3d gaussian splatting"
    ],
    "gold_summary": "This paper proposes 3D-LATTE, a method for instruction-based 3D editing that operates directly in the latent space of a 3D diffusion model (DiffSplat) rather than relying on 2D priors or score-distillation."
  },
  {
    "paper_id": "X3ReIoucQs",
    "title": "HAPDA: A Human-Machine Predictive Discrepancy Adapter for AI-Generated Text Detection",
    "domain": "applications to computer vision",
    "content": "Recent advances in large language models (LLMs) have enabled them to generate text with increasingly human-like linguistic styles, posing significant challenges for AI-generated text detection (AGTD). Mainstream zero-shot AGTD methods primarily compute token-level AI-likeness scores from a machine-centric perspective represented by proxy models, and treat all tokens equally in the overall detection score calculation. However, these methods overlook predictive discrepancies between humans and LLMs in interpreting the same text. Our key intuition is that tokens exhibiting greater divergence in human and machine predictions offer stronger cues for authorship attribution. To address this limitation, we propose \\textbf{HAPDA}, a \\underline{h}uman-m\\underline{a}chine \\underline{p}redictive \\underline{d}iscrepancy \\underline{a}dapter for the AGTD task. HAPDA consists of (i) a joint fine-tuning strategy for training paired human and machine preference models, and (ii) a discrepancy-aware reweighting mechanism to calibrate token-level detection scores in downstream detectors. Extensive experiments across multiple datasets demonstrate that HAPDA consistently and significantly improves the performance of five representative baselines under diverse evaluation settings.",
    "key_points": [
      "ai-generated text detection",
      "prediction discrepancy modeling",
      "fine-tune"
    ],
    "gold_summary": "The paper proposes a framework for AI generated text detection which identifying the more discriminative feature between human and AI text."
  },
  {
    "paper_id": "3AnRMvlVDw",
    "title": "DVD-Quant: Data-free Video Diffusion Transformers Quantization",
    "domain": "applications to computer vision",
    "content": "Diffusion Transformers (DiTs) have emerged as the state-of-the-art architecture for video generation, yet their computational and memory demands hinder practical deployment. While post-training quantization (PTQ) presents a promising approach to accelerate Video DiT models, existing methods suffer from two critical limitations: (1) dependence on computation-heavy and inflexible calibration procedures, and (2) considerable performance deterioration after quantization.\nTo address these challenges, we propose DVD-Quant, a novel Data-free quantization framework for Video DiTs. Our approach integrates three key innovations:\n(1) Bounded-init Grid Refinement (BGR) and \n(2) Auto-scaling Rotated Quantization (ARQ) for calibration data-free quantization error reduction, as well as\n(3) $\\delta$-Guided Bit Switching ($\\delta$-GBS) for adaptive bit-width allocation.\nExtensive experiments across multiple video generation benchmarks demonstrate that DVD-Quant achieves an approximately 2$\\times$ speedup over full-precision baselines on  advanced DiT models while maintaining visual fidelity. Notably, DVD-Quant is the first to enable W4A4 PTQ for Video DiTs without compromising video quality. Code and models will be released to facilitate future research.",
    "key_points": [
      "video generation models; post-training quantization"
    ],
    "gold_summary": "This paper focuses on post-training quantization (PTQ) for text-to-video generation models and proposes three key techniques **weight refinement**, **rotation-aware transformation**, and **big switching area** to enhance quantization performance."
  },
  {
    "paper_id": "tjZHVvgmZt",
    "title": "Rustify: Towards Repository-Level C to Safer Rust via Workflow-Guided Multi-Agent Transpiler",
    "domain": "applications to computer vision",
    "content": "Translating C to Rust at the repository level presents unique challenges because of complex dependencies and the differences between C's manual memory model and Rust's strict ownership rules.\nExisting approaches often overlook repository-wide dependencies and contextual structure, resulting in impractical and potentially unsafe Rust code.\nWe propose Rustify, a workflow-guided architecture for repository-level C-to-Rust translation. \nRustify decomposes the translation process into modular and role-specific stages, aligned with the structure of source repositories rather than dynamic plan-and-act strategies. These stages address the structural challenges of repository-level C-to-Rust translation, such as determining translation units and resolving cross-file dependencies, with each stage assigned to a dedicated LLM-powered agent.\nBy orchestrating these agents through a structured workflow, Rustify systematically manages repository-wide translation while maintaining semantic equivalence and memory safety.The framework further integrates compiler feedback through tree search–based iterative repair and leverages a dynamic experience base to guide future translations.\nExperiments show that Rustify consistently produces fully memory-safe Rust code, reducing unsafe code by up to 99% compared to prior approaches. It successfully compiles eight out of nine repositories, raises the test pass rate from 10.5% in the baseline to 86.4%, and achieves high-quality, idiomatic Rust translation with CodeBLEU scores reaching 0.76.\nA replication repository is available at https://github.com/rustify712/Rustify.",
    "key_points": [
      "program translation; repository-level code translation; agent-based workflow; large language models."
    ],
    "gold_summary": "This paper presents Rustify, a workflow-guided, multi-agent framework for repository-level C-to-Rust translation, comprising four components: ProjectManager, TechLeader, CodeMonkey, and ErrorResolver. The results show that Rustify successfully compiles eight out of nine repositories."
  },
  {
    "paper_id": "F7GmbfyVg9",
    "title": "TTS Can Speak in Any Style with Any Voice",
    "domain": "applications to computer vision",
    "content": "This study proposes FlexiVoice, a text-to-speech (TTS) synthesis system speaking in any style with any voice. The speaking style is controlled by a natural-language instruction and the voice timbre is provided by a speech reference in zero-shot manner. FlexiVoice is built with an LLM core, which takes text as input, and also takes an optional natural language instruction and an optional speech reference to control style and timbre, respectively. FlexiVoice is equipped with a novel Progressive Post-Training (PPT) scheme that progressively unlocks accurate and flexible controllability. In particular, it first employs Direct Preference Optimization (DPO) to enable FlexiVoice to accurately follow both natural language instruction and speech reference simultaneously. It then uses a multi-objective Group Relative Policy Optimization (GRPO) to disentangle style instruction, reference timbre, and textual content. Finally, it adapts instruction GRPO for more advanced instruction following. Experimental results show that FlexiVoice surpasses competing baselines and demonstrates strong capability in decoupling control factors. Human evaluations further confirm its naturalness, controllability, and robustness.\nAudio samples are available at https://flexi-voice.github.io/.",
    "key_points": [
      "instruction tts",
      "controllable speech synthesis",
      "decoupling",
      "reinforcement learning"
    ],
    "gold_summary": "The paper presented a TTS system that follows natural language instructions. The authors proposed to increase the synthesis naturalness and the instruction-following capability through a three stage Progressive Post-Training process."
  },
  {
    "paper_id": "PJ29BlwG7w",
    "title": "CausalAffect: Causal Discovery for Facial Affective Understanding",
    "domain": "applications to computer vision",
    "content": "Understanding human affect from facial behavior requires not only accurate recognition but also structured reasoning over the latent dependencies that drive muscle activations and their expressive outcomes. \nAlthough Action Units (AUs) have long served as the foundation of affective computing, existing approaches rarely address how to infer psychologically plausible causal relations between AUs and expressions directly from data. \nWe propose CausalAffect, the first framework for causal graph discovery in facial affect analysis. \nCausalAffect models AU$\\rightarrow$AU and AU$\\rightarrow$Expression dependencies through a two-level polarity and direction aware causal hierarchy that integrates population-level regularities with sample-adaptive structures. \nA feature-level counterfactual intervention mechanism further enforces true causal effects while suppressing spurious correlations. \nCrucially, our approach requires neither jointly annotated datasets nor handcrafted causal priors, yet it recovers causal structures consistent with established psychological theories while revealing novel inhibitory and previously uncharacterized dependencies. \nExtensive experiments across six benchmarks demonstrate that CausalAffect advances the state of the art in both AU detection and expression recognition, establishing a principled connection between causal discovery and interpretable facial behavior.",
    "key_points": [
      "affective analysis",
      "emotion recognition",
      "action units",
      "basic emotions"
    ],
    "gold_summary": "This paper introduces CausalAffect, a novel framework designed to learn causal relations among Action Units (AUs) and between expressions and AUs. The work features extensive experimentation and analysis, providing interesting insights into these relationships."
  },
  {
    "paper_id": "f4GtuI2blh",
    "title": "CudaForge: An Agent Framework with Hardware Feedback for CUDA Kernel Optimization",
    "domain": "applications to computer vision",
    "content": "Developing efficient CUDA kernels is increasingly critical for AI applications such as large-scale LLM training. However, manual kernel design is both costly and time-consuming, motivating automatic approaches that leverage LLMs for code generation. Existing methods for automatic kernel generation, however, often produce low-efficiency kernels, incur high computational overhead, and fail to generalize across settings. \n\nIn this work, we propose CudaForge, a training-free multi-agent workflow for CUDA kernel generation and optimization. Our workflow is inspired by the iterative workflow of human experts, which contains steps such as developing initial kernels, testing correctness, analyzing hardware feedback, and iterative improvement.\nMore specifically, CudaForge employs two LLM agents -- a Coder and a Judge -- that iteratively generate, correct, and optimize CUDA kernels, while integrating hardware feedback such as Nsight Compute (NCU) metrics. In our extensive evaluations, we show that CudaForge, by leveraging base models like OpenAI-o3, achieves 97.6\\% correctness of generated kernels and an average 1.68$\\times$ speedup over PyTorch baselines, substantially surpassing state-of-the-art models including OpenAI-o3 and Kevin on KernelBench. Beyond accuracy and speed, CudaForge demonstrates strong generalization across GPUs (A100, RTX 6000, 4090, 3090) and base models (OpenAI-o3, GPT5, gpt-oss-120B, Claude-Sonnet-4, QwQ-32B), while maintaining high efficiency. In particular, generating an optimized kernel takes about $25$ minutes on one RTX6000 and incurs \\$0.30 API cost. Our results highlight that multi-agent, training-free workflows can enable cost-effective, generalizable, and high-performance CUDA kernel optimization.",
    "key_points": [
      "large language models",
      "code generation",
      "cuda kernel optimization",
      "multi-agent systems"
    ],
    "gold_summary": "The paper proposes CudaForge, a framework for LLM-based kernel generation that incorporates separate Coder and Judge models, with the judge being guided by actual hardware profiling feedback."
  },
  {
    "paper_id": "OxDdAscau3",
    "title": "FreeRet: MLLMs as Training-Free Retrievers",
    "domain": "applications to computer vision",
    "content": "Multimodal large language models (MLLMs) are emerging as versatile foundations for mixed-modality retrieval.\nYet, they often require heavy post-hoc training to convert them into contrastive encoders for retrieval.\nThis work asks: \\textit{Can off-the-shelf MLLMs serve as powerful retrievers without additional training?}\nWe present \\textbf{FreeRet}, a plug‑and‑play framework that turns any MLLM into a two‑stage retriever.\nFreeRet first derives semantically grounded embeddings directly from the model for fast candidate search, and then exploits its reasoning ability for precise reranking.\nThe framework contributes three advances: bypassing lexical alignment layers to obtain semantically faithful embeddings, conditioning representation generation with explicit priors, and mitigating framing effect in reranking via neutral choice framing.\nOn the MMEB and MMEB-V2 benchmarks spanning 46 datasets, FreeRet substantially outperforms models trained on millions of pairs.\nBeyond benchmarks, FreeRet is model-agnostic and scales seamlessly across MLLM families and sizes, preserves their generative abilities, supports arbitrary modality combinations, and unifies retrieval, reranking, and generation into end-to-end RAG within a single model.\nOur findings demonstrate that pretrained MLLMs, when carefully harnessed, can serve as strong retrieval engines without training, closing a critical gap in their role as generalists.",
    "key_points": [
      "multimodal large language model",
      "multimodal retrieval"
    ],
    "gold_summary": "The paper proposes a plug-and-play framework that turns any pretrained multimodal large language model (MLLM) into a two-stage retriever without further training."
  },
  {
    "paper_id": "1tYymCWmG5",
    "title": "DeFake: Data-Efficient Adaptation for Generalized Deepfake Detection",
    "domain": "applications to computer vision",
    "content": "While deepfake detection methods have seen significant progress, current approaches\nfocus on detecting fully synthetic or partially manipulated images separately,\nand often rely on large amounts of labeled training data. However, in\nreal world, deepfakes can originate from any paradigm. In this work, we propose\na generalized deepfake detection method, DeFake (Data-Efficient Adaptation for\nGeneralized Deepfake Detection) which can detect both fully synthetic and partially\nmanipulated images simultaneously. We reframe the generalization problem\nas a data-efficient adaptation of a base synthetic image detector to the task of partial\nmanipulation detection using limited training samples, without degrading the\noriginal synthetic image detection task. We introduce three novel modules: (a)\nNoise-aware Patch Enhancement (NPE) which captures local manipulation artifacts\npresent in partially manipulated images, (b) Adaptive Score Aggregation\n(ASA) which modulates the influence of the global image-level semantics and\nthe local patch-level artifacts, and (c) Multi-scale alignment which enhances discriminative\nlearning at both image and patch-level. The proposed modules are\ngeneralizable and can be integrated into various base models. Extensive experiments\non 14 datasets across both paradigms demonstrate the effectiveness of our\nproposed DeFake, outperforming state-of-the-art approaches in both settings.",
    "key_points": [
      "deepfake detection",
      "data-efficient learning",
      "vision-language models"
    ],
    "gold_summary": "This paper presents a framework to unify the detection of two classes of manipulated media: fully synthetic images and partially manipulated images."
  },
  {
    "paper_id": "llMfmDtWka",
    "title": "Scaling Speech Tokenizers with Diffusion Autoencoders",
    "domain": "applications to computer vision",
    "content": "Speech tokenizers are foundational to speech language models, yet existing approaches face two major challenges: (1) balancing trade-offs between encoding semantics for understanding and acoustics for reconstruction, and (2) achieving low bit rates and low token rates. We propose Speech Diffusion Tokenizer (SiTok), a diffusion autoencoder that jointly learns semantic-rich representations through supervised learning and enables high-fidelity audio reconstruction with diffusion. We scale SiTok to 1.6B parameters and train it on 2 million hours of speech.\nExperiments show that SiTok outperforms strong baselines on both reconstruction and understanding tasks, at an extremely low token rate of 12.5 Hz and a bit-rate of 200 bits-per-second.",
    "key_points": [
      "speech tokenizer",
      "diffusion autoencoder",
      "codec",
      "asr",
      "speech language model"
    ],
    "gold_summary": "The paper proposes several improvements to audio tokenizer training. \nFlow matching objective replaces the adversarial training, CTC loss to enforce semantic preservation, decoder finetuning, token CFG."
  },
  {
    "paper_id": "EzHQZ991im",
    "title": "SONAR: Spectral‑Contrastive Audio Residuals for Robust Deepfake Detection",
    "domain": "applications to computer vision",
    "content": "Deepfake (DF) audio detectors still struggle to generalize to out of distribution inputs. A central reason is \\emph{spectral bias}, the tendency of neural networks to learn low‑frequency structure before high‑frequency (HF) details, which both causes DF generators to leave HF artifacts and leaves those same artifacts under-exploited by common detectors. To address this gap, we propose \\textbf{Spectral‑cONtrastive Audio Residuals (SONAR)}, a frequency‑guided framework that explicitly disentangles an audio signal into complementary representations. An XLSR encoder captures the dominant low‑frequency content, while the same cloned path, preceded by learnable SRM, value-constrained high‑pass filters, distills faint HF residuals. Frequency cross‑attention reunites the two views for long‑ and short‑range frequency dependencies, and a frequency‑aware Jensen–Shannon contrastive loss pulls real content–noise pairs together while pushing fake embeddings apart, accelerating optimization and sharpening decision boundaries. Evaluated on the ASVspoof 2021 and in‑the‑wild benchmarks, SONAR attains state‑of‑the‑art performance and converges four times faster than strong baselines. By elevating faint high‑frequency residuals to first‑class learning signals, SONAR unveils a fully data‑driven, frequency‑guided contrastive framework that splits the latent space into two disjoint manifolds: natural‑HF for genuine audio and distorted‑HF for synthetic audio, thereby sharpening decision boundaries. Because the scheme operates purely at the representation level, it is architecture‑agnostic and, in future work, can be seamlessly integrated into any model or modality where subtle high‑frequency cues are decisive.",
    "key_points": [
      "frequency learning",
      "audio deepfake detection",
      "speech",
      "spectral bias"
    ],
    "gold_summary": "This paper proposes a simple method that performs frequency-differentiated learning using a dual-branch architecture."
  },
  {
    "paper_id": "XTWqhhyzcG",
    "title": "Let Androids Dream of Electric Sheep: A Human-Inspired Image Implication Understanding and Reasoning Framework",
    "domain": "applications to computer vision",
    "content": "Metaphorical comprehension in images remains a critical challenge for AI systems, as existing models struggle to grasp the nuanced cultural, emotional, and contextual implications embedded in visual content. \nWhile multimodal large language models (MLLMs) excel in basic Visual Question Answer (VQA) tasks, they exhibit a fundamental limitation on image implication tasks: contextual gaps that obscure the relationships between different visual elements and their abstract meanings. \nInspired by the human cognitive process, we propose ***Let Androids Dream (LAD)***, a novel framework for image implication understanding and reasoning. \nLAD addresses contextual missing through the three-stage framework: (1) **Perception**: converting visual information into rich and multi-level textual representations, (2) **Search**: iteratively searching and integrating cross-domain knowledge to resolve ambiguities, and (3) **Reasoning**: generating contextual-alignment image implication via explicit reasoning.\nOur framework with the lightweight GPT-4o-mini model achieves SOTA performance compared to 15+ MLLMs on English image implication benchmark and a huge improvement on Chinese benchmark, performing comparable with the GPT-4o model on Multiple-Choice Question (MCQ) and outperforms 36.7\\% on Open-Style Question (OSQ). Additionally, our work provides new insights into how AI can more effectively interpret image implications, advancing the field of vision-language reasoning and human-AI interaction. Our project is publicly available at https://anonymous.4open.science/r/Let-Androids-Dream-of-Electric-Sheep.",
    "key_points": [
      "image implication",
      "image metaphor",
      "visual question answering",
      "vision and language",
      "vision language model"
    ],
    "gold_summary": "Proposes LAD, an inference-time technique to improve VLM responses to image implication queries via a perception-search-reasoning process. LAD is shown to improve baseline performance on image implication benchmarks."
  },
  {
    "paper_id": "GSLoB1myS8",
    "title": "EAT: Expert Account Tracker for Efficient MoE Inference",
    "domain": "applications to computer vision",
    "content": "Mixture-of-Experts (MoE) models have emerged as a revolutionary method to scale Transformer models. However, traditional MoE architecture still suffers from inefficiency since a large number of experts are unnecessarily activated. Existing approaches for reducing the number of activated experts often overlook the historical performance of each expert. In this paper, we propose EAT, a novel method called $\\textbf{Expert Account Tracker (EAT)}$, which utilizes history-awareness metrics and adaptive thresholding to dynamically select the most important experts, thereby reducing the activated expert number while effectively maintaining the model performance. Experiments show that EAT outperforms the existing baseline Top-P method across multiple models and datasets, achieving over 25% an average reduction compared to the vanilla method in the number of activated experts and performing better token generation speed compared to the baseline. Additionally, through ablation studies, we find that excessively reducing the number of activated experts can significantly harm model performance, and the importance of experts varies across layers, with higher-level experts being generally more critical.",
    "key_points": [
      "eat; efficiency moe"
    ],
    "gold_summary": "This paper proposes EAT (Expert Account Tracker) to utilizes history-awareness metrics and adaptive thresholding to dynamically select the most important experts, aiming to reduce the activated expert number."
  },
  {
    "paper_id": "5eqbDG2rKZ",
    "title": "ALPS: Adaptive LLM Pruning via Gradient Search in Learned Representation Space",
    "domain": "applications to computer vision",
    "content": "Deploying Large Language Models (LLMs) at the edge is crucial for data privacy and offline operation, yet their massive parameter count poses significant resource challenges. While existing methods rely on discrete-space heuristics to search for pruning configurations, we introduce a fundamentally different approach: reformulating the search for optimal LLM pruning configurations as gradient optimization in a learned continuous representation space. Our method, ALPS (Adaptive Layer Pruning via Search), embeds discrete pruning configurations into a continuous space where efficient gradient-based optimization becomes possible, then decodes optimal representations back to implementable discrete pruning schemes. This encoder-evaluator-decoder architecture automatically learns from collected “pruning-score\" data pairs, eliminating manual tuning while jointly optimizing for model performance, latency, and energy consumption in a deployment-specific manner. Extensive experiments across Llama-7B, Llama2-7B, Llama2-13B, and Vicuna-7B demonstrate ALPS's superiority, achieving up to 34.1% energy reduction and 33.5\\% lower latency while maintaining over 91% of original performance. At high pruning ratios (50%), ALPS consistently outperforms state-of-the-art methods in both perplexity and downstream task accuracy.",
    "key_points": [
      "large language models",
      "adaptive pruning",
      "gradient-steered search"
    ],
    "gold_summary": "The paper proposes a framework for pruning LLMS, which reformulates the pruning configuration optimization as a continuous optimization problem and solves the problem by gradient-based optimization method."
  },
  {
    "paper_id": "ycZSujtyz4",
    "title": "TACS-Guided Self-Alignment of LVLMs for Explainable Chest X-ray Analysis",
    "domain": "applications to computer vision",
    "content": "Large vision–language models (LVLMs) hold promise for medical imaging but face two critical\nchallenges: dependence on curated human-annotated datasets for alignment and poor robustness to\nreal-world perturbations. We show that LVLMs can produce inconsistent outputs between original chest X-rays and WhatsApp-compressed versions that appear visually indistinguishable. Such failures raise serious concerns for mHealth platforms, where compressed or perturbed images are common in real-world diagnostic workflows. Moreover, current LVLMs often attribute lung abnormality predictions to irrelevant regions outside the lungs—a phenomenon we term out-of-lung saliency (OLS)—which is exacerbated by compression artifacts. These challenges highlight the urgent need for robust and explainable LVLMs in CXR diagnosis.\n\nTo address these issues, we propose Self-CXRAlign, a self-alignment framework that enhances\nexplainability robustness through multi-task learning (MTL)-driven supervised fine-tuning (SFT). Self-CXRAlign enforces explainability robustness, ensuring stability of predictions and attributions across original and perturbed images. Central to our method is the Inter-Task Attribution Conflict Score (TACS), a novel metric that guides the selection of auxiliary tasks to reduce attribution conflicts and mitigate negative transfer. By steering SFT with TACS, Self-CXRAlign achieves up to 80% reduction in OLS compared to naïve MTL, paving the way for explainable and trustworthy LVLM deployment in mHealth-driven chest X-ray analysis.",
    "key_points": [
      "lvlm",
      "vision language models",
      "self-alignment",
      "robustness",
      "explainability",
      "llm",
      "lmm"
    ],
    "gold_summary": "We propose Self-CXRAlign, a self-alignment framework that improves explainability robustness via MTL-driven supervised fine-tuning. The method ensures prediction and attribution consistency across clean and perturbed CXR inputs."
  },
  {
    "paper_id": "td682AAuPr",
    "title": "AVERE: Improving Audiovisual Emotion Reasoning with Preference Optimization",
    "domain": "applications to computer vision",
    "content": "Emotion understanding is essential for building socially intelligent agents. Although recent multimodal large language models (MLLMs) have shown strong performance on this task, two key challenges remain: (i) spurious associations between emotions and irrelevant audiovisual cues and (ii) hallucination of audiovisual cues driven by text priors in the language model backbone. To quantify and understand these issues, we introduce **EmoReAlM**, a benchmark designed to evaluate MLLMs for cue–emotion associations, hallucinations and modality agreement. We then propose **AVEm-DPO**, a preference optimization technique that aligns model responses with both audiovisual inputs and emotion-centric queries. Specifically, we construct preferences over (i) responses exhibiting spurious associations or hallucinations and (ii) audiovisual input pairs guided by textual prompts. We also include a regularization term that penalizes reliance on text priors, thereby mitigating modality-specific cue hallucinations. Experimental results on DFEW, RAVDESS and EMER demonstrate that our method significantly improves the performance of the reference baseline models (6-19\\% of relative performance) in zero-shot settings. By providing both a rigorous benchmark and a robust optimization framework, this work enables principled evaluation and improvement of MLLMs for emotion understanding and social AI.",
    "key_points": [
      "mllm",
      "emotion recognition",
      "multimodal reasoning"
    ],
    "gold_summary": "This paper introduce a benchmark designed to evaluate MLLMs for cue–emotion associations, hallucinations and modality agreement and propose a preference optimization technique that aligns model responses with both audiovisual inputs and emotion-centric queries."
  },
  {
    "paper_id": "Tc0b9KEZWB",
    "title": "Lumina-OmniLV: A Unified Multimodal Framework for General Low-Level Vision",
    "domain": "applications to computer vision",
    "content": "We present Lunima-OmniLV (abbreviated as OmniLV), a universal multimodal multi-task framework for low-level vision that addresses over 100 sub-tasks across four major categories, including image restoration, image enhancement, weak-semantic dense prediction, and stylization. OmniLV leverages both textual and visual prompts to offer flexible, user-friendly interactions. Built on Diffusion Transformer (DiT)-based generative priors, our framework supports arbitrary resolutions — achieving optimal performance at 1K resolution — while preserving fine-grained details and high fidelity. Through extensive experiments, we demonstrate that separately encoding text and visual instructions, combined with co-training using shallow feature control, is essential to mitigate task ambiguity and enhance multi-task generalization. Our findings also reveal that integrating high-level generative tasks into low-level vision models can compromise detail-sensitive restoration. These insights pave the way for more robust and generalizable low-level vision systems.",
    "key_points": [
      "low level vision"
    ],
    "gold_summary": "OmniLV proposes a unified multimodal framework for >100 low-level vision sub-tasks. It uses a DiT/flow-matching backbone (Lumina-Next), separate encoders for text (Gemma-2B) and visual exemplars, and a co-training “condition adapter.”"
  },
  {
    "paper_id": "D8fW5tAHq8",
    "title": "COME: Advancing Representation Learning and Generative Modeling for High-Quality Text-to-Motion Generation",
    "domain": "applications to computer vision",
    "content": "Text-to-Motion generation aims to synthesize realistic 3D human motion from natural language descriptions. Although continuous diffusion models naturally align with the temporal and spatial continuity of motion, they have underperformed discrete token-based approaches in generation quality. However, as T2M tasks evolve to include motion editing, personalization, and multimodal control, they increasingly demand fine-grained semantics, compositionality, and diverse sampling—capabilities better supported by continuous frameworks. Motivated by these real-world demands and the inherent continuity of motion, we revisit continuous diffusion modeling and identify two core limitations: (1) motion representations are often crowded and poorly separable, which increases the difficulty of generation and denoising; (2) suboptimal generative modeling that further degrades generation quality. To address these challenges, we propose COME, a continuous diffusion framework that enhances both motion representation and generative modeling. COME comprises two main components: the Motion Contrastive Masked Autoencoder (MoCMAE) and the Cross-Condition Diffusion Transformer (ccDIT).\nMoCMAE employs an asymmetric hybrid architecture that integrates Masked Motion Modeling to extract key spatio-temporal features and Contrastive Learning to further enhance feature discriminability, thereby providing an expressive latent space. Meanwhile, ccDIT incorporates ccDIT block for global and fine-grained semantic comprehension and then utilizes Stable-Min-SNR-$\\gamma$ to address training-inference inconsistencies and the conflicts across different timesteps, thus boosting generation quality. Extensive experiments show that COME achieves SOTA performance while improving inference and training efficiency, highlighting the effectiveness of our approach.",
    "key_points": [
      "text to motion generation",
      "human motion generation",
      "diffusion model"
    ],
    "gold_summary": "This paper introduces a new text-to-motion generation framework, COME. It learns expressive latents via propsoed MoCMAE and generates motion sequence via ccDIT transformer and Stable-Min-SNR-r schedule to align training and sampling."
  },
  {
    "paper_id": "YA4IaLOaHH",
    "title": "Lost in the Maze: Overcoming Context Limitations in Long-Horizon Information-Seeking",
    "domain": "applications to computer vision",
    "content": "Long-horizon information seeking tasks require iteratively searching the web over long trajectories and synthesizing information across many sources, and is a key capability to enable powerful applications like deep research systems. In this work, we show that popular information-seeking frameworks struggle to scale to long trajectories primarily due to context mismanagement—they accumulate long, noisy content, hit context window and tool budgets, or stop early. We introduce SLIM (Simple Lightweight Information Management), a simple framework that separates retrieval into distinct search and browse tools and periodically summarizes the trajectory, keeping context concise while enabling longer, more focused searches. On long-horizon tasks, SLIM achieves comparable accuracy at substantially lower cost and with far fewer tool calls than strong open-source baselines across multiple base models. Specifically, with o3 as the base model, SLIM achieves 55% on BrowseComp and 31% on HLE, outperforming all open-source frameworks by 7 and 3 absolute points, respectively, while incurring 5x fewer tool calls. Finally, we release an automated fine-grained trajectory analysis pipeline and error taxonomy for characterizing long-horizon information-seeking frameworks; SLIM exhibits less hallucination and fewer unfocused searches than prior systems. We hope our analysis framework and simple tool design inform future long-horizon agents.",
    "key_points": [
      "deep research",
      "agents",
      "long-context"
    ],
    "gold_summary": "The paper presents an approach for long-horizon search agents and evaluates it against a benchmark. The results are promising and show reduced computational effort with increased effectiveness."
  },
  {
    "paper_id": "wBD61QFEpm",
    "title": "Multimodal Fusion of RGB and Complementary Modalities for Semantic Segmentation",
    "domain": "applications to computer vision",
    "content": "Multi-modal semantic segmentation augments RGB imagery with an auxiliary sensing stream X (RGB+X), e.g., thermal, event, LiDAR, polarization, or light field, to improve robustness under adverse illumination and motion blur. We target two coupled bottlenecks in RGB+X segmentation: selecting the most predictive modality at each location and aligning semantics across different modalities. The proposed framework performs token-wise auxiliary selection to activate a single, reliable auxiliary stream per token and applies style-consistent, polarity-aware cross-modality fusion that transfers auxiliary appearance statistics to RGB features while preserving both supportive and contradictory evidence. We evaluate across five modality pairings: RGB+Thermal, RGB+Event, RGB+LiDAR, RGB+Polarization, and RGB+Light Field and obtain new state of the art on each. Representative results include 76.89% mIoU on MFNet (RGB-Thermal) and 52.54% mIoU on MCubeS (RGB+A+D+N) and other combinations, surpassing recent fusion frameworks under comparable backbones and training protocols. Overall, this selective, alignment-aware fusion design provides a robust path to better RGB+X segmentation without sacrificing efficiency.",
    "key_points": [
      "semantic segmentation",
      "multimodal fusion"
    ],
    "gold_summary": "This paper proposed a bidirectional polarity-aware cross-modality fusion method that effectively captures complementary cues while enhancing feature alignment. The proposed method is evaluated on multiple benchmarks and achieves large gains."
  },
  {
    "paper_id": "AFJMB9SkHT",
    "title": "FideDiff: Efficient Diffusion Model for High-Fidelity Image Motion Deblurring",
    "domain": "applications to computer vision",
    "content": "Recent advancements in image motion deblurring, driven by CNNs and transformers, have made significant progress. Large-scale pre-trained diffusion models, which are rich in true-world modeling, have shown great promise for high-quality image restoration tasks such as deblurring, demonstrating stronger generative capabilities than CNN and transformer-based methods. However, challenges such as unbearable inference time and compromised fidelity still limit the full potential of the diffusion models. To address this, we introduce FideDiff, a novel single-step diffusion model designed for high-fidelity deblurring. We reformulate motion deblurring as a diffusion-like process where each timestep represents a progressively blurred image, and we train a consistency model that aligns all timesteps to the same clean image. By reconstructing training data with matched blur trajectories, the model learns temporal consistency, enabling accurate one-step deblurring. We further enhance model performance by integrating Kernel ControlNet for blur kernel estimation and introducing adaptive timestep prediction. Our model achieves superior performance on full-reference metrics, surpassing previous diffusion-based methods and matching the performance of other state-of-the-art models. FideDiff offers a new direction for applying pre-trained diffusion models to high-fidelity image restoration tasks, establishing a robust baseline for further advancing diffusion models in real-world industrial applications. Our dataset and code will be publicly available.",
    "key_points": [
      "image motion-deblurring",
      "diffusion model"
    ],
    "gold_summary": "This paper proposed a novel motion deblurring architecture based on a pre-trained stable diffusion model, successfully distil the multi-step diffusion model into a single-step model."
  },
  {
    "paper_id": "1iT1nSyDCh",
    "title": "Intercept Cancer: Cancer Pre-Screening with Large Scale Healthcare Foundation Models",
    "domain": "applications to computer vision",
    "content": "Cancer screening, leading to early detection, saves lives. Unfortunately, existing screening techniques require expensive and intrusive medical procedures, not globally available, resulting in too many lost would-be-saved lives. We present CATCH-FM, CATch Cancer early with Healthcare Foundation Models, a cancer pre-screening methodology that identifies high-risk patients for further screening solely based on their historical medical records. With millions of electronic healthcare records (EHR), we establish the scaling law of EHR foundation models pretrained on medical code sequences, pretrain compute-optimal foundation models of up to 2.4 billion parameters, and finetune them on clinician-curated cancer risk prediction cohorts. In our retrospective evaluation comprising of thirty thousand patients, CATCH-FM achieves strong efficacy, with 50\\% sensitivity in predicting first cancer risks at 99\\% specificity cutoff, and outperforming feature-based tree models and both general and medical LLMs by up to 20\\% AUPRC. Despite significant demographic, healthcare system, and EHR coding differences, CATCH-FM achieves state-of-the-art pancreatic cancer risk prediction on the EHRSHOT few-shot leaderboard, outperforming EHR foundation models pretrained using on-site patient data. Our analysis demonstrates the robustness of CATCH-FM in various patient distributions, the benefits of operating in the ICD code space, and its ability to capture non-trivial cancer risk factors. Our code will be open-sourced.",
    "key_points": [
      "scaling law",
      "large language model",
      "healthcare foundation model",
      "ai for healthcare"
    ],
    "gold_summary": "This paper demonstrates that next token pretraining is an effective pretraining strategy for improving cancer prediction."
  },
  {
    "paper_id": "9tFRj7cmrS",
    "title": "StockBench:Can Llm Agents Trade Stocks Profitably In Real-world Markets?",
    "domain": "datasets and benchmarks",
    "content": "Large language models (LLMs) have recently demonstrated strong capabilities as autonomous agents, showing promise in reasoning, tool use, and sequential decision-making. While prior benchmarks have evaluated LLM agents in domains such as software engineering and scientific discovery, the finance domain remains underexplored, despite its direct relevance to economic value and high-stakes decision-making. Existing financial benchmarks primarily test static knowledge through question answering, but they fall short of capturing the dynamic and iterative nature of trading. To address this gap, we introduce StockBench, a contamination-free benchmark designed to evaluate LLM agents in realistic, multi-month stock trading environments. Agents receive daily market signals---including prices, fundamentals, and news---and must make sequential buy, sell, or hold decisions. Performance is assessed using financial metrics such as cumulative return, maximum drawdown, and the Sortino ratio. Our evaluation of state-of-the-art proprietary (e.g., GPT-5, Claude-4) and open-weight (e.g., Qwen3, Kimi-K2, GLM-4.5) models shows that while most LLM agents struggle to outperform the simple buy-and-hold baseline, several models demonstrate the potential to deliver higher returns and manage risk more effectively. These findings highlight both the challenges and opportunities in developing LLM-powered financial agents, showing that excelling at static financial knowledge tasks does not necessarily translate into successful trading strategies. We release StockBench as an open-source resource to support reproducibility and advance future research in this domain.",
    "key_points": [
      "llm agents",
      "benchmark",
      "financial decision evaluation"
    ],
    "gold_summary": "This paper introduces STOCKBENCH, a benchmark for evaluating the ability of LLM agents to conduct stock trading."
  },
  {
    "paper_id": "CS3HsLScNw",
    "title": "PrismLayers: Open Data for High-Quality Multi-Layer Transparent Image Generative Models",
    "domain": "datasets and benchmarks",
    "content": "Generating high-quality, multi-layer transparent images from text prompts can unlock a new level of creative control, allowing users to edit each layer as effortlessly as editing text outputs from LLMs. However, the development of multi-layer generative models lags behind that of conventional text-to-image models due to the absence of a large, high-quality corpus of multi-layer transparent data. We address this fundamental challenge by: (i) releasing four open, ultra-high-fidelity datasets—\\multilayertrain, \\multilayertrainplus, \\multilayertrainpro, and \\multilayerreal—consisting of 200K, 100K, 20K, and 1K multi-layer transparent images with accurate alpha mattes, respectively. (ii) introducing a training-free synthesis pipeline that generates such data on demand using off-the-shelf diffusion models, and (iii) delivering a strong multi-layer generation model, ART+, which matches the aesthetics of modern text-to-image generation models. The key technical contributions include: LayerFLUX, which excels at generating high-quality single transparent layers with accurate alpha mattes, and MultiLayerFLUX, which composes multiple LayerFLUX outputs into complete images, guided by human-annotated semantic layout. To ensure higher quality, we apply a rigorous filtering stage to remove artifacts and semantic mismatches, followed by human selection. Fine-tuning the state-of-the-art ART model on our synthetic \\multilayertrainpro yields ART+, which outperforms the original ART in 60\\% of head-to-head user study comparisons and even matches the visual quality of images generated by the FLUX.1-[dev] model. Our work establishes a solid dataset foundation for multi-layer transparent image generation, enabling research and applications that require precise, editable, and visually compelling layered imagery.",
    "key_points": [
      "graphic design; multi-layer transparent image; diffusion model"
    ],
    "gold_summary": "The paper releases PrismLayers family datasets for multi-layer transparent image generation and builds LayerFLUX / MultiLayerFLUX, plus an ART+ model fine-tuned on the data. Most pipelines and benchmarks are coupled with FLUX.1-[dev]."
  },
  {
    "paper_id": "A8UKo53z3R",
    "title": "WFDroneBench: A Benchmark for Sensor Placement and Drone Routing for Wildfire Detection",
    "domain": "datasets and benchmarks",
    "content": "Increasingly frequent and severe wildfires threaten ecosystems, public health, and infrastructure. Early detection is vital, but limited by existing monitoring systems. Drones offer mobile, real-time coverage, but optimizing sensor placement and drone routing in dynamic fire zones remains challenging. To address this, we introduce WFDroneBench, an open-source Python benchmarking library for early wildfire detection that integrates machine-learned risk maps with optimization-based deployment strategies for sensors, charging stations, and drones. It evaluates risk maps, optimization strategies, and monitoring equipment using standardized metrics and realistic wildfire simulations. The framework supports benchmarking across predictive and decision-making components: machine learning researchers can assess risk models, operations research experts can compare routing strategies, policymakers can explore resource trade-offs, and engineers can evaluate how drone specs impact detection. WFDroneBench includes 7746 scenarios across 49 locations, built from historical ignitions, real-world wildfire risk maps, and simulated fire spread, along with two ground detector and four drone routing strategies. Our experiments show that risk-aware strategies, especially Team Orienteering Problem (TOP) and Max-Coverage, significantly outperform other baselines, with TOP achieving the fastest detection on the most difficult fires. We openly release all code, data, and documentation.",
    "key_points": [
      "wildfire",
      "optimization",
      "benchmark",
      "dataset"
    ],
    "gold_summary": "The authors have a good idea in trying to develop a risk-based approach to determining wildfire fighting strategies, but this paper is trying to do too much. It was very hard to follow."
  },
  {
    "paper_id": "K0idbmzcgc",
    "title": "OS-W2S: An Automatic Labeling Engine for Language-Guided Open-Set Aerial Object Detection",
    "domain": "datasets and benchmarks",
    "content": "In recent years, language-guided open-set aerial object detection has gained significant attention due to its better alignment with real-world application needs. However, due to limited datasets, most existing language-guided methods primarily focus on vocabulary-level descriptions, which fail to meet the demands of fine-grained open-world detection. To address this limitation, we propose constructing a large-scale language-guided open-set aerial detection dataset, encompassing three levels of language guidance: from words to phrases, and ultimately to sentences. Centered around an open-source large vision-language model and integrating image-operation-based preprocessing with BERT-based postprocessing, we present the $\\textbf{OS-W2S Label Engine}$, an automatic annotation pipeline capable of handling diverse scene annotations for aerial images. Using this label engine, we expand existing aerial detection datasets with rich textual annotations and construct a novel benchmark dataset, called Multi-instance Open-set Aerial Dataset ($\\textbf{MI-OAD}$), addressing the limitations of current remote sensing grounding data and enabling effective language-guided open-set aerial detection. Specifically, MI-OAD contains 163,023 images and 2 million image-caption pairs, with multiple instances per caption, approximately 40 times larger than comparable datasets.\nTo demonstrate the effectiveness and quality of MI-OAD, we evaluate three representative tasks: language-guided open-set aerial detection, open-vocabulary aerial detection (OVAD), and remote sensing visual grounding (RSVG). On language-guided open-set aerial detection, training on MI-OAD lifts Grounding DINO by +31.1 AP$_{50}$ and +34.7 Recall@10 with sentence-level inputs under zero-shot transfer. Moreover, using MI-OAD for pre-training yields state-of-the-art performance on multiple existing OVAD and RSVG benchmarks, validating both the effectiveness of the dataset and the high quality of its OS-W2S annotations. More details are available at \\url{https://anonymous.4open.science/r/MI-OAD}.",
    "key_points": [
      "open-set aerial object detection",
      "automatic label engine",
      "multi-instance open-set aerial dataset"
    ],
    "gold_summary": "This paper presents an automatic labeling tool (OS-W2S) and uses it to create MI-OAD, a large-scale aerial imagery dataset designed to advance language-guided aerial open-set object detection research."
  },
  {
    "paper_id": "UFwgg44VZq",
    "title": "ReTabAD: A Benchmark for Restoring Semantic Context in Tabular Anomaly Detection",
    "domain": "datasets and benchmarks",
    "content": "In tabular anomaly detection (AD), textual semantics often carry critical signals, as the definition of an anomaly is closely tied to domain-specific context. However, existing benchmarks provide only raw data points without semantic context, overlooking rich textual metadata such as feature descriptions and domain knowledge that experts rely on in practice. This limitation restricts research flexibility and prevents models from fully leveraging domain knowledge for detection. ReTabAD addresses this gap by Restoring textual semantics to enable context-aware Tabular AD research. We provide (1) 20 carefully curated tabular datasets enriched with structured textual metadata, together with implementations of state-of-the-art AD algorithms—including classical, deep learning, and LLM-based approaches—and (2) a zero-shot LLM framework that leverages semantic context without task-specific training, establishing a strong baseline for future research. Furthermore, this work provides insights into the role and utility of textual metadata in AD through experiments and analysis. Results show that semantic context improves detection performance and enhances interpretability by supporting domain-aware reasoning. These findings establish ReTabAD as a benchmark for systematic exploration of context-aware AD.",
    "key_points": [
      "tabular anomaly detection",
      "anomaly detection benchmark",
      "large language models"
    ],
    "gold_summary": "ReTabAD makes a significant contribution by pushing tabular anomaly detection towards a more semantic-aware paradigm, excelling particularly in benchmark construction and the design of a zero-shot LLM framework."
  },
  {
    "paper_id": "dYAW0qUzUc",
    "title": "Monopath DAGs: Structuring Patient Trajectories from Clinical Case Reports",
    "domain": "datasets and benchmarks",
    "content": "High-quality datasets capturing rare diseases, atypical responses, and complex care pathways are critically needed in clinical machine learning. While electronic health records (EHRs) remain the dominant data source, they are constrained by institutional silos, privacy regulations, and the inherent scarcity of many clinically significant scenarios. Narrative case reports offer a complementary source: publicly available and often focused on diagnostically or therapeutically challenging cases. Yet their unstructured format limits reuse for modeling and data generation. We present a modular framework that transforms free-text case reports into Monopath Directed Acyclic Graphs (DAGs)—structured representations of patient trajectories that are both temporally ordered and semantically grounded. DAGs are a natural fit for modeling clinical narratives as they encode time-ordered clinical states and transitions, supporting branching and causal reasoning. We apply the pipeline to a curated corpus of 485 lung cancer case reports. Graph fidelity is supported both by automated metrics (ClinicalBERT BERTScore, F1 = 0.798 ± 0.051) and by direct clinical assessment, with practicing physicians rating event order and content positively. Compared to free-text vignettes, DAG embeddings yield higher Calinski–Harabasz clustering scores in raw space (110.5 vs. 41.9) and after PCA/UMAP (157% and 69% relative gains). In a clinician evaluation, graph-conditioned synthetic narratives are preferred in 62% of 106 comparisons and scored higher on timeline validity and decision support. In addition, we demonstrate applicability beyond lung cancer by applying the framework to four rare diseases across body systems, observing consistent clustering gains. Pending large-scale validation, these results highlight the promise of Monopath DAGs to serve as reusable, clinically grounded templates for patient similarity, augmentation, and controlled narrative generation. We release all graphs, schema, and code.",
    "key_points": [
      "graphical models",
      "structured prediction",
      "healthcare",
      "natural language processing",
      "patient trajectories"
    ],
    "gold_summary": "The authors present an approach to summarizing clinical case reports as graphs, based on a pipeline of variously prompted LLMs. The approach is primarily evaluated on a set of lung cancer case reports."
  },
  {
    "paper_id": "I3dPEvbp8o",
    "title": "Can Vision-Language Models Answer Face to Face Questions in the Real-World?",
    "domain": "datasets and benchmarks",
    "content": "AI models have made significant strides in recent years in their ability to describe and answer questions about real-world images. They have also made progress in the ability to converse with users in real-time using audio input. This raises the question: have we reached the point where AI models, connected to a camera and microphone, can converse with users in real-time about scenes and events that are unfolding live in front of the camera? This has been a long-standing goal in AI and is a prerequisite for real-world AI assistants and humanoid robots to interact with humans in everyday situations. In this work, we introduce a new dataset and benchmark, the Interactive Video Dataset (IVD), which allows us to assess the extent to which existing models can support these abilities, and to what degree these capabilities can be instilled through fine-tuning. The dataset is based on a simple question-answering setup, where users ask questions that the system has to answer, in real-time, based on the camera and audio input. We show that existing models fall far behind human performance on this task, and we identify the main sources for the performance gap. However, we also show that for many of the required perceptual skills, fine-tuning on this form of data can significantly reduce this gap.",
    "key_points": [
      "situated dataset",
      "multi-modal dataset",
      "vision language models"
    ],
    "gold_summary": "The paper proposes a new dataset, the Interactive Video Dataset (IVD), to evaluate the online responsiveness of LMMs."
  },
  {
    "paper_id": "HSWE9aceZb",
    "title": "CXMArena: Unified Dataset to benchmark performance in realistic CXM Scenarios",
    "domain": "datasets and benchmarks",
    "content": "Large Language Models (LLMs) hold immense potential for revolutionizing Customer Experience Management (CXM), particularly in contact center operations. However, evaluating their practical utility in complex operational environments is hindered by data scarcity (due to privacy concerns) and the limitations of current benchmarks. Existing benchmarks often lack realism, failing to incorporate deep knowledge base (KB) integration, real-world noise, or critical operational tasks beyond conversational fluency.\n\nTo bridge this gap, we introduce CXMdataset, a novel, large-scale synthetic benchmark dataset specifically designed for evaluating AI in operational CXM contexts. Given the diversity in possible contact center features, we have developed a scalable LLM-powered pipeline that simulates the brand's CXM entities that form the foundation of our datasets—such as knowledge articles including product specifications, issue taxonomies, and contact center conversations. The entities closely represent real-world distribution because of controlled noise injection (informed by domain experts) and rigorous automated validation.\n\nBuilding on this, we release CXMdataset, which provides dedicated benchmarks targeting five important operational tasks: Knowledge Base Refinement, Intent Prediction, Agent Quality Adherence, Article Search, and Multi-turn RAG with Integrated Tools.\n\nOur baseline experiments underscore the benchmark's difficulty: even state-of-the-art embedding and generation models achieve only 68% accuracy on article search, while standard embedding methods yield a low F1 score of 0.3 for knowledge base refinement, highlighting significant challenges for current models necessitating complex pipelines and solutions over conventional techniques.",
    "key_points": [
      "benchmark dataset",
      "customer experience management",
      "cxm",
      "large language models",
      "synthetic data generation",
      "contact center ai",
      "retrieval augmented generation",
      "rag",
      "intent prediction",
      "llm",
      "cxmarena"
    ],
    "gold_summary": "The authors introduce CXMArena: a novel, large-scale synthetic benchmark dataset specifically designed for evaluating AI in operational Customer Experience Management contexts."
  },
  {
    "paper_id": "TJWhvS5JXg",
    "title": "TabPalooza: A Benchmark Odyssey for Tabular Model Evaluation",
    "domain": "datasets and benchmarks",
    "content": "Tabular data is fundamental to machine learning, yet a lack of a widely accepted and comprehensive benchmark hinders the reliable evaluation of models, which range from tree-based models and neural network to more recent in-context learning-based approaches. Existing benchmarks are often limited in the diversity of meta-features considered, leading to inconsistent model rankings and reduced generalizability. To address these issues, this study constructs a novel benchmark for tabular data classification and regression, designed with an explicit focus on two key, often competing, characteristics: Diversity and Efficiency. We propose a pipeline to quantitatively assess benchmark diversity and introduce a method for selecting a representative subset of datasets. Our results demonstrate that the proposed benchmark achieves superior diversity compared to existing alternatives while maintaining evaluation efficiency. The main contributions include the new benchmark TabPalooza, the evaluation pipeline, and an empirical validation of the benchmark's enhanced coverage. The proposed TabPalooza is available at https://huggingface.co/datasets/data-hub-xyz987/TabPalooza.",
    "key_points": [
      "tabular data",
      "deep learning",
      "deep tabular prediction",
      "machine learning"
    ],
    "gold_summary": "This paper proposes TabPalooza, a tabular benchmark designed around \"diversity\" and \"efficiency\"; it develops pipelines for dataset selection, verifies that TabPalooza shows evaluation efficiency."
  },
  {
    "paper_id": "87KfYrIPff",
    "title": "Improving Active-Learning Evaluation, with Applications to Protein-Property Prediction",
    "domain": "datasets and benchmarks",
    "content": "We highlight that current evaluations of active-learning methods often fail to reflect important aspects of real-world applications, giving an incomplete picture of how methods can behave in practice. Most notably, evaluation problems are commonly constructed from heavily curated datasets, limiting their ability to rigorously stress-test data acquisition: even the worst acquirable data in these datasets is often reasonably useful with respect to the task at hand. To address this we introduce Active Learning on Protein Sequences (ALPS), a set of problems constructed to test key challenges that active-learning methods need to handle in real-world settings. We use ALPS to assess a number of previously successful methods, revealing a number of interesting behaviours and methodological issues. The ALPS codebase serves to support straightforward extensions of our evaluations in future work.",
    "key_points": [
      "active learning",
      "protein property prediction",
      "evaluation",
      "benchmark"
    ],
    "gold_summary": "This paper introduces a protein-property-based benchmark aimed at exposing weaknesses in current active learning evaluations that rely on overly curated datasets, offering more realistic yet domain-specific test conditions."
  },
  {
    "paper_id": "xyJ6ivc8ZU",
    "title": "Shared Contexts, Personalized Outputs: A Benchmark for Document Generation",
    "domain": "datasets and benchmarks",
    "content": "Large Language Models (LLMs) have recently demonstrated strong capabilities in long-context text generation, enabling applications such as meeting summarization and multi-document question answering. However, these tasks typically focus on producing a single, context-consistent output, without accounting for user-specific roles, preferences, or intents. Personalized Contextual Document Generation (PCDG) requires models to generate distinct, user-tailored documents grounded in the same extended context. Generating user-tailored outputs is key to adaptive applications, reducing manual edits and improving downstream utility, yet this capability remains underexplored due to the difficulty of evaluation. Furthermore, benchmarking PCDG effectively demands realistic, controllable context modeling, explicit personalization signals, well-defined intermediate sub-tasks, and evaluation metrics that go beyond surface-level similarity. To this end, we present PersonaContextWeaver, a benchmarking framework designed to meet these requirements through three key innovations: (1) a knowledge-graph-based synthesis pipeline that generates rich, multi-user, cross-domain conversational contexts with controllable personalization variables; (2) a task decomposition strategy that evaluates not only final document quality but also intermediate reasoning steps including as intent detection, context filtering, reference prediction; and (3) a multi-dimensional evaluation protocol to evaluate LLM's capability of user intent/profile understanding, relevant context retrieval, and document customization. Empirical evaluation of state-of-the-art LLMs on PersonaContextWeaver reveals substantial gaps in their ability to consistently generate highly personalized, contextually accurate documents. Models often struggle with nuanced user modeling, context filtering, and reference integration, indicating that personalized contextual document generation remains a challenging frontier for current LLMs.",
    "key_points": [
      "dataset and benchmark",
      "document generation",
      "personalization",
      "long-context",
      "natural language generation",
      "large language mode"
    ],
    "gold_summary": "This paper presents PersonaContextWeaver, a benchmark for evaluating personalized contextual document generation. This benchmark decomposes the PCDG in interpretable sub-tasks and uses a multi-dimensional evaluation protocol to evaluate LLM’s capability."
  },
  {
    "paper_id": "TAKA812wuY",
    "title": "Beyond Overconfidence: Rethinking Calibration in Large-Scale Vision Models",
    "domain": "datasets and benchmarks",
    "content": "Reliable uncertainty calibration is crucial for safe deployment of deep neural networks in high-stakes settings. While these networks are known to exhibit systematic overconfidence, particularly under distribution shifts, the calibration of large-scale vision models, such as ConvNeXt, EVA, and BEiT, remains underexplored. We comprehensively examine their calibration behavior, uncovering findings that challenge well-established assumptions. We find that these models are underconfident on in-distribution data, resulting in increased calibration error, but exhibit improved calibration under distribution shifts. This phenomenon is primarily driven by modern training techniques, including massive pretraining and sophisticated regularization and augmentation methods, rather than architectural innovations alone. We also demonstrate that these large-scale models are highly responsive to post-hoc calibration techniques in the in-distribution setting, enabling practitioners to mitigate underconfidence bias effectively. However, these methods become progressively less reliable under severe distribution shifts and can occasionally produce counterproductive results. Our findings highlight the complex, non-monotonic effects of architectural and training innovations on calibration, challenging established narratives of continuous improvement.",
    "key_points": [
      "model calibration",
      "post-hoc calibration",
      "calibration benchmark"
    ],
    "gold_summary": "The paper investigates how miscalibration differs under various distribution shifts, showing that models tend to be *underconfident* for in-distribution data but become *overconfident* under out-of-distribution (OOD) shifts."
  },
  {
    "paper_id": "5o9uKo2Wol",
    "title": "DriveE2E: Closed-Loop Benchmark for End-to-End Autonomous Driving through Real-to-Simulation",
    "domain": "datasets and benchmarks",
    "content": "Closed-loop evaluation is increasingly critical for end-to-end autonomous driving. Current closed-loop benchmarks using the CARLA simulator rely on manually configured traffic scenarios, which can diverge from real-world conditions, limiting their ability to reflect actual driving performance. To address these limitations, we introduce a simple yet challenging closed-loop evaluation framework that closely integrates real-world driving scenarios into the CARLA simulator with infrastructure cooperation. Our approach involves extracting 800 dynamic traffic scenarios selected from a comprehensive 100-hour video dataset captured by high-mounted infrastructure sensors, and creating static digital twin assets for 15 real-world intersections with consistent visual appearance. These digital twins accurately replicate the traffic and environmental characteristics of their real-world counterparts, enabling more realistic simulations in CARLA. This evaluation is challenging due to the diversity of driving behaviors, locations, weather conditions, and times of day at complex urban intersections. In addition, we provide a comprehensive closed-loop benchmark for evaluating end-to-end autonomous driving models. Code and dataset examples are in the supplementary materials.",
    "key_points": [
      "end-to-end autonomous driving",
      "closed-loop evaluation",
      "real-to-simulation",
      "infrastructure cooperation"
    ],
    "gold_summary": "This paper presents DriveE2E, a Real2Sim-based closed-loop evaluation framework built upon the CARLA simulator. It features high-fidelity digital twins of 15 diverse urban intersections and 800 traffic scenarios generated from infrastructure sensor data."
  },
  {
    "paper_id": "i9q9xDMjG7",
    "title": "When to use Graphs in RAG: A Comprehensive Analysis for Graph Retrieval-Augmented Generation",
    "domain": "datasets and benchmarks",
    "content": "Graph retrieval-augmented generation (GraphRAG) has emerged as a powerful paradigm for enhancing large language models (LLMs) with external knowledge. It leverages graphs to model the hierarchical structure between specific concepts, enabling more coherent and effective knowledge retrieval for accurate reasoning. Despite its conceptual promise, recent studies report that GraphRAG frequently underperforms vanilla RAG on many real-world tasks. This raises a critical question: Is GraphRAG really effective, and in which scenarios do graph structures provide measurable benefits for RAG systems? To address this, we propose GraphRAG-Bench, a comprehensive benchmark designed to evaluate GraphRAG models on both hierarchical knowledge retrieval and deep contextual reasoning. GraphRAG-Bench features a comprehensive dataset with tasks of increasing difficulty, covering fact retrieval, complex reasoning, contextual summarize, and creative generation, and a systematic evaluation across the entire pipeline, from graph construction and knowledge retrieval to final generation. Leveraging this novel benchmark, we systematically investigate the conditions when GraphRAG surpasses traditional RAG and the underlying reasons for its success, offering guidelines for its practical application. All related resources and analysis are collected for the community at https://anonymous.4open.science/r/GraphRAG-Benchmark-CE8D/.",
    "key_points": [
      "rag",
      "graphrag",
      "graphrag benchmark"
    ],
    "gold_summary": "This paper systematically investigates when graph-based retrieval augmentation (GraphRAG) surpasses traditional RAG, revealing that GraphRAG excels in complex reasoning and structured knowledge integration while RAG remains more efficient for simple retrieval tasks."
  },
  {
    "paper_id": "skctEx59f2",
    "title": "NLMOptimizer: A neurosymbolic framework and benchmark for operations research optimization problems from natural language",
    "domain": "datasets and benchmarks",
    "content": "Large Language Models (LLMs) are increasingly applied to structured reasoning tasks, but remain prone to generating outputs that are both syntactically coherent and semantically invalid, posing a serious challenge for the domain of mathematical optimization. \nIn particular, applications to operations research (OR) problems, where problem descriptions are often ambiguous, context-rich, and semantically dense, are compromised by these issues and a dearth of publicly available datasets appropriately designed for both training and benchmarking model performance. In this paper, we address these issues by first introducing \\textbf{NLMOptimizer}, a neurosymbolic framework built on two classes: (i) the \\textbf{Problem} class, which systematically generates optimization problems; and (ii) the \\textbf{SymInterchange} class, an exploratory suite of neurosymbolic methods intended to map word problems into structured, solver-executable forms. We then address the dearth of plausibly complex OR problems with the associated NLMOptimizer dataset, generated using \\textbf{Problem}, which pairs structured natural-language descriptions with solver-checked mathematical programs across 1000 different linear (LP) and quadratic programs (QP) across integer, mixed-integer, and continuous types. We evaluate four instruction-tuned LLMs (LLaMa-3.3, LLaMa-4-Scout, Gemini-1.5-Pro, GPT-OSS-120B) under zero-shot prompting and observe substantial degradation on our set, with the strongest model dropping from 66.6\\% end-to-end accuracy on the NL4OPT benchmark dataset to 14.6\\% on NLMOptimizer. Our results indicate that (i) widely used benchmarks understate the difficulty of mapping natural language to formal optimization structure, (ii) current LLMs struggle to represent even modestly more complex problems than LPs with 3 variables, and (iii) progress will require methods that directly target representational fidelity without training models to fit fixed examples.",
    "key_points": [
      "optimization",
      "symbolic representation",
      "nlp",
      "operations research",
      "modeling"
    ],
    "gold_summary": "This paper proposes a neurosymbolic framework, NLMOptimizer, and compares the performance of four instruction-tuned LLMs."
  },
  {
    "paper_id": "AGCOnxvJAh",
    "title": "Constrained-Data-Value-Maximization: Utilizing Data Attribution for Effective Data Pruning in Low-Data Environments",
    "domain": "datasets and benchmarks",
    "content": "Attributing model behavior to training data is an evolving research field. \nA common benchmark is data removal, which involves eliminating data points with either low or high values, then assessing a model's performance trained on the modified dataset.  It is generally expected that removing low-value points results in a gradual decline in accuracy, while the removal of high-value points leads to a sharp decrease in performance. Many existing studies leverage Shapley-based data values for this task. In this paper, we demonstrate that these data values are not optimally suited for pruning low-value data when only a limited amount of data remains. To address this limitation, we introduce the Contsraint-Data-Value-Maximization approach, which effectively utilizes data attributions for pruning in low-data scenarios. By casting pruning as a constrained optimization that both maximizes total influence and penalizes excessive per‐test contributions, CDVM delivers robust performance even when only a small fraction of the data is retained. On the OpenDataVal benchmark, CDVM consistently outperforms existing alternatives, achieving state‐of‐the‐art accuracy and competitive runtime.",
    "key_points": [
      "data valuation",
      "data attribution",
      "data pruning",
      "constrained optimization"
    ],
    "gold_summary": "Paper proposes a new algorithm to prune train datasets using linear programming."
  },
  {
    "paper_id": "aUnheo6zFD",
    "title": "SmellNet: A Large-scale Dataset for Real-world Smell Recognition",
    "domain": "datasets and benchmarks",
    "content": "The ability of AI to sense and identify various substances based on their smell alone can have profound impacts on allergen detection (e.g., smelling gluten or peanuts in a cake), monitoring the manufacturing process, and sensing hormones that indicate emotional states, stress levels, and diseases. Despite these broad impacts, there are virtually no large-scale benchmarks, and therefore little progress, for training and evaluating AI systems’ ability to smell in the real world. In this paper, we use portable gas and chemical sensors to create SMELLNET, the first large-scale database that digitizes a diverse range of smells in the natural world. SMELLNET contains about 828,000 data points across 50 substances, spanning nuts, spices, herbs, fruits, and vegetables, and 43 mixtures among them, with 68 hours of data collected. Using SMELLNET, we developed SCENTFORMER, a Transformer-based architecture combining temporal differencing and sliding-window augmentation for smell data. For the SMELLNET-BASE classification task, SCENTFORMER achieves 58.5% Top-1 accuracy, and for the SMELLNET-MIXTURE distribution prediction task, SCENTFORMER achieves 50.2% Top-1@0.1 on the test-seen split. SCENTFORMER’s ability to generalize across conditions and capture transient chemical dynamics demonstrates the promise of temporal modeling in olfactory AI. SMELLNET and SCENTFORMER lay the groundwork for real-world olfactory applications across healthcare, food and beverage, environmental monitoring, manufacturing, and entertainment.",
    "key_points": [
      "smell sensing",
      "multimodal ai",
      "ai for smell",
      "smell recognition",
      "chemistry",
      "physical sensing"
    ],
    "gold_summary": "This paper introduces a new olfactory dataset, combining temporal sensor data with with object labels, and proposes several models to decode single- and multi-source odorants to establish the baseline results for these data."
  },
  {
    "paper_id": "Aq67wV1iZx",
    "title": "Right Side Up? Disentangling Orientation Understanding in MLLMs with Fine-grained Multi-axis Perception Tasks",
    "domain": "datasets and benchmarks",
    "content": "Object orientation understanding represents a fundamental challenge in visual perception that underpins critical real-world applications like robotic manipulation and augmented reality. However, current vision-language benchmarks fail to isolate and evaluate this core capability, often conflating it with positional relationships (such as above/below or proximity between objects) and general scene understanding. To address this, we introduce \\textbf{DORI} (\\textbf{D}iscriminative \\textbf{O}rientation \\textbf{R}easoning \\textbf{I}ntelligence), a comprehensive hierarchical benchmark that establishes object orientation perception as a primary evaluation target. DORI rigorously assesses four essential dimensions of object(s) orientation comprehension: frontal alignment, rotational transformations, relative directional relationships, and canonical orientation understanding. DORI provides valuable insights on how existing multi-modal systems process and understand object orientations through carefully curated tasks from 14 sources that spans $67$ object categories across synthetic and real-world scenarios. Our evaluation of $18$ state-of-the-art vision-language models using DORI reveals critical limitations: even the best models achieve only $54.2\\%$ accuracy on coarse tasks and $33.0\\%$ on granular orientation judgments, with performance deteriorating substantially for tasks requiring reference frame shifts or compound rotations. These findings demonstrate the urgent need for dedicated orientation representation mechanisms in future architectures, as models show a systematic inability to perform precise angular estimations, track orientation changes across multiple viewpoints, and understand compound rotations—suggesting fundamental limitations in their internal 3D spatial representations. As the first diagnostic framework specifically designed for advancing orientation awareness in multimodal systems, DORI offers immediate implications for improving robotic control, 3D scene reconstruction, and human-AI interaction in physical environments",
    "key_points": [
      "orientation understanding",
      "3d scene understanding",
      "mllm probing",
      "benchmark dataset",
      "computer vision"
    ],
    "gold_summary": "The paper introduces a hierarchical benchmark that evaluates MLLM’s ability to understand and reason about orientation. The paper evaluates multiple MLLMs on the benchmarking and shows poor performance."
  },
  {
    "paper_id": "WbV6w9R2Ox",
    "title": "Reference-Specific Unlearning Metrics Can Hide the Truth: A Reality Check",
    "domain": "datasets and benchmarks",
    "content": "Current unlearning metrics for generative models evaluate success based on reference responses or classifier outputs rather than assessing the core objective: whether the unlearned model behaves indistinguishably from a model that never saw the unwanted data. This reference-specific approach creates systematic blind spots, allowing models to appear successful while retaining unwanted knowledge accessible through alternative prompts or attacks. We address these limitations by proposing Functional Alignment for Distributional Equivalence (FADE), a novel metric that measures distributional similarity between unlearned and reference models by comparing bidirectional likelihood assignments over generated samples. Unlike existing approaches that rely on predetermined references, FADE captures functional alignment across the entire output distribution, providing a principled assessment of genuine unlearning. Our experiments on the TOFU benchmark for LLM unlearning and the UnlearnCanvas benchmark for text-to-image diffusion model unlearning reveal that methods achieving near-optimal scores on traditional metrics fail to achieve distributional equivalence, with many becoming more distant from the gold standard than before unlearning. These findings expose fundamental gaps in current evaluation practices and demonstrate that FADE provides a more robust foundation for developing and assessing truly effective unlearning methods.",
    "key_points": [
      "unlearning evaluation",
      "large language models",
      "text-to-image diffusion models"
    ],
    "gold_summary": "This paper proposes a distribution-level unlearning metric FADE, to address the limitations of previous reference-specific approaches. Moreover, its experiments expose the failure of existing unlearning methods under this new metric."
  },
  {
    "paper_id": "fKYZ6T3dmI",
    "title": "BRED: A Comprehensive Benchmark for the Robust Evaluation of LLM-Generated Text Detection in Realistic Scenarios",
    "domain": "datasets and benchmarks",
    "content": "The rapid advancement of large language models (LLMs) has created a pressing need for robust detectors capable of distinguishing between machine-generated and human-written texts. However, existing benchmarks often lack the comprehensive scope needed for rigorous testing. We introduce BRED, a new benchmark that offers four key contributions: 1) extensive coverage of diverse domains and compositional operations, 2) in-depth analysis of LLM pipeline and compositional operations, 3) evaluation across different LLM variants and groups, and 4) in-depth exploration of supervised detectors. Through extensive evaluation of baseline detectors, we have three key findings: 1) supervised embedding-based detectors are the most robust against diverse generation strategies, 2) text generated by larger models does not exhibit significant resistance to detection; and 3) current detection methods struggle significantly with texts that have undergone secondary operations from both LLM and operations. BRED provides a standardized platform for assessing detector robustness and offers practical insights for advancing AI-generated text detection.",
    "key_points": [
      "ai generated text detection; llm"
    ],
    "gold_summary": "The paper proposes a comprehensive benchmark for LLM-generated text detection. The benchmark consists of diverse domains, and compositional operations. The paper also provides extensive experiments on different detectors."
  },
  {
    "paper_id": "lJxRCW0UOI",
    "title": "Large Language Models outperform state-of-the-art methods on multiclass sentiment polarity detection",
    "domain": "datasets and benchmarks",
    "content": "Sentiment polarity detection remains a significant problem with applications such as opinion tracking and social network analysis. In this study, we evaluate whether contemporary open-weight large language models (LLMs) can rival or surpass specialized approaches on multiclass polarity detection while accounting for inference cost. We perform a systematic zero-shot evaluation of 31 open-weight LLMs on two canonical five-class benchmarks, assessing accuracy, Macro-Average Mean Absolute Error, and instances-per-second measures to quantify cost-performance trade-offs, also analyzing the best models according to the Pareto criterion. We found that several LLMs, without fine-tuning or elaborate prompting, outperform previous state-of-the-art results on a large dataset (SemEval) and approach a similar to state-of-the-art performance on a smaller benchmark (SST-5). Our Pareto frontier analysis highlights models that combine high accuracy with low inference costs, offering practical deployment choices for fine-grained sentiment polarity detection.",
    "key_points": [
      "sentiment polarity detection",
      "multiclass sentiment polarity",
      "open-weight llm",
      "pareto frontier"
    ],
    "gold_summary": "This paper evaluate the performance of 31 open-source large language models (open-weight LLMs) on the task of multiclass sentiment polarity detection, whilst examining the trade-off between performance and inference cost."
  },
  {
    "paper_id": "11ZzyjZEcc",
    "title": "LLM-ORBench: Designing a Benchmark Dataset for Complex Ontology-Based Reasoning Tasks in Large Language Models",
    "domain": "datasets and benchmarks",
    "content": "Large Language Models (LLMs) are increasingly applied to tasks requiring complex reasoning, yet their capabilities in formal logical reasoning remain underexplored. Existing benchmarks often focus on pattern recognition and fail to adequately assess symbolic reasoning, abstraction, or noise handling. To address this, we introduce \\textit{LLM-ORBench}, a benchmark framework for evaluating LLMs on structured, ontology-based tasks with verifiable multi-step inferences generated by a symbolic reasoner. The framework combines natural language and formal SPARQL questions, and systematically removes domain knowledge (i.e., abstraction) to isolate formal logical reasoning. We evaluated \\textit{GPT-5-mini}, \\textit{DeepSeek-V3-0324}, and \\textit{LLaMA-4-Maverick-17B-128E-Instruct} on two ontologies—\\textit{Family} and \\textit{OWL2Bench}—across binary and open-ended question-answering tasks. Our results show that reasoning complexity, abstraction, and question type strongly affect accuracy and reliability, with reasoning on abstracted tasks producing low accuracy and overconfidence, and open-ended tasks exhibiting substantial hallucination rates.",
    "key_points": [
      "neurosymbolic artificial intelligence",
      "benchmark",
      "ontology reasoning",
      "large language model"
    ],
    "gold_summary": "This work introduces a novel benchmark called LLM-ORBench for evaluating LLMs' reasoning capabilities on ontologies. Compared to the existing benchmarks, the new benchmark includes open-ended questions and supports evaluation beyond quantitative metrics."
  },
  {
    "paper_id": "DKAUzhGiDa",
    "title": "EfficientLLM: Evaluating Large Language Models Efficiency",
    "domain": "datasets and benchmarks",
    "content": "Large Language Models (LLMs) have achieved remarkable advances across reasoning, generation, and problem-solving, yet their scaling comes with prohibitive training, deployment, and environmental costs. Training frontier models like GPT-3 or PaLM consumes thousands of GPU/TPU days and millions of dollars. As these costs escalate, there is a pressing need for rigorous benchmarks that quantify efficiency–performance trade-offs. However, existing evaluations remain inadequate: 1) they rely on narrow metrics such as FLOPs or latency, neglecting complementary dimensions like memory, throughput, energy, and compression, leading to mischaracterized efficiency; 2) they are often limited to small models or a single hardware setup, making conclusions difficult to generalize to billion-parameter deployments across diverse accelerators; and 3) they fragment coverage across pretraining, fine-tuning, or inference, failing to provide an end-to-end perspective on the full lifecycle of model efficiency. To address these gaps, we present \\textbf{EfficientLLM}, the first large-scale empirical benchmark that systematically quantifies efficiency–performance trade-offs across the entire lifecycle of LLMs. 1) First, to overcome missing multi-dimensional metrics, EfficientLLM unifies six orthogonal dimensions into a consistent evaluation framework. 2) Second, to address scale and hardware diversity, we evaluate over 150 model–technique pairs spanning 0.5B–72B parameters on production-class clusters with 48*GH200, 8*H200, and 8*A100 accelerators, ensuring conclusions generalize to realistic deployment conditions. 3) Third, to provide end-to-end lifecycle coverage, EfficientLLM benchmarks architectural pretraining, fine-tuning, and bit-width quantization. By systematically resolving these three limitations, EfficientLLM establishes the most comprehensive benchmark to date for evaluating efficiency in large-scale models. Our results not only highlight critical trade-offs between accuracy, cost, and sustainability but also offer actionable guidance for both academic researchers and industrial practitioners in designing, training, and deploying the next generation of foundation models. All code and datasets are released as an open-source toolkit, accessible via \\texttt{pip install efficientllm-toolkit}.",
    "key_points": [
      "large language models (llms)",
      "efficiency benchmark",
      "architecture pretraining"
    ],
    "gold_summary": "The paper introduces EfficientLLM, a large-scale empirical benchmark designed to systematically evaluate the efficiency of Large Language Models (LLMs) across three critical dimensions: architecture pretraining, fine-tuning, and inference quantization."
  },
  {
    "paper_id": "qqzxKudD4T",
    "title": "PoseX: AI Defeats Physics-based Methods on Protein Ligand Cross-Docking",
    "domain": "datasets and benchmarks",
    "content": "Recently, significant progress has been made in protein-ligand docking, especially in deep learning methods, and some benchmarks were proposed, such as PoseBench and PLINDER. However, these studies typically focus on the self-docking scenario, which is less practical in real-world applications. Moreover, some studies involve heavy frameworks requiring extensive training, posing challenges to convenient and efficient assessment of docking methods. To fill these gaps, we design PoseX, an open-source benchmark to evaluate both self-docking and cross-docking, enabling a practical and comprehensive assessment of algorithmic advances. Specifically, we curated a novel dataset comprising 718 entries for self-docking and 1,312 entries for cross-docking; secondly, we incorporated 23 docking methods in three methodological categories, including physics-based methods (e.g., Schrödinger Glide), AI docking methods (e.g., DiffDock) and AI co-folding methods (e.g., AlphaFold3); thirdly, we developed a relaxation method for post-processing to minimize conformational energy and refine binding poses; fourthly, we established a public leaderboard to rank submitted models in real-time. We derived some key insights and conclusions through extensive experiments: (1) AI-based approaches consistently outperform physics-based methods in overall docking success rate. (2) Most intra- and intermolecular clashes of AI-based approaches can be greatly alleviated with relaxation, which means combining AI modeling with physics-based post-processing could achieve excellent performance. (3) AI co-folding methods exhibit ligand chirality issues, except for Boltz-1x, which introduced physics-inspired potentials to fix hallucinations, suggesting that stereochemical modeling greatly improves the structural plausibility of the predicted protein-ligand complexes. (4) Specifying binding pockets significantly promotes docking performance, indicating that pocket information can be leveraged adequately, particularly for AI co-folding methods, in future modeling efforts.",
    "key_points": [
      "ai docking",
      "ai co-folding",
      "protein-ligand interaction",
      "cross docking"
    ],
    "gold_summary": "PoseX is a new benchmark for a new variant in docking task using a series of new \"co-folding\" methods. Compared to previous benchmarks, PoseX have more design related to the recent changes in docking methods."
  },
  {
    "paper_id": "wCV1efgkyV",
    "title": "Evaluating Language Models in Longer Conversational Contexts",
    "domain": "datasets and benchmarks",
    "content": "Evaluating long-form conversations between humans and large language models (LLMs) presents a significant challenge in the field of natural language processing. Traditional evaluation metrics and benchmarks have largely focused on shorter language interactions and often fail to capture the nuanced inherent in extended dialogues. To address this, we introduce UPHELD, a publicly available dataset featuring human-annotated long-form dialogues. This dataset not only facilitates robust benchmarking but also serves as a foundation for further research into conversation evaluation methodologies. Using our dataset, we systematically analyze the correlation between current LLM evaluation metrics and human judgment within long-form conversation scenarios. Our findings reveal that conventional metrics lack the sensitivity necessary to assess the complex and often subjective nature of prolonged interactions. We use our dataset to develop an improved evaluation metric that demonstrates a significantly higher correlation with human assessments. The work highlights the need for advanced metric designs and outlines a clear pathway to refine the evaluation of LLM long-form conversations.",
    "key_points": [
      "evaluation",
      "long-form conversation",
      "llm-as-a-judge",
      "dataset"
    ],
    "gold_summary": "This paper introduces UPHELD, a dataset designed to evaluate LLMs in long-form conversation. The dataset consists of 400 dialogues, with an average length of 5.2 turn pairs."
  },
  {
    "paper_id": "pW7ORPqwzG",
    "title": "Epidemiology of Large Language Models: A Benchmark for Observational Distribution Knowledge",
    "domain": "datasets and benchmarks",
    "content": "Artificial intelligence (AI) systems hold great promise for advancing various scientific disciplines, and are increasingly used in real-world applications. Despite their remarkable progress, further capabilities are expected in order to achieve more general types of intelligence. A critical distinction in this context is between factual knowledge, which can be evaluated against true or false answers (e.g., \"what is the capital of England?\"), and probabilistic knowledge, which reflects probabilistic properties of the real world (e.g., \"what is the sex of a computer science graduate in the US?\").\nMuch of previous work on evaluating large language models (LLMs) focuses on factual knowledge,\nwhile in this paper, our goal is to build a benchmark for understanding the capabilities of LLMs in terms of knowledge of probability distributions describing the real world.\nGiven that LLMs are trained on vast amounts of text, it may be plausible that they internalize aspects of these distributions. \nIndeed, this idea has gained traction, with LLMs being touted as powerful and universal approximators of real-world distributions. At the same time, classical results in statistics, known under the term curse of dimensionality, highlight fundamental challenges in learning distributions in high dimensions, challenging the notion of universal distributional learning. In this work, \nwe develop the first benchmark to directly test this hypothesis, evaluating whether LLMs have access to empirical distributions describing real-world populations across domains such as economics, health, education, and social behavior. Our results demonstrate that LLMs perform poorly overall, and do not seem to internalize real-world statistics naturally.\nThis finding also has important implications that can be interpreted in the context of Pearl’s Causal Hierarchy (PCH). Our benchmark demonstrates that language models do not contain knowledge on observational distributions (Layer 1 of the PCH), and thus the Causal Hierarchy Theorem implies that interventional (Layer 2) and counterfactual (Layer 3) knowledge of these models is also limited.",
    "key_points": [
      "large language models",
      "probabilistic reasoning"
    ],
    "gold_summary": "This paper proposes a benchmark to evaluate LLMs' inherent cognitive abilities in describing real-world population distributions, and tests both open-source and closed-source models on this benchmark."
  },
  {
    "paper_id": "KjgyAm383Z",
    "title": "EXP-Bench: Can AI Conduct AI Research Experiments?",
    "domain": "datasets and benchmarks",
    "content": "Automating AI research holds immense potential for accelerating scientific progress, yet current AI agents struggle with the complexities of rigorous, end-to-end experimentation. We introduce EXP-Bench, a novel benchmark designed to systematically evaluate AI agents on complete research experiments sourced from influential AI publications. Given a research question and incomplete starter code, EXP-Bench challenges AI agents to formulate hypotheses, design and implement experimental procedures, execute them, and analyze results. To enable the creation of such intricate and authentic tasks with high-fidelity, we design a semi-autonomous pipeline to extract and structure crucial experimental details from these research papers and their associated open-source code. With the pipeline, EXP-Bench curated 461 AI research tasks from 51 top-tier AI research papers. Evaluations of leading AI agents, such as OpenHands and IterativeAgent on EXP-Bench demonstrate partial capabilities: while scores on individual experimental aspects such as design or implementation correctness reach 20-35%, the success rate for complete, executable experiments was a mere 0.5%. By identifying these bottlenecks and providing realistic step-by-step experiment procedures, EXP-Bench serves as a vital tool for future AI agents to improve their ability to conduct AI research experiments.",
    "key_points": [
      "ai agents"
    ],
    "gold_summary": "The paper contributes a benchmark called EXP-Bench that consists of tasks from 51 papers publised at Computer Science conferences. Tasks include implementing experiments from these papers given a high-level research plan and question."
  },
  {
    "paper_id": "ZY9nFE36OY",
    "title": "BRIDGEBENCH: AN OFFLINE CONSTRAINED MULTI- AGENT REINFORCEMENT LEARNING BENCHMARK FOR INFRASTRUCTURE MANAGEMENT",
    "domain": "datasets and benchmarks",
    "content": "Effective infrastructure management, particularly bridge maintenance, is critical for public safety and economic benefits. Reinforcement Learning (RL) offers a promising paradigm for optimizing maintenance policies. Real-world applications often involve multiple decision-makers, rely on pre-collected offline data, and necessitate strict adherence to operational constraints. Existing RL benchmarks and methodologies frequently fall short in simultaneously addressing these multi-agent, offline, and constrained aspects within a practical domain. To bridge this gap, we introduce BridgeBench, a novel offline constrained multi-agent RL benchmark for bridge maintenance. It provides a realistic and challenging environment for evaluating algorithms designed for complex infrastructure management tasks. We integrate various state-of-the-art single-agent and multi-agent offline constrained RL algorithms on this platform, providing insights into their performance and limitations. Our work aims to accelerate research in applying advanced RL techniques to critical real-world infrastructure challenges, fostering the development of more robust, safe, and cost-effective maintenance strategies.",
    "key_points": [
      "multi-agent reinforcement learning",
      "offline reinforcement learning",
      "constrained reinforcement learning",
      "infrastructure management",
      "bridge maintenance",
      "benchmark",
      "real-world applications",
      "decision making"
    ],
    "gold_summary": "The authors propose BridgeBench, a benchmark for bridge maintenance. It focuses on offline, constrained, multi-agent RL methods. Different methods are tested on it."
  },
  {
    "paper_id": "1uujlDeIry",
    "title": "MolPILE - large-scale, diverse dataset for molecular representation learning",
    "domain": "datasets and benchmarks",
    "content": "The size, diversity, and quality of pretraining datasets critically determine the generalization ability of foundation models. Despite their growing importance in chemoinformatics, the effectiveness of molecular representation learning has been hindered by limitations in existing  small molecule datasets. To address this gap, we present MolPILE, large-scale, diverse, and rigorously curated collection of 222 million compounds, constructed from 6 large-scale databases using an automated curation pipeline. We present a comprehensive analysis of current pretraining datasets, highlighting considerable shortcomings for training ML models, and demonstrate how retraining existing models on MolPILE yields improvements in generalization performance. This work provides a standardized resource for model training, addressing the pressing need for an ImageNet-like dataset in molecular chemistry.",
    "key_points": [
      "datasets & benchmarks",
      "molecular representation learning",
      "chemical foundation models",
      "chemoinformatics"
    ],
    "gold_summary": "This paper introduces MolPILE, a large-scale, diverse, and rigorously curated dataset for molecular representation learning, developed to overcome the size, diversity, and quality limitations of existing small-molecule datasets."
  },
  {
    "paper_id": "3d0FRYx0D0",
    "title": "CMPhysBench: A Benchmark for Evaluating Large Language Models in Condensed Matter Physics",
    "domain": "datasets and benchmarks",
    "content": "We introduce CMPhysBench, designed to assess the proficiency of Large Language Models (LLMs) in Condensed Matter Physics, as a novel Benchmark. CMPhysBench is composed of more than 520 graduate-level meticulously curated questions covering both representative subfields and foundational theoretical frameworks of condensed matter physics, such as magnetism, superconductivity, strongly correlated systems, etc. To ensure a deep understanding of the problem-solving process,we focus exclusively on calculation problems, requiring LLMs to independently generate comprehensive solutions. Meanwhile, leveraging tree-based representations of expressions, we introduce the Scalable Expression Edit Distance (SEED) score, which provides fine-grained (non-binary) partial credit and yields a more accurate assessment of similarity between prediction and ground-truth. Our results show that even the best models, Grok-4, reach only 36 average SEED score and 28% accuracy on CMPhysBench, underscoring a significant capability gap, especially for this practical and frontier domain relative to traditional physics.",
    "key_points": [
      "llm benchmark",
      "condensed matter physics",
      "llm evaluation",
      "ai for physics"
    ],
    "gold_summary": "This manuscript introduces CMPhysBench, a novel benchmark that successfully establishes a rigorous standard for evaluating LLMs on advanced scientific reasoning tasks in physics. The adoption of a fine-grained evaluation protocol is a major contribution."
  },
  {
    "paper_id": "8yJyEKHkB8",
    "title": "TextAtlas5M: A Large-Scale Dataset for Long and Structured Text Image Generation",
    "domain": "datasets and benchmarks",
    "content": "Text-conditioned image generation has gained significant attention in recent years and is processing increasingly longer and comprehensive text prompts.  In everyday life, dense and intricate text appears in contexts like advertisements, infographics, and signage, where the integration of both text and visuals is essential for conveying complex information.  However, despite these advances, the rendering of images containing long-form text remains a persistent challenge, largely due to the limitations of existing datasets, which often focus on shorter and simpler text.  To address this gap, we introduce TextAtlas5M, a novel dataset specifically designed to evaluate long-text rendering, where ``long text'' refers not only to textual length but also to layout complexity and semantic richness.  In our context, long text involves dense visual content, hierarchical structures, and interleaved text-image layouts, as exemplified by subsets like TextVisionBlend, PPT2Structured, CoverBook, and TextScenesHQ.  Our dataset consists of 5 million generated and collected images across diverse data types, enabling comprehensive evaluation of large-scale generative models on long-text image generation.  We further curate 4,000 human-improved test cases (TextAtlasEval) across 4 domains, establishing one of the most extensive benchmarks for text rendering.  Evaluations suggest that TextAtlasEval presents significant challenges even for the most advanced proprietary models (e.g., GPT4o), while open-source counterparts show an even larger performance gap.  Notably, diffusion and autoregressive models with weak text rendering improve substantially after training on our dataset. These findings position TextAtlas5M as a valuable resource for training and evaluating next-generation text-conditioned image generation models.",
    "key_points": [
      "long-form text",
      "text rendering",
      "text-conditioned image generation"
    ],
    "gold_summary": "This paper presents the construction of a text-rich image dataset and demonstrates its empirical effect for training and evaluation."
  },
  {
    "paper_id": "eQ4kdm5iYj",
    "title": "Real-IKEA : Simulating What Robots Will Really See and Touch",
    "domain": "datasets and benchmarks",
    "content": "Robotic manipulation has greatly benefited from simulated data, yet in contact-rich tasks policies often fail to transfer. We trace this sim-to-real gap to three sources: object assets, physical realism and visual fidelity. We emphasize accuracy along all three axes—precise meshes and collisions, calibrated friction and hinge resistance, and visually realistic observations—and present Real-IKEA, a dataset and simulation framework designed with accuracy as a first-class goal. At scale, Real-IKEA provides 1,079 articulated asset configurations, created by combining real IKEA furniture bases with a curated library of 83 authentic IKEA handles and knobs. For contact-geometry accuracy, we introduce a bidirectional surface-deviation metric ($E_{Q\\to P}$, $E_{P\\to Q}$) that quantifies collision meshes against the visual mesh. For dynamics accuracy, we establish resistance-calibrated benchmarks that vary damping and friction. To narrow the vision gap, we pair real-time teleoperation with offline high-fidelity re-rendering and quantify alignment via FID/EMD across multiple encoders. Extensive comparisons show that Real-IKEA yields more realistic asset structure, more accurate physical interactions, and visuals more closely aligned with real data, enabling policies to exploit geometry and torque rather than rely on friction-only pulling. This accuracy-centric design, coupled with large scale, enables the scalable collection of reliable manipulation data and more robust sim-to-real transfer.",
    "key_points": [
      "contact-rich robotic manipulation",
      "articulated object",
      "simulation fidelity",
      "sim-to-real gap"
    ],
    "gold_summary": "This paper introduces a new dataset of 3D assets of IKEA cabinets with realistic visuals and collision geometry, diverse coverage, and configurable joint resistance."
  },
  {
    "paper_id": "S7KyLgHqJf",
    "title": "M3CoTBench: Benchmark Chain-of-Thought of MLLMs in Medical Image Understanding",
    "domain": "datasets and benchmarks",
    "content": "Chain-of-Thought (CoT) reasoning has proven effective in enhancing large language models by encouraging step-by-step intermediate reasoning, and recent advances have extended this paradigm to Multimodal Large Language Models (MLLMs). In the medical domain, where diagnostic decisions depend on nuanced visual cues and sequential reasoning, CoT aligns naturally with clinical thinking processes. However, Current benchmarks for medical image understanding generally focus on the final answer while ignoring the reasoning path. An opaque process lacks reliable bases for judgment, making it difficult to assist doctors in diagnosis. \nTo address this gap, we introduce a new M3CoTBench benchmark specifically designed to evaluate the correctness, efficiency, impact, and consistency of CoT reasoning in medical image understanding. M3CoTBench features  (1) a diverse, multi-level difficulty dataset covering 24 examination types, (2) 13 varying-difficulty tasks,  (3) a suite of CoT-specific evaluation metrics (correctness, efficiency, impact, and consistency) tailored to clinical reasoning,  and (4) a performance analysis of multiple MLLMs. M3CoTBench systematically evaluates CoT reasoning across diverse medical imaging tasks, revealing current limitations of MLLMs in generating reliable and clinically interpretable reasoning, and aims to foster the development of transparent, trustworthy, and diagnostically accurate AI systems for healthcare.",
    "key_points": [
      "chain-of-thought",
      "multimodal large language models",
      "m3cotbench",
      "benchmark"
    ],
    "gold_summary": "This paper introduces M3CoTBench, a benchmark for evaluating Chain-of-Thought reasoning in medical image understanding MLLMs. The dataset contains 1,079 image-QA pairs across 24 medical imaging modalities with expert-annotated reasoning steps and four evaluation dimensions."
  },
  {
    "paper_id": "GwpD2TpAEi",
    "title": "RealUnify: Do Unified Models Truly Benefit from Unification? A Comprehensive Benchmark",
    "domain": "datasets and benchmarks",
    "content": "The integration of visual understanding and generation into unified multimodal models represents a significant stride toward general-purpose AI. However, a fundamental question remains unanswered by existing benchmarks: does this architectural unification actually enable synergetic interaction between the constituent capabilities? Existing evaluation paradigms, which primarily assess understanding and generation in isolation, are insufficient for determining whether a unified model can leverage its understanding to enhance its generation, or use generative simulation to facilitate deeper comprehension. To address this critical gap, we introduce RealUnify, a benchmark specifically designed to evaluate bidirectional capability synergy. RealUnify comprises 1,000 meticulously human-annotated instances spanning 10 categories and 32 subtasks. It is structured around two core axes: 1) Understanding Enhances Generation, which requires reasoning (e.g., commonsense, logic) to guide image generation, and 2) Generation Enhances Understanding, which necessitates mental simulation or reconstruction (e.g., of transformed or disordered visual inputs) to solve reasoning tasks. A key contribution is our dual-evaluation protocol, which combines direct end-to-end assessment with a diagnostic stepwise evaluation that decomposes tasks into distinct understanding and generation phases. This protocol allows us to precisely discern whether performance bottlenecks stem from deficiencies in core abilities or from a failure to integrate them. Through large-scale evaluations of 12 leading unified models and 6 specialized baselines, we find that current unified models still struggle to achieve effective synergy, indicating that architectural unification alone is insufficient. These results highlight the need for new training strategies and inductive biases to fully unlock the potential of unified modeling.",
    "key_points": [
      "unified model",
      "multimodal benchmark"
    ],
    "gold_summary": "This paper presents RealUnify, a benchmark designed to evaluate the visual understanding and generation capabilities of unified multimodal models. Experiments show that current models still lack the capability to synergize."
  },
  {
    "paper_id": "1FnCrZtBNQ",
    "title": "LAMDA: A Longitudinal Android Malware Benchmark for Concept Drift Analysis",
    "domain": "datasets and benchmarks",
    "content": "Machine learning (ML)-based malware detection systems often fail to account for the dynamic nature of real-world training and test data distributions. In practice, these distributions evolve due to frequent changes in the Android ecosystem, adversarial development of new malware families, and the continuous emergence of both benign and malicious applications. Prior studies have shown that such concept drift—distributional shifts in benign and malicious samples, leads to significant degradation in detection performance over time. Despite the practical importance of this issue, existing datasets are often outdated and limited in temporal scope, diversity of malware families, and sample scale, making them insufficient for the systematic evaluation of concept drift in malware detection.\n\nTo address this gap, we present LAMDA, the largest and most temporally diverse Android malware benchmark to date, designed specifically for concept drift analysis. LAMDA spans 12 years (2013–2025, excluding 2015), includes over 1 million samples (approximately 37\\% labeled as malware), and covers 1,380 malware families and 150,000 singleton samples, reflecting the natural distribution and evolution of real-world Android applications. We empirically demonstrate LAMDA's utility by quantifying the performance degradation of standard ML models over time and analyzing feature stability across years. As the most comprehensive Android malware dataset to date, LAMDA enables in-depth research into temporal drift, generalization, explainability, and evolving detection challenges.",
    "key_points": [
      "machine learning",
      "android malware",
      "concept drift analysis",
      "explainability",
      "dataset benchmark"
    ],
    "gold_summary": "The authors present LAMDA, a malware dataset that spans 12 years and therefore is aimed at capturing classifier drop in performance due to representational drift."
  },
  {
    "paper_id": "uUYcKsPNgM",
    "title": "MAVOS-DD: Multilingual Audio-Video Open-Set Deepfake Detection Benchmark",
    "domain": "datasets and benchmarks",
    "content": "We present the first large-scale open-set benchmark for multilingual audio-video deepfake detection. Our dataset comprises over 300 hours of real and fake videos across eight languages, with 58% of data being generated. For each language, the fake videos are generated with several distinct audio and video deepfake generation models, selected based on the quality of the generated content. We organize the training, validation and test splits such that only a subset of the chosen generative models and languages are available during training, thus creating several challenging open-set evaluation setups. We perform experiments with various pre-trained and fine-tuned deepfake detectors proposed in recent literature. Our results show that state-of-the-art detectors are not currently able to maintain their performance levels when tested in our open-set scenarios. We publicly release our data and code at: https://anonymous.4open.science/r/MAVOS-DD.",
    "key_points": [
      "deepfake detection",
      "audio-video benchmark",
      "multilingual benchmark"
    ],
    "gold_summary": "This work introduces MAVOS-DD, the first audio-visual deepfake detection benchmark designed for multilingual and open-set scenarios, featuring 300 hours of data across eight languages, diverse generator combinations, and open-set evaluation splits."
  },
  {
    "paper_id": "UDeDdxZOwl",
    "title": "MathViz-Bench: Evaluating Text-to-Image Models on Visually Solving Math Problems",
    "domain": "datasets and benchmarks",
    "content": "We present MathViz-Bench, a comprehensive benchmark for evaluating Text-to-Image (T2I) models' capability to visualize step-by-step solutions for high school mathematics problems.\nMathViz-Bench comprises 500 carefully curated problems sampled from levels 1-3 of the MATH dataset, spanning seven mathematical domains: Prealgebra, Algebra, Number Theory, Counting \\& Probability, Geometry, Intermediate Algebra, and Precalculus.\nWe transform these problems into prompts requiring models to generate visual step-by-step solutions with proper mathematical notation and logical flow. \nOur automated assessment pipeline employs three metrics: Sequential Consistency for logical flow, Symbol Fidelity for notation accuracy, and Mathematical Correctness for calculation validity, each scored 0-5. \nOur evaluation shows that models with built-in language understanding (GPT-Image-1: 84.05\\%, Gemini-2.5-Pro: 75.13\\%) perform much better than diffusion models (FLUX1.1-Pro: 35.23\\%, WAN2.2: 28.05\\%, Stable Diffusion 3.5 Ultra: 22.05\\%), achieving 2-3 times higher scores.\nAll models exhibit high Symbol Fidelity (1.81-4.57) but fail at Mathematical Correctness (0.65-4.05), indicating they process mathematical symbols as visual patterns rather than semantic operators. \nDiffusion models demonstrate complete difficulty invariance and 33.8\\% critical failure rates, confirming absence of mathematical reasoning. \nThese findings establish that mathematical visualization requires architectural integration of symbolic reasoning with visual generation, beyond current T2I capabilities.",
    "key_points": [
      "text-to-image models",
      "foundation model",
      "benchmark"
    ],
    "gold_summary": "The paper introduces MathViz-Bench, a benchmark sampled from the MATH dataset that evaluates text-to-image models on step-by-step mathematical visualization."
  },
  {
    "paper_id": "LlDsbqsvn5",
    "title": "RedNote-Vibe: A Dataset for Capturing Temporal Dynamics of AI-Generated Text in Social Media",
    "domain": "datasets and benchmarks",
    "content": "The proliferation of Large Language Models (LLMs) has led to widespread AI-Generated Text (AIGT) on social media platforms, creating new challenges for content authenticity. The identification of AIGT on social media platforms presents unique challenges due to engagement-driven content and temporal dynamics. To bridge this gap, we introduce a novel RedNote-Vibe dataset, collected from RedNote (Xiaohongshu), one of the most influential Chinese social media platforms. This dataset contains user posts and their parallel AIGT variants generated using diverse LLMs, spanning from before ChatGPT's release to the present. We further propose a detection method based on psycholinguistic principles, namely PsychoLinguistic AIGT Detection Framework (PLAD), which achieves SOTA performance compared to recent model-based methods and provides superior interpretability. Our analysis also reveals temporal trends of AI content adoption and engagement pattern differences between human and AI-generated content.",
    "key_points": [
      "ai-generated text",
      "social media",
      "user engagement",
      "rednote(xiaohongshu)",
      "psycholinguistics"
    ],
    "gold_summary": "RedNote-Vibe - the first longitudinal AIGT dataset."
  },
  {
    "paper_id": "NRWUAo075J",
    "title": "GneissWeb: Preparing High Quality Data for LLMs at Scale",
    "domain": "datasets and benchmarks",
    "content": "Data quantity and quality play a vital role in determining the performance of Large Language Models (LLMs). High-quality data, in particular, can significantly boost the LLM's ability to generalize on a wide range of downstream tasks. In this paper, we introduce **GneissWeb**, a large dataset of around 10 trillion tokens that caters to the data quality and quantity requirements of training LLMs. Our GneissWeb recipe that produced the dataset consists of sharded exact sub-string deduplication and a judiciously constructed ensemble of quality filters. \nGneissWeb goes beyond simple model-based quality filtering used in recent datasets by designing an ensemble of filters incorporating novel quality filters. Novel components enable us to achieve a favorable trade-off between data quality and quantity, producing models that outperform models trained on state-of-the-art open large datasets (5+ trillion tokens). We show that models trained using GneissWeb outperform those trained on FineWeb-V1.1.0 by 2.73 percentage points in terms of average scores on a set of 11 commonly used benchmarks (both zero-shot and few-shot) for pre-training dataset evaluation. When the evaluation set is extended to 20 benchmarks (both zero-shot and few-shot), models trained using GneissWeb still achieve a 1.75 percentage points gain over those trained on FineWeb-V1.1.0.",
    "key_points": [
      "large language modes",
      "pre-training datasets",
      "data quality",
      "evaluation benchmarks"
    ],
    "gold_summary": "This method uses an ensemble of quality filters and exact deduplication to improve the pretraining data recipe. This paper works, demonstrates consistent improvement across scales. The evaluations were diverse and rigorous."
  },
  {
    "paper_id": "U004uqALWl",
    "title": "SpeakerVid-5M: A Large-Scale High-Quality Dataset for Audio-Visual Dyadic Interactive Human Generation",
    "domain": "datasets and benchmarks",
    "content": "The rapid development of large-scale models has catalyzed significant breakthroughs in the digital human domain. These advanced methodologies offer high-fidelity solutions for avatar driving and rendering, leading academia to focus on the next major challenge: audio-visual dyadic interactive virtual human. To facilitate research in this emerging area, we present SpeakerVid-5M dataset, the first large-scale, high-quality dataset designed for audio-visual dyadic interactive virtual human generation. Totaling over $8,743$ hours, SpeakerVid-5M contains more than $5.2$ million video clips of human portraits. It covers diverse scales and interaction types, including monadic talking, listening, and dyadic conversations. Crucially, the dataset is structured along two key dimensions: interaction type and data quality. First, it is categorized into four types (dialogue branch, single branch, listening branch and multi-turn branch) based on the interaction scenario. Second, it is stratified into a large-scale pre-training subset and a curated, high-quality subset for Supervised Fine-Tuning (SFT). This dual structure accommodates a wide array of 2D virtual human tasks. In addition, we provide an autoregressive (AR)-based video chat baseline trained on this data, accompanied by a dedicated set of metrics and test data to serve as a benchmark (VidChatBench) for future work. Both the dataset and the corresponding data processing code will be publicly released.",
    "key_points": [
      "video generation",
      "digital human",
      "human-centric dataset"
    ],
    "gold_summary": "SpeakerVid-5M îs a large-scale dyadic talking humans dataset. The dataset contains automatically extracted annotations of 2D kpts, audio, audio-to-text, and scene descriptions. The dataset is accompanied by an extensive video benchmark."
  },
  {
    "paper_id": "tnPZNgYlBH",
    "title": "FORGE: Forming Semantic Identifiers for Generative Retrieval in Industrial Datasets",
    "domain": "datasets and benchmarks",
    "content": "Semantic identifiers (SIDs) have gained increasing attention in generative \nretrieval (GR) due to their meaningful semantic discriminability. However, current research on SIDs faces three main challenges: (1) the absence of large-scale public datasets with multimodal features, (2) limited investigation into optimization strategies for SID generation, which typically rely on costly GR training for evaluation, and (3) slow online convergence in industrial deployment. To address these challenges, we propose **FORGE**, a comprehensive benchmark for **FO**rming semantic identifie**R** in **G**enerative r**E**trieval with industrial datasets. Specifically, FORGE is equipped with a dataset comprising **14 billion** user interactions and multimodal features of **250 million** items sampled from one of the biggest e-commerce platforms in China, which serves over 300 million users each day. Leveraging this dataset, FORGE explores several optimizations to enhance the SID construction and validates their effectiveness via offline experiments across different settings and tasks. Further online study deployed in our platform for the homepage recommendation shows a 0.35\\% increase in transaction count, highlighting the practical impact of our method. Regarding the expensive SID validation accompanied by the full training of GRs, we propose two novel metrics of SID that correlate positively with the recommendation performance, enabling convenient evaluations without any GR training. For real-world applications, FORGE introduces an offline pretraining schema that reduces online convergence by half of the original. The code and data are available at https://anonymous.4open.science/r/forge.",
    "key_points": [
      "semantic identifiers",
      "industry dataset",
      "generative retrieval"
    ],
    "gold_summary": "This paper introduces FORGE, a generative recommendation dataset built upon real-world industrial scenarios, and focuses on investigating the impact of different SID construction strategies on model performance."
  },
  {
    "paper_id": "ddFN3lWpIr",
    "title": "Everything in Its Place: Benchmarking Spatial Intelligence of Text-to-Image Models",
    "domain": "datasets and benchmarks",
    "content": "Text-to-image (T2I) models have achieved remarkable success in generating high-fidelity images, but they often fail in handling complex spatial relationships, e.g., spatial perception, reasoning, or interaction. These critical aspects are largely overlooked by current benchmarks due to their short or information-sparse prompt design. In this paper, we introduce SpatialGenEval, a new benchmark designed to systematically evaluate the spatial intelligence of T2I models, covering two key aspects: (1) SpatialGenEval involves 1,230 long, information-dense prompts across 25 real-world scenes. Each prompt integrates 10 spatial sub-domains and corresponding 10 multi-choice question-answer pairs, ranging from object position and layout to occlusion and causality. Our extensive evaluation of 21 state-of-the-art models reveals that higher-order spatial reasoning remains a primary bottleneck. (2) To demonstrate that the utility of our information-dense design goes beyond simple evaluation, we also construct the SpatialT2I dataset. It contains 15,400 text-image pairs with rewritten prompts to ensure image consistency while preserving information density. Fine-tuned results on current foundation models (i.e., Uniworld-V1, OmniGen2) yield consistent performance gains (+5.7%, +4.4%) and more realistic effects in spatial relations, highlighting a data-centric paradigm to achieve spatial intelligence in T2I models.",
    "key_points": [
      "text-to-image generative evaluation",
      "spatial intelligence"
    ],
    "gold_summary": "The paper introduces a new benchmark for critically evaluating the spatial understanding of current text-to-image models."
  },
  {
    "paper_id": "dRwsN1DvNV",
    "title": "AI’s Visual Blind Spot: Benchmarking MLLMs on Visually Smuggled Threats",
    "domain": "datasets and benchmarks",
    "content": "Visual Smuggling Threats (VSTs) spread illicit information by embedding concealed or encrypted text within seemingly innocuous images, adversarially evading automated moderation and proliferating across online platforms, while the effectiveness of recent Multimodal Large Language Models (MLLMs) in identifying VSTs to safeguard online security remains underexplored. To bridge this gap, we construct VST-Bench, a benchmark for comprehensively evaluating models’ ability to detect diverse VSTs. It encompasses three major challenges, i.e., Perceptual Difficulty, Reasoning Traps, and AI Illusion, which are further divided into ten subcategories, and includes 3,400 high-quality samples collected from real smuggling scenarios or synthesized by replicating smuggling workflows. Evaluation of 29 mainstream MLLMs on VST-Bench shows that existing models perform poorly in judging violative images. The state-of-the-art open-source model Gemma-3-27B achieves only 32.67% F1 on the challenging AI Blended Background category, and even the proprietary Gemini-2.5 Pro reaches just 46.32%, indicating that current MLLMs are far from reliably preventing the spread of harmful content in real-world deployment. Through an in-depth analysis of failure cases, we discover three core challenges posed by VSTs: (1) Perceptual Failure on Subtle Threats, (2) Reasoning Failure on Semantic Puzzles, and (3) Recognition Failure against AI Illusions. We will release the dataset and evaluation code of VST-Bench to facilitate further research on VST and the broader online risk content recognition.",
    "key_points": [
      "mllms；visually smuggled threats；mllms safety；ocr"
    ],
    "gold_summary": "This paper focuses on Visually Smuggled Threats (VSTs)—harmful content that embeds concealed or encrypted illicit text in seemingly benign images to evade automated moderation."
  },
  {
    "paper_id": "OOYO9x9gpH",
    "title": "LU-500: A Logo Benchmark for Concept Unlearning",
    "domain": "datasets and benchmarks",
    "content": "Current concept unlearning approaches for copyright have achieved notable progress in handling styles or portrait-like representations. However, the task of unlearning company logos remains largely unexplored. This challenge stems from logos’ simplicity, omnipresence, and strong associations with branded products, often occupying minimal space within an image. To bridge this gap, we introduce LU-500, a comprehensive benchmark for logo unlearning, consisting of 10 prompts to generate images of logos from Fortune Global 500 companies. Our benchmark features two tracks: LUex-500, with explicit prompts, and LUim-500, requiring implicit reasoning to address real-world scenarios like standard usage and adversarial attacks. We further propose five novel, multi-grained evaluation metrics, ranging from local logo regions to global image attributes and spanning both pixel and latent spaces, enabling a robust quantitative analysis of complex visual scenes. Experimental results reveal that existing inference-time unlearning techniques, such as NP, SLD, SEGA, and fine-tuning-based methods like ESD and Forget-Me-Not, all fall short in logo unlearning. To investigate this limitation, we propose a prompt-based baseline using large language models, which demonstrates significant improvements, highlighting the potential of unlearning in semantic space. Additionally, we analyze the correlation between the unlearning performance of an image and its characteristics such as logo area, location, and fractal dimension. We find that SSIM might be a profit control for logo unlearning.",
    "key_points": [
      "benchmark",
      "concept unlearn"
    ],
    "gold_summary": "The paper proposes LU-500, a benchmark for “logo unlearning” in text-to-image models, built from 9,584 prompts across Fortune Global 500 brands with explicit (LUex-500) and implicit (LUim-500) tracks."
  },
  {
    "paper_id": "AZ0VQouDmR",
    "title": "DetailMaster: Can Your Text-to-Image Model Handle Long Prompts?",
    "domain": "datasets and benchmarks",
    "content": "While recent text-to-image (T2I) models show impressive capabilities in synthesizing images from brief descriptions, their performance significantly degrades when confronted with long, detail-intensive prompts required in professional applications. We present DetailMaster, the first comprehensive benchmark specifically designed to evaluate T2I models' systematic abilities to handle extended textual inputs that contain complex compositional requirements. Our benchmark introduces four critical evaluation dimensions: Character Attributes, Structured Character Locations, Multi-Dimensional Scene Attributes, and Spatial/Interactive Relationships. The benchmark comprises long and detail-rich prompts averaging 284.89 tokens, with high quality validated by expert annotators. Evaluation on 7 general-purpose and 5 long-prompt-optimized T2I models reveals critical performance limitations: state-of-the-art models achieve merely ~50% accuracy in key dimensions like attribute binding and spatial reasoning, while all models showing progressive performance degradation as prompt length increases. Our analysis reveals fundamental limitations in compositional reasoning, demonstrating that current encoders flatten complex grammatical structures and that diffusion models suffer from attribute leakage under detail-intensive conditions. We open-source our dataset, data curation code, and evaluation tools to advance detail-rich T2I generation and  enable applications previously hindered by the lack of a dedicated benchmark.",
    "key_points": [
      "generative model",
      "long prompt",
      "detail-rich prompt",
      "compositional text-to-image generation"
    ],
    "gold_summary": "This paper proposes the comprehensive benchmark to address ex\u0002tended textual inputs that contain complex compositional requirements. The benchmark introduces four critical evaluation dimensions: Character Attributes, Structured Character Locations, Multi-Dimensional Scene Attributes, and Spatial/Interactive Relationships."
  },
  {
    "paper_id": "LcgzZZ921O",
    "title": "VaseVQA-3D: Benchmarking 3D VLMs on Ancient Greek Pottery",
    "domain": "datasets and benchmarks",
    "content": "Vision-Language Models (VLMs) have achieved significant progress in multimodal understanding tasks, demonstrating strong capabilities particularly in general tasks such as image captioning and visual reasoning. However, when dealing with specialized cultural heritage domains like 3D vase artifacts, existing models face severe data scarcity issues and insufficient domain knowledge limitations. Due to the lack of targeted training data, current VLMs struggle to effectively handle such culturally significant specialized tasks. To address these challenges, we propose the VaseVQA-3D dataset, which serves as the first 3D visual question answering dataset for ancient Greek pottery analysis, collecting 664 ancient Greek vase 3D models with corresponding question-answer data and establishing a complete data construction pipeline. We further develop the VaseVLM model, enhancing model performance in vase artifact analysis through domain-adaptive training. Experimental results validate the effectiveness of our approach, where we improve by 12.8% on R@1 metrics and by 6.6% on lexical similarity compared with previous state-of-the-art on the VaseVQA-3D dataset, significantly improving the recognition and understanding of 3D vase artifacts, providing new technical pathways for digital heritage preservation research.",
    "key_points": [
      "vision-language models",
      "vision question answering",
      "ancient greek pottery",
      "cultural heritage",
      "dataset construction",
      "3d generation",
      "archaeological ai",
      "multimodal learning"
    ],
    "gold_summary": "The paper proposes a dataset and benchmark for 3D visual question answering on ancient Greek pottery. It develops a VLM model that demonstrated improved performance on vase artifact analysis."
  },
  {
    "paper_id": "RebPBMrMmk",
    "title": "RobustSpring: Benchmarking Robustness to Image Corruptions for Optical Flow, Scene Flow and Stereo",
    "domain": "datasets and benchmarks",
    "content": "Standard benchmarks for optical flow, scene flow, and stereo vision algorithms generally focus on model accuracy rather than robustness to image corruptions like noise or rain. Hence, the resilience of models to such real-world perturbations is largely unquantified. To address this, we present RobustSpring, a comprehensive dataset and benchmark for evaluating robustness to image corruptions for optical flow, scene flow, and stereo models. RobustSpring applies 20 different image corruptions, including noise, blur, color changes, quality degradations, and weather distortions, in a time-, stereo-, and depth-consistent manner to the high-resolution Spring dataset, creating a suite of 20,000 corrupted images that reflect challenging conditions. RobustSpring enables comparisons of model robustness via a new corruption robustness metric. Integration with the Spring benchmark enables public two-axis evaluations of both accuracy and robustness. We benchmark a curated selection of initial models, observing that robustness varies widely by corruption type and experimentally show that evaluations on RobustSpring indicate real-world robustness. RobustSpring is a new computer vision benchmark that treats robustness as a first-class citizen to foster models that combine accuracy with resilience.",
    "key_points": [
      "out-of-distribution",
      "image corruptions",
      "optical flow",
      "scene flow",
      "stereo"
    ],
    "gold_summary": "This paper proposes RobustSpring, a new benchmark that extends Spring with various augmentations. The authors also propose novel corruption robustness metrics along with efficient subsampling methods for evaluation. Detailed experiments are provided."
  },
  {
    "paper_id": "RjDplwaI5H",
    "title": "Eye of Judgement: Dissecting the Evaluation  of Russian-speaking LLMs with POLLUX",
    "domain": "datasets and benchmarks",
    "content": "Evaluating open-ended generation remains a highly non-trivial challenge, as responses vary in style, quality, and correctness, making reliable assessment difficult. To address this, we introduce POLLUX, an open-source framework for evaluating Russian-speaking large language models (LLMs). Its novelty lies in a criteria-based methodology that improves interpretability by combining a structured benchmark with a family of LLM-as-a-Judge evaluators. For each task type, we define explicit criteria and a scoring protocol in which models not only rate responses but also justify their judgments, offering a transparent alternative to resource-intensive human comparisons. The benchmark spans 35 task types across domains such as code generation, creative writing, and assistant-style interactions, supported by 2,115 expert-authored prompts stratified by difficulty. In addition, we release specialized evaluators (7B and 32B) trained for fine-grained assessment of generative outputs. By uniting a comprehensive taxonomy with automated judges, POLLUX provides scalable and interpretable evaluation tools that move beyond the costs and inconsistencies of human annotation.",
    "key_points": [
      "benchmarking",
      "automatic creation and evaluation of language resources",
      "nlp datasets",
      "metrics"
    ],
    "gold_summary": "This paper proposes POLLUX, a Russian-based framework for LLM-as-a-judge evaluation with more clearly defined judging criteria. The paper evaluates POLLUX against typical LLM-as-a-judge approaches, in contrast to human expert evaluation."
  },
  {
    "paper_id": "WxTlAbRUE6",
    "title": "Benchmarking Compositional generalisation for Learning Inter-atomic Potentials",
    "domain": "datasets and benchmarks",
    "content": "Inter-atomic potentials play an important role for modelling molecular dynamics. Unfortunately, traditional methods for computing such potentials are computationally heavy. In recent years, the idea of using neural networks to approximate these computations has gained in popularity, and a variety of Graph Neural Networks and Transformer based methods have been proposed for this purpose. Recent approaches provide highly accurate estimates, but they are typically trained and tested on the same molecules. It thus remains unclear whether these models mostly learn to interpolate the training labels, or whether their physically-informed designs actually allow them to capture the underlying principles. To address this gap, we propose a benchmark consisting of four tasks that each require some form of compositional generalisation. Training and testing involves separate molecules, but the training data is chosen such that generalisation to the test examples should be feasible for models that learn the physical principles. Our empirical analysis shows that the considered tasks are highly challenging for state-of-the-art models, with errors for out-of-distribution examples often being orders of magnitude higher than for in-distribution examples.",
    "key_points": [
      "neural networks",
      "graph neural networks",
      "transformers",
      "compositional generalization",
      "benchmark tasks"
    ],
    "gold_summary": "This paper proposes a new benchmark dataset for interatomic potentials, testing the generalizability on the chemical space."
  },
  {
    "paper_id": "8yWECy22Zi",
    "title": "MFCL: A Multi-modal Function Calling Evaluation for Large Language Models",
    "domain": "datasets and benchmarks",
    "content": "Large language models are evolving into multi-modal agents that call tools directly from raw speech or images. Yet we still lack a principled metric for how well they convert perception into accurate function calls. We introduce \\textbf{MFCL}, the first large-scale benchmark for \\emph{Multi-modal Function Calling}, comprising \\textbf{8.2K} expert-verified tasks across three suites—\\textbf{True Audio}, \\textbf{Text Audio}, and \\textbf{Vision}. Each example pairs a multi-modal user query with a ground-truth tool-call trace. To examine different capabilities of the LLM's perception-to-action pipeline, we introduce controlled perturbations: for audio, accents, contractions, simplified forms, casual pronouns, slang, disfluencies (fillers, hesitations, repetitions), and background noise; for images, crops and resizes, occlusions, grayscale and other color shifts, and related transformations. Image crops and resizes, occlusions, black-and-white and other color filters, etc for images. Our automatic grader computes exact-match scores for both function names and their arguments, removing dependence on brittle LLM judges and isolating errors in perception, reasoning, and formatting. We evaluate  leading models and present a taxonomy of failure models: named-entity ASR errors, conversational drift, and tool avoidance. By releasing MFCL's dataset, taxonomy, and diagnostics, we hope to accelerate research on multi-modal agents that can effectively invoke tools.",
    "key_points": [
      "function calling evaluation",
      "tool use",
      "large language models",
      "multimodal",
      "audio",
      "vision"
    ],
    "gold_summary": "This paper introduces MFCL, a new benchmark for function calling in multimodal scenarios. The paper examines several cutting-edged models and reveals common failure patterns of these models, providing insights into developing multimodal agents."
  },
  {
    "paper_id": "Xobl2VHyVb",
    "title": "Can LLMs Design Real Hardware? A New Benchmark for RTL Design and Verification Tasks",
    "domain": "datasets and benchmarks",
    "content": "We present the XYZ benchmark [note to reviewers: name withheld in accordance with ICLR double-blind policy], a new dataset and infrastructure to advance LLM and agent research in hardware design and verification. XYZ includes 783 problems across 13 task categories, covering RTL generation, verification, debugging, specification alignment, and technical Q&A authored by experienced hardware engineers. Problems are offered in both non-agentic and agentic formats. The benchmark introduces more realistic and challenging contexts than prior work, with state-of-the-art models achieving no more than 34% pass@1 on code generation. Agentic tasks—especially those involving RTL reuse and verification—are particularly difficult. Evaluation uses open-source tools and model scoring infrastructure, with comprehension tasks assessed via BLEU and LLM-based judging. XYZ reveals substantial gaps in current model capabilities, underscoring the need for continued research toward robust, real-world hardware design automation.",
    "key_points": [
      "large language models",
      "benchmark",
      "hardware design automation",
      "hardware code generation",
      "hardware design verification",
      "ai agent"
    ],
    "gold_summary": "The paper introduces XYZ benchmark for evaluating LLMs on hardware design tasks that include Verilog code generation tasks and verification tasks. The benchmark is oriented towards both agentic and non-agentic evaluations."
  },
  {
    "paper_id": "z7nS4MgMS7",
    "title": "Social Human Robot Embodied Conversation (SHREC) Dataset: Benchmarking Foundational Models’ Social Reasoning",
    "domain": "datasets and benchmarks",
    "content": "Our work focuses on the social reasoning capabilities of foundational models for real-world human–robot interactions. We introduce the Social Human Robot Embodied Conversation (SHREC) Dataset, a large-scale benchmark of 400 real-world human-robot interaction videos and over 10K annotations, capturing robot social errors, competencies, underlying rationales, and corrections. Unlike prior datasets focused on human–human interactions, the SHREC Dataset uniquely highlights the challenges faced by real-world embodied social AI agents, where robots lack innate social abilities such as emotion understanding, intention tracking, and conversational mechanics. Moreover, current foundational models struggle to recognize these deficits, which manifest as subtle, socially situated failures. To evaluate AI models’ capacity for social reasoning, we define eight benchmark tasks targeting critical areas such as (1) detection of social errors and competencies, (2) identification of underlying social attributes, (3) comprehension of interaction flow, and (4) providing rationale and alternative correct actions. Experiments with state-of-the-art foundational models, alongside human evaluations, reveal substantial performance gaps—underscoring the difficulty and providing directions in developing socially intelligent AI.",
    "key_points": [
      "social intelligence",
      "large language models",
      "foundational models",
      "vision-language models",
      "robotics",
      "social robots",
      "social interactions"
    ],
    "gold_summary": "The paper introduces SHREC, a real-world benchmark of ~400 human–robot interaction videos with10k+ annotations capturing social competencies, social errors, their underlying social attributes(seven categories), and rationales/corrections."
  },
  {
    "paper_id": "ofgxkMLqic",
    "title": "Human-AI Curation Synergy: Scaling Preference Data Curation via Human-Guided AI Feedback",
    "domain": "datasets and benchmarks",
    "content": "Despite the critical role of reward models (RMs) in reinforcement learning from human feedback (RLHF), current state-of-the-art open RMs perform poorly on most existing evaluation benchmarks, failing to capture the spectrum of nuanced and sophisticated human preferences. Even approaches incorporating advanced training techniques have failed to yield meaningful performance improvements. We hypothesize that this brittleness stems primarily from limitations in preference datasets, which are often narrowly scoped, synthetically labeled, or lack rigorous quality control. To address these challenges, we present a large-scale preference dataset comprising 40 million preference pairs. To enable data curation at scale, we design a human-AI synergistic two-stage pipeline that leverages the complementary strengths of human annotation quality and AI scalability. In this pipeline, humans provide verified annotations, while large language models~(LLMs) perform automatic curation based on human guidance. Based on this preference mixture, we train simple Bradley-Terry reward models ranging from 0.6B to 8B parameters on a carefully curated subset of 26 million preference pairs from the 40M pool. We demonstrate that the resulting reward models are versatile across a wide range of capabilities, including alignment with human preferences, objective correctness, safety, resistance to stylistic biases, and best-of-N scaling. These reward models achieve state-of-the-art performance across seven major reward model benchmarks, outperform the latest paradigm of generative reward models, and demonstrate strong downstream performance. Ablation studies confirm that the effectiveness of our approach stems not only from data scale but also from high-quality curation. Our approach represents substantial progress in open reward models, revealing the untapped potential of existing preference datasets and demonstrating how human-AI curation synergy can unlock significantly higher data quality.",
    "key_points": [
      "preference data",
      "reward modeling",
      "data curation",
      "data annotation"
    ],
    "gold_summary": "SynergyPref-40M introduces a 40M-pair preference dataset and eight reward models (0.6B–8B params) trained via a human-AI curation pipeline. Models achieve SOTA across seven benchmarks, demonstrating strong alignment with human preferences, safety, and bias resistance."
  },
  {
    "paper_id": "e80U2cGtv4",
    "title": "InfantNet: A Large Scale Dataset for Infant Body Pose and Shape Estimation",
    "domain": "datasets and benchmarks",
    "content": "Infant pose and shape estimation is essential for applications in childcare, developmental monitoring, and medical diagnosis. However, existing methods and datasets are largely designed for adults, and direct transfer to infants fails due to substantial differences in body proportions, articulation limits, and frequent self-occlusion. To address this gap, we introduce InfantNet, the largest real-image infant dataset to date, comprising 108,902 RGB images of infants aged 6-18 months. Each image is annotated with 2D keypoints, and a curated subset of 11,642 images additionally includes 3D pose and shape annotations with full SMIL parameters. We use an iterative annotation pipeline to ensure high fidelity across both 2D and 3D labels. InfantNet establishes a large-scale, comprehensive benchmark for infant 2D keypoint detection and 3D pose-and-shape recovery. Baseline experiments demonstrate that state-of-the-art adult pose estimators do not generalize well to infants, whereas fine-tuning on InfantNet yields a consistent improvement. The gains are even more pronounced for 3D pose and shape estimation. By releasing the InfantNet dataset and benchmark, we provide a vital resource for advancing infant pose analysis and related healthcare applications.",
    "key_points": [
      "infant pose",
      "keypoint detection",
      "smil",
      "pose estimation"
    ],
    "gold_summary": "This paper introduce an interesting Infant pose dataset. The dataset has 108,902 RGB images of infants aged 6-18 months."
  },
  {
    "paper_id": "MDECkMARVE",
    "title": "DynamicBench: Evaluating Real-Time Report Generation in Large Language Models",
    "domain": "datasets and benchmarks",
    "content": "Traditional benchmarks for large language models (LLMs) typically rely on static evaluations through storytelling or opinion expression, which fail to capture the dynamic requirements of real-time information processing in contemporary applications. To address this limitation, we present DynamicBench, a benchmark designed to evaluate the proficiency of LLMs in storing and processing up-to-the-minute data. DynamicBench utilizes a dual-path retrieval pipeline, integrating web searches with local report databases. It necessitates domain-specific knowledge, ensuring accurate responses report generation within specialized fields. By evaluating models in scenarios that either provide or withhold external documents, DynamicBench effectively measures their capability to independently process recent information or leverage contextual enhancements. Additionally, we introduce an advanced report generation system adept at managing dynamic information synthesis. Our experimental results confirm the efficacy of our approach, with our method achieving state-of-the-art performance, surpassing GPT4o in document-free and document-assisted scenarios by 7.0% and 5.8%, respectively. The code and data will be made publicly available.",
    "key_points": [
      "large language models",
      "benchmark",
      "writing benchmark",
      "rag"
    ],
    "gold_summary": "This paper present DynamicBench to evaluate the ability of LLM to acquire, process and synthesize real-time information  for report generation. It integrated dual-path retrieval from web and local databases."
  },
  {
    "paper_id": "foOyv8KTj7",
    "title": "JIR-Arena: The First Comprehensive Benchmark Dataset for Just-in-time Information Recommendation",
    "domain": "datasets and benchmarks",
    "content": "Just-in-time Information Recommendation (JIR) is a service that delivers the most relevant information precisely when users need it the most. It plays a critical role in filling users' information gaps during pivotal moments like those in learning, work, and social interactions, thereby enhancing decision-making quality and life efficiency with minimal user effort. Recent device-efficient deployment of performant foundation models and the proliferation of intelligent wearable devices have made the realization of always-on JIR assistants feasible. However, despite the potential of JIR systems to transform our daily life, there has been little prior systematic effort to formally define JIR tasks, establish evaluation frameworks, or propose a large-scale multimodal benchmark with high-quality multi-party-sourced ground-truth labels. To bridge this gap, we present a comprehensive mathematical definition of JIR tasks and their associated evaluation metrics. Furthermore, we introduce JIR-Arena, the first multimodal JIR benchmark dataset with diverse and information-request-intensive scenarios, designed to evaluate JIR systems across multiple dimensions, including whether they can i) accurately infer user information needs, ii) provide timely and helpfully relevant recommendations, and iii) effectively avoid the inclusion of irrelevant content that might distract users. \n\nConstructing a JIR benchmark is challenging due to the subjectivity of user information needs and the difficulty of achieving reproducible evaluations. To overcome these, our benchmark approximates user need distribution by combining human and large AI model inputs, and enhances objectivity through a multi-turn validation framework. Additionally, we ensure assessment reproducibility by evaluating information recommendation outcomes against static knowledge bases. We also develop a baseline JIR system architecture, and instantiate it with several large foundation models. Our evaluation of the baselines on JIR-Arena reveals that while large foundation model-based JIR systems can simulate user needs with reasonable precision, they struggle with recall and effective content retrieval. Finally, to facilitate future development of JIR systems and exploration of more JIR application scenarios, we release our code and data in the supplementary materials.",
    "key_points": [
      "information access",
      "ai agent",
      "user simulation"
    ],
    "gold_summary": "This study presents the just-in-time information recommendation task and introduces a systematic benchmark for evaluation. Using this benchmark, this paper conducts error analysis and reveal potential opportunities for improvement."
  },
  {
    "paper_id": "oM69q4817x",
    "title": "Protein-SE(3): Unified Framework and Comprehensive Benchmark for SE(3)-based Protein Structure Design",
    "domain": "datasets and benchmarks",
    "content": "SE(3)-based generative models have shown great promise in protein geometry modeling and effective structure design. However, the field currently lacks a pipeline to support consistent re-training and fair comparison across different methods. In this paper, we propose Protein-SE(3), a unified framework accompanied by the comprehensive benchmark for SE(3)-based protein design. Protein-SE(3) integrates recent advanced methods, supports diverse evaluation metrics and also develops a mathematical decoupling toolkit. Specifically, state-of-the-art generative models for typical protein design tasks (unconditional generation and motif scaffolding), from multiple perspectives like DDPM (Genie1 and Genie2), Score Matching (FrameDiff and RfDiffusion) and Flow Matching (FoldFlow and FrameFlow) are systematically incorporated into our framework. All methods are re-trained on identical datasets and evaluated with consistent metrics, ensuring fair and reproducible comparison. Furthermore, our proposed decoupling toolkit abstracts the mathematical foundations of generative models, facilitating rapid prototyping of future algorithms without reliance on explicit protein structures. Taken together, Protein-SE(3) establishes a standardized foundation for the advancing research field of SE(3)-based protein design.",
    "key_points": [
      "protein structure design",
      "unified training framework",
      "mathematical decoupling",
      "comprehensive benchmark"
    ],
    "gold_summary": "The paper introduces a framework to benchmark protein generative models, including a training set that can be used to retrain the models for fair comparison"
  },
  {
    "paper_id": "biGW7e0Bvv",
    "title": "TheMCPCompany: Creating General-purpose Agents with Task-specific Tools",
    "domain": "datasets and benchmarks",
    "content": "Since the introduction of the Model Context Protocol (MCP), the number of available tools for Large Language Models (LLMs) has increased significantly. These task-specific tool sets offer an alternative to general-purpose tools such as web browsers, while being easier to develop and maintain than GUIs. However, current general-purpose agents predominantly rely on web browsers for interacting with the environment. Here, we introduce TheMCPCompany, a benchmark for evaluating tool-calling agents on tasks that involve interacting with various real-world services. We use the REST APIs of these services to create MCP servers, which include over 18,000 tools. We also provide manually annotated ground-truth tools for each task. In our experiments, we use the ground truth tools to show the potential of tool-calling agents for both improving performance and reducing costs, assuming perfect tool retrieval. Next, we explore agent performance using tool retrieval to study the real-world practicality of tool-based agents. While all models with tool retrieval perform similarly or better than browser-based agents, smaller models cannot take full advantage of the available tools through retrieval. On the other hand, GPT-5's performance with tool retrieval is very close to its performance with ground-truth tools. Overall, our work shows that the most advanced reasoning models are effective at discovering tools in simpler environments, but seriously struggle with navigating complex enterprise environments. TheMCPCompany reveals that navigating tens of thousands of tools and combining them in non-trivial ways to solve complex problems is still a challenging task for current models and requires both better reasoning and better retrieval models.",
    "key_points": [
      "agent",
      "tools",
      "tool-use",
      "mcp",
      "retrieval",
      "llm"
    ],
    "gold_summary": "This paper provide a new benchmark to evaluate the tool use and tool calling of LLM agent with MCP tools. This benchmark is notable for its scale, including over 18,000 MCP tools."
  },
  {
    "paper_id": "I9ED9VWZq6",
    "title": "SpeechJudge: Towards Human-Level Judgment for Speech Naturalness",
    "domain": "datasets and benchmarks",
    "content": "Aligning large generative models with human feedback is a critical challenge. In speech synthesis, this is particularly pronounced due to the lack of a large-scale human preference dataset, which hinders the development of models that truly align with human perception. To address this, we introduce ***SpeechJudge***, a comprehensive suite comprising a dataset, a benchmark, and a reward model centered on naturalness—one of the most fundamental subjective metrics for speech synthesis. First, we present ***SpeechJudge-Data***, a large-scale human feedback corpus of 99k speech pairs. The dataset is constructed using a diverse set of advanced zero-shot text-to-speech (TTS) models across diverse speech styles and multiple languages, with human annotations for both intelligibility and naturalness preference. From this, we establish ***SpeechJudge-Eval***, a challenging benchmark for speech naturalness judgment. Our evaluation reveals that existing metrics and AudioLLMs struggle with this task; the best-performing model, Gemini-2.5-Flash, achieves less than 70% agreement with human judgment, highlighting a significant gap for improvement. To bridge this gap, we develop ***SpeechJudge-GRM***, a generative reward model (GRM) based on Qwen2.5-Omni-7B. It is trained on SpeechJudge-Data via a two-stage post-training process: Supervised Fine-Tuning (SFT) with Chain-of-Thought rationales followed by Reinforcement Learning (RL) with GRPO on challenging cases. On the SpeechJudge-Eval benchmark, the proposed SpeechJudge-GRM demonstrates superior performance, achieving 77.2% accuracy (and 79.4% after inference-time scaling @10) compared to a classic Bradley-Terry reward model (72.7%). Furthermore, SpeechJudge-GRM can be also employed as a reward function during the post-training of speech generation models to facilitate their alignment with human preferences.",
    "key_points": [
      "speech naturalness",
      "human dataset",
      "rlhf",
      "generative reward model",
      "audiollm"
    ],
    "gold_summary": "This paper introduces a corpus containing paired TTS samples with human preferences, a benchmark built upon this corpus for evaluating speech naturalness, and a reward model trained on it."
  },
  {
    "paper_id": "8CZshTogXk",
    "title": "ArabiDoc: A Holistic Arabic-English Evaluation Suite for End-to-End Document Processing",
    "domain": "datasets and benchmarks",
    "content": "Document intelligence sits at the intersection of computer vision and natural language processing, where the goal is to transform complex real-world documents into structured, machine-readable representations. While progress has been made, current benchmarks for low-resource languages such as Arabic remain limited, typically emphasizing individual components, like text, tables, or charts, without providing a comprehensive evaluation of full-document parsing. To address this gap, we present a new bilingual (Arabic-English) benchmark that brings together diverse document elements within a single evaluation framework for end-to-end document parsing. Our benchmark offers three main contributions. First, it preserves reading order information, which allows models to better capture the natural flow of documents. Second, it supports visual content parsing, encompassing not only text blocks but also tables, charts, and figures, thereby reflecting the full range of document structures. Third, it introduces relaxed evaluation metrics that more fairly assess model performance by tolerating minor deviations in reading order or localized errors in table and chart parsing, ensuring the evaluation reflects practical usability rather than strict exactness. Constructed through a two-step annotation process, layout segmentation followed by object-level labeling, our dataset includes 137 pages that have been carefully segmented and verified by human annotators. By unifying previously separate evaluation tracks, this benchmark establishes the first comprehensive standard for structured document parsing in Arabic and provides a more realistic basis for bilingual evaluation with English. We expect this resource to foster progress in multimodal reasoning, enable stronger baselines, and support the development of vision-language models that generalize robustly across languages and document types.",
    "key_points": [
      "end-to-end document parsing",
      "bilingual benchmark"
    ],
    "gold_summary": "This paper proposes an arabic-english document parsing evaluation benchmark."
  },
  {
    "paper_id": "ULQt51DRug",
    "title": "TRQA: Time Series Reasoning Question And Answering Benchmark",
    "domain": "datasets and benchmarks",
    "content": "Time series data underpin critical applications across domains such as finance, healthcare, transportation, and environmental science.\nWhile recent work has begun to explore multi-task time series question answering (QA), current benchmarks remain limited in scope, with an emphasis largely on forecasting and anomaly detection tasks.\nWe introduce \\trqa, a novel time series QA benchmark that substantially broadens task coverage and provides a unified setting for evaluating diverse temporal reasoning abilities..\n\\trqa unifies six diverse tasks under a single framework, organized into two complementary groups: \n(1) \\emph{conventional reasoning tasks}, including anomaly detection and classification, \nand (2) \\emph{advanced reasoning tasks}, such as characterization, comparison, data transformation, and temporal relationship reasoning.\nThese tasks span multiple question types, such as \\emph{true-or-false (TF)}, \\emph{multiple-choice (MC)}, and a novel \\emph{puzzling (PZ}), enabling a more comprehensive evaluation of diverse aspects of time series reasoning.\nWe curated a large-scale dataset with 210k samples, covering a diverse 13 domains.\nEach sample consists of one or more time series, an accompanying question, contextual information about the time series, and a corresponding answer.\nZero-shot evaluation demonstrates that these tasks are challenging for both commercial and open-source Large Language Models (LLMs). For example, the best-performing commercial LLM, Gemini-2.5-Flash, achieves an average score of only 65.08.\nWhile open-source LLMs show notable performance gains after instruction tuning, there remains considerale room for improvement. For instance, the best-performing open-source model, LLaMA-3.1-8B, reaches an average score of 85.26, suggesting that these tasks are still non-trivial and pose ongoing challenges for current models.",
    "key_points": [
      "time series",
      "question answering"
    ],
    "gold_summary": "A Q&A benchmark curated from existing domain specific time series."
  },
  {
    "paper_id": "dXOh7bX6KU",
    "title": "A Large-scale Dataset for Robust Complex Anime Scene Text Detection",
    "domain": "datasets and benchmarks",
    "content": "Current text detection datasets primarily target natural or document scenes, where text typically appear in regular font and shapes, monotonous colors, and orderly layouts. The text usually arranged along straight or curved lines. However, these characteristics differ significantly from anime scenes, where text is often diverse in style, irregularly arranged, and easily confused with complex visual elements such as symbols and decorative patterns. Text in anime scene also includes a large number of handwritten and stylized fonts. Motivated by this gap, we introduce \\textit{AnimeText}, a large-scale dataset containing 735K images and 4.2M annotated text blocks. It features hierarchical annotations and hard negative samples tailored for anime scenarios. To evaluate the robustness of \\textit{AnimeText} in complex anime scenes, we conducted cross-dataset benchmarking using state-of-the-art text detection methods. Experimental results demonstrate that models trained on \\textit{AnimeText} outperform those trained on existing datasets in anime scene text detection tasks.",
    "key_points": [
      "text detection",
      "dataset",
      "anime"
    ],
    "gold_summary": "This paper introduces the AnimeText dataset, the first large-scale dataset (735K images, 4.2M text blocks) for anime scene text detection, addressing the lack of benchmarks in stylized 2D visual contexts."
  },
  {
    "paper_id": "CkrqfhD4fV",
    "title": "RelEval: A Structured Benchmark for Logical and Relational Reasoning in LLMs",
    "domain": "datasets and benchmarks",
    "content": "We introduce RelEval, a benchmark for evaluating large language models (LLMs) in logical reasoning over complex relational structures. Such reasoning underpins applications where LLMs generate or query structured graphs, including network infrastructure, knowledge bases, and business process schemas. Our framework enables fine-grained control of task difficulty by varying the number of objects,\nrelations, and the depth of relational chains. RelEval encompasses three complementary tasks: (1) Plan Generation, requiring construction of valid directed relational graphs under structural constraints; (2) Consistency Detection, detecting inconsistencies in relational structures; and (3) Comparison Question, assessing the validity of queried relationships. We also test models’ self-correction by prompting them to verify and refine their answers. We evaluate DeepSeek R1, Gemini 2.0 Pro, Gemini 2 Flash Thinking, GPT-4.5, GPT-4o, Llama 3.1 405B, O3-mini, O1, and Claude 3.7 Sonnet, finding large performance gaps linked to model scale and architecture. While recent reasoning-focused models excel on simpler cases, they struggle with more complex configurations requiring deeper reasoning.",
    "key_points": [
      "reasoning",
      "logical reasoning",
      "large language models",
      "evaluation",
      "benchmark"
    ],
    "gold_summary": "The paper proposes a mechanically generated benchmark for Large Language Models, and evaluates several state-of-the-art LLMs against it."
  },
  {
    "paper_id": "BIHsM6SZ3f",
    "title": "Will AI Tell Lies to Save Sick Children? Litmus-Testing AI Values Prioritization with AIRiskDilemmas",
    "domain": "datasets and benchmarks",
    "content": "Detecting AI risks becomes more challenging as stronger models emerge and find novel methods such as Alignment Faking to circumvent these detection attempts. Inspired by how risky behaviors in humans (i.e., illegal activities that may hurt others) are sometimes guided by strongly-held values, we believe that identifying values within AI models can be an early warning system for AI's risky behaviors. We create LitmusValues, an evaluation pipeline to reveal AI models' priorities on a range of AI value classes. Then, we collect AIRiskDilemmas, a diverse collection of dilemmas that pit values against one another in scenarios relevant to AI safety risks such as Power Seeking. By measuring an AI model's value prioritization using its aggregate choices, we obtain a self-consistent set of predicted value priorities that uncover potential risks. We show that values in LitmusValues (including seemingly innocuous ones like Care) can predict for both seen risky behaviors in AIRiskDilemmas and unseen risky behaviors in HarmBench.",
    "key_points": [
      "ai values",
      "value alignment",
      "ai risk",
      "dilemma"
    ],
    "gold_summary": "They gathered a set of value classes and then constructed a dataset (AIRiskDilemmas) to evaluate models on competing value based scenarios. The scenarios are generated by Claude 3.5 Sonnet and seeded from advanced-ai-risk."
  },
  {
    "paper_id": "UK0j7E1f4i",
    "title": "PhyX: Does Your Model Have the \"Wits\" for Physical Reasoning?",
    "domain": "datasets and benchmarks",
    "content": "Existing benchmarks fail to capture a crucial aspect of intelligence: physical reasoning, the integrated ability to combine domain knowledge, symbolic reasoning, and understanding of real-world constraints. To address this gap, we introduce PhyX: the first large-scale benchmark designed to assess models' capacity for physics-grounded reasoning in visual scenarios. PhyX includes 3K meticulously curated multimodal questions spanning 6 reasoning types across 25 sub-domains and 6 core physics domains: thermodynamics, electromagnetism, mechanics, modern physics, optics, and wave & acoustics. In our comprehensive evaluation, even state-of-the-art models struggle significantly with physical reasoning. GPT-o4-mini, Gemini-2.5-Pro, and GPT-5 achieve only 45.8%, 62.4%, and 65.2% accuracy respectively—performance gaps exceeding 10% compared to human experts. Our analysis exposes critical limitations in current models: over-reliance on memorized disciplinary knowledge, excessive dependence on mathematical formulations, and surface-level visual pattern matching rather than genuine physical understanding. We provide in-depth analysis through fine-grained statistics, detailed case studies, and multiple evaluation paradigms to thoroughly examine physical reasoning capabilities. To ensure reproducibility, we implement a compatible evaluation protocol based on widely-used toolkits such as VLMEvalKit and lmms-eval, enabling one-click evaluation.",
    "key_points": [
      "lmm evaluation",
      "physical benchmark",
      "reasoning benchmark"
    ],
    "gold_summary": "This work introduces a new benchmark PhyX for physical reasoning with visual components of 3k problems and the results reveal that the physical understanding ability of existing models is still lacking."
  },
  {
    "paper_id": "82dbfUN3uf",
    "title": "Do LLMs Really Understand Code? A Semantic Benchmark with Automated Question Generation and Evaluation",
    "domain": "datasets and benchmarks",
    "content": "Large language models (LLMs) have demonstrated impressive results in code generation tasks, yet it is unclear to what extent they genuinely understand code semantics and whether this affects their ability to write high-quality code. To address this question, we introduce \\textbf{SemBench}, a novel benchmark consisting of \\textbf{1,000} diverse C programs sourced from the CodeParrot GitHub-code dataset, with \\textbf{15,404} semantic questions spanning six fundamental properties: function reachability, loop reachability, data dependency, liveness of variables, dominator sets, and dead code. These six types of concepts are taught in undergraduate-level programming language classes and can be computed precisely and efficiently by deterministic algorithms. In contrast to existing benchmarks (e.g. HumanEval, MBPP, CodeXGLUE, SWE-bench) that emphasize code generation or functional correctness, our benchmark focuses on semantic understanding with deterministic answers.  We evaluate \\textbf{14} popular LLMs across \\textbf{7} families—including GPT-4o Mini, GPT-3.5 Turbo, DeepSeek-Coder, CodeLlama, Qwen, StarCoder, Mistral, and Phi. To our surprise, they have very high failure rates, ranging from \\textbf{21.40\\%} to \\textbf{81.86\\%}. Category analysis reveals a sharp split between “shallow” control-flow and “deep” data-flow reasoning and highlights performance divergence across task types, where different models excel on different categories. SemBench rankings demonstrate high correlation with HumanEval and MBPP, %(Spearman’s correlation \\(\\rho{=}\\)0.61/0.72),  which proves its potential to be a good indicator of whether an LLM can produce high-quality code. In fact, further study shows that the LLMs under evaluation have difficulty even understanding their \\textit{own coding output}.  For example, DeepSeek-Coder-V2-Lite-Instruct fails to identify variable liveness correctly 58.23\\% time. Overall, our experiments provide deeper insights into semantic understanding, reveal the substantial gap between semantics and code completion in modern LLMs, and open new opportunities for further improvements of coding LLMs.",
    "key_points": [
      "code semantics evaluation",
      "large language models (llms)",
      "benchmark design",
      "automated question generation"
    ],
    "gold_summary": "This paper mainly presents a new benchmark SemBench, consisting 1000 diverse C programs with 15404 semantic questions spanning six fundamental properties. Besides, this paper evalaute 14 poplular LLMs across 7 families."
  },
  {
    "paper_id": "LGmO9VvuP5",
    "title": "$\\tau^2$-bench: : Evaluating Conversational Agents in a Dual-Control Environment",
    "domain": "datasets and benchmarks",
    "content": "Existing benchmarks for conversational AI agents simulate **single-control environments**, where only the AI agent can use tools to interact with the world, while the user remains a passive information provider. This differs from real-world scenarios like technical support, where users need to actively participate in modifying the state of the (shared) world. In order to address this gap, we introduce $\\tau^2$-bench, with four key contributions: \n\n1. A novel **Telecom dual-control domain** modeled as a Dec-POMDP, where both agent and user make use of tools to act in a shared, dynamic environment that tests both agent coordination and communication,\n\n2. A **compositional task generator** that programmatically creates diverse, verifiable tasks from atomic components, ensuring domain coverage and controlled complexity,\n\n3. A **reliable user simulator** tightly coupled with the environment, whose behavior is constrained by tools and observable states, improving simulation fidelity,\n\n4. **Fine-grained analysis of agent performance** through multiple ablations including separating errors arising from reasoning vs communication/coordination.\n\nIn particular, our experiments show significant performance drops when agents shift from no-user to dual-control, highlighting the challenges of guiding users. Overall, $\\tau^2$-bench provides a controlled testbed for agents that must both reason effectively and guide user actions.",
    "key_points": [
      "benchmark",
      "evaluation",
      "dual control",
      "conversational ai agents",
      "user simulation"
    ],
    "gold_summary": "This is an extension of Tao-Bench with an additional new domain of customer support. For that additional domain, they use sophisticated DEC-POMDP approach for establishing agent and user simulator dialogues."
  },
  {
    "paper_id": "chLlLbI7de",
    "title": "Beyond the Final Answer: Evaluating the Reasoning Trajectories of Tool-Augmented Agents",
    "domain": "datasets and benchmarks",
    "content": "Driven by recent advancements in tool-augmented Large Language Model (LLM) agents, comprehensive benchmark datasets for evaluating these tool-augmented agents are being actively developed. Although these benchmarks incorporate increasingly complex user requests and a diverse array of tools, the evaluation methods for most of them remain limited to answer matching. However, as the number of steps required to resolve a user request increases, a proper evaluation of an agent's performance must go beyond the final answer to also assess the problem-solving trajectory, including previously ignored aspects such as efficiency, hallucinations, and adaptivity. The most straightforward method for evaluating these aspects is to compare the trajectory of the agent with a ground-truth trajectory, but this approach is fundamentally limited since annotating all possible ground-truth trajectories is prohibitively expensive. To address these significant gaps, we introduce TRACE, a framework for the multi-dimensional evaluation of tool-augmented LLM agent performance. By incorporating evidence store, TRACE enables a multi-faceted analysis and evaluation of an agent's reasoning trajectory, eliminating the need for a predefined ground-truth trajectory. To validate our framework, we develop a new meta-evaluation dataset by augmenting existing benchmarks with diverse and flawed trajectories, each labeled with multi-faceted performance scores. Our results confirm that TRACE accurately evaluates these complex behaviors in a scalable and cost-effective manner, even with small open-source LLMs.",
    "key_points": [
      "tool-augmented agent",
      "llm agent",
      "evaluation",
      "benchmark"
    ],
    "gold_summary": "The paper proposes the TRACE framework, which utilizes an \"evidence bank\" to enable LLM evaluators to assess an agent's reasoning trajectory across three dimensions—efficiency, hallucination, and adaptivity—without relying on a single ground-truth trajectory."
  },
  {
    "paper_id": "txULULgU8F",
    "title": "TelecomTS: Observability Dataset for Multi-Modal Time-Series and Language Analysis",
    "domain": "datasets and benchmarks",
    "content": "Modern enterprises generate vast streams of time series metrics when monitoring complex systems, known as observability data. Unlike conventional time series from domains such as weather, observability data are zero-inflated, highly stochastic, and exhibit minimal temporal structure.  Despite their importance, observability datasets are underrepresented in public benchmarks due to proprietary restrictions. Existing datasets are often anonymized and normalized, removing scale information and limiting their use for tasks beyond forecasting, such as anomaly detection, root-cause analysis, and multi-modal reasoning. To address this gap, we introduce TelecomTS, a large-scale observability dataset derived from a 5G telecommunications network. TelecomTS features heterogeneous, de-anonymized covariates with explicit scale information and supports a suite of downstream tasks, including anomaly detection, root-cause analysis, and a question-answering benchmark requiring multi-modal reasoning.  Benchmarking state-of-the-art time series, language, and reasoning models reveals that existing approaches struggle with the abrupt, noisy, and high-variance dynamics of observability data. Our experiments also underscore the importance of preserving covariates’ absolute scale, emphasizing the need for foundation time series models that natively leverage scale information for practical observability applications.",
    "key_points": [
      "large language models",
      "time-series",
      "multi-modal analysis",
      "observability data"
    ],
    "gold_summary": "A real-world observability dataset in time series domain, de-anonymized and without normalization."
  },
  {
    "paper_id": "qIsGS463qk",
    "title": "LiveMCP-101: Stress Testing and Diagnosing MCP-enabled Agents on Challenging Queries",
    "domain": "datasets and benchmarks",
    "content": "Tool calling has emerged as a critical capability for AI agents to interact with the real world and solve complex tasks. While the Model Context Protocol (MCP) provides a powerful standardized framework for tool integration, there is a significant gap in benchmarking how well agents can solve multi-step tasks using diverse MCP tools in realistic, dynamic scenarios. In this work, we present LiveMCP-101, a benchmark of 101 carefully curated real-world queries, refined through iterative LLM rewriting and manual revision, that require coordinated use of multiple MCP tools. To address temporal variability in real-world tool responses, we introduce a parallel evaluation framework where a reference agent executes a validated plan simultaneously with the evaluated agent to produce real-time reference outputs, rather than relying on static ground-truth answers. Experiments show that even frontier LLMs achieve a task success rate below 60\\%, highlighting major challenges in multi-step tool use. Comprehensive error analysis identifies seven failure modes spanning tool planning, parameterization, and output handling, pointing to concrete directions for improving current models. LiveMCP-101 sets a rigorous standard for evaluating real-world agent capabilities, advancing toward autonomous agent systems that reliably execute complex tasks through MCP tool orchestration.",
    "key_points": [
      "agent",
      "tool calling",
      "evaluation"
    ],
    "gold_summary": "This paper proposes LiveMCP-101, a benchmark of 101 multi-step real-world tasks requiring coordinated use of multiple tools via the Model Context Protocol (MCP). A parallel reference-agent evaluation is also introduced to handle dynamic tool outputs."
  },
  {
    "paper_id": "pKqt8psClA",
    "title": "HAI-Eval: Measuring Human-AI Synergy in Collaborative Coding",
    "domain": "datasets and benchmarks",
    "content": "LLM-powered coding agents are reshaping the development paradigm. However, existing evaluation systems, neither traditional tests for humans nor benchmarks for LLMs, fail to capture this shift. They remain focused on well-defined algorithmic problems, which excludes problems where success depends on human-AI collaboration. Such collaborative problems not only require human reasoning to interpret complex contexts and guide solution strategies, but also demand AI efficiency for implementation. To bridge this gap, we introduce HAI-Eval, a unified benchmark designed to measure the synergy of human-AI partnership in coding. HAI-Eval's core innovation is its \"Collaboration-Necessary\" problem templates, which are intractable for both standalone LLMs and unaided humans, but solvable through effective collaboration. Specifically, HAI-Eval uses 45 templates to dynamically create tasks. It also provides a standardized IDE for human participants and a reproducible toolkit with 450 task instances for LLMs, ensuring an ecologically valid evaluation. We conduct a within-subject study with 45 participants and benchmark their performance against 5 state-of-the-art LLMs under 4 different levels of human intervention. Results show that while standalone LLMs and unaided participants achieve poor pass rates (0.67% and 18.89%), human–AI collaboration significantly improves performance to 31.11%. Our analysis reveals an emerging co-reasoning partnership. This finding challenges the traditional human-tool hierarchy by showing that strategic breakthroughs can originate from either humans or AI. HAI-Eval establishes not only a challenging benchmark for next-generation coding agents but also a grounded, scalable framework for assessing core developer competencies in the AI era. Our benchmark and interactive demo are openly accessible.",
    "key_points": [
      "coding benchmark",
      "developer evaluation",
      "human-ai collaboration",
      "coding agent"
    ],
    "gold_summary": "The paper creates a method to create tasks for human-AI collaboration, an interface, and conducts a user study evaluating the performance of collaboration."
  },
  {
    "paper_id": "UyiTjp0oKU",
    "title": "Gaze Following in Question Answering: A Comprehensive Benchmark for Vision-Language Models",
    "domain": "datasets and benchmarks",
    "content": "Gaze following aims to infer human intention within scene images. Conventional methods typically rely on scene and face images to regress the gaze point coordinates which is unnatural and restrictive. Recently, vision-language models (VLMs) have attracted significant attention for their powerful reasoning abilities, raising an important question: can VLMs be leveraged to advance the gaze following? In this work, we introduce GazeVQA, the first large-scale text-image dataset for VLM-based gaze following. GazeVQA is the first to provide accurate textual annotations for both observers and gaze targets, along with natural language question-answering (QA) pairs tailored for the gaze following task. The dataset contains 410K QA pairs across 102K scene images, offering rich supervision for training and evaluating VLMs. Building on GazeVQA, we establish the first benchmark for VLM-based gaze following. Experiments demonstrate that existing VLMS exhibit limited zero-shot performance on gaze following. However, with training on our dataset, their performance improves significantly, demonstrating the potential of GazeVQA to drive progress in this area. We will release the dataset and code to facilitate future research.",
    "key_points": [
      "gaze following",
      "vision-language model"
    ],
    "gold_summary": "This work introduces GazeVQA, the first large-scale benchmark designed to explore the potential of Visual Language Models (VLM) in gaze tracking tasks. This dataset reframes the gaze-following task as a Visual Question Answering (VQA) problem."
  },
  {
    "paper_id": "6YktIxJTJr",
    "title": "SYNAPSE: Simulation Benchmark of Neuro-Adaptive Patient-Specific Evaluation for Episodic Decision-Making",
    "domain": "datasets and benchmarks",
    "content": "Recent advances in time-series analysis, treatment outcome prediction, and reinforcement learning (RL) have demonstrated great potential to automate decision-making in healthcare. However, the high stakes nature complicates the deployment of such frameworks in practice, clinically, or in the long term. A major challenge is the absence of realistic benchmark environments that capture the sequential, patient-specific nature of various therapies, which could enable extensive offline testing, evaluation, and model selection prior to clinical adoption. To address this, we introduce the SImulation Benchmark of Neuro-Adaptive Patient-Specific Evaluation (SYNAPSE), in the context of adaptive deep brain stimulation (DBS), a treatment for managing the motor symptoms of Parkinson’s disease (PD). Specifically, SYNAPSE is constructed using real-world data collected from both clinical and at-home studies involving participants undergoing DBS therapy. It enables offline training and evaluation of different treatment strategies, reflecting both short- and long-term effects, as well as treatment outcome prediction capturing participants’ responses to a range of temporal dynamics. Additionally, it allows for the assessment of safety-critical constraints inherent to neurostimulation decision-making. By rigorously validating its realism against clinical data and supporting both short- and long-term decision-making, SYNAPSE offers clear guidance for future DBS policy development, as well as helps identify and address key challenges in advancing truly personalized neurostimulation therapies.",
    "key_points": [
      "simulator and benchmark",
      "deep brain stimulation for parkinson’s disease treatment",
      "healthcare reinforcement learning"
    ],
    "gold_summary": "The paper presents an environment (SYNAPSE) for accelerating RL research and benchmarking adaptive deep brain stimulation policies for Parkinson's disease."
  },
  {
    "paper_id": "uIJyYkOgAy",
    "title": "Can Large Language Models Match the Conclusions of Systematic Reviews?",
    "domain": "datasets and benchmarks",
    "content": "Systematic reviews (SR), in which experts summarize and analyze evidence across\nindividual studies to provide insights on a specialized topic, are a cornerstone\nfor evidence-based clinical decision-making, research, and policy. Given the exponential growth of scientific articles, there is growing interest in using large\nlanguage models (LLMs) to automate SR generation. However, the ability of\nLLMs to critically assess evidence and reason across multiple documents to provide recommendations at the same proficiency as domain experts remains poorly\ncharacterized. We therefore ask: Can LLMs match the conclusions of systematic\nreviews written by clinical experts when given access to the same studies?\nTo explore this question, we present MedEvidence, a benchmark pairing findings\nfrom 100 SRs with the studies they are based on. We benchmark 24 LLMs on\nMedEvidence, including reasoning, non-reasoning, medical specialist, and models\nacross varying sizes (from 7B-700B). Through our systematic evaluation, we find\nthat reasoning does not necessarily improve performance, larger models do not\nconsistently yield greater gains, and knowledge-based fine-tuning degrades accuracy on MedEvidence. Instead, most models exhibit similar behavior: performance\ntends to degrade as token length increases, their responses show overconfidence,\nand, contrary to human experts, all models show a lack of scientific skepticism\ntoward low-quality findings. These results suggest that more work is still required\nbefore LLMs can reliably match the observations from expert-conducted SRs, even\nthough these systems are already deployed and being used by clinicians. We release our codebase\nand benchmark\nto the broader research community to further\ninvestigate LLM-based SR systems.",
    "key_points": [
      "benchmarks",
      "multi-document reasoning",
      "medical ai"
    ],
    "gold_summary": "This work presents two contributions: (1) a dataset of systematic reviews from Cochrane, and (2) an assessment of LLM ability to generate a conclusion over the SR evidence strength."
  },
  {
    "paper_id": "tJU1wP6bW7",
    "title": "Evolvable Safety Benchmarking: Multi-agent Pipeline for LVLMs",
    "domain": "datasets and benchmarks",
    "content": "Large vision-language models (LVLMs) exhibit remarkable capabilities in vision and language tasks but face significant safety challenges, which undermine their reliability in real-world applications. Efforts have been made to build LVLM safety evaluation benchmarks to uncover their vulnerability. However, existing benchmarks are hindered by their labor-intensive construction process and static complexity that fail to keep pace with rapidly evolving model architectures and emerging risks. To address these limitations, we propose VLSafetyBencher, the first multi-agent system designed to automated LVLM safety benchmarking, which introduces four collaborative agents: preprocessing, cross-modal processing, augmentation, and post-sampling agents. With the optimized sampling algorithm at the sample level, VLSafetyBencher can be conveniently applied to benchmark construction, update, and sample evaluation. We conduct experiments on benchmark construction and updating tasks with VLSafetyBencher and evaluate the extensive LVLMs. Our results demonstrate that the automatically generated dataset effectively distinguishes model safety, with a safety rate disparity of nearly 70% between the most and least safe models. Ablation analyses further validate VLSafetyBencher's effectiveness.",
    "key_points": [
      "lvlm evaluation",
      "safety",
      "agent"
    ],
    "gold_summary": "This paper utilizes multi-agent pipeline to synthesize harmful image-question pair and introduces the optimization-based sampling method to select high-value test data. Various experiments confirm the effectiveness of proposed method."
  },
  {
    "paper_id": "LfdFnakqGJ",
    "title": "A2ASecBench: A Protocol-Aware Security Benchmark for Agent-to-Agent Multi-Agent Systems",
    "domain": "datasets and benchmarks",
    "content": "Multi-agent systems (MAS) built on large language models (LLMs) increasingly rely on agent-to-agent (A2A) protocols to enable capability discovery, task orchestration, and artifact exchange across heterogeneous stacks. While these protocols promise interoperability, they also introduce new vulnerabilities. In this paper, we present the first comprehensive security evaluation of A2A-MAS. We develop a taxonomy and threat model that categorize risks into supply-chain manipulations and protocol-logic weaknesses, and we detail six concrete attacks spanning all A2A stages and components with impacts on confidentiality, integrity, and availability. Building on this taxonomy, we introduce A2ASecBench, the first A2A-specific security benchmark framework capable of probing diverse and previously unexplored attack vectors. Our framework incorporates a dynamic adapter layer for deployment across heterogeneous agent stacks and downstream workloads, alongside a joint safety–utility evaluation methodology that explicitly measures the trade-off between harmlessness and helpfulness by pairing adversarial trials with benign tasks. We empirically validate our framework using official A2A Project demos across three representative high-stakes domains (travel, healthcare, and finance), demonstrating that the identified attacks are both pervasive and highly effective, consistently bypassing default safeguards. These findings highlight the urgent need for protocol-level defenses and standardized benchmarking to secure the next generation of agentic ecosystems.",
    "key_points": [
      "agent-to-agent protocol",
      "multi-agent systems",
      "security benchmark"
    ],
    "gold_summary": "This paper presents a benchmark framework for studying the multi-agent security of the Agent-to-Agent protocol, named A2ASecBENCH. Using A2ASecBENCH, this paper identifies six types of security threats present in the A2A protocol."
  },
  {
    "paper_id": "ZTAvANYFL5",
    "title": "NurValues: Real-World Nursing Values Evaluation for Large Language Models in Clinical Context",
    "domain": "datasets and benchmarks",
    "content": "While LLMs have demonstrated medical knowledge and conversational ability, their deployment in clinical practice raises new risks: patients may place greater trust in LLM-generated responses than in nurses' professional judgments, potentially intensifying nurse–patient conflicts. Such risks highlight the urgent need of evaluating whether LLMs align with the core nursing values upheld by human nurses. This work introduces the first benchmark for nursing value alignment, consisting of five core value dimensions distilled from international nursing codes: _Altruism_, _Human Dignity_, _Integrity_, _Justice_, and _Professionalism_. We define two-level tasks on the benchmark, considering the two characteristics of emerging nurse–patient conflicts. The **Easy-Level** dataset consists of 2,200 value-aligned and value-violating instances, which are collected through a five-month longitudinal field study across three hospitals of varying tiers; The **Hard-Level** dataset is comprised of 2,200 dialogue-based instances that embed contextual cues and subtle misleading signals, which increase adversarial complexity and better reflect the subjectivity and bias of narrators in the context of emerging nurse-patient conflicts. We evaluate a total of 23 SoTA LLMs on their ability to align with nursing values, and find that general LLMs outperform medical ones, and _Justice_ is the hardest value dimension. As the first real-world benchmark for healthcare value alignment, NurValues provides novel insights into how LLMs navigate ethical challenges in clinician–patient interactions.",
    "key_points": [
      "large language models",
      "value alignment",
      "nursing values"
    ],
    "gold_summary": "The paper explores the ability of LLMs to track nursing values from a situational summary. Authors conduct numerous evaluations on their chosen \"values\""
  },
  {
    "paper_id": "f5lIozG83H",
    "title": "AccidentBench: Benchmarking Multimodal Understanding and Reasoning in Vehicle Accidents and Beyond",
    "domain": "datasets and benchmarks",
    "content": "Rapid advances in multimodal models demand benchmarks that rigorously evaluate understanding and reasoning in safety-critical, dynamic real-world settings. We present AccidentBench, a large-scale benchmark that combines vehicle accident scenarios with Beyond domains, safety-critical settings in air and water that emphasize spatial and temporal reasoning (e.g., navigation, orientation, multi-vehicle motion). The benchmark contains approximately 2000 videos and over 19000 human-annotated question--answer pairs spanning multiple video lengths (short/medium/long) and difficulty levels (easy/medium/hard). Tasks systematically probe core capabilities: temporal, spatial, and intent understanding and reasoning.  By unifying accident-centric traffic scenes with broader safety-critical scenarios in air and water, AccidentBench offers a comprehensive, physically grounded testbed for evaluating models under real-world variability. Evaluations of state-of-the-art models (e.g., Gemini-2.5 Pro and GPT-5) show that even the strongest models achieve only about 18% accuracy on the hardest tasks and longest videos, revealing substantial gaps in real-world temporal, spatial, and intent reasoning. AccidentBench is designed to expose these critical gaps and drive the development of multimodal models that are safer, more robust, and better aligned with real-world safety-critical challenges. The code and dataset are available at: http://accident-bench.site",
    "key_points": [
      "multimodal understanding and reasoning",
      "large-scale dataset",
      "traffic accident",
      "land space",
      "airplane navigation",
      "ship motion"
    ],
    "gold_summary": "This paper introduces AccidentBench, a large-scale video benchmark designed to rigorously evaluate multimodal models’ understanding and reasoning capabilities in safety-critical, dynamic real-world environments."
  },
  {
    "paper_id": "FFxkFMU89E",
    "title": "EgoDex: Learning Dexterous Manipulation from Large-Scale Egocentric Video",
    "domain": "datasets and benchmarks",
    "content": "Imitation learning for manipulation has a well-known data scarcity problem. Unlike natural language and 2D computer vision, there is no Internet-scale corpus of data for dexterous manipulation. One appealing option is egocentric human video, a passively scalable data source. However, existing large-scale datasets such as Ego4D do not have native hand pose annotations and do not focus on object manipulation. To this end, we use Apple Vision Pro to collect EgoDex: the largest and most diverse dataset of dexterous human manipulation to date. EgoDex has 829 hours of egocentric video with paired 3D hand and finger tracking data collected at the time of recording, where multiple calibrated cameras and on-device SLAM can be used to precisely track the pose of every joint of each hand. The dataset covers a wide range of diverse manipulation behaviors with everyday household objects in 194 different tabletop tasks ranging from tying shoelaces to folding laundry. Furthermore, we train and systematically evaluate imitation learning policies for hand trajectory prediction on the dataset, introducing metrics and benchmarks for measuring progress in this increasingly important area. By releasing this large-scale dataset, we hope to push the frontier of robotics, computer vision, and foundation models. EgoDex is publicly available for download.",
    "key_points": [
      "egocentric video",
      "manipulation",
      "embodied ai",
      "robotics"
    ],
    "gold_summary": "This paper introduces a large-scale egocentric manipulation video dataset. It includes comprehensive annotations and is more suitable for robotics task. The data is used to train and evaluate imitation learning policies."
  },
  {
    "paper_id": "7cHHibwDXH",
    "title": "CRSA: A Chinese Single-Domain Task-Oriented Dialogue Dataset with Contextual Rich Semantic Annotations",
    "domain": "datasets and benchmarks",
    "content": "Task-oriented dialogue (TOD) systems support users in achieving domain-specific goals via natural language interactions and critically depend on high-quality datasets. However, existing datasets often lack authenticity, fine-grained semantic annotations, and explicit process control, limiting effectiveness in complex business scenarios. To address these, we introduce CRSA, a Chinese TOD dataset that integrates diverse sources to construct semantically rich, structurally realistic dialogues, and adopts a multi-level annotation framework to model dialogue acts, user intents, and task flows more effectively. To evaluate the quality and application potential of CRSA, we conduct three sets of experiments spanning data quality, system training effectiveness, and task adaptability. Results demonstrate that CRSA provides strong support for process modeling, strategy learning, and response generation, establishing it as a robust and versatile resource for TOD research. The dataset is publicly available at https://anonymous.4open.science/r/CRSA-CBBB.",
    "key_points": [
      "task-oriented dialogue",
      "multi-turn dialogue dataset",
      "benchmark",
      "semantic annotation",
      "llm training resource",
      "dialogue system training",
      "tod subtask evaluation"
    ],
    "gold_summary": "This paper proposed a Chinese single-domain task-oriented dialogue dataset, focusing on flight booking. The dataset is composed of three different sources, including real dialogues, crowd-sourced dialogues, and LLM-assisted generated dialogues."
  },
  {
    "paper_id": "Nw7vkJKHba",
    "title": "Indoor 3.6M : A Dataset and Benchmark for Indoor Image Geolocation",
    "domain": "datasets and benchmarks",
    "content": "Image geolocation has advanced rapidly for outdoor imagery, driven by large-scale benchmarks and strong visual cues such as landmarks, skylines, and vegetation. In contrast, indoor image geolocation remains underexplored: indoor scenes lack distinctive geographic features, are highly ambiguous, and are not adequately represented in existing datasets. We address this gap by introducing the first large-scale benchmark for indoor geolocation, consisting of \\textbf{3.6 million} images across \\textbf{213 countries}. We finetune state-of-the-art CLIP-based models such as Pigeon and GeoCLIP and report performance at country and continent levels using both top-$k$ accuracy as well as distance based accuracy metrics. Results highlight that continent-level geolocation is feasible, but fine grained indoor geolocation e.g street and city level geolocation remains an open challenge. This work defines a new frontier for geolocation research and provides the resources to advance it.",
    "key_points": [
      "geolocation",
      "dataset",
      "geolocalisaton"
    ],
    "gold_summary": "The paper proposes a **3.6M geolocation dataset specialized with Indoor images**. The authors **fine-tune a Geoclip model** to benchmark this dataset."
  },
  {
    "paper_id": "ld6JUQbhes",
    "title": "AssetOpsBench: Benchmarking AI Agents for Task Automation in Industrial Asset Operations and Maintenance",
    "domain": "datasets and benchmarks",
    "content": "AI for Industrial Asset Lifecycle Management aims to automate complex operational workflows—such as condition monitoring, maintenance planning, and intervention scheduling—to reduce human workload and minimize system downtime. Traditional AI/ML approaches have primarily tackled these problems in isolation, solving narrow tasks within the broader operational pipeline. In contrast, the emergence of AI agents and large language models (LLMs) introduces a next-generation opportunity: enabling end-to-end automation across the entire asset lifecycle. This paper envisions a future where AI agents autonomously manage tasks that previously required distinct expertise and manual coordination. To this end, we introduce AssetOpsBench—a unified framework and environment designed to guide the development, orchestration, and evaluation of domain-specific agents tailored for Industry 4.0 applications. We outline the key requirements for such holistic systems and provide actionable insights into building agents that integrate perception, reasoning, and control for real-world industrial operations.",
    "key_points": [
      "agentic ai",
      "industry 4.0",
      "time series"
    ],
    "gold_summary": "This paper constucts a benchmark for AI agents in industrial asset operations and maintenance, including 141 open-source scenarios. Several LLMs are then evaluated."
  },
  {
    "paper_id": "0YRVlxY9BH",
    "title": "ChinaTravel: An Open-Ended Travel Planning Benchmark with Compositional Constraint Validation for Language Agents",
    "domain": "datasets and benchmarks",
    "content": "Travel planning stands out among real-world applications of \\emph{Language Agents} because it couples significant practical demand with a rigorous constraint-satisfaction challenge. However, existing benchmarks typically rely on synthetic queries with limited constraints and explicit intent, which diverge from real-world scenarios, where user requirements are open-ended, diverse, and often implicitly expressed. To address this gap, we introduce \\emph{ChinaTravel}, with four key contributions: 1) a practical sandbox aligned with the multi-day, multi-POI travel planning, 2) a compositionally generalizable domain-specific language (DSL) for scalable evaluation, covering feasibility, constraint satisfaction, and preference comparison 3) an open-ended dataset that integrates diverse travel requirements and implicit intent from 1154 human participants, and 4) fine-grained analysis reveal the potential of neuro-symbolic agents in travel planning, achieving a 37.0\\% constraint satisfaction rate on human queries, a 10$\\times$ improvement over purely neural models. Overall, ChinaTravel provides a foundation for advancing language agents through compositional constraint validation in complex, real-world planning scenarios.",
    "key_points": [
      "benchmarking",
      "travel planning",
      "neuro-symbolic learning",
      "llm planning"
    ],
    "gold_summary": "This paper constructs a dataset for the travel planning problem to address the limitations of existing benchmarks, which typically rely on synthetic queries with limited constraints and explicit intent, diverging from real-world scenarios."
  },
  {
    "paper_id": "1Q85tfZaOa",
    "title": "Practical estimation of the optimal classification error with soft labels and calibration",
    "domain": "datasets and benchmarks",
    "content": "While the performance of machine learning systems has experienced significant improvement in recent years, relatively little attention has been paid to the fundamental question: to what extent can we improve our models? This paper provides a means of answering this question in the setting of binary classification, which is practical and theoretically supported. We extend a previous work that utilizes soft labels for estimating the Bayes error, the optimal error rate, in two important ways. First, we theoretically investigate the properties of the bias of the hard-label-based estimator discussed in the original work. We reveal that the decay rate of the bias is adaptive to how well the two class-conditional distributions are separated, and it can decay significantly faster than the previous result suggested as the number of hard labels per instance grows. Second, we tackle a more challenging problem setting: estimation with _corrupted_ soft labels. One might be tempted to use calibrated soft labels instead of clean ones. However, we reveal that _calibration guarantee is not enough_, that is, even perfectly calibrated soft labels can result in a substantially inaccurate estimate. Then, we show that isotonic calibration can provide a statistically consistent estimator under an assumption weaker than that of the previous work. Our method is _instance-free_, i.e., we do not assume access to any input instances. This feature allows it to be adopted in practical scenarios where the instances are not available due to privacy issues. Experiments with synthetic and real-world datasets show the validity of our methods and theory.",
    "key_points": [
      "bayes error",
      "irreducible error",
      "uncertainty quantification",
      "soft labels",
      "calibration",
      "evaluation"
    ],
    "gold_summary": "The paper studies the estimation of the Bayes error. It improves the existing estimates from hard labels and proposes an approach to compute it using corrupted soft labels."
  },
  {
    "paper_id": "R1u1qWfosc",
    "title": "Benchmarking LLMs on Authentic Cases from Medical Journals",
    "domain": "datasets and benchmarks",
    "content": "In recent years, large language models (LLMs) have demonstrated remarkable capabilities in the medical domain. However, existing medical benchmarks suffer from performance saturation and are predominantly derived from medical exam questions, which fail to adequately capture the complexity of real-world clinical scenarios. To bridge this gap, we introduce ClinBench, a challenging benchmark based on authentic clinical cases sourced from authoritative medical journals. Each question retains the complete patient information and clinical test results from the original case, effectively simulating real-world clinical practice. Additionally, we implement a rigorous human review process involving medical experts to ensure the quality and reliability of the benchmark. ClinBench supports both textual and multimodal evaluation formats, covering 12 medical specialties with over 2,000 questions, which provides a comprehensive benchmark for assessing LLMs’ medical capabilities. We evaluate the performance of over 20 open-source and proprietary LLMs and benchmark them against human medical experts. Our findings reveal that human experts still retain an advantage within their specialized fields, while LLMs demonstrate superior overall performance on a broader range of medical specialties.",
    "key_points": [
      "medical benchmark",
      "large language models",
      "real clinical scenarios"
    ],
    "gold_summary": "This paper introduces ClinBench, a benchmark built from real clinical cases published in medical journals. It also benchmarked large language models in these more clinically relevant medical questions."
  },
  {
    "paper_id": "m4VAwxLMqt",
    "title": "SafeRBench: A Comprehensive Benchmark for Safety Assessment of Large Reasoning Models",
    "domain": "datasets and benchmarks",
    "content": "Large Reasoning Models (LRMs) improve answer quality through explicit chain-of-thought, yet this very capability introduces new safety risks: harmful content can be subtly injected, surface gradually, or be justified by misleading rationales within the reasoning trace. Existing safety evaluations, however, primarily focus on output-level judgments and rarely capture these dynamic risks along the reasoning process. In this paper, we present **SafeRBench**, *the first benchmark that assesses LRM safety end-to-end—from inputs and intermediate reasoning to final outputs*: (i) ***Input Characterization:*** We pioneer the incorporation of risk categories and levels into input design, explicitly accounting for affected groups and severity, and thereby establish a balanced prompt suite reflecting diverse harm gradients. (ii) ***Fine-Grained Output Analysis:*** We introduce a micro-thought chunking mechanism to segment long reasoning traces into semantically coherent units, enabling fine-grained evaluation across ten safety dimensions. (iii) ***Human Safety Alignment:*** We validate LLM-based evaluations against human annotations specifically designed to capture safety judgments. Evaluations on 19 LRMs demonstrate that SafeRBench enables detailed, multidimensional safety assessment, offering insights into risks and protective mechanisms from multiple perspectives.",
    "key_points": [
      "safety",
      "large reasoning model",
      "benchmark",
      "evaluation"
    ],
    "gold_summary": "The paper introduces a benchmark SafeRBench that assesses large reasoning models safety from inputs, and intermediate reasoning to outputs. through structured input characterization, micro-thought chunking for fine-grained analysis, and human-aligned safety evaluation"
  },
  {
    "paper_id": "YE5scJekg5",
    "title": "DM4CT: Benchmarking Diffusion Models for Computed Tomography Reconstruction",
    "domain": "datasets and benchmarks",
    "content": "Diffusion models have recently emerged as powerful priors for solving inverse problems. While computed tomography (CT) is theoretically a linear inverse problem, it poses many practical challenges. These include correlated noise, artifact structures, reliance on system geometry, and misaligned value ranges, which make the direct application of diffusion models more difficult than in domains like natural image generation. To systematically evaluate how diffusion models perform in this context and compare them with established reconstruction methods, we introduce DM4CT, a comprehensive benchmark for CT reconstruction. DM4CT includes datasets from both medical and industrial domains with sparse-view and noisy configurations. To explore the challenges of deploying diffusion models in practice, we additionally acquire a high-resolution CT dataset at a high-energy synchrotron facility and evaluate all methods under real experimental conditions. We benchmark nine recent diffusion-based methods alongside seven strong baselines, including model-based, unsupervised, and supervised approaches. Our analysis provides detailed insights into the behavior, strengths, and limitations of diffusion models for CT reconstruction. The real-world dataset is publicly available at zenodo.org/records/15420527, and the codebase is open-sourced at github.com/DM4CT/DM4CT.",
    "key_points": [
      "benchmark",
      "dataset",
      "inverse problem",
      "computed tomography",
      "diffusion models",
      "reconstruction"
    ],
    "gold_summary": "This paper provides a benchmark on CT reconstruction algorithms on different datasets and settings."
  },
  {
    "paper_id": "bGVkAhR7Eu",
    "title": "SAS-Bench: A Fine-Grained Benchmark for Evaluating Short Answer Scoring with Large Language Models",
    "domain": "datasets and benchmarks",
    "content": "Short Answer Scoring (SAS) is a critical task in automated subjective answer grading, playing an essential role in education, standardized testing, and large-scale assessment systems. However, existing approaches often produce coarse-grained scores and lack detailed reasoning. Although large language models (LLMs) have demonstrated potential as zero-shot evaluators, they remain susceptible to bias, inconsistencies with human judgment, and limited transparency in scoring decisions. To overcome these limitations, we introduce SAS-Bench, a benchmark specifically designed for LLM-based SAS tasks. SAS-Bench provides fine-grained, step-wise scoring, expert-annotated error categories, and a diverse range of question types derived from real-world subject-specific exams. This benchmark facilitates detailed evaluation of model reasoning processes and explainability. We also release an open-source dataset containing 1,030 questions and 4,109 student responses, each annotated by domain experts. Furthermore, we conduct comprehensive experiments with various LLMs, identifying major challenges in scoring science-related questions and highlighting the effectiveness of few-shot prompting in improving scoring accuracy. Our work offers valuable insights into the development of more robust, fair, and educationally meaningful LLM-based evaluation systems.",
    "key_points": [
      "automated assessment",
      "short answer scoring",
      "llm-as-a-judge"
    ],
    "gold_summary": "This paper introduces SAS-bench, a benchmark to evaluate LLM-based short answer scoring (SAS) by providing fine-grained, step-wise scoring, expert-annotated error categories, and a diverse range of question types derived from real-world subject-specific exams."
  },
  {
    "paper_id": "66207RUZBX",
    "title": "Towards Robust Benchmark of Object Hallucination on Multiple Images",
    "domain": "datasets and benchmarks",
    "content": "Multimodal Large Language Models (MLLMs) are evolving into sophisticated agentic systems, engaging users in complex, multi-image scenarios. However, current MLLMs are limited by object hallucination, generating information inconsistent with visual evidence. Existing benchmarks, largely designed for single-image settings or offering only high-level multi-image assessments, fail to capture the nuanced causes of object hallucination, particularly under adversarial conditions. To address this, we introduce the Multi-Image Object Hallucination (MIOH) benchmark, a comprehensive framework specifically designed to diagnose MLLM vulnerabilities in complex multi-image contexts. MIOH integrates four object-centric tasks (existence, counting, attribute, position) with four controllable adversarial factors (visual context scale, perceptual difficulty, contextual bias, and misleading textual context). Through our systematic evaluation using MIOH, we reveal that even state-of-the-art models including GPT-5 and Gemini Pro still suffer from significant performance degradation under adversarial conditions, with models showing increased susceptibility to both false positive and false negative hallucinations when visual and linguistic contexts become challenging.",
    "key_points": [
      "multimodal large language model",
      "object hallucination",
      "benchmark"
    ],
    "gold_summary": "The authors propose the MIOH benchmark to evaluate multi-image object hallucination which contains  4 object-centric tasks (existence, counting, attribute, position) via 3 question types (comprehensive, comparative, selective)."
  },
  {
    "paper_id": "xx3DCKbt1T",
    "title": "AV-Odyssey Bench: From Fundamental Audio Perception to Audio-Visual Understanding",
    "domain": "datasets and benchmarks",
    "content": "Recent multimodal large language models (MLLMs), such as GPT-4o, Gemini 1.5/2.5 Pro, and Reka Core, have advanced audio-visual reasoning capabilities, achieving strong performance in tasks like cross-modal understanding and generation. However, our \\textbf{DeafTest} uncovers unanticipated failures: most of the state-of-the-art MLLMs struggle with very simple audio tasks, such as \\textit{distinguishing louder sounds} or \\textit{sound counting}. This raises a fundamental question—does a deficiency in low-level audio perception constrain higher-level audio-visual reasoning? To address this, we introduce \\textbf{AV-Odyssey Bench}—a comprehensive benchmark of 4,555 meticulously designed problems that integrate text, audio, and visual modalities. Each task requires models to unify cross-modal reasoning, leveraging synchronized audio-visual cues to infer solutions. By structuring questions as multiple-choice, we ensure objective, reproducible evaluations without reliance on subjective human or LLM-based judgments. Through comprehensive benchmarking of closed-source and open-source models, we showcase: (i) current MLLMs lack robust audio-visual integration ability and (ii) performance on DeafTest (Pearson’s $r = 0.945$) strongly correlates with AV-Odyssey accuracy. These findings not only challenge prevailing assumptions about the “multimodal proficiency” of leading models, but also highlight the importance of fundamental audio perception as a bottleneck for audio-visual reasoning. We believe that our results provide concrete guidance for future research in future dataset design, alignment strategies, and architectures toward truly integrated audio-visual understanding.",
    "key_points": [
      "audio-visual understanding",
      "multi-modal large language models"
    ],
    "gold_summary": "An Audio Visual Benchmark that focuses on showing audio perception has fundamental to AudioVisual Understanding.\nThe paper shows that a hearing test predicts well the performance on the benchmark."
  },
  {
    "paper_id": "PX1EsE9Hut",
    "title": "BEYOND RETRIEVAL: GENERATIVE EVIDENCE CALIBRATION FOR ANSWER-UTILITY SEARCH",
    "domain": "datasets and benchmarks",
    "content": "Strong BM25+BGE fusions often saturate at the head; heavy rerankers (CE) do not consistently help. We introduce GEC, combining BM25, BGE, and Multi-GES via gPoE-HeadSafe, a calibrated product-of-experts with explicit head-safety guards. We quantify headroom with an OUB, bound what is reachable with PRA, and convert part of that gap via an APC pass. On NQ/FiQA/SciFact, gPoE-HeadSafe and/or GEC-WRRF improve MRR@10 over strong BM25+BGE fusions; APC captures a measurable fraction of OUB headroom (0.147 average gap, 58.3% reachable). The pipeline holds across Mixtral-8x7B-Instruct-v0.1 and Mistral-7B-Instruct-v0.3 with consistent early-precision gains; in our runs, CE is typically outperformed by gPoE-HeadSafe by ∼0.06–0.08 MRR@10 on Mixtral and ∼0.03–0.05 on Mistral.",
    "key_points": [
      "head-safe calibration",
      "product-of-experts",
      "generative evidence",
      "hybrid dense–sparse retrieval",
      "early precision",
      "beir",
      "oracle upper bound (oub) & reachability",
      "reranking vs calibration",
      "wrrf blending"
    ],
    "gold_summary": "The paper proposes Generative Evidence Calibration (GEC): it derives evidence signals from citation-anchored “synthesis packs” (Multi-GES) and fuses them with BM25/BGE using either a guarded product-of-experts (gPoE-HeadSafe) or a learned WRRF fusion."
  },
  {
    "paper_id": "RuUXnRyqcy",
    "title": "M4PQA: A Comprehensive QA Dataset for AI Research with Instance-Level Evaluation",
    "domain": "datasets and benchmarks",
    "content": "The growing volume of academic papers has made it increasingly difficult for researchers to efficiently extract key information. While large language models (LLMs) based agents are capable of automating question answering (QA) workflows for scientific papers, there still lacks a comprehensive and realistic benchmark to evaluate their capabilities. Moreover, training an interactive agent for this task is hindered by the shortage of high-quality interaction trajectories. In this work, we propose M4PQA, a human-annotated comprehensive paper QA dataset in the field of artificial intelligence, with 13,948 papers and 1,246 questions, that encompasses multi-task, multi-modal and instance-level evaluation. Furthermore, we propose ExTrActor, an automated framework for instruction data synthesis. With three LLM-based agents, ExTrActor can perform example generation and trajectory collection without human intervention. Evaluations of multiple open-source and proprietary models show that most models underperform on M4PQA, demonstrating its quality. Extensive experiments confirm that ExTrActor consistently improves the multi-turn tool-use capability of small models, enabling them to achieve performance comparable to larger ones.",
    "key_points": [
      "question answering",
      "supervised fine-tuning",
      "trajectory synthesis"
    ],
    "gold_summary": "This paper introduce lots work to \n0) frame question answering as multi turn agentic calling \n1) create enviornments to generate agentic tractergories recognize the limits of human-input\n2) showcase scaling law to small 7b/14B model"
  },
  {
    "paper_id": "7UMbamWXts",
    "title": "MiLDEdit: Reasoning-Based Multi-Layer Design Document Editing",
    "domain": "datasets and benchmarks",
    "content": "Real-world design documents (e.g., posters) are inherently multi-layered, combining decoration, text, and images. Editing them from natural-language instructions requires fine-grained, layer-aware reasoning to identify relevant layers and coordinate modifications. Prior work largely overlooks multi-layer design document editing, focusing instead on single-layer image editing or multi-layer generation, which assume a flat canvas and lack the reasoning needed to determine what and where to modify.\nTo address this gap, we introduce the Multi-Layer Document Editing Agent (MiLDEAgent), a reasoning-based framework that combines an RL-trained multimodal reasoner for layer-wise understanding with an image editor for targeted modifications.\nTo systematically benchmark this setting, we introduce the Multi-Layer Document Editing Benchmark (MiLDEBench), a human-in-the-loop corpus of over 20K design documents paired with diverse editing instructions. The benchmark covers both content and layout edits and is complemented by a task-specific evaluation protocol, MiLDEEval, which spans four dimensions for content editing (instruction following, layout consistency, aesthetics, and text rendering) and two dimensions for layout editing (instruction following and content consistency).\nExtensive experiments on 14 open-source and 2 closed-source models reveal that existing approaches fail to generalize: open-source models often cannot complete multi-layer document editing tasks, while closed-source models suffer from instruction misalignment and format violations. In contrast, MiLDEAgent achieves strong layer-aware reasoning and precise editing, delivering over 50% improvements compared to all open-source baselines and attaining performance comparable to closed-source models, thereby establishing the first strong baseline for multi-layer document editing.",
    "key_points": [
      "multi-layer document editing",
      "reasoning-based document editing",
      "multimodal agent",
      "benchmark"
    ],
    "gold_summary": "The paper tackles the multi-layer design document editing task, where a new dataset and benchmark, MiLDEBench, are proposed to evaluate existing models and the GRPO fine-tuned Qwen model in this work."
  },
  {
    "paper_id": "ggAJSyCAKf",
    "title": "ShoppingComp: Are LLMs Really Ready for Your Shopping Cart?",
    "domain": "datasets and benchmarks",
    "content": "We present ShoppingComp, a challenging real-world benchmark for rigorously evaluating LLM-powered shopping agents on three core capabilities: precise product retrieval, expert-level report generation, and safety critical decision making. Unlike prior e-commerce benchmarks, ShoppingComp introduces highly complex tasks under the principle of guaranteeing real products and ensuring easy verifiability, adding a novel evaluation dimension for identifying product safety hazards alongside recommendation accuracy and report quality. The benchmark comprises 120 tasks and 1,026 scenarios,  curated by 35 experts to reflect authentic shopping needs. Results reveal stark limitations of current LLMs: even state-of-the-art models achieve low performance (e.g., 11.22\\% for GPT-5, 3.92\\% for Gemini-2.5-Flash). These findings highlight a substantial gap between research benchmarks and real-world deployment, where LLMs make critical errors such as failure to identify unsafe product usage or falling for promotional misinformation, leading to harmful recommendations. ShoppingComp fills the gap and thus establishes a new standard for advancing reliable and practical agents in e-commerce.",
    "key_points": [
      "deep research",
      "agent",
      "web search",
      "benchmark",
      "llm real-world utility",
      "s ecurity",
      "report evaluation",
      "rubric"
    ],
    "gold_summary": "Overall, I think the paper is good for writing and I have been enjoyed reading it. My judgement is that the paper might not meet the high standard of the papers at ICLR level."
  },
  {
    "paper_id": "ehXVDJm0PS",
    "title": "CodeSense: a Real-World Benchmark and Dataset for Code Semantic Reasoning",
    "domain": "datasets and benchmarks",
    "content": "Understanding and reasoning about code semantics is essential for enhancing code LLMs' abilities to solve real-world software engineering (SE) tasks. Although several code reasoning benchmarks exist, most rely on synthetic datasets or educational coding problems and focus on coarse-grained reasoning tasks such as input/output prediction, limiting their effectiveness in evaluating LLMs in practical SE contexts. To bridge this gap, we propose CodeSense, the first benchmark that makes available a spectrum of fine-grained code reasoning tasks concerned with the software engineering of real-world code. We collected Python, C and Java software projects from real-world repositories. We executed tests from these repositories, collected their execution traces, and constructed a ground truth dataset for fine-grained semantic reasoning tasks.  We then performed comprehensive evaluations on state-of-the-art LLMs. Our results show a clear performance gap for the models to handle fine-grained reasoning tasks. Although prompting techniques such as chain-of-thought and in-context learning helped, the lack of code semantics in LLMs fundamentally limit models' capabilities of code reasoning. Besides dataset, benchmark and evaluation, our work produced an execution tracing framework and tool set that make it easy to collect ground truth for fine-grained SE reasoning tasks, offering a strong basis for future benchmark construction and model post training. Our code and data are located at \\url{https://codesense-bench.github.io/}.",
    "key_points": [
      "code semantics",
      "benchmark",
      "llm"
    ],
    "gold_summary": "Obvious template tampering. Recommended to desk reject."
  },
  {
    "paper_id": "QcgkUJbfxT",
    "title": "GraphRAG-Bench: Challenging Domain-specific Reasoning for Evaluating Graph Retrieval-Augmented Generation",
    "domain": "datasets and benchmarks",
    "content": "Graph Retrieval Augmented Generation (GraphRAG) has garnered increasing recognition for its potential to enhance large language models (LLMs) by structurally organizing domain-specific corpora and facilitating complex reasoning. However, current evaluations of GraphRAG models predominantly rely on traditional question-answering datasets. Their limited scope in questions and evaluation metrics fails to comprehensively assess the reasoning capacity improvements enabled by GraphRAG models. To address this gap, we introduce GraphRAG-Bench, a large-scale, domain-specific benchmark designed to rigorously evaluate GraphRAG models. Our benchmark offers three key superiorities: \\((i)\\) Challenging question design. Featuring college-level, domain-specific questions that demand multi-hop reasoning, the benchmark ensures that simple content retrieval is insufficient for problem-solving. For example, some questions require mathematical reasoning or programming. \\((ii)\\) Diverse task coverage. The dataset includes a broad spectrum of reasoning tasks, multiple-choice, true/false, multi-select, open-ended, and fill-in-the-blank. It spans 16 disciplines in twenty core textbooks. \\((iii)\\) Holistic evaluation framework. GraphRAG-Bench provides comprehensive assessment across the entire GraphRAG pipeline, including graph construction, knowledge retrieval, and answer generation. Beyond final-answer correctness, it evaluates the logical coherence of the reasoning process. By applying nine contemporary GraphRAG methods to GraphRAG-Bench, we demonstrate its utility in quantifying how graph-based structuring improves model reasoning capabilities. Our analysis reveals critical insights about graph architectures, retrieval efficacy, and reasoning capabilities, offering actionable guidance for the research community.",
    "key_points": [
      "graphrag",
      "reasoning",
      "domain-specific"
    ],
    "gold_summary": "This paper introduces GraphRAG-Bench, which is a large-scale, domain-specific benchmark designed to evaluate GraphRAG methods."
  },
  {
    "paper_id": "F0NLxHasGU",
    "title": "What Are You Doing? A Closer Look at Controllable Human Video Generation",
    "domain": "datasets and benchmarks",
    "content": "High-quality benchmarks are crucial for driving progress in machine learning research. However, despite the growing interest in video generation, there is no comprehensive dataset to evaluate human synthesis. Humans can perform a wide variety of actions and interactions, but existing datasets, like TikTok and TED-Talks, lack the diversity and complexity to fully capture the capabilities of video generation models. We close this gap by introducing 'What Are You Doing?' (WYD): a new benchmark for fine-grained evaluation of controllable image-to-video generation of humans. WYD consists of 1,544 captioned videos that have been meticulously collected and annotated with fine-grained categories. These allow us to systematically measure performance across 9 aspects of human generation, including actions, interactions and motion. We also propose and validate an evaluation framework that leverages our annotations and reflects well human preferences. Equipped with our dataset and metrics, we perform in-depth analyses of state-of-the-art open-source models in controllable image-to-video generation, showing how WYD provides novel insights about their capabilities. We release our data and code to drive forward progress in human video generation.",
    "key_points": [
      "benchmark",
      "dataset",
      "evaluation",
      "video generation",
      "controllable video generation",
      "human video generation"
    ],
    "gold_summary": "The paper proposes a new benchmark for fine-grained evaluation of controllable image-to-video generation of humans."
  },
  {
    "paper_id": "Ts6j3GoZDE",
    "title": "STAR-Bench: Probing Deep Spatio-Temporal Reasoning as Audio 4D Intelligence",
    "domain": "datasets and benchmarks",
    "content": "Despite rapid progress in Multi-modal Large Language Models and Large Audio-Language Models, existing audio benchmarks largely test semantics that can be recovered from text captions, masking deficits in fine-grained perceptual reasoning.\nWe formalize audio 4D intelligence that is defined as reasoning over sound dynamics in time and 3D space, and introduce a STAR-Bench to measure it. STAR-Bench combines a Foundational Acoustic Perception setting (six attributes under absolute and relative  regimes) with a Holistic Spatio-Temporal Reasoning setting that includes segment reordering for continuous and discrete processes and spatial tasks spanning static localization, multi-source relations, and dynamic trajectories. Our data curation pipeline uses two methods to ensure high-quality samples. For foundational tasks, we use procedurally synthesized and physics-simulated audio. For holistic data, we follow a four-stage process that includes human annotation and final selection based on human performance. Unlike prior benchmarks where caption-only answering reduces accuracy slightly, STAR-Bench induces far larger drops (-31.5\\% temporal, -35.2\\% spatial), evidencing its focus on linguistically hard-to-describe cues. Evaluating 19 models reveals substantial gaps to humans and a capability hierarchy: closed-source models are bottlenecked by fine-grained perception, while open-source models lag across perception, knowledge, and reasoning. Our STAR-Bench provides critical insights and a clear path forward for developing future models with a more robust understanding of the physical world.",
    "key_points": [
      "audio understanding",
      "spatio-temporal reasoning",
      "4d intelligence"
    ],
    "gold_summary": "A very topical benchmark for large audio language models, which adds basic audio perception modalities, and explores categories where linguistic descriptions are hard."
  },
  {
    "paper_id": "9uX8pPUOHH",
    "title": "GeoArena: An Open Platform for Benchmarking Large Vision-language Models on WorldWide Image Geolocalization",
    "domain": "datasets and benchmarks",
    "content": "Image geolocalization aims to predict the geographic location of images captured anywhere on Earth, but its global nature presents significant challenges. Current evaluation methodologies suffer from two major limitations. First, static datasets: advanced approaches often rely on large vision-language models (LVLMs) to predict image locations, yet these models are frequently pretrained on the test datasets, compromising the accuracy of evaluating a model's actual geolocalization capability. Second, existing metrics primarily rely on exact geographic coordinates to assess predictions, which not only neglects the reasoning process but also raises privacy concerns when user-level location data is required. To address these issues, we propose GeoArena, a first open platform for evaluating LVLMs on worldwide image geolocalization tasks, offering true in-the-wild and user-preference-based benchmarking. GeoArena enables users to upload in-the-wild images for a more diverse evaluation corpus, and it leverages pairwise human judgments to determine which model output better aligns with human expectations. Our platform has been deployed online for three months, during which we collected over thousands voting records. Based on this data, we conduct a detailed analysis and establish a leaderboard of different LVLMs on the image geolocalization task.",
    "key_points": [
      "image geolocalization",
      "lvlms",
      "benchmark"
    ],
    "gold_summary": "This paper proposes a dynamic, user-preference-based benchmarking platform for image geolocalization. The platform allows users to upload their own images, provide feedback, and contribute to the evaluation of vision-language models (VLMs) on geolocation tasks."
  },
  {
    "paper_id": "5EKY1epoff",
    "title": "Seemingly Simple Planning Problems are Computationally Challenging: The Countdown Game",
    "domain": "datasets and benchmarks",
    "content": "There is a broad consensus that the inability to form long-term plans is one of the key limitations of current foundational models and agents. However, the existing planning benchmarks remain woefully inadequate to truly measure their planning capabilities. Most existing benchmarks either focus on loosely defined tasks like travel planning or end up leveraging existing domains and problems from international planning competitions. While the former tasks are hard to formalize and verify, the latter were specifically designed to test and challenge the weaknesses of existing automated planners. To address these shortcomings, we propose a procedure for creating a planning benchmark centered around the game called Countdown, where a player is expected to form a target number from a list of input numbers through arithmetic operations. We discuss how this problem meets many of the desiderata associated with an ideal benchmark for planning capabilities evaluation. Specifically, the domain allows for an intuitive, natural language description for each problem instance, it is computationally challenging (NP-complete), and the instance space is rich enough that we do not have to worry about memorization. We\nperform an extensive theoretical analysis, establishing the computational complexity result and demonstrate the advantage of our instance generation procedure over public benchmarks. We evaluate a variety of existing LLM-assisted planning methods on instances generated using our procedure. Our results show that, unlike other domains like 24 Game (a special case of Countdown), our proposed dynamic benchmark remains extremely challenging for existing LLM-based approaches.",
    "key_points": [
      "planning benchmark",
      "planning with language models"
    ],
    "gold_summary": "This is a strong, interesting paper that investigates the planning capabilities of today's LLM. It proposes a simple, easy-to-use benchmark for assessing LLM planning, and it discusses the empirical results."
  },
  {
    "paper_id": "66v0c2oOHK",
    "title": "KnowMT-Bench: Benchmarking Knowledge-Intensive Long-Form Question Answering In Multi-Turn Dialogues",
    "domain": "datasets and benchmarks",
    "content": "Multi-Turn Long-Form Question Answering (MT-LFQA) is a key application paradigm of Large Language Models (LLMs) in knowledge-intensive domains. However, existing benchmarks are limited to single-turn dialogue, while multi-turn dialogue benchmarks typically assess other orthogonal capabilities rather than knowledge-intensive factuality. To bridge this critical gap, we introduce **KnowMT-Bench**, the first-ever benchmark designed to systematically evaluate MT-LFQA for LLMs across knowledge-intensive fields, including medicine, finance, and law. To faithfully assess the model's real-world performance, KnowMT-Bench employs a dynamic evaluation setting where models generate their own multi-turn dialogue histories given logically progressive question sequences. The factual capability and information delivery efficiency of the final-turn answer are then evaluated using a human-validated automated pipeline. Our experiments reveal that multi-turn contexts degrade performance: factual capability declines due to the contextual noise from self-generated histories, while information efficiency drops as models become more verbose with increasing dialogue length. We then investigate mitigation strategies, demonstrating that retrieval-augmented generation (RAG) can effectively alleviate and even reverse this factual degradation. These findings underscore the importance of our benchmark in evaluating and enhancing the conversational factual capabilities of LLMs in real-world knowledge-intensive applications.",
    "key_points": [
      "benchmark",
      "multi-turn dialogues",
      "long form question answering"
    ],
    "gold_summary": "The paper introduces KnowMT-Bench, the first benchmark specifically designed to evaluate multi-turn long-form question answering (MT-LFQA) in knowledge-intensive domains (medicine, finance, and law)."
  },
  {
    "paper_id": "M3uTWE4FhR",
    "title": "LLMTrace: A Corpus for Classification and Fine-Grained Localization of AI-Written Text",
    "domain": "datasets and benchmarks",
    "content": "The widespread use of human-like text from Large Language Models (LLMs) necessitates the development of robust detection systems. However, progress is limited by a critical lack of suitable training data; existing datasets are often generated with outdated models, are predominantly in English, and fail to address the increasingly common scenario of mixed human-AI authorship. Crucially, while some datasets address mixed authorship, none provide the character-level annotations required for the precise localization of AI-generated segments within a text. To address these gaps, we introduce LLMTrace, a new large-scale, bilingual (English and Russian) corpus for AI-generated text detection. Constructed using a diverse range of modern proprietary and open-source LLMs, our dataset is designed to support two key tasks: traditional full-text binary classification (human vs. AI) and the novel task of AI-generated interval detection, facilitated by character-level annotations. We believe LLMTrace will serve as a vital resource for training and evaluating the next generation of more nuanced and practical AI detection models.",
    "key_points": [
      "ai-generated text detection",
      "dataset",
      "mixed-authorship detection",
      "natural language processing",
      "ai safety",
      "large language models"
    ],
    "gold_summary": "LLMTRACE introduces a large-scale, bilingual (English/Russian) corpus for detecting AI-generated text at two levels."
  },
  {
    "paper_id": "GrbNjReVC6",
    "title": "RTL-OPT: Rethinking the Generation of PPA-Optimized RTL Code and A New Benchmark",
    "domain": "datasets and benchmarks",
    "content": "The rapid advancements of AI rely on the support of integrated circuits (ICs). Recently, large language models (LLMs) have been increasingly explored in the generation of IC designs, mostly in Register-Transfer Level (RTL) code format, such as Verilog or VHDL. However, most existing benchmarks focus primarily on the accuracy of RTL code generation, rather than the optimization of IC design quality in terms of power, performance, and area (PPA). \nThis work critically examines RTL optimization benchmarks and highlights the challenges of assessing RTL code quality. Our findings show that optimization assessments are complex and existing works yield misleading results, as the perceived superiority of RTL code often depends on the downstream synthesis tool and setup. \nTo address these issues, we introduce RTL-OPT, a benchmark comprising 36 digital IC designs handcrafted by our human designers. \nThese designs incorporate diverse optimization patterns derived from proven industry-standard RTL practices. Such optimization opportunities are not utilized by automated downstream logic synthesis, making them meaningful RTL code improvements. \nIn addition, RTL-OPT covers a wide range of RTL implementation types, including combinational logic, pipelined datapath, finite-state machines, and memory interfaces, making it sufficiently representative.\nFor each design task, RTL-OPT provides a pair of RTL codes: a carefully designed suboptimal (i.e., to-be-optimized) RTL code and an optimized RTL code as the golden reference. LLMs are expected to take the suboptimal RTL code as input, then generate a more optimized RTL code that leads to better ultimate PPA quality. The golden references, as a comparison baseline, reflect optimizations at the human-expert level. \nRTL-OPT further provides an integrated evaluation framework to automatically verify functional correctness and quantify PPA improvements of the LLM-optimized RTL code. This framework enables a standardized assessment of generative AI's ability in hardware design optimization. RTL-OPT is available at https://anonymous.4open.science/r/RTL-OPT-20C5.",
    "key_points": [
      "rtl optimization",
      "llm for hardware design",
      "benchmark dataset",
      "electronic design automation",
      "vlsi design"
    ],
    "gold_summary": "The paper proposes RTL-OPT, a benchmark to evaluate whether LLMs can improve RTL code for power, performance, area (PPA). RTL-OPT comprises 36 hand-crafted RTL pairs spanning arithmetic, control/FSM, pipelined datapaths, etc."
  },
  {
    "paper_id": "IoxPb2FynZ",
    "title": "Musical Score Understanding Benchmark: Evaluating Large Language Models’ Comprehension of Complete Musical Scores",
    "domain": "datasets and benchmarks",
    "content": "Understanding complete musical scores requires reasoning over symbolic structures such as pitch, rhythm, harmony, and form. \nDespite the rapid progress of Large Language Models (LLMs) and Vision-Language Models (VLLMs) in natural language and multimodal tasks, their ability to comprehend musical notation remains underexplored. We introduce Musical Score Understanding Benchmark (MSU-Bench), the first large-scale, human-curated benchmark for evaluating score-level musical understanding across both textual (ABC notation) and visual (PDF) modalities. MSU-Bench comprises 1,800 generative question-answer (QA) pairs drawn from works spanning Bach, Beethoven, Chopin, Debussy, and others, organised into four progressive levels of comprehension: Onset Information, Notation \\& Note, Chord \\& Harmony, and Texture \\& Form. Through extensive zero-shot and fine-tuned evaluations of over 15+ state-of-the-art (SOTA) models, we reveal sharp modality gaps, fragile level-wise success rates, and the difficulty of sustaining multilevel correctness. Low-Rank Adaptation (LoRA) markedly improves performance in both modalities while preserving general knowledge, establishing MSU-Bench as a rigorous foundation for future research at the intersection of AI, musicological, and multimodal reasoning.",
    "key_points": [
      "musical score understanding",
      "music information retrieval",
      "texture",
      "harmony",
      "form"
    ],
    "gold_summary": "This paper presents MSU-Bench, a large scale benchmark and finetuning set for evaluating LLM and VLLMs on symbolic music reasoning tasks."
  },
  {
    "paper_id": "fBagP6w6yE",
    "title": "From Natural Alignment to Conditional Controllability in Multimodal Dialogue",
    "domain": "datasets and benchmarks",
    "content": "The recent advancement of Artificial Intelligence Generated Content (AIGC) has led to significant strides in modeling human interaction, particularly in the context of multi-modal dialogue. \nWhile current methods impressively generates realistic dialogue in speech and vision modalities, challenges remain in multi-modal conditional dialogue generation. \nThis paper focuses on the natural alignment between speech, vision, and text, aiming at expressive dialogue generation through multi-modal conditional control. \nSince existing datasets lack the richness and diversity in dialogue expressiveness, we introduce a novel multi-modal dialogue annotation pipeline to exploit meaningful dialogues from movies and TV series with fine-grained annotations across multi-modalities.\nThe resultant dataset, MM-Dia, provides over 360 hours and 54,700 dialogues, facilitating the Multimodal Dialogue Generation task through explicit control over style-controllable dialogue speech synthesis. \nWhile the proposed benchmark, MM-Dia-Bench, containing 309 dialogues that are highly expressive with visible dual/single speaker scenes, supporting the evaluation of implicit cross-modal control through downstream multi-modal dialogue generation tasks to assess the audio-visual style consistency across modalities. \nOur experiments demonstrate the effectiveness of our data in enhancing style controllability and reveal limitations in current frameworks' ability to replicate human interaction expressiveness, providing new insights and challenges for multi-modal conditional dialogue generation. Code, demo and data will be released at: https://mmdiaiclr26.github.io/mmdiaiclr26/.",
    "key_points": [
      "multimodal dialogue dataset",
      "multimodal conditional dialogue generation",
      "spoken dialogue generation"
    ],
    "gold_summary": "The paper introduces MM-DIA, a large-scale, richly annotated multimodal dialogue dataset from movies and TV series, and MM-DIA-BENCH, a benchmark for evaluating cross-modal conditional generation. Experiments show MM-DIA improves style-controllable dialogue generation"
  },
  {
    "paper_id": "VStKtgGXUc",
    "title": "jqBench: a benchmark for reading and editing JSON from natural language and/or examples",
    "domain": "datasets and benchmarks",
    "content": "We introduce jqBench, a new benchmark for evaluating language models on JSON querying and transformation tasks, where the intent can be given specified using natural language and/or examples.\nWhereas jqBench is mainly aimed at using the `jq` tool, it can be used to evaluate other programming languages that query and/or transform JSON.\nBenchmarks are automatically created from two rich sources of data: Stack Overflow discussions (751 instances with instructions and examples, called jqStack) and the Spider dataset for SQL generation from natural language (893 instances with instructions and JSON Schema, called jqSpider).\nWe describe and analyze the automated pipeline for benchmark creation, and perform extensive baseline experiments on different models to analyze the complexity and failure modes.\nUsing implicit feedback, the best model (Claude Opus 4.1) scores 77% on the jqStack benchmarks and 81\\% on the jqSpider benchmarks.\nAdditionally, we show (1) that access to the documentation surprisingly does not help, (2) `jq` performs comparable to Python, and (3) that automatic feedback (and therefore examples) is crucial.\nBesides the final benchmarks, we release the intermediate artifacts from each generation step (including failed or invalid conversions) as well as an LLM-friendly version of the documentation, to facilitate further research on JSON querying and transformation.",
    "key_points": [
      "json",
      "benchmark",
      "code generation",
      "nl-to-code",
      "programming-by-example"
    ],
    "gold_summary": "The paper introduces jqBench, a new benchmark for testing language models on JSON querying and transformation tasks using natural language or examples. jqBench is automatically generated using Stack Overflow and Spider dataset."
  },
  {
    "paper_id": "PzCrvhSarX",
    "title": "HomeSafeBench: A Benchmark for Embodied Vision-Language Models in Free-Exploration Home Safety Inspection",
    "domain": "datasets and benchmarks",
    "content": "Embodied agents can identify and report safety hazards in the home environments. Accurately evaluating their capabilities in home safety inspection tasks is curcial, but existing benchmarks suffer from two key limitations. First, they oversimplify safety inspection tasks by using textual descriptions of the environment instead of direct visual information, which hinders the accurate evaluation of embodied agents based on Vision-Language Models (VLMs). Second, they use a single, static viewpoint for environmental observation, which restricts the agents' free exploration and cause the omission of certain safety hazards, especially those that are occluded from a fixed viewpoint.\nTo alleviate these issues, we propose HomeSafeBench, a benchmark with 12,900 data points covering five common home safety hazards: fire, electric shock, falling object, trips, and child safety. HomeSafeBench provides dynamic first-person perspective images from simulated home environments, enabling the evaluation of VLM capabilities for home safety inspection. By allowing the embodied agents to freely explore the room, HomeSafeBench provides multiple dynamic perspectives in complex environments for a more thorough inspection. Our comprehensive evaluation of mainstream VLMs on HomeSafeBench reveals that even the best-performing model achieves an F1-score of only 10.23\\%, demonstrating significant limitations in current VLMs. The models particularly struggle with identifying safety hazards and selecting effective exploration strategies. We hope HomeSafeBench will provide valuable reference and support for future research related to home security inspections. Our dataset and code will be publicly available soon.",
    "key_points": [
      "home safty inspection",
      "embodied agent",
      "vision language model"
    ],
    "gold_summary": "The manuscript proposes a new benchmark for evaluating embodied AI agents’ abilities to identify and report safety hazards in home environments, according to five pre-defined safety hazard categories, via first-person perspective images under free exploration."
  },
  {
    "paper_id": "kRpTTF7drV",
    "title": "SysIdBench: A Benchmark for System Identification Methods",
    "domain": "datasets and benchmarks",
    "content": "Modeling the behaviour of dynamic systems is a difficult problem because (i) there is a plenitude of existing system identification methods and (ii) the broadly varying characteristics of different dynamic systems are not all addressed by a single best method.\nWhile benchmarking system identification methods has been recognized as an important asset for developers who want to select the most suitable method for their problem, these benchmarks currently lack the capabilities developers require for systematic benchmarking.\nAnalysing related work and our own, we have worked out five requirements on benchmarking system identification methods that have shaped the design of SysIdBench, our novel benchmark, which comprises data sets with specifically tailored data types, data splits, and evaluation metrics. \nIn particular, SysIdBench comprises a principle-based summarizing evaluation metrics using predictions of energy as the key measurement target, it allows for judging generalization capabilities of system identification methods, and it investigates the fulfillment of physical principles. \nThe code for our benchmark, including the links to the datasets, is available on [GitHub](anonymous.github.repository).",
    "key_points": [
      "system identification",
      "benchmark",
      "dynamic sytems"
    ],
    "gold_summary": "The paper proposes a new benchmark for system identification. The authors rigorously identify requirements for benchmark evaluation. A small set of data sets is provided and empirically evaluated on a small set of methods."
  },
  {
    "paper_id": "LAYCYiIgZ1",
    "title": "Aurelius: Relation Aware Text-to-Audio Generation At Scale",
    "domain": "datasets and benchmarks",
    "content": "We present Aurelius, a new framework that enables relation aware text-to-audio (TTA) generation research at scale. Given the lack of essential audio event and relation corpora, \\emph{Aurelius} contributes a large-scale audio event corpus \\emph{AudioEventSet} and another large-scale relation corpus \\emph{AudioRelSet}. Comprising 110 event categories, AudioEventSet maximally covers all commonly heard audio events and each event is unique, realistic and of high-quality. AudioRelSet consists of 100 relations, comprehensively covering the relations that present in the physical world or can be neatly described by text.  As the two corpora provide audio event and relation independently, they can be combined to create massive <text,audio> pairs with our pair generation strategy to support relation aware TTA investigation at scale. We comprehensively benchmark all existing TTA models from both general and relation aware evaluation perspective. We further provide in-depth investigation on scaling up existing TTA models' relation aware generation by either training from scratch or leveraging cross-domain general TTA knowledge. The introduced corpora and the findings through investigation in this work potentially facilitate future research on relation aware TTA generation.",
    "key_points": [
      "relation aware text-to-audio generaion",
      "audio event corpus",
      "relation corpus"
    ],
    "gold_summary": "This paper introduces Aurelius, a large-scale benchmark framework with two corpora, AudioEventSet and AudioRelSet, that enables systematic evaluation and development of relation-aware text-to-audio generation at scale."
  },
  {
    "paper_id": "DEA4s0Bokq",
    "title": "Partner-Bench: Evaluating Visually-Grounded IQ and Interactive EQ in Audio-Visual Dialogue",
    "domain": "datasets and benchmarks",
    "content": "Developing Multi-Modal Large Language Models (MLLMs) from \"tool-oriented\" auxiliary AI to \"partner-oriented\" interactive AI requires the capacity to act as an active participant in Audio-Visual Dialogue (AVD)—a role that blends high **Visually-Grounded IQ** (the capacity to reason over joint audio-visual information) and high **Interactive EQ** (the ability to respond with empathy and expressiveness). However, progress in this area faces a key obstacle: the absence of a unified standard for defining and evaluating a \"good\" AVD model. The current evaluation landscape is thus fragmented: audio dialogue benchmarks can assess Interactive EQ but remain visually blind, while audio-visual understanding benchmarks evaluate Visually-Grounded IQ but lack interactivity, creating a methodological gap that leaves the critical synthesis of IQ and EQ in conversational contexts entirely unmeasured. To address this gap, we introduce **Partner-Bench**, the first benchmark designed to evaluate this synthesis, and to construct it, we present a novel Data Engine, **Partner-DE**, which automatically mines, filters, and annotates high-quality conversational data from web videos. Partner-Bench comprises 376 samples (3.49 hours total) and features a fine-grained, 7-dimensional evaluation framework: it decomposes IQ into three dimensions (Recognition, Comprehension, and Reasoning) and decouples EQ into two quality categories (Linguistic, including Persona and Cohesion; and Prosodic, including Naturalness and Affect). Our initial experiments on Partner-Bench yield three critical findings: (1) All current models perform significantly below the human baseline, indicating substantial room for improvement; (2) there is a significant performance gap between paradigms, with current SOTA cascaded models significantly outperforming existing end-to-end models (e.g., Cascaded Mimo-Audio at 68.38 vs. Qwen2.5-Omni at 51.53); and (3) a \"context cliff\" exists, where model performance initially improves with longer context but then sharply declines, revealing a failure to process extended interactions. By providing a rigorous standard and a diagnostic tool to pinpoint such weaknesses, Partner-Bench aims to steer the improvement of AVD models and ultimately accelerate the development of the next generation of truly perceptive and engaging AI companions.",
    "key_points": [
      "audio-visual dialogue; audio dialogue; audio-visual understanding"
    ],
    "gold_summary": "This paper proposed a new audio-visual benchmark focusing on assessing the visual-grounded IQ and interactive EQ. The evaluation methods are not enough."
  },
  {
    "paper_id": "rXai4fyJbE",
    "title": "FGD-VO: Flow-Guided Deformable Correlation with Hybrid Masks for Visual Odometry",
    "domain": "applications to robotics",
    "content": "Learning-based visual odometry remains vulnerable to outliers, particularly dynamic objects and background regions irrelevant to motion. It also suffers from weak modeling of inter-frame geometry, that is, the explicit pixel-wise correspondences that provide reliable motion cues. Many methods still rely on frame concatenation followed by convolutions, which tends to overlook fine-grained pixel correspondences across frames. This paper presents FGD-VO, an end-to-end monocular VO framework that addresses these issues within a unified architecture. First, we introduce a Flow-Guided Deformable Correlation (FGDC) module, which leverages dense optical flow to locate pixel correspondences between consecutive frames and augments them with learnable local offsets, enabling the aggregation of geometrically relevant features beyond fixed pixel matches. Second, we propose a Hybrid Masking strategy that combines an explicit optical-flow consistency mask with an implicit, learnable attention mask, allowing the network to simultaneously suppress unreliable correspondences and adaptively emphasize informative regions during pose refinement. Extensive experiments on the KITTI odometry benchmark demonstrate that FGD-VO achieves state-of-the-art accuracy among learning-based VO methods, significantly reducing both translational and rotational errors. Our findings suggest that explicitly coupling flow-guided deformable correlation with hybrid masking is a promising direction for improving the reliability and generalization of real-time visual odometry in autonomous systems. We will release our source code to facilitate reproducibility and future research.",
    "key_points": [
      "autonomous driving",
      "visual odometry",
      "deep learning"
    ],
    "gold_summary": "This paper proposed a optical flow-guided visual odometry pipeline. A hybrid masking module is designed to filter outliers. Authors prove the effectiveness of their design on KITTI."
  },
  {
    "paper_id": "iKJbmx1iuQ",
    "title": "Contractive Diffusion Policies: Robust Action Diffusion via Contractive Score-Based Sampling with Differential Equations",
    "domain": "applications to robotics",
    "content": "Diffusion policies have emerged as powerful generative models for offline policy learning, whose sampling process can be rigorously characterized by a score function guiding a Stochastic Differential Equation (SDE). However, the same score-based SDE modeling that grants diffusion policies the flexibility to learn diverse behavior also incurs solver and score-matching errors, large data requirements, and inconsistencies in action generation. While less critical in image generation, these inaccuracies compound and lead to failure in continuous control settings. We introduce **C**ontractive **D**iffusion **P**olicies (CDPs) to induce contractive behavior in the diffusion sampling dynamics. Contraction pulls nearby flows closer to enhance robustness against solver and score-matching errors while reducing unwanted action variance. We develop an in-depth theoretical analysis along with a practical implementation recipe to incorporate CDPs into existing diffusion policy architectures with minimal modification and computational cost. We evaluate CDPs for offline learning by conducting extensive experiments in simulation and real world settings. Across benchmarks, CDPs often outperform baseline policies, with pronounced benefits under data scarcity.",
    "key_points": [
      "diffusion policy",
      "contraction theory",
      "robot learning"
    ],
    "gold_summary": "This paper proposes a novel diffusion policy called contractive diffusion policy. Comprehensive numerical experiments are conducted."
  },
  {
    "paper_id": "wDHaTrs8UT",
    "title": "GDC: From Brittle Optimality to Robust Satisfiability  via Riemannian Risk Geometry",
    "domain": "applications to robotics",
    "content": "Standard reinforcement learning (RL) often yields brittle policies that fail under hard safety constraints. We propose **Geodesic Duality Control (GDC)**, which adapts an agent’s risk posture endogenously by re-weighting the Bellman target using local geometric cues of the value function—specifically, the gradient magnitude $||\\nabla V||$ and a curvature surrogate $\\kappa$. To accommodate piecewise-smooth neural critics, we formulate a Sub-Riemannian / generalized-gradient treatment and provide practical, numerically stable curvature surrogates. Our main theoretical result shows that, under explicit regularity and stochastic-model assumptions, GDC induces a curvature-decreasing learning dynamic:\n\n$$\n\\frac{d\\kappa}{dt} < 0,\n$$\n\nwhich in turn increases a quantifiable safety margin $\\Delta_s$. We validate the mechanism with proof-of-concept experiments—including a hard-boundary safety environment (*Optimal-Trap*), targeted ablations, and a computational-cost study on Humanoid-Safety—to confirm the intended geometric risk posture. We do not claim broad empirical superiority on all benchmarks; rather, the paper’s primary contribution is theoretical, with key components validated empirically.",
    "key_points": [
      "differential geometry",
      "risk-sensitive control",
      "robustness"
    ],
    "gold_summary": "This paper proposes the Geodesic Duality Control (GDC), which adapts an agent’s risk posture endogenously by re-weighting the Bellman target using local geometric cues of the value function, aiming at enhancing safe RL."
  },
  {
    "paper_id": "qRjLjYrvMi",
    "title": "Foundation Models for Industrial Scheduling Leveraging the Techniques from LLMs",
    "domain": "applications to robotics",
    "content": "The advent of large language models (LLMs) has significantly boosted productivity across various sectors. However, their application in the industrial domain remains underexplored and often yields suboptimal results, primarily due to stringent requirements for technological maturity, safety, and standardization. \nTo address this gap, we leverage key techniques instrumental to the success of LLMs—such as the decoder-only architecture and scaling laws—rather than using LLMs directly, to develop a foundational model for industrial scheduling. In contrast to prior methods that focus on specific types of scheduling problems, our model is designed as a general-purpose framework capable of handling diverse task operations, objectives, and constraints reflective of real-world industrial environments. \nThrough extensive experiments, our foundation models have demonstrated clear superiority over conventional scheduling methods and algorithms using LLMs directly. Notably, the foundation models for scheduling have exhibited scaling law, generalization ability, and adaptability analogous to those observed in LLMs. \nThese results indicate that the principles underpinning LLMs extend beyond natural language processing, showing strong potential for broader industrial and manufacturing applications. \nCode at \\url{https://anonymous.4open.science/r/Foundation-Models-for-Industrial-Scheduling-7BD4}",
    "key_points": [
      "industrial scheduling",
      "llms",
      "reinformance learning",
      "scaling law"
    ],
    "gold_summary": "The paper proposes an original decoder only architecture for scheduling problems and compares it to state of the art algorithms and LLMs. It has good results on standard and industrial benchmarks even for multi-objective problems."
  },
  {
    "paper_id": "jG9W6nAwVz",
    "title": "TwinVLA: Data-Efficient Bimanual Manipulation with Twin Single-Arm Vision-Language-Action Models",
    "domain": "applications to robotics",
    "content": "Vision-language-action models (VLAs) trained on large-scale robotic datasets have demonstrated strong performance on manipulation tasks, including bimanual tasks. However, because most public datasets focus on single-arm demonstrations, adapting VLAs for bimanual tasks typically requires substantial additional bimanual data and fine-tuning. To address this challenge, we introduce TwinVLA, a modular framework that composes two copies of a pretrained single-arm VLA into a coordinated bimanual VLA. Unlike monolithic cross-embodiment models trained on mixtures of single-arm and bimanual data, TwinVLA improves both data efficiency and performance by fusing pretrained single-arm policies. Across diverse bimanual tasks in real-world and simulation settings, TwinVLA matches or exceeds previous approaches trained with larger data and compute budgets without requiring *any* bimanual pretraining. These results highlight modular policy composition as a scalable route to bimanual manipulation using existing public single-arm data.",
    "key_points": [
      "vla",
      "bimanual manipulation",
      "imitation learning"
    ],
    "gold_summary": "This paper improves bimanual manipulation by combining single-arm pretraining with a Mixture-of-Experts (MoE) mechanism.\nThis approach enables the model to achieve performance close to state-of-the-art (SOTA) results while using significantly less pretraining data."
  },
  {
    "paper_id": "LnbMSnQpXb",
    "title": "ADDI: A Simplified E2E Autonomous Driving Model with Distinct Experts and Implicit Interactions",
    "domain": "applications to robotics",
    "content": "End-to-end autonomous driving has emerged as a promising research trend aimed at achieving autonomy from a human-like driving perspective. Traditional solutions often divide the task into four sub-tasks—tracking-by-detection, online mapping, prediction, and planning—with several interactions to polish planning. However, this modular approach disrupts the cohesion of autonomous driving by ecomposing these processes and then linking them through interactions, leading to suboptimal and inefficient practical applications. To address this limitation, we propose ADDI, a simple and efficient end-to-end autonomous driving method. First, ADDI integrates tracking-by-detection and online mapping through a unified detection module paired with distinct expert designs, enabling simultaneous output of detection and mapping elements. Second, ADDI employs a unified motion planning model with distinct experts to jointly predict agent trajectories and ego planning trajectories. With this unified model structure, most interactions required by previous methods are rendered unnecessary. ADDI implements two implicit (resource-free) and two explicit interactions to associate the different components. Experimental results demonstrate that ADDI achieves state-of-the-art performance on both open-loop and closed-loop benchmarks while running significantly faster than prior end-to-end methods.",
    "key_points": [
      "cv",
      "imitation learning",
      "applications",
      "3d vision"
    ],
    "gold_summary": "This paper introduces ADDI, which unifies multiple tasks with Tracking&Perception and Motion Planning. Experiments on the open-loop and closed-loop evaluations demonstrate that this method achieves state-of-the-art performance."
  },
  {
    "paper_id": "iuSOOkPxSm",
    "title": "Work Zones challenge VLM Trajectory Planning: Toward Mitigation and Robust Autonomous Driving",
    "domain": "applications to robotics",
    "content": "Visual Language Models (VLMs), with powerful multimodal reasoning capabilities, are gradually integrated into autonomous driving by several automobile manufacturers to enhance planning capability in challenging environment.\nHowever, the trajectory planning capability of VLMs in work zones, which often include irregular layouts, temporary traffic control, and dynamically changing geometric structures, is still unexplored.\nTo bridge this gap, we conduct the first systematic study of VLMs for work zone trajectory planning, revealing that mainstream VLMs fail to generate correct trajectories in 68.0\\% of cases.\nTo better understand these failures, we first identify candidate patterns via subgraph mining and clustering analysis, and then confirm the validity of 8 common failure patterns through human verification.\nBuilding on these findings, we propose REACT-Drive, a trajectory planning framework that integrates VLMs with Retrieval-Augmented Generation (RAG). Specifically,\nREACT-Drive leverages VLMs to convert prior failure cases into constraint rules and executable trajectory planning code, while RAG retrieves similar patterns in new scenarios to guide trajectory generation.\nExperimental results on the ROADWork dataset show that REACT-Drive yields a reduction of around $3\\times$ in average displacement error relative to VLM baselines under evaluation with Qwen2.5-VL.\nIn addition, REACT-Drive yields the lowest inference time ($0.58$s) compared with other methods such as fine-tuning ($17.90$s).\nWe further conduct experiments using a real vehicle in 15 work zone scenarios in the physical world, demonstrating the strong practicality of REACT-Drive. \nOur code and demos are available on https://sites.google.com/view/react-drive.",
    "key_points": [
      "autonomous driving",
      "vision language models",
      "work zones"
    ],
    "gold_summary": "This paper presents a novel approach to addressing the failure of VLM in trajectory planning for autonomous driving, particularly in dynamic and complex work zone environments."
  },
  {
    "paper_id": "zHexNab8uH",
    "title": "Large Language Model-guided Multi-modal Motion Planning via Mixed Integer Program",
    "domain": "applications to robotics",
    "content": "Multi-Modal Motion Planning (M$^3$P) is a rather challenging form of motion planning where the planner searches through the continuous space of motions as well as discrete space of modes. However, brute-force global search is typically sample-inefficient and computationally expensive. Recent research has explored the use of Mixed-Integer Programming (MIP) to reformulate global search problems in robotic applications. MIP leverages the branch-and-bound algorithm to efficiently prune infeasible or sub-optimal solutions. Despite its strengths, MIP is limited to problems with disjoint convex feasible domains---a constraint that is often too restrictive for general motion planning. To address this, prior work has proposed techniques to approximate non-convex motion planning problems as disjoint convex MIPs. Unfortunately, these methods are typically hand-crafted and domain-specific, limiting their generalizability. In this work, we explore the use of Large Language Models (LLMs) to automatically translate non-convex optimization problems into approximate MIP formulations. To this end, we construct a dataset comprising various M$^3$P problems paired with their known MIP approximations. We evaluate LLM performance on this reformulation task using both In-Context Learning (ICL) and Supervised Fine-Tuning (SFT). Our results demonstrate that LLMs are capable of capturing common patterns in MIP reformulations and can even generalize to complex, unseen translation tasks beyond those encountered during fine-tuning.",
    "key_points": [
      "large language model",
      "robotics",
      "mix integer programming"
    ],
    "gold_summary": "This paper introduces LLM+MIP, a large language model that can translate natural-language multi-modal motion planning problems into MIP scripts."
  },
  {
    "paper_id": "qwA04SZeCa",
    "title": "Grounding Multimodal LLMs to Embodied Agents that Ask for Help with Reinforcement Learning",
    "domain": "applications to robotics",
    "content": "Embodied agents operating in household environments must interpret ambiguous and under-specified human instructions. A capable household robot should recognize ambiguity and ask relevant clarification questions to infer the user intent accurately, leading to more effective task execution. To study this problem, we introduce the Ask-to-Act task, where an embodied agent is tasked with a single or multi-object rearrangement task using an under-specified instruction in a home environment. The agent must strategically ask minimal, yet relevant, clarification questions to resolve ambiguity while navigating under partial observability. To address this challenge, we propose a novel approach that fine-tunes multi-modal large language models (MLLMs) as vision-language-action (VLA) policies using online reinforcement learning (RL) with LLM-generated rewards. Our method eliminates the need for large-scale human demonstrations or manually engineered rewards for training such agents. We benchmark against strong zero-shot baselines including GPT-4o as well as supervised fine-tuned MLLMs on our task. Our results show that our RL-finetuned MLLM outperforms all baselines by a significant margin ($10.4$-$16.5\\%$), generalizing well to novel scenes and tasks. To the best of our knowledge, this is the first demonstration of adapting MLLMs as VLA agents that can act and ask for help using LLM-generated rewards with online RL.",
    "key_points": [
      "embodied ai",
      "reinforcement learning"
    ],
    "gold_summary": "The papers proposes to use RL to fun-tune the VLA to VLA by LLM-generated rewards. Also, the paper focus on enable the RL tuned VLA to do multi-round ask-reasoning and act by ultilizing online RL."
  },
  {
    "paper_id": "32lhWShxy8",
    "title": "IN-RIL: Interleaved Reinforcement and Imitation Learning for Policy Fine-Tuning",
    "domain": "applications to robotics",
    "content": "Imitation learning (IL) and reinforcement learning (RL) offer complementary strengths for robot learning, and yet each has severe limitations when used in isolation. Recent studies have proposed hybrid approaches to integrate IL with RL, but still face major challenges such as over-regularization  and  poor sample efficiency. Thus motivated, we develop IN-RIL, \\textbf{IN}terleaved \\textbf{R}einforcement learning and \\textbf{I}mitation \\textbf{L}earning, for policy fine-tuning, which periodically injects IL updates after multiple RL updates. In essence, IN-RIL  leverages\n`alternating optimization' to exploit the strengths of both IL and RL without overly constraining the policy learning, and hence can benefit from both the stability of IL and the expert-guided exploration of RL accordingly. Since IL and RL involve different optimization objectives, we devise gradient separation mechanisms to prevent their interference. Furthermore, our rigorous analysis sheds light on how interleaving IL with RL stabilizes learning and improves iteration efficiency. We conduct extensive experiments on Robomimic, FurnitureBench, and Gym, and demonstrate that IN-RIL as a general plug-in compatible with various state-of-the-art RL algorithms, can improve RL sample efficiency, and mitigate performance collapse.",
    "key_points": [
      "reinforcement learning",
      "imitation learning",
      "robot learning"
    ],
    "gold_summary": "The paper introduces a method for policy finetuning by interleaving RL and IL updates.  The paper provides experimental and theoretical results showing why this approach can result in better performance."
  },
  {
    "paper_id": "4siOgDfJn1",
    "title": "Decoupling Bidirectional Geometric Representations of 4D cost volume via 2D convolution",
    "domain": "applications to robotics",
    "content": "High-performance real-time stereo matching methods invariably rely on 3D regularization of the 4D cost volume, which is unfriendly to mobile devices.\nWhile methods based on 2D regularization of 3D cost volume struggles in ill-posed regions.\nIn this paper, we propose Decoupling  Bidirectional Geometric Representations of 4D cost volume and present a deployment-friendly network DBStereo, which is based on pure 2D convolutions. \nSpecifically, we first provide a thorough analysis of the decoupling characteristics of 4D cost volume. And design a lightweight decoupled bidirectional geometry aggregation block to capture spatial and disparity representation respectively.\nThrough decoupled learning, our approach  achieves real-time performance and impressive accuracy simultaneously.\nExtensive experiments demonstrate that our proposed DBStereo outperforms all existing aggregation-based methods in both  inference time and accuracy, even surpassing the iterative-based methods such as RAFT-Stereo and IGEV-Stereo.\nOur study breaks the empirical design of using 3D convolution for 4D cost volume and provides a simple yet strong baseline, i.e., the proposed decoupled aggregation paradigm, to facilitate further study.",
    "key_points": [
      "stereo matching",
      "deep learning"
    ],
    "gold_summary": "The manuscript proposed DBStereo, which decouples the traditional 3D aggregation into spatial aggregation and disparity aggregation, and outperforms some existing methods in terms of inference time and speed."
  },
  {
    "paper_id": "Fjd2O8RIqu",
    "title": "Beyond Generalist LLMs: Specialist Agentic Systems For Structured Code Workflow Execution",
    "domain": "applications to robotics",
    "content": "The rise of Large Language Models (LLMs) has accelerated the adoption of software development agents, now commonly found as IDE extensions and standalone applications. These agents enable users with minimal programming experience to build complete applications in minutes. Typically designed as generalists, they leverage the broad capabilities of LLMs to perform a wide range of tasks. This versatility raises a key question: do specialist agents offer meaningful advantages over generalist ones, particularly given the additional development effort they require? To explore this question empirically, we focus on business process automation specifically, the transformation of tasks defined in Business Process Model and Notation (BPMN) diagrams into executable agentic workflows. We introduce a specialist workflow tailored for this purpose and evaluate its performance against generalist solutions. Our findings show that, in this context, the specialist agentic solution produces agents that outperform those generated by generalist agents such as Roo and Cline by 2.75% in accurate task completion, while reducing the token cost of agent generation by 96%. Additionally, we identify several limitations in generalist agents, including inconsistent code generation in terms of both functionality and quality. These inconsistencies hinder their applicability in industrial settings, where reliability and maintainability are critical for large-scale adoption.",
    "key_points": [
      "llm agents",
      "automatic creation of agentic systems",
      "efficient workflow generation"
    ],
    "gold_summary": "This paper proposes a specialist agentic system that transforms BPMN diagrams into executable agentic workflows. It evaluates the baseline performance of generalist solutions and confirms the applicability of the proposed system under production."
  },
  {
    "paper_id": "zhYCLQeMIV",
    "title": "GDaT: Generalizable Density-aware Transformer for Solving the Traveling Salesman Problem",
    "domain": "applications to robotics",
    "content": "Recently, Neural Combinatorial Optimization (NCO) solvers have demonstrated significant potential in solving the Traveling Salesman Problem (TSP). However, existing NCO solvers typically model only the positional features of nodes, neglecting the differences in regional density among the unvisited nodes during route construction. This would hinder their generalization capability on tasks with unseen distributions and varying scales. To address this issue, we propose the $\\textbf{G}$eneralizable $\\textbf{D}$ensity-$\\textbf{a}$ware $\\textbf{T}$ransformer ($\\textbf{GDaT}$) for solving the TSP. Specifically, GDaT mainly includes two modules: the multi-scale density extraction module and the density-aware attention module. The former generates multiple nested subgraphs of each unvisited node via the k-nearest neighbors strategy and estimates its densities using Gaussian kernels under each nested subgraph. These densities are then fused by a multi-layer perceptron for capturing multi-scale density features for each unvisited node during route construction. The latter leverages the extracted multi-scale density features to guide the attention-based modeling of positional features, enabling the model to perceive variations in problem scale and node distribution, thereby facilitating more accurate next-node selection under unseen distributions and varying scales. Experimental results on synthetic and real-world TSP datasets across diverse scales and distributions demonstrate that GDaT achieves superior generalization performance.",
    "key_points": [
      "neural combinatorial optimization",
      "traveling salesman problem",
      "generalization",
      "density-aware modeling"
    ],
    "gold_summary": "This manuscript proposes GDaT to solve TSP with unseen distributions and varying scales."
  },
  {
    "paper_id": "Yz2DnYBJXd",
    "title": "MVP: Memory-enhanced Vision-Language-Action Policy with Feedback Learning",
    "domain": "applications to robotics",
    "content": "Recent advances in Vision-Language-Action (VLA) models have enabled robots to perform a wide range of manipulation tasks conditioned on language instructions, offering strong generalization across tasks, objects, and environments. However, most existing VLAs operate under a Markov assumption, limiting their ability to handle temporally extended tasks and learn from feedback. To address these limitations, we propose MVP, a non-Markovian VLA model that leverages episodic memory composed of historical actions and visual observations. To mitigate the computational cost of storing high-dimensional histories, we introduce a compact memory representation inspired by video understanding techniques. Additionally, to prevent the model from disregarding historical inputs during training, we design a novel feedback learning strategy based on SO(3) trajectory perturbation. This approach encourages the model to associate actions with their environmental consequences through observation-action-observation sequences. Experimental results on both simulated and real-world benchmarks demonstrate that MVP outperforms existing models, particularly on tasks that require temporal reasoning and history-dependent decision-making. Our findings highlight the importance of memory and feedback in advancing the capabilities of general-purpose robotic manipulation systems.",
    "key_points": [
      "robotic manipulation",
      "vision-language-action models",
      "memory"
    ],
    "gold_summary": "This paper proposes a non-Markovian Vision-Language-Action (VLA) model that incorporates past observations and actions as auxiliary information, along with an augmentation method to enhance robustness."
  },
  {
    "paper_id": "LQD1MrnbxH",
    "title": "Test-Time Mixture of World Models for Embodied Agents in Dynamic Environments",
    "domain": "applications to robotics",
    "content": "Language model (LM)-based embodied agents are increasingly deployed in real-world settings. Yet, their adaptability remains limited in dynamic environments, where constructing accurate and flexible world models is crucial for effective reasoning and decision-making. To address this challenge, we extend the Mixture-of-Experts (MoE) paradigm to embodied agents. While conventional MoE architectures modularize knowledge into expert components with pre-trained routing, they remain rigid once deployed, making them less effective for adapting to unseen domains in dynamic environments. We therefore propose Test-time Mixture of World Models (TMoW), a framework that enhances adaptability to unseen and evolving domains. TMoW updates its routing function over world models at test time, unlike conventional MoE where the function remains fixed, enabling agents to recombine existing models and integrate new ones for continual adaptation. It achieves this through (i) multi-granular prototype-based routing, which adapts mixtures across object- to scene-level similarities, (ii) test-time refinement that aligns unseen domain features with prototypes during inference, and (iii) distilled mixture-based augmentation, which efficiently constructs new models from few-shot data and existing prototypes. We evaluate TMoW on VirtualHome, ALFWorld, and RLBench benchmarks, demonstrating strong performance in both zero-shot adaptation and few-shot expansion scenarios, and showing that it enables embodied agents to operate effectively in dynamic environments.",
    "key_points": [
      "embodied ai",
      "world model",
      "mixture of expert",
      "test time adaptation",
      "few-shot expansion"
    ],
    "gold_summary": "This paper proposes the Test-time Mixture of World Models (TMoW) framework to enable embodied agents to adapt dynamically to unseen domains through prototype-based routing and mixture refinement."
  },
  {
    "paper_id": "f2nxdOv1Uh",
    "title": "MTG-RPD: Multimodal Trajectories Generation with Rule-Based Prior Diffusion for End-to-End Autonomous Driving",
    "domain": "applications to robotics",
    "content": "Replicating human driving behaviors in complex and authentic real-world environments remains a key challenge in autonomous driving. While end-to-end autonomous driving technologies have advanced substantially, generating safe and diverse multimodal trajectories poses a persistent hurdle. In recent years, diffusion-based methods have demonstrated remarkable potential across image generation, robotics, and autonomous driving—with trajectory generation approaches based on diffusion models also emerging. However, balancing real-time performance and reconstruction accuracy remains an unresolved issue. To address these limitations, we propose MTG-RPD, an innovative trajectory generation method that integrates rule-based prior knowledge. The approach first generates trajectory anchor points via rule-based prior clustering, then leverages a conditional diffusion model to transform an anchored Gaussian distribution into a multimodal trajectory distribution under scene information guidance. Notably, the diffusion model is specifically designed to facilitate agent-agent and agent-environment interactions. On the planning-based NAVSIM dataset, MTG-RPD achieved a PDMS of 88.5 when evaluated using the ResNet-34 backbone network.",
    "key_points": [
      "end-to-end autonomous driving",
      "trajectory planning"
    ],
    "gold_summary": "This paper introduces MTG-RPD, an innovative trajectory generation method that integrates rule-based prior knowledge for end-to-end autonoumous driving."
  },
  {
    "paper_id": "TNfjckDeh4",
    "title": "UnLoc: Leveraging Depth Uncertainties for Floorplan Localization",
    "domain": "applications to robotics",
    "content": "We propose UnLoc, an efficient data-driven solution for sequential camera localization within floorplans. Floorplan data is readily available, long-term persistent, and robust to changes in visual appearance. We address key limitations of recent methods, such as the lack of uncertainty modeling in depth predictions and the necessity for custom depth networks trained for each environment. We introduce a novel probabilistic model that incorporates uncertainty estimation, modeling depth predictions as explicit probability distributions. By leveraging off-the-shelf pre-trained monocular depth models, we eliminate the need to rely on per-environment-trained depth networks, enhancing generalization to unseen spaces. We evaluate UnLoc on large-scale synthetic and real-world datasets, demonstrating significant improvements over existing methods in terms of accuracy and robustness. Notably, we achieve $2.7$ times higher localization recall on long sequences (100 frames) and $42.2$ times higher on short ones (15 frames) than the state of the art on the challenging LaMAR HGE dataset.",
    "key_points": [
      "floorplan localization",
      "sequential localization",
      "depth uncertainties",
      "mono-depth networks"
    ],
    "gold_summary": "This paper proposes combining pre-trained depth models with uncertainty modeling to improve the accuracy of floor-plan localization. Experiments are conducted on multiple datasets, including both real-world and synthetic scenes."
  },
  {
    "paper_id": "oXYZHg7HiZ",
    "title": "Interactive Post-Training for Vision-Language-Action Models",
    "domain": "applications to robotics",
    "content": "We introduce RIPT-VLA, a simple and scalable reinforcement-learning-based interactive post-training paradigm that fine-tunes pretrained Vision-Language-Action (VLA) models using only sparse binary success rewards. Existing VLA training pipelines rely heavily on offline expert demonstration data and supervised imitation, limiting their ability to adapt to new tasks and environments under low-data regimes. RIPT-VLA addresses this by enabling interactive post-training with a stable policy optimization algorithm based on dynamic rollout sampling and leave-one-out advantage estimation. Without requiring shaped rewards or value models, RIPT-VLA achieves state-of-the-art results across a wide range of tasks and benchmarks. It improves the lightweight QueST model by up to 21.2% in few-shot settings, achieving state-of-the-art 94.3% on LIBERO-90, and pushes the large-scale OpenVLA-OFT model to achieve 97.5% on the LIBERO 4-Suite benchmark. Remarkably, when only one demonstration is given, RIPT-VLA enables an unworkable SFT model (4%) to succeed with 97% success rate within 15 iterations. These results highlight RIPT-VLA as a practical and effective paradigm for post-training VLA models through minimal supervision. Code and checkpoints will be released (We included anonymous code in the supplementary material for review).",
    "key_points": [
      "reinforcement learning",
      "vla"
    ],
    "gold_summary": "This paper proposes RIPT-VLA, advancing VLA models via enabling interactive post-training with dynamic rollout sampling and stable reinforcement learning methods.\nExperiments on various VLA benchmarks demonstrate that RIPT-VLA outperforms existing methods and has significant generalisation ability."
  },
  {
    "paper_id": "MSL8gSuCj2",
    "title": "Can Weak Quantization Make World Models Physically Interpretable?",
    "domain": "applications to robotics",
    "content": "Deep learning models are increasingly employed for perception, prediction, and control in autonomous systems. For achieving realistic and consistent outputs, it is crucial to embed physical knowledge into their learned representations. \n However, doing so is difficult due to high-dimensional observation data, such as images, particularly under conditions of incomplete system knowledge and imprecise state sensing. To address this, we propose  Physically Interpretable World Models, a novel architecture that aligns learned latent representations with real-world physical quantities. To this end, our architecture combines a physical interpretable image autoencoding model and a partially known learnable dynamical model. We conduct an in-depth analysis of the latent space, evaluating the effects of continuous versus discrete representations, as well as intrinsic versus extrinsic physical interpretable encodings. The training incorporates weak distributional supervision to eliminate the impractical reliance on ground-truth physical knowledge. Through three case studies, we demonstrate that our approach not only provides physical interpretability but also achieves state prediction accuracy superior to state-of-the-art models, thus advancing interpretable representation learning.",
    "key_points": [
      "world models",
      "physically interpretable representation learning",
      "autoencoders"
    ],
    "gold_summary": "The paper presents Physically Interpretable World Models where the main idea is to constraint the physical information in the latent space. Two ideas - intrinsic and extrinsic are presented to investigate the same."
  },
  {
    "paper_id": "tmIRNo66Rg",
    "title": "TriVLA: A Triple-System-Based Unified Vision-Language-Action Model with Episodic World Modeling for General Robot Control",
    "domain": "applications to robotics",
    "content": "Recent advances in vision–language models (VLMs) have enabled robots to follow open-ended instructions and demonstrate impressive commonsense reasoning. However, current vision–language–action (VLA) frameworks primarily rely on static representations and limited temporal context, restricting agents to short-horizon, reactive behaviors and hindering robust generalization in dynamic embodied environments. Inspired by cognitive neuroscience theories of episodic memory, we are, to our knowledge, among the first to introduce a formalized episodic world model in VLA, enabling embodied robots to accumulate, recall, and predict sequential experiences. As an instantiation of this concept, our unified \\textbf{TriVLA} realizes the episodic world model through a triple-system architecture: integrating multimodal grounding from a pretrained VLM (System 2) and temporally rich dynamics perception from a video diffusion model (System 3). This enables the agent to accumulate and recall sequential experiences, interpret current contexts, and predict future environmental evolution. Guided by episodic representations that span both the past and anticipated future, the downstream policy (System 1) generates coherent, context-aware action sequences through flow-matching and cross-modal attention mechanisms. Experimental results show that TriVLA operates efficiently at ~36 Hz and consistently outperforms baseline models on standard benchmarks and challenging real-world manipulation tasks. It demonstrates strong long-horizon planning and open-ended intent understanding, showcasing the advantages of episodic world model-inspired reasoning for robust, generalizable robot intelligence.",
    "key_points": [
      "vision-language-action model (vla)",
      "episodic world model",
      "general robot control",
      "imitation learning"
    ],
    "gold_summary": "The paper aims to train VLAs more effectively. The proposed method leverages a pretrained and fine-tuned diffusion model to generate predicted future frames that hopefully can help  the prediction of current actions."
  },
  {
    "paper_id": "ey2w57KZTe",
    "title": "RoboMemory: A Brain-inspired Multi-memory Agentic Framework for Interactive Environmental Learning in Physical Embodied Systems",
    "domain": "applications to robotics",
    "content": "Embodied agents face persistent challenges in real-world environments, including partial observability, limited spatial reasoning, and high-latency multi-memory integration. We present RoboMemory, a brain-inspired framework that unifies Spatial, Temporal, Episodic, and Semantic memory under a parallelized architecture for efficient long-horizon planning and interactive environmental learning. A dynamic spatial knowledge graph (KG) ensures scalable and consistent memory updates, while a closed-loop planner with a critic module supports adaptive decision-making in dynamic settings. Experiments on EmbodiedBench show that RoboMemory, built on Qwen2.5-VL-72B-Ins, improves average success rates by 25% over its baseline and exceeds the closed-source state-of-the-art (SOTA) Gemini-1.5-Pro by 3%. Real-world trials further confirm its capacity for cumulative learning, with performance improving across repeated tasks. These results highlight RoboMemory as a scalable foundation for memory-augmented embodied intelligence, bridging the gap between cognitive neuroscience and robotic autonomy.",
    "key_points": [
      "embodied ai",
      "agentic ai",
      "interactive environmental learning",
      "brain-like memory"
    ],
    "gold_summary": "A method called RoboMemory is proposed for creating an agent with memory based on a visual-language model for embodied artificial intelligence tasks."
  },
  {
    "paper_id": "6MgD2sXZmg",
    "title": "Deep Cognition: A Multi-Agent Framework for Collaborative Research with Real-Time Cognitive Oversight",
    "domain": "applications to robotics",
    "content": "Despite advances in large language models, current systems for deep research are limited by an asynchronous, \"input-wait-output\" interaction paradigm. This model creates a critical disconnect between human intent and AI execution, leading to error propagation and an inability to dynamically course-correct during complex problem-solving. We propose that a more effective form of human-AI partnership requires a shift from passive command-giving to cognitive oversight, where humans actively guide and intervene in the AI's thinking process. This perspective treats interaction as a core component of intelligence, rather than a peripheral interface.\n\nWe introduce Deep Cognition, a system designed to enable this paradigm through three technical pillars: transparent and interruptible AI reasoning, fine-grained bidirectional dialogue, and a shared cognitive context. At the core of our system is a layered StateManager architecture and a novel multi-stage budget allocation algorithm. This architecture ingests and normalizes all interaction data (e.g., dialogue trajectories and user artifacts) into a perpetually optimized, high-information-density working memory. By dynamically prioritizing context based on a combination of static heuristics and a time-sensitive scoring function, our system mitigates error cascades and allows the AI to adapt its reasoning pathways based on the user's implicit focus.\n\nWe conduct a comprehensive user study on challenging deep research tasks to evaluate the efficacy of our system. Results show that our approach significantly enhances the user experience, yielding improvements of up to 29.2% in Fine-Grained Interaction and 27.7% in Ease of Collaboration compared to a competitive baseline. Most notably, our system demonstrates a 31.8% to 50.0% points improvement in overall task performance. These results highlight the critical importance of designing interactive AI systems that facilitate continuous human guidance and transparent reasoning, rather than merely responding to isolated commands.",
    "key_points": [
      "interactive ai systems",
      "human-in-the-loop",
      "multi agent framework"
    ],
    "gold_summary": "This paper suggests an extended DeepResearch system where the agent can proactively ask for clarifing questions."
  },
  {
    "paper_id": "WatS7243Zl",
    "title": "ReDiG: Reinforced Diffusion on Graphs for Decentralized Coordinated Multi-Robot Navigation with Smooth Formation Adaptation",
    "domain": "applications to robotics",
    "content": "Coordinated navigation is a fundamental capability for multi-robot teams to traverse complex unstructured environments.\nDuring navigation, robots are often required to maintain mission-specific formations, such as wedge formations for enhanced visibility and area coverage.\nHowever, rigid formations can hinder navigation in challenging scenarios like narrow corridors, which demand formation adaptation.\nReinforcement learning (RL) is commonly used for coordinated multi-robot navigation due to its ability to learn through interaction with the environment.\nHowever, its step-wise decision-making process often results in jerky motion.\nIn contrast, diffusion models generate smoother trajectories through probabilistic denoising, but rely heavily on high-quality demonstrations.\nCollecting such demonstrations is challenging in multi-robot systems due to the coordination and synchronization required among individual robots.\nTo address these issues, we introduce a novel method named Reinforced Diffusion on Graphs (ReDiG) to enable\ndecentralized coordinated multi-robot navigation with smooth formation adaptation. \nUnder a unified learning paradigm, ReDiG integrates:\n(1) graph learning for decentralized coordination to enable formation adaptation,\n(2) diffusion models for generating smooth individual robot trajectories, and\n(3) online RL to refine noisy demonstrations by leveraging feedback from environment interaction, which enables robot synchronization and guides effective diffusion training.\nWe evaluate ReDiG through extensive experiments in both indoor and outdoor environments using physical robot teams and robotics simulations.\nExperimental results show that ReDiG enables smooth formation adaptation and achieves state-of-the-art performance in coordinated multi-robot navigation within complex environments.\nMore details are available on the project website: https://anonymous23885.github.io/ReDiG",
    "key_points": [
      "decentralized multi-robot systems",
      "diffusion model",
      "reinforcement learning",
      "graph learning"
    ],
    "gold_summary": "This paper proposes a learning-based method to achieve decentralized multi-robot navigation with smooth formation adaptation. Experimental results in both indoor and outdoor environments demonstrate the effectiveness of the proposed method."
  },
  {
    "paper_id": "JjOGAvb7oc",
    "title": "Holistic Advances through Large-Scale Embodied Dialog Augmentation for Navigation",
    "domain": "applications to robotics",
    "content": "For embodied agents capable of physical interaction, dialog capability is crucial to ensure both safety and effectiveness. \nWhile DialNav provides a framework for holistic evaluation of the dialog--execution loop in photorealistic indoor navigation, its performance is constrained. \nIn this work, we introduce holistic advances spanning data and training.\nFirst, we develop a large-scale dialog generation pipeline to enhance coverage and diversity. Second, we propose task-aligned training for the Navigator to better reflect the dynamic dialog–navigation loop. \nFinally, we address the bottleneck of localization with a stronger graph-aware transformer model. \nTogether, these advances more than double success rates over prior baselines, achieving 58.24% SR on Val Seen and 29.05% on Val Unseen, establishing a new state of the art in dialog-driven embodied navigation.",
    "key_points": [
      "vln",
      "embodied dialog"
    ],
    "gold_summary": "This paper presents incremental results on the embodied dialogue navigation task."
  },
  {
    "paper_id": "hTTfQG7fwN",
    "title": "MAPLE: Context-aware Multimodal Augmentation for Long-tail 3D Object Detection",
    "domain": "applications to robotics",
    "content": "3D object detection is essential for autonomous driving but remains limited by the long-tail distribution of real-world data. \nInstance-level augmentation methods, whether copy-paste or asset rendering, are typically restricted to LiDAR and offer only modest variation with limited scene context. \nWe introduce MAPLE, a training-free pipeline for multimodal augmentation that generates synchronized RGB-LiDAR pairs. \nObjects are inserted through context-aware inpainting in the image domain, and paired pseudo-LiDAR is reconstructed via depth estimation. \nTo ensure cross-modal plausibility, MAPLE incorporates semantic and geometric verification modules that filter inconsistent generations. \nWe further propose a success-rate evaluation that quantifies error reduction across verification stages, providing a principled measure of pipeline reliability. \nOn the nuScenes benchmark, MAPLE consistently improves both detection and segmentation in multimodal and LiDAR-only settings. \nCode will be released publicly.",
    "key_points": [
      "instance augmentation",
      "3d perception",
      "autonomous driving"
    ],
    "gold_summary": "The paper proposes a training-free pipeline for multimodal instance augmentation to address long-tail 3D object detection. It generates synchronized RGB–LiDAR pairs by inserting objects via context-aware image inpainting and reconstructing pseudo-LiDAR through depth estimation."
  },
  {
    "paper_id": "BK7Mk5d4WE",
    "title": "LongHorizonUI: A Unified Framework for Robust long-horizon Task Automation of GUI Agent",
    "domain": "applications to robotics",
    "content": "Although agents based on multimodal large language models (MLLMs) demonstrate proficiency in general short-term graphical user interface (GUI) tasks, their robustness remains a significant challenge for handling complex long-horizon tasks in dynamic environments . In response, the LongHorizonUI framework is proposed to improve the sustained reliability of agents in long-horizon GUI tasks. To overcome core limitations, we establish a comprehensive long-horizon benchmark, LongGUIBench, covering multiple categories of games and complex general applications, with long-horizon tasks defined as requiring more than 15 steps for rigorous evaluation of long-horizon reasoning capabilities. Based on this, a Multimodal Enhanced Perceiver is designed to incorporate element detection and text recognition models, assigning unique indices to interface elements, thereby reinforcing state representation. Furthermore, a Deep Reflection Decider engine is introduced, incorporating a structured multi-level feedback validation mechanism to enable progressive reasoning and ensure accurate action execution with predictable trajectories. Finally, we introduce a Compensatory Action Executor that combines multiple degradation compensation operations with a process rollback strategy based on execution progress monitoring to ensure operational effectiveness in long-horizon task logic. Experimental results demonstrate that LongHorizonUI achieves substantial long-horizon modeling improvements on LongGUIBench while retaining competitive performance on diverse public benchmarks. The code and models will be publicly available.",
    "key_points": [
      "multimodal large language models"
    ],
    "gold_summary": "The paper primarily addresses the performance degradation of GUI agents in long-horizon tasks (over 15 steps), proposing a unified framework named LongHorizonUI along with a corresponding long-task benchmark, LongGUIBench."
  },
  {
    "paper_id": "qswPmdtuPM",
    "title": "KineDiff3D: Kinematic-Aware Diffusion for Category-Level Articulated Object Shape Reconstruction and Generation",
    "domain": "applications to robotics",
    "content": "Articulated objects, such as laptops and drawers, exhibit significant challenges for 3D reconstruction and pose estimation due to their multi-part geometries and variable joint configurations, which introduce structural diversity across different states. To address these challenges, we propose KineDiff3D: Kinematic-Aware Diffusion for Category-Level Articulated Object Shape Reconstruction and Generation, a unified framework for reconstructing diverse articulated instances and pose estimation from single view input. Specifically, we first encode complete geometry (SDFs), joint angles, and part segmentation into a structured latent space via a novel Kinematic-Aware VAE (KA-VAE). In addition, we employ two conditional diffusion models: one for regressing global pose (SE(3)) and joint parameters, and another for generating the kinematic-aware latent code from partial observations. Finally, we produce an iterative optimization module that bidirectionally refines reconstruction accuracy and kinematic parameters via Chamfer-distance minimization while preserving articulation constraints. Experimental results on synthetic, semi-synthetic, and real-world datasets demonstrate the effectiveness of our approach in accurately reconstructing articulated objects and estimating their kinematic properties.",
    "key_points": [
      "articulated object reconstruction​​， articulated object generation​，articulated object pose estimation"
    ],
    "gold_summary": "This paper presents KineDiff3D, a diffusion-based framework for reconstructing articulated 3D objects from sparse multi-view or single-view inputs. The approach achieves state-of-the-art results on benchmarks like PartNet-Mobility and new synthetic data."
  },
  {
    "paper_id": "8soGuDwlxK",
    "title": "SymLight: Exploring Interpretable and Deployable Symbolic Policies for Traffic Signal Control",
    "domain": "applications to robotics",
    "content": "Deep Reinforcement Learning have achieved significant success in automatically devising effective traffic signal control (TSC) policies. Neural policies, however, tend to be over-parameterized and non-transparent, hindering their interpretability and deployability on resource-limited edge devices. This work presents SymLight, a priority function search framework based on Monte Carlo Tree Search (MCTS) for discovering inherently interpretable and deployable symbolic priority functions to serve as the TSC policies. The priority function, in particular, accepts traffic features as input and then outputs a priority for each traffic signal phase, which subsequently directs the phase transition. For effective search, we propose a concise yet expressive priority function representation. This helps mitigate the combinatorial explosion of the action space in MCTS. Additionally, a probabilistic structural rollout strategy is introduced to leverage structural patterns from previously discovered high-quality priority functions, guiding the rollout process. Our experiments on real-world datasets demonstrate SymLight's superior performance across a range of baselines. A key advantage is SymLight's ability to produce interpretable and deployable TSC policies while maintaining excellent performance. Our codes will be released upon acceptance.",
    "key_points": [
      "reinforcement learning",
      "traffic signal control",
      "monte carlo tree search"
    ],
    "gold_summary": "This paper proposed a Monte Carlo Tree Search method to improve the interpretability of traffic signal control. Experiments show that the performance is achieved a new SOTA."
  },
  {
    "paper_id": "03Ek1qDZmI",
    "title": "SSTP: Efficient Sample Selection for Trajectory Prediction",
    "domain": "applications to robotics",
    "content": "Trajectory prediction is a core task in autonomous driving. However, training advanced trajectory prediction models on existing large-scale datasets is both time-consuming and computationally expensive. More critically, these datasets are highly imbalanced in scenario density, with normal driving scenes (low-moderate traffic) overwhelmingly dominating the datasets, while high-density and safety-critical cases are underrepresented. As a result, models tend to overfit low/moderate-density scenarios and perform poorly in high-density scenarios. To address these challenges, we propose the SSTP framework, which constructs a compact yet density-balanced dataset tailored to trajectory prediction. SSTP consists of two main stages: (1) Extraction, where a baseline model is pretrained for a few epochs to obtain stable gradient estimates, and the dataset is partitioned by scenario density. (2) Selection, where gradient-based scores and a submodular objective select representative samples within each density category, while biased sampling emphasizes rare high-density interactions to avoid dominance by low-density cases. This approach significantly reduces the dataset size and mitigates scenario imbalance, without sacrificing prediction accuracy. Experiments on the Argoverse 1 and Argoverse 2 datasets with recent state-of-the-art models show that SSTP achieves comparable performance to full-dataset training using only half the data while delivering substantial improvements in high-density traffic scenes and significantly reducing training time. Robust trajectory prediction depends not only on data scale but also on balancing scene density to ensure reliable performance under complex multi agent interactions. The code is available at https://anonymous.4open.science/r/SSTP_v2-69E5/README.md.",
    "key_points": [
      "data efficiency",
      "trajectory prediction"
    ],
    "gold_summary": "The paper aims to address an important problem of reducing dependency on large-scale datasets in trajectory prediction, particularly under imbalanced data distributions."
  },
  {
    "paper_id": "pjBQRDmx9u",
    "title": "Robots Ask the Way: Communication-Enabled Social Navigation",
    "domain": "applications to robotics",
    "content": "Assistive autonomous robots operating in multi-agent environments require efficient strategies to locate specific individuals among multiple residents. Current social navigation methods focus on reactive collision avoidance and trajectory adaptation, but lack mechanisms to proactively gather information through human-robot communication.\n\nWe introduce Communication-enabled Social Navigation (CommNav). In this novel task, robotic agents actively seek assistance from residents to locate target individuals by requesting information about recent sightings, locations, and movement patterns.\nTo evaluate CommNav, we extend Habitat 3.0 to create Habitat 3.0c, a communication-enabled variant supporting multi-human environments with structured information exchange protocols. Adding COMM to a state-of-the-art social navigation model yields an improvement of 7\\% in finding a specific individual and 8\\% in overall episode success.\n\n\nOur experiments reveal that: (i) explicit human-robot communication substantially enhances multi-person navigation performance; (ii) pre-training COMM on a communication pretext task effectively addresses the challenge of occasional interaction signals.",
    "key_points": [
      "embodied ai",
      "simulator",
      "social navigation"
    ],
    "gold_summary": "This paper presents an approach for a robot to proactively ask questions to bystanders in an environment when tasked to search for a specific human in an environment."
  },
  {
    "paper_id": "otrng1WHxG",
    "title": "World-Env: Leveraging World Model as a Virtual Environment for VLA Post-Training",
    "domain": "applications to robotics",
    "content": "Vision-Language-Action (VLA) models trained via imitation learning suffer from significant performance degradation in data-scarce scenarios due to their reliance on large-scale demonstration datasets. Although reinforcement learning (RL)-based post-training has proven effective in addressing data scarcity, its application to VLA models is hindered by the non-resettable nature of real-world environments. This limitation is particularly critical in high-risk domains such as industrial automation, where interactions often induce state changes that are costly or infeasible to revert. Furthermore, existing VLA approaches lack a reliable mechanism for detecting task completion, leading to redundant actions that reduce overall task success rates. To address these challenges, we propose World-Env, an RL-based post-training framework that replaces physical interaction with a low-cost, world model-based virtual simulator. World-Env  consists of two key components: (1) a video-based world simulator that generates temporally consistent future visual observations, and (2) a vision-language model (VLM)-guided instant reflector that provides continuous reward signals and predicts action termination. This simulated environment enables VLA models to safely explore and generalize beyond their initial imitation learning distribution. Our method achieves notable performance gains with as few as five expert demonstrations per task. Experiments on complex robotic manipulation tasks demonstrate that World-Env effectively overcomes the data inefficiency, safety constraints, and inefficient execution of conventional VLA models that rely on real-world interaction, offering a practical and scalable solution for post-training in resource-constrained settings.",
    "key_points": [
      "vla; world model; rl"
    ],
    "gold_summary": "The paper proposes World-Env, a post-training framework to finetune pretrained VLA models on a learned world model and reward / done model (reflector)."
  },
  {
    "paper_id": "e0RmOknoM4",
    "title": "ContextVLA: Vision-Language-Action Model with Amortized Multi-Frame Context",
    "domain": "applications to robotics",
    "content": "Leveraging temporal context is crucial for success in partially observable robotic tasks. However, prior work in behavior cloning has demonstrated inconsistent performance gains when using multi-frame observations. In this paper, we introduce ContextVLA, a policy model that robustly improves robotic task performance by effectively leveraging multi-frame observations. Our approach is motivated by the key observation that Vision-Language-Action models (VLA), i.e., policy models built upon a Vision-Language Model (VLM), more effectively utilize multi-frame observations for action generation. This suggests that VLMs’ inherent temporal understanding capability enables them to extract more meaningful context from multi-frame observations. However, the high dimensionality of video inputs introduces significant computational overhead, making VLA training and inference inefficient. To address this, ContextVLA compresses past observations into a single context token, allowing the policy to efficiently leverage temporal context for action generation. Our experiments show that ContextVLA consistently improves over single-frame VLAs and achieves the benefits of full multi-frame training but with reduced training and inference times.",
    "key_points": [
      "vision-language-action model",
      "imitation learning",
      "multi-frame policy"
    ],
    "gold_summary": "This work enables the usage of multi-frame visual observations for action generation in VLAs, while mitigating common problems that come with history-conditioned policies such as causal confusion. The proposed approach is additionally computationally efficient."
  },
  {
    "paper_id": "OKGcbsGMqc",
    "title": "Nostra: Enabling Robust Robot Imitation via Multimodal Latent Imagination",
    "domain": "applications to robotics",
    "content": "Similar to humans, robots benefit from multiple sensing modalities when performing complex manipulation tasks. Current behavior cloning (BC) policies typically fuse learned observation embeddings from multimodal inputs before decoding them into actions. This approach suffers from two key limitations: 1) it requires all modalities to be present and in-distribution at test time, otherwise corrupting the latent state and leading to fragile execution; and 2) naive fusion across all inputs hinders learning from large-scale heterogeneous datasets, where only a subset of modalities may be informative at different phases of a task. We introduce Nostra, a multimodal state-space model that learns a modular per-modality latent representation, enabling flexible action prediction with or without specific inputs. BC-Nostra improves robustness to unseen noise by using KL divergence between inferred and imagined multimodal latents as a noise measure, and by employing latent imagination to predict action trajectories over arbitrary horizons. On a suite of MuJoCo-based tasks, BC-Nostra fits expert demonstrations up to six input modalities (multi-view RGB, depth, and proprioception), achieving over 20% higher performance under noisy evaluation. Furthermore, Nostra adaptively down-weights non-informative inputs, facilitating effective co-training on large heterogeneous robotics datasets with O(10k) demonstrations spanning diverse tasks and visual conditions. Finally, we demonstrate real-world deployment, where BC-Nostra achieves up to a 40% performance gain under camera occlusions on multiple manipulation tasks.",
    "key_points": [
      "robotics",
      "multimodality",
      "state-space models",
      "robustness"
    ],
    "gold_summary": "The paper presents an approach for robot learning using behavior cloning. The architecture is a state-space model with per-modality latents. The model is evaluated on simulated robotic manipulation tasks."
  },
  {
    "paper_id": "m6mRGNO7Yj",
    "title": "Teleportation, Simulation, or Human Video? Data Utilization Law for Robot Manipulation",
    "domain": "applications to robotics",
    "content": "Teleoperation, simulation, and human video represent the three primary data sources for robotic manipulation. Teleoperation data offers high quality at a high collection cost, whereas simulation and human video data are cheaper to acquire but introduce significant embodiment gaps. This trade-off has sparked a debate in the robotics community about the most effective data types for training robot policies. To address this, we introduce a data utilization law for robotic manipulation, drawing an analogy from economics to establish a formal \"exchange rate\" across data types. We quantify data utilization by using a single real-world teleoperated trajectory as a base unit and then measuring the volume of other data (i.e., simulation or human video) required to achieve equivalent performance. Through a comprehensive investigation across three manipulation tasks—training Diffusion Policy and $\\pi_{0}$ on over 8000 trajectories—we systematically analyze the interplay between real, simulated, and human video data. Our analysis reveals several key findings: 1) Simulation data generally improves model generalization, with an approximate exchange rate of 8 simulation samples providing the equivalent benefit of 1 teleoperated sample. 2) Human video tends to degrade in-domain model performance, where adding approximately 10 human video samples can negate the benefit of a single teleoperated data point. 3) Whether human video helps generalization or simulation aids in-domain performance varies significantly across tasks. We believe that our work provides crucial insights into balancing the costs of data collection with the computational demands of model training.",
    "key_points": [
      "data utility law",
      "imitation learning",
      "robotic manipulation"
    ],
    "gold_summary": "The paper studies the relative utility of different data sources (teleoperated data, simulation, human video) for robotic manipulation."
  },
  {
    "paper_id": "NAXQWSwDUD",
    "title": "FlashPlanner: Accelerating Diffusion-based Planner for Autonomous Driving via Globally Consistent Velocity Field and Redundancy Reduction",
    "domain": "applications to robotics",
    "content": "Standard diffusion and flow matching approaches have recently been explored as imitation-based planners for autonomous driving due to their ability to produce multi-modal trajectories with high fidelity. However, these methods still suffer from limitations, e.g., low efficiency and reliance on post-processing. These issues are alleviated through practices from conventional imitation-based methods, but the principles of well-designed diffusion-based planners are still underexplored. In this paper, we propose FlashPlanner, a flow-matching-based planner for online planning of autonomous driving. FlashPlanner introduces a novel globally consistent velocity field as the training objective, which frames flow matching to model instantaneous dynamics in a consistent velocity field. This training objective manages to unleash the potential of diffusion-based planners and enables stable one-step generation of high-quality trajectories in closed-loop planning. Moreover, we systematically analyze the existing design choices of diffusion-based methods and prune inherent redundancy, which further accelerates the diffusion-based planning. It achieves state-of-the-art performance on the closed-loop nuPlan benchmark and delivers 12× faster inference (166FPS) compared to the existing best baseline (13FPS). We will open-source our project.",
    "key_points": [
      "autonomous driving",
      "flow matching",
      "generative model"
    ],
    "gold_summary": "This paper introduces FlashPlanner, an approach that empirically investigates the training of diffusion planners. By employing a flow matching loss and several architectural modifications, it achieves state-of-the-art performance on the nuPlan benchmark."
  },
  {
    "paper_id": "Ha9JSVDIQo",
    "title": "SpinVLA: A Spectral-Invariant Vision-Language-Action Model for Robotic Manipulation",
    "domain": "applications to robotics",
    "content": "Vision-language-action (VLA) models trained on large-scale robot demonstration datasets have achieved impressive in-distribution performance, yet they can fail catastrophically under minor domain shifts. For instance, a VLA-trained robot tasked to “pick the red block” may flounder due to various environmental disturbances such as lighting changes or scene clutter. To address this limitation, we propose SpinVLA, a novel end-to-end VLA architecture that leverages the mathematical equivalence between spectral decomposition and contrastive learning to improve robustness. Drawing inspiration from causal inference principles, which suggest that stable features persist across environments, we hypothesize that consistent patterns in successful demonstrations represent task-relevant information rather than spurious correlations, i.e., statistical associations unrelated to the true causal factors of task performance. Our approach integrates spectral decomposition to identify demonstration-consistent features, contrastive learning to enforce representational stability, and efficient low-rank adaptation modules for environment-specific tuning. Extensive experiments using the open-source LIBERO datasets show that SpinVLA significantly improves robotic manipulation task success rates compared to baseline VLAs under visual perturbations and the presence of out-of-distribution objects, while maintaining comparable in-distribution performance.",
    "key_points": [
      "vision-language-action models; robotic manipulation"
    ],
    "gold_summary": "This paper presents SpinVLA which leverages the equivalence between contrastive learning and spectral decomposition to learn stable multimodal representations. Trained on LIBERO benchmarks with low-rank adaptation, SpinVLA achieves higher performance than Tiny-VLA."
  },
  {
    "paper_id": "e9L22Mix0w",
    "title": "AutoMoMa: Scalable Coordinated Mobile Manipulation Trajectory Generation",
    "domain": "applications to robotics",
    "content": "Mobile robots need coordinated whole-body motion to perform household tasks effectively. Current mobile manipulation datasets rely on expensive teleoperation or slow planning methods, limiting available data to hundreds of demonstrations. This data scarcity severely constrains the development of generalizable learning-based policies. Here, we demonstrate that GPU-accelerated planning generates up to 5,000 episodes per GPU hour, over 80$\\times$ faster than existing methods. Our AutoMoMa pipeline produces 500K diverse physically valid whole-body motions across 300 household scenes and multiple robot embodiments, compared to previous datasets limited to narrow robot-scene pairs with a few hundred demonstrations. Downstream validation demonstrates consistent policy improvements with large-scale training data. This work provides the first scalable solution to the mobile manipulation data bottleneck. By enabling massive dataset generation, AutoMoMa accelerates progress toward general-purpose household robots capable of complex coordination tasks.",
    "key_points": [
      "robotics",
      "mobile manipulation"
    ],
    "gold_summary": "The paper proposes a data generation approach for mobile manipulation based on motion planning in simulation."
  },
  {
    "paper_id": "3y3hnL7KhS",
    "title": "AEGIS: Adversarial Target–Guided Retention-Data-Free Robust Concept Erasure from Diffusion Models",
    "domain": "alignment",
    "content": "Concept erasure helps stop diffusion models (DMs) from generating harmful content; but current methods face robustness-retention trade-off. **Robustness** means the model fine-tuned by concept erasure methods resists reactivation of erased concepts, even under semantically related prompts. **Retention** means unrelated concepts are preserved so the model’s overall utility stays intact. Both are critical for concept erasure in practice, yet addressing them simultaneously is challenging, as existing works typically improve one factor while sacrificing the other. Prior work typically strengthens one while degrading the other—e.g., mapping a single erased prompt to a fixed safe target leaves class-level remnants exploitable by prompt attacks, whereas retention-oriented schemes underperform against adaptive adversaries. This paper introduces AEGIS (Adversarial Erasure with Gradient-Informed Synergy), a retention-data-free framework that advances both robustness and retention. First, AEGIS replaces handpicked targets with an Adversarial Erasure Target (AET) optimized to approximate the semantic center of the erased concept class. By aligning the model’s prediction on the erased prompt to an AET-derived target in the shared text–image space, AEGIS increases predicted-noise distances not just for the instance but for semantically related variants, substantially hardening the DMs against state-of-the-art adversarial prompt attacks. Second, AEGIS preserves utility without auxiliary data via Gradient Regularization Projection (GRP), a conflict-aware gradient rectification that selectively projects away the destructive component of the retention update only when it opposes the erasure direction. This directional, data-free projection mitigates interference between erasure and retention, avoiding dataset bias and accidental relearning. Extensive experiments show that AEGIS markedly reduces attack success rates across various concepts while maintaining or improving FID/CLIP versus advanced baselines, effectively pushing beyond the prevailing robustness–retention trade-off. The source code is in the supplementary.",
    "key_points": [
      "adversarial learning; prompt injection attacks; adversarial defending"
    ],
    "gold_summary": "The paper addresses the problem of robust concept erasure in diffusion models. The paper proposes Adversarial Erasure with Gradient-Informed Synergy (AEGIS), improving erasure robustness and retain performance after unlearning."
  },
  {
    "paper_id": "USjSdem7WO",
    "title": "Just a Simple Transformation is Enough for Data Protection in Split Learning",
    "domain": "alignment",
    "content": "Split Learning (SL) aims to enable collaborative training of deep learning models while maintaining privacy protection. However, the SL procedure still has components that are vulnerable to attacks by malicious parties. In our work, we consider feature reconstruction attacks --- a common risk targeting input data compromise. We theoretically claim that feature reconstruction attacks cannot succeed without knowledge of the prior distribution on data. Consequently, we demonstrate that even simple model architecture transformations can significantly impact the protection of input data during SL. Confirming these findings with experimental results, we show that MLP-based models are resistant to state-of-the-art feature reconstruction attacks.",
    "key_points": [
      "privacy",
      "split learning",
      "feature reconstruction attacks"
    ],
    "gold_summary": "The paper found that in split learning, the MLP-mixer is enough to defend against inversion attacks in split learning frameworks as more than 1 layer is placed on the client side."
  },
  {
    "paper_id": "SnEywLKodN",
    "title": "VeriGuard: Enhancing LLM Agent Safety via Verified Code Generation",
    "domain": "alignment",
    "content": "The deployment of autonomous AI agents in sensitive domains, such as healthcare, introduces critical risks to safety, security, and privacy. These agents may deviate from user objectives, violate data handling policies, or be compromised by adversarial attacks. Mitigating these dangers necessitates a mechanism to formally guarantee that an agent's actions adhere to predefined safety constraints, a challenge that existing systems do not fully address.\nWe introduce \\ours{}, a novel framework that provides formal safety guarantees for LLM-based agents through a dual-stage architecture designed for robust and verifiable correctness. The initial offline stage involves a comprehensive validation process. \nIt begins by clarifying user intent to establish precise safety specifications. \\ours{} then synthesizes a behavioral policy and subjects it to both extensive testing in simulated environments and rigorous formal verification to mathematically prove its compliance with these specifications. \nThis iterative process refines the policy until it is deemed correct. Subsequently, the second stage provides online action monitoring, where \\ours{} operates as a runtime monitor to validate each proposed agent action against the pre-verified policy before execution. This separation of the exhaustive offline validation from the lightweight online monitoring allows formal guarantees to be practically applied, providing a robust safeguard that substantially improves the trustworthiness of LLM agents in complex, real-world environments.",
    "key_points": [
      "agent security",
      "llm security",
      "code verification",
      "security policies generation",
      "safety"
    ],
    "gold_summary": "The paper develops a method to compile policies into codes and then safeguard LLM agents with the verifiable code policies. Evaluations show it outperforms different methods."
  },
  {
    "paper_id": "VRFbLr8Uhv",
    "title": "Mitigating Disparate Impact of Differentially Private Learning through Bounded Adaptive Clipping",
    "domain": "alignment",
    "content": "Differential privacy (DP) has become an essential framework for privacy-preserving machine learning. Existing DP learning methods, however, often have disparate impacts on model predictions, e.g., for minority groups. Gradient clipping, which is often used in DP learning, can suppress larger gradients from challenging samples. We show that this problem is amplified by adaptive clipping, which will often shrink the clipping bound to tiny values to match a well-fitting majority, while significantly reducing the accuracy for others. We propose bounded adaptive clipping, which introduces a tunable lower bound to prevent excessive gradient suppression. Our method improves worst-class accuracy by over 10 percentage points on Skewed and Fashion MNIST compared to unbounded adaptive clipping, 7 points compared to Automatic clipping, and 5 points compared to constant clipping.",
    "key_points": [
      "differential privacy",
      "machine learning",
      "fairness",
      "adaptive clipping"
    ],
    "gold_summary": "This work proposes lower-bounded adaptive clipping for differential privacy learning to address disparate impact of DP learning on minority and confusable groups. The method leads to improvement in worst-class accuracy for skewed and Fashion MNIST."
  },
  {
    "paper_id": "ILGdkBIfE3",
    "title": "FORCE: Transferable Visual Jailbreaking Attacks via Feature Over-Reliance CorrEction",
    "domain": "alignment",
    "content": "The integration of new modalities enhances the capabilities of multimodal large language models (MLLMs) but also introduces additional vulnerabilities.\nIn particular, simple visual jailbreaking attacks can manipulate open-source MLLMs more readily than sophisticated textual attacks.\nHowever, these underdeveloped attacks exhibit extremely limited cross-model transferability, failing to reliably identify vulnerabilities in closed-source MLLMs.\nIn this work, we analyse the loss landscape of these jailbreaking attacks and find that the generated attacks tend to reside in high-sharpness regions, whose effectiveness is highly sensitive to even minor parameter changes during transfer.\nTo further explain the high-sharpness localisations, we analyse their feature representations in both the intermediate layers and the spectral domain, revealing an improper reliance on narrow layer representations and semantically poor frequency components.\nBuilding on this, we propose a Feature Over-Reliance CorrEction (FORCE) method, which guides the attack to explore broader feasible regions across layer features and rescales the influence of frequency features according to their semantic content.\nBy eliminating non-generalizable reliance on both layer and spectral features, our method discovers flattened feasible regions for visual jailbreaking attacks, thereby improving cross-model transferability.\nExtensive experiments demonstrate that our approach effectively facilitates visual red-teaming evaluations against closed-source MLLMs.",
    "key_points": [
      "visual jailbreaking attack",
      "multimodal large language models",
      "red-teaming evaluation"
    ],
    "gold_summary": "This paper investigates transferable adversarial attacks on MLLMs, first examining their effectiveness in representation space and then proposing a solution."
  },
  {
    "paper_id": "a5TEibKZ9z",
    "title": "Safeguarding Vision-Language Models via Dynamic Token Reweighting",
    "domain": "alignment",
    "content": "Large vision-language models (VLMs) are highly vulnerable to jailbreak attacks that exploit visual-textual interactions to bypass safety guardrails. In this paper, we present DTR, a novel inference-time defense that mitigates multimodal jailbreak attacks through optimizing the model's key-value (KV) caches. Rather than relying on curated safety-specific data or costly image-to-text conversion, we introduce a new formulation of the safety-relevant distributional shift induced by the visual modality. This formulation enables DTR to dynamically adjust visual token weights, minimizing the impact of adversarial visual inputs while preserving the model's general capabilities and inference efficiency. Extensive evaluation across diverse VLMs and attack benchmarks demonstrates that \\sys outperforms existing defenses in both attack robustness and benign task performance, marking the first successful application of KV cache optimization for safety enhancement in multimodal foundation models. The code for replicating DTR is available: https://anonymous.4open.science/r/DTR-2755 (warning: this paper contains potentially harmful content generated by VLMs.)",
    "key_points": [
      "vision language models",
      "jailbreak attack",
      "kv optimization"
    ],
    "gold_summary": "This paper proposes to reweight the visual tokens in a VLM in order to defend against multimodal jailbreak attacks."
  },
  {
    "paper_id": "rxJP0jWqX4",
    "title": "QuadSentinel: Sequent Safety for Machine-Checkable Control in Multi-agent Systems",
    "domain": "alignment",
    "content": "Safety risks arise as large language model-based agents solve complex tasks with tools, multi-step plans, and inter-agent messages.\nHowever, deployer-written policies in natural language are ambiguous and context dependent, so they map poorly to machine-checkable rules and runtime enforcement is unreliable.\nExpressing safety policies as sequents, we propose QuadSentinel, a four-agent guard (state tracker, policy verifier, threat watcher, and referee) that compiles these policies into machine-checkable rules built from predicates over observable state and enforces them online.\nReferee logic plus an efficient top-$k$ predicate updater keeps costs low by prioritizing checks and resolving conflicts hierarchically.\nMeasured on ST-WebAgentBench (ICML CUA '25) and AgentHarm (ICLR '25), QuadSentinel improves guardrail accuracy and rule recall while reducing false positives.\nAgainst single-agent baselines such as ShieldAgent (ICML '25), it yields better overall safety control.\nNear-term deployments can adopt this pattern without modifying core agents by keeping policies separate and machine-checkable.",
    "key_points": [
      "ai safety",
      "multi-agent system"
    ],
    "gold_summary": "The paper develops a multi-agent guardrail framework to safeguard agent framework. The framework consists of state tracker, threat watcher, policy verifier, and referee."
  },
  {
    "paper_id": "2OcklgJiU0",
    "title": "Leveraging Data to Say No: Memory Augmented Plug-and-Play Selective Prediction",
    "domain": "alignment",
    "content": "Selective prediction aims to endow predictors with a reject option, to avoid low confidence predictions. However, existing literature has primarily focused on closed-set tasks, such as visual question answering with predefined options or fixed-category classification. This paper considers selective  prediction for visual language foundation models, addressing a taxonomy of tasks ranging from closed to open set and from finite to unbounded vocabularies, as in image captioning. We seek training-free approaches of low-complexity, applicable to any foundation model and consider methods based on external vision-language model (VLM) embeddings, like CLIP. This is denoted as $\\textit{Plug-and-Play Selective Prediction} (\\textbf{\\texttt{PaPSP}})$. We identify two key challenges: (1) $\\textit{instability of the visual-language representations}$, leading to high variance in image-text embeddings, and (2) $\\textit{poor calibration of similarity scores}$. To address these issues, we propose a $\\textit{memory augmented}$ $\\textbf{\\texttt{PaPSP}}$ ($\\textbf{\\texttt{MA-PaPSP}}$) model, which augments $\\textbf{\\texttt{PaPSP}}$ with a retrieval dataset of image-text pairs. This is leveraged to reduce embedding variance by averaging retrieved nearest-neighbor pairs and is complemented by the use of contrastive normalization to improve score calibration. Through extensive experiments on multiple datasets, we show that $\\textbf{\\texttt{MA-PaPSP}}$ outperforms $\\textbf{\\texttt{PaPSP}}$ and other selective prediction baselines for selective captioning, image-text matching, and fine-grained classification. Source code will be made public.",
    "key_points": [
      "selective prediction",
      "vision language alignment",
      "ai safety"
    ],
    "gold_summary": "This paper introduces MA-PaPSP, a lightweight and training-free method for selective prediction in vision-language models. It addresses the instability and poor calibration of standard similarity scores by an external memory and a calibration algorithm."
  },
  {
    "paper_id": "rClVHcVUgT",
    "title": "PATEin: A Privacy-Preserving Framework for Knowledge Integration via Adaptive Teacher Selection in C-LLMs",
    "domain": "alignment",
    "content": "In-context learning (ICL) enables task adaptation without modifying model parameters, making it well-suited for commercial large language models (C-LLMs) with closed-source constraints. However, ICL prompts often contain sensitive information, raising significant privacy concerns. Most existing privacy-preserving methods for ICL require access to model parameters, making them incompatible with C-LLMs. Recent methods based on teacher ensembles with differentially private aggregation have shown promise but face two fundamental challenges: ensemble inconsistency and limited knowledge integration. We propose PATEin, a novel privacy-preserving knowledge transfer framework that dynamically selects the optimal individual teacher model for labeling, thereby mitigating the loss of individual knowledge. Furthermore, it introduces a supervised teacher strategy that selectively incorporates high-consistency voting, effectively integrating individual and ensemble knowledge. Experiments on various C-LLMs (e.g., GPT-3.5-turbo, GPT-4o-mini, Claude-3.5-haiku, DeepSeek-v3) demonstrate that PATEin significantly improves labeling accuracy, reduces computational overhead, and consistently outperforms existing baseline methods.",
    "key_points": [
      "commercial large language models (c-llms)，in-context learning（icl），privacy-preserving，private aggregation of teacher ensembles (pate)，knowledge integration"
    ],
    "gold_summary": "The paper studies privacy-preserving in-context learning. It proposes PATEin, a framework that combines teacher selection and selective ensemble voting to improve labeling accuracy and reduce query cost under claimed differential privacy guarantees."
  },
  {
    "paper_id": "SQ9jHvtFOh",
    "title": "Omni-SafetyBench: A Benchmark for Safety Evaluation of Audio-Visual Large Language Models",
    "domain": "alignment",
    "content": "The rise of Omni-modal Large Language Models (OLLMs), which integrate visual and auditory processing with text, necessitates robust safety evaluations to mitigate harmful outputs. However, no dedicated benchmarks currently exist for OLLMs, and existing benchmarks fail to assess safety under joint audio-visual inputs or cross-modal consistency. To fill this gap, we introduce Omni-SafetyBench, the first comprehensive parallel benchmark for OLLM safety evaluation, featuring 24 modality variations with 972 samples each, including audio-visual harm cases. Considering OLLMs' comprehension challenges with complex omni-modal inputs and the need for cross-modal consistency evaluation, we propose tailored metrics: a Safety-score based on conditional Attack Success Rate (C-ASR) and Refusal Rate (C-RR) to account for comprehension failures, and a Cross-Modal Safety Consistency Score (CMSC-score) to measure consistency across modalities. Evaluating 6 open-source and 4 closed-source OLLMs reveals critical vulnerabilities: (1) only 3 models achieving over 0.6 in both average safety-score and CMSC-score; (2) safety defenses weaken with complex inputs, especially audio-visual joints; (3) severe weaknesses persist, with some models scoring as low as 0.14 on specific modalities. Using Omni-SafetyBench, we evaluated existing safety alignment algorithms and identified key challenges in OLLM safety alignment: (1) Inference-time methods are inherently less effective as they cannot alter the model's underlying understanding of safety; (2) Post-training methods struggle with out-of-distribution issues due to the vast modality combinations in OLLMs; and, safety tasks involving audio-visual inputs are more complex, making even in-distribution training data less effective. Our proposed benchmark, metrics and the findings highlight urgent needs for enhanced OLLM safety. Code and data are available in anonymous repositories: https://anonymous.4open.science/r/omni-safetybench-submit-54DB/ and https://huggingface.co/datasets/anonymous-researcher-11111/Omni-SafetyBench.",
    "key_points": [
      "omni-modal",
      "safety",
      "benchmark"
    ],
    "gold_summary": "This paper presents Omni-SafetyBench, the first safety-evaluation benchmark for audio–visual–text joint inputs to OLLMs, and introduces two new metrics: Safety-score and CMSC-score."
  },
  {
    "paper_id": "5ystL0PeGx",
    "title": "Private Federated Multiclass Post-hoc Calibration",
    "domain": "alignment",
    "content": "Calibrating machine learning models so that predicted probabilities better reflect the true outcome frequencies is crucial for reliable decision-making across many applications. In Federated Learning (FL), the goal is to train a global model on data which is distributed across multiple clients and cannot be centralized due to privacy concerns. FL is applied in key areas such as healthcare and finance where calibration is strongly required, yet federated private calibration has been largely overlooked. This work introduces the integration of post-hoc model calibration techniques within FL. Specifically, we transfer traditional centralized calibration methods such as histogram binning and temperature scaling into federated environments and define new methods to operate them under strong client heterogeneity. We study (1) a federated setting and (2) a user-level Differential Privacy (DP) setting and demonstrate how both federation and DP impacts calibration accuracy. We propose strategies to mitigate degradation commonly observed under heterogeneity and our findings highlight that our federated temperature scaling works best for DP-FL whereas our weighted binning approach is best when DP is not required.",
    "key_points": [
      "classifier calibration; federated learning; differential privacy;"
    ],
    "gold_summary": "This paper introduces two frameworks for federated post-hoc calibration in DP settings. The authors validate the effectivenss of the proposed methods on 7 datasets."
  },
  {
    "paper_id": "1azfkKV93x",
    "title": "CamoDocs: Poisoning Attack against Retrieval-Augmented Language Models",
    "domain": "alignment",
    "content": "As retrieval-augmented generation (RAG) grows in popularity for compensating the knowledge cutoff of pretrained language models, its security concerns have also increased: RAG retrieves external documents to augment an LLM’s knowledge, and these sources (e.g., Wikipedia, Reddit, X) are often public and editable by uncertified users, creating a new attack surface. Specifically, the risk of poisoning attacks—where malicious documents are injected to steer the LLM to output a targeted answer or to disseminate incorrect information—especially rises with the RAG adoption. Although adversarial attacks on LLMs have been studied (e.g., jailbreaking, backdoor triggers in prompts, and pretraining data poisoning), these approaches do not fully consider RAG’s weakness, in which the external documents can be directly leveraged by attackers. To investigate this threat, we present a method named CamoDocs. Through this, we study how an adversary can construct poisoned documents and how much attack success rate (ASR) can be achieved. CamoDocs chunks synthesized adversarial documents and relevant benign documents from the knowledge database to dilute distinctive signals that defenses might exploit, and further optimizes the chunked benign documents to be more dispersed in embedding space—using a surrogate embedding model and retriever—thereby hiding distinctive characteristics of the final adversarial documents formed by concatenating optimized benign content with chunked adversarial content. We find that this procedure achieves an ASR of 60.56% against heuristic defenses across three LLMs (Mixtral, Llama, Mistral) on three benchmarks (HotpotQA, NQ, MS-MARCO), and that a recently proposed RAG defense is insufficient: the attack attains an average ASR of 27.78%, which is intolerable for deployed RAG systems. These results underscore the urgency of developing stronger defenses to detect and prevent malicious manipulation of RAG pipelines.",
    "key_points": [
      "retrieval-augmented generation",
      "poisoning attack",
      "adversarial attack",
      "large language models"
    ],
    "gold_summary": "In this paper, the authors introduce CamoDocs, a method that generates adversarial documents by dividing texts into chunks and merging optimized benign sub-documents with adversarial components."
  },
  {
    "paper_id": "O02qsgSUtY",
    "title": "STEDiff: Revealing the Spatial and Temporal Redundancy of Backdoor Attacks in Text-to-Image Diffusion Models",
    "domain": "alignment",
    "content": "Recently, diffusion models have been recognized as state-of-the-art models for image generation due to their ability to produce high-quality images. However, recent studies have shown that diffusion models are susceptible to backdoor attacks, where an attacker can activate hidden biases using a specific trigger pattern, causing the model to generate a predefined target. Fortunately, executing backdoor attacks is still challenging, as they typically require substantial time and memory to perform parameter-based fine-tuning. In this paper, we are the first to reveal the **spatio-temporal redundancy** in backdoor attacks on diffusion models. **Regarding spatial redundancy**, we observed the *enrichment phenomenon*, which reflects the abnormal gradient accumulation induced by backdoor injection. **Regarding temporal redundancy**, we observed a marginal effect associated with specific time steps, indicating that only a limited subset of time steps plays a critical role in backdoor injection. Building on these findings, we present a novel framework, *STEDiff*, comprising two key components: *STEBA* and *STEDF*. *STEBA* is a spatio-temporally efficient accelerated attack strategy that achieves up to **15.07×** speedup in backdoor injection while reducing video memory usage by **82%**. *STEDF* is a detection framework leveraging spatio-temporal features, by modeling the enrichment phenomenon in weights and anisotropy across time steps, which achieves a backdoor detection rate of up to **99.8%**.  Our code is available at: [https://anonymous.4open.science/r/STEDiff-9E9F/](https://anonymous.4open.science/r/STEDiff-9E9F/).",
    "key_points": [
      "diffusion models; backdoor attacks; backdoor defense; ai security"
    ],
    "gold_summary": "The paper observes redundancies in the backdoor attacks against diffusion models. The authors propose an attack method, STEBA, and a defense method, STEDF, based on the observations."
  },
  {
    "paper_id": "mBTIx8H9yh",
    "title": "Efficiently Attacking Memorization Scores",
    "domain": "alignment",
    "content": "Influence estimation tools—such as memorization scores—are widely used to understand model behavior, attribute training data, and inform dataset curation. However, recent applications in data valuation and responsible machine learning raise the question: can these scores themselves be adversarially manipulated? In this work, we present a systematic study of the feasibility of attacking memorization-based influence estimators. We characterize attacks for producing highly memorized samples as highly sensitive queries in the regime where a trained algorithm is accurate. Our attack (calculating the pseudoinverse of the input) is practical, requiring only black-box access to model outputs and incur modest computational overhead. We empirically validate our attack across a wide suite of image classification tasks, showing that even state-of-the-art proxies are vulnerable to targeted score manipulations. In addition, we provide a theoretical analysis of the stability of memorization scores under adversarial perturbations, revealing conditions under which influence estimates are inherently fragile. Our findings highlight critical vulnerabilities in influence-based attribution and suggest the need for robust defenses. All code can be found at https://anonymous.4open.science/r/MemAttack-5413/",
    "key_points": [
      "memorization",
      "robustness",
      "attacks"
    ],
    "gold_summary": "The paper proposes attacks on memorization-based data valuation scores, claiming to make minimal assumptions."
  },
  {
    "paper_id": "nCJF1CDapQ",
    "title": "TwinShield: Secure Foundation Model Execution by Unifying TEEs and Crypto-protected Accelerators",
    "domain": "alignment",
    "content": "Recent advances in Transformer-based foundation models (FMs) have driven significant developments across diverse AI tasks, facilitating their deployment in security-sensitive domains. Despite their capabilities, FMs impose substantial inference costs, driving reliance on third-party cloud infrastructure equipped with high-performance computation resources. However, these cloud platforms cannot be fully trusted and remain vulnerable to data breaches, introducing dual confidentiality challenges: protecting user data from exposure and safeguarding models against unauthorized access. Mainstream protection mechanisms leverage trusted execution environments (TEEs), where confidentiality and integrity are enforced through hardware-based isolation, encryption, and integrity verification. But executing inference entirely within TEEs incurs a significant overhead, which is further exacerbated in large-scale FMs. Recent studies have proposed schemes that combine TEEs with untrusted accelerators (e.g., GPUs) to offload partial inference operations. However, prior offloading schemes cannot solve dual confidentiality challenges in FM inference, since operations such as ***Attention*** depend on dynamic operands that prevent secure precomputation and must remain within TEEs. Moreover, the communication overhead between TEEs and accelerators grows dramatically with model scale, constituting a new system design challenge for FMs.\nTo address these challenges, we propose ***Twinshield***, a framework that enables secure inference of Transformer-based FMs in heterogeneous TEE–accelerator systems with dual protection for both model and data. ***Twinshield*** improves efficiency through ***protocol-level*** outsourcing, which securely offloads the majority of operations to accelerators, and enhances throughput via a ***system-level*** design that overlaps TEE preparation, communication, and accelerator execution. Our evaluation on representative LLMs and VLMs shows that ***Twinshield*** offloads about 87% of computations to accelerators and achieves $3.3\\times$–$5.1\\times$ speedups over baselines. The code is publicly available at https://anonymous.4open.science/r/Twinshield/README.md.",
    "key_points": [
      "trusted execution environments",
      "cloud computing",
      "model privacy",
      "data privacy"
    ],
    "gold_summary": "The paper proposes to use existing trusted execution environments for securely evaluating transformer models. The main novelty is to outsource some part of the computation to an untrusted GPU."
  },
  {
    "paper_id": "sGiE05Dc0v",
    "title": "Recast Your Input via a Mapping Function for Alignment",
    "domain": "alignment",
    "content": "Alignment is promoting its critical role among the large language model (LLM) scenarios, which ensures safety, controllability, and trustworthiness of the generation. The popular alignment methods, that is, reinforcement learning from human feedback (RLHF), direct preference optimization (DPO) and such series, usually change weights of the model by elaborate algorithm. Nevertheless, they suffer from the compute drain for training, especially when the parameters' size getting huge. Worse still, people typically do not have access to the weights of the SOTA models, such as GPT-4, which consequently renders the aforementioned algorithms unimplementable. In this paper, we propose to employ a separate LM as the Refiner, an input mapping function essentially, to transform the original query into a novel formulation that impels the final generation to align with the expectations. During optimization, an evolution strategy, namely CMA-ES, is leveraged to fine-tune the LM with linkage to the generation model. We conduct extensive experiments on various refiner and generation types, and achieving surpassing results.",
    "key_points": [
      "alignment",
      "input refiner",
      "cma-es",
      "posterior regularization"
    ],
    "gold_summary": "This paper proposes using an additional Language Model (LM) as a Refiner to improve the input, which ultimately leads to outputs with better alignment. Experimental results have demonstrated the effectiveness of this method."
  },
  {
    "paper_id": "upo66G6AAB",
    "title": "SELFI: Selective Fusion of Identity for Generalizable Deepfake Detection",
    "domain": "alignment",
    "content": "Face identity provides a remarkably powerful signal for deepfake detection. Prior studies have shown that even when not explicitly modeled, deepfake classifiers tend to implicitly learn identity features during training. This has led to two conflicting viewpoints in the literature: some works attempt to completely suppress identity cues to mitigate bias, while others rely on them exclusively as a strong forensic signal. To reconcile these opposing stances, we conduct a detailed empirical analysis based on two central hypotheses: (1) whether face identity alone is inherently discriminative for detecting deepfakes, and (2) whether such identity features generalize poorly across manipulation methods. Through extensive experimentation, we confirm that face identity is indeed a highly informative signal—but its utility is context-dependent. While some manipulation methods preserve identity-consistent artifacts, others distort identity cues in ways that can harm generalization. These findings suggest that identity features should not be suppressed or relied upon blindly. Instead, they should be explicitly modeled and adaptively controlled based on their per-sample relevance. To this end, we propose SELFI (SELective Fusion of Identity), a generalizable deepfake detection framework that dynamically modulates identity usage. SELFI consists of: (1) a Forgery-Aware Identity Adapter (FAIA) that explicitly extracts face identity embeddings from a frozen face recognition model and projects them into a forgery-relevant space using auxiliary supervision, and (2) an Identity-Aware Fusion Module (IAFM) that selectively integrates identity and visual features via a relevance-guided fusion mechanism. Extensive experiments on four benchmark datasets demonstrate that SELFI achieves strong generalization across manipulation methods and datasets, outperforming prior state-of-the-art methods by an average of 3.1% frame-level AUC in cross-dataset evaluations. Notably, on the challenging DFDC benchmark, SELFI improves over the previous best by a significant 6% margin, highlighting the effectiveness of adaptive identity control. The code will be released upon acceptance of the paper.",
    "key_points": [
      "deepfake detection",
      "identity fusion",
      "generalization",
      "forgery analysis",
      "cross-dataset evaluation",
      "face recognition",
      "robust ai"
    ],
    "gold_summary": "This paper addresses the challenge of generalization in deepfake detection by analyzing the role of face identity cues. Authors propose Selective Fusion of Identity method to learn identity features for DFDC."
  },
  {
    "paper_id": "JbyaS5zhcB",
    "title": "Geo-Invariant Scoring Lead with Domain-Adversarial Transformers",
    "domain": "alignment",
    "content": "Predicting B2B lead conversion requires not only modeling long‑range dependencies in richly sequenced customer interactions but also ensuring fair performance across under‑represented geographies. While our DeepScore transformer backbone improved overall AUPR from $0.266$ to $0.360$, it exhibited significant geo‑skew: majority‑region (America) signals dominated feature learning (AUPR $0.474$), leaving East-Asia ($0.262$) under‑served. To address this, we embed a Domain‑Adversarial Neural Network (DANN) module into DeepScore’s architecture. A gradient‑reversal layer connects a geo‑discriminator to the shared transformer encoder, enforcing a minimax game that drives hidden representations to be predictive of conversion yet uninformative of geography. Simultaneously, lightweight geo‑specific classifier heads learn residual region‑nuances without re‑introducing large divergence. DeepScore + geo‑DANN achieves a $4.3 \\%$ relative gain in macro‑AUPR and reduces inter‑region AUPR gaps by up to $12.3\\%$ , all without degrading America accuracy. To our knowledge, this is the first demonstration of adversarial domain adaptation in large‑scale B2B lead scoring, offering a scalable path to equitable, high‑fidelity predictions across heterogeneous markets.",
    "key_points": [
      "domain adaptation",
      "transformers",
      "lead scoring",
      "adversarial learning",
      "geographic fairness",
      "dann",
      "sequential modeling"
    ],
    "gold_summary": "The paper addresses a meaningful and challenging real-world problem. The core idea of using DANN to achieve geographic invariance is sound and shows empirical promise."
  },
  {
    "paper_id": "1bUeVB3fov",
    "title": "How Do Coding Agents Spend Your Money? Analyzing and Predicting Token Consumptions in Agentic Coding Tasks",
    "domain": "alignment",
    "content": "AI agents offer substantial opportunities to boost human productivity across many settings. However, their use in complex workflows also drives rapid growth in LLM token consumption. When agents are deployed on tasks that can require millions of tokens, a natural question arises: where does token consumption come from in agentic coding tasks, and can we predict how many tokens a task will require? In this paper, we present the first empirical analysis of agent token consumption patterns using agent trajectories on SWE-bench, and we further explore the possibility of predicting token costs at the beginning of task execution. We find that (1) more complex tasks tend to consume more tokens, yet token usage also exhibits large variance across runs (some runs use up to 10$\\times$ more tokens than others); (2) unlike chat and reasoning tasks, input tokens dominate overall consumption and cost, even with token caching; and (3) while predicting total token consumption before execution is very challenging (Pearson’s $r<0.15$), predicting output-token amounts and the range of total consumption appears practical and reasonably accurate. Understanding and predicting agentic token consumption is a key step toward transparent and reliable agent pricing. Our study provides important empirical evidence on the inherent challenges of token consumption prediction and could inspire new studies in this direction.",
    "key_points": [
      "ai agent",
      "coding agent"
    ],
    "gold_summary": "This paper systematically investigates the token consumption patterns and cost predictability of coding agents driven by large language models (LLMs) when performing real-world software engineering tasks on the SWE-bench Verified dataset."
  },
  {
    "paper_id": "fp51nxr5B1",
    "title": "Automatic Generation of Safety-compliant Linear Temporal Logic via Large Language Model: A Self-supervised Framework",
    "domain": "alignment",
    "content": "Converting high‑level natural‑language task descriptions into formal specifications such as Linear Temporal Logic (LTL) is essential for ensuring safety in cyber‑physical systems (CPS). Existing work, however, only optimizes translation quality without explicitly verifying the output against safety constraints. We present AutoSafeLTL, a self‑supervised, cloud–edge–collaborative framework that automates the generation of safety‑compliant LTL specifications while preserving logical consistency and semantic fidelity. A lightweight edge‑side three-stage-fine-tuned LLM offers real‑time conversion from natural language to LTL specifications (NL2LTL) and guarantees safety‑critical latency and data locality. Two larger‑capacity cloud‑side agents then iteratively refine the alignment: 1) LLM‑as‑an‑Aligner matches atomic propositions to safety constraints, and 2) LLM‑as‑a‑Critic interprets counterexamples from Inclusion Check to guide corrective regeneration. This collaborative architecture provides a safety-guaranteed alignment mechanism between high-level user intent and formally verifiable system behavior, demonstrating the potential of our framework to advance AI Alignment in safety-critical domains. Our approach achieves 0% violation rates on multiple benchmarks, enabling trustworthy specification generation and verification for both AI and critical CPS applications.",
    "key_points": [
      "linear temporal logic",
      "large language model",
      "language inclusion check",
      "automated verification"
    ],
    "gold_summary": "This work proposed a framework to generate LTL based on natrual language description with saferty complience."
  },
  {
    "paper_id": "8N2f6nbeUL",
    "title": "Noisy Scrubber: Unlearning Using Noisy Representations",
    "domain": "alignment",
    "content": "Machine Unlearning (MU) aims to remove the influence of specific data points from trained models, with applications ranging from privacy enforcement to debiasing and mitigating data poisoning. Although exact unlearning ensures complete data removal via retraining, this process is computationally intensive, motivating the development of efficient approximate unlearning methods. Existing approaches typically modify model parameters, which limits scalability, introduces instability, and requires extensive tuning. We propose Noisy Scrubber, a novel MU framework that learns to inject perturbations into the latent representations rather than modifying model parameters. To show Noisy Scrubber attains approximate unlearning we theoretically establish bounds on the parameter gap between original and exact unlearned model, as well as on the output discrepancy between Noisy Scrubber and exact unlearning. Empirical results on CIFAR-10, CIFAR-100, and AGNews demonstrate that Noisy Scrubber closely matches exact unlearning while being significantly more efficient, reducing unlearning gaps to 0.024, 0.129, and 0.006, respectively. Moreover, membership inference evaluations confirm that Noisy Scrubber removes information comparably to retraining. Our approach scales across model families in both vision and text, and introduces a flexible, attachable noise module that enables on-demand and reversible unlearning.",
    "key_points": [
      "machine unlearning",
      "exact unlearning",
      "approximate unlearning",
      "unlearning with representation"
    ],
    "gold_summary": "The paper presents an alternative strategy to unlearning where perturbation is used to change the latent representations using an optimization of knowledge distillation loss function with respect to the exact unlearned model."
  },
  {
    "paper_id": "lTUfCi9Smh",
    "title": "Defeating Cerberus: Concept-Guided Privacy-Leakage Mitigation in Multimodal Language Models",
    "domain": "alignment",
    "content": "Multimodal large language models (MLLMs) have demonstrated remarkable capabilities in processing and reasoning over diverse modalities, but their advanced abilities also raise significant privacy concerns, particularly regarding Personally Identifiable Information (PII) leakage. While relevant research has been conducted on single-modal language models to some extent, the vulnerabilities in the multimodal setting have yet to be fully investigated. In this work, we investigate these emerging risks with a focus on vision language models (VLMs), a representative subclass of MLLMs that covers the two modalities most relevant for PII leakage, vision and text. We introduce a concept-guided mitigation approach that identifies and modifies the model’s internal states associated with PII-related content. Our method guides VLMs to refuse PII-sensitive tasks effectively and efficiently, without requiring re-training or fine-tuning. We also address the current lack of multimodal PII datasets by constructing various ones that simulate real-world scenarios. Experimental results demonstrate that the method can achieve an average refusal rate of 93.3\\% for various PII-related tasks with minimal impact on unrelated model performances. We further examine the mitigation's performance under various conditions to show the adaptability of our proposed method.",
    "key_points": [
      "multi-modal",
      "privacy",
      "personal identifiable information"
    ],
    "gold_summary": "Summary: This paper presents a concept-guided mitigation approach that identifies and modifies the model’s internal states associated with PII-related content to mitigate the PII leakage attacks in Vision Language Models, without fine-tuning the model."
  },
  {
    "paper_id": "yPgbdOdOPG",
    "title": "AlignSentinel: Alignment-Aware Detection of Prompt Injection Attacks",
    "domain": "alignment",
    "content": "Prompt injection attacks insert malicious instructions into an LLM's input to steer it toward an attacker-chosen task instead of the intended one. Existing detection defenses typically classify any input with instruction as malicious, leading to misclassification of benign inputs containing instructions that align with the intended task. In this work, we account for the instruction hierarchy and distinguish among three categories: inputs with misaligned instructions, inputs with aligned instructions, and non-instruction inputs. We introduce AlignSentinel, a three-class classifier that leverages features derived from the LLM's attention maps to categorize inputs accordingly. To support evaluation, we construct the first systematic benchmark containing inputs from all three categories. Experiments on both our benchmark and existing ones--where inputs with aligned instructions are largely absent--show that AlignSentinel accurately detects inputs with misaligned instructions  and substantially outperforms baselines.",
    "key_points": [
      "llm security",
      "prompt injection attacks",
      "detection defense"
    ],
    "gold_summary": "The authors present a prompt injection defense AlignSentinel which classifies inputs using attention scores and adds an \"aligned instruction\" category to the standard categories for a prompt injection defense."
  },
  {
    "paper_id": "qRGKHBE5RY",
    "title": "PSG-Agent: Personality-Aware Safety Guardrail for LLM-based Agents",
    "domain": "alignment",
    "content": "Effective guardrails are essential for safely deploying LLM-based agents in critical applications. \nDespite recent advances, existing guardrails suffer from two fundamental limitations: \n(i) they apply uniform guardrail policies to all users, ignoring that the same agent behavior can harm some users while being safe for others; \n(ii) they check each response in isolation, missing how risks evolve and accumulate across multiple interactions. \nTo solve these issues, we propose PSG-Agent, a personalized and dynamic system for LLM-based agents.\nFirst, PSG-Agent creates personalized guardrails by mining the interaction history for stable traits and capturing real-time states from current queries, generating user-specific risk thresholds and protection strategies.\nSecond, PSG-Agent implements continuous monitoring across the agent pipeline with specialized guards, including Plan Monitor, Tool Firewall, Response Guard, Memory Guardian, that track cross-turn risk accumulation and issue verifiable verdicts.\nFinally, we validate PSG-Agent in multiple scenarios including healthcare, finance, and daily life automation scenarios with diverse user profiles. \nIt significantly outperform existing agent guardrails including LlamaGuard3 and AGrail, providing an executable and auditable path toward personalized safety for LLM-based agents.",
    "key_points": [
      "guardrail",
      "agent",
      "safety"
    ],
    "gold_summary": "This paper proposes a novel personalized agent safety barrier. By extracting features from users' historical interactions, it provides tailored safeguards for specific users, enabling risk monitoring."
  },
  {
    "paper_id": "5IHuwRwMHK",
    "title": "Sound Verification of Deployed Neural Networks",
    "domain": "alignment",
    "content": "Verification methods aim at mathematically proving desirable properties of neural networks, such as robustness to adversarial perturbations. A verifier is sound if and only if it never claims that a neural network has the desired property when it does not. It was shown recently that none of the currently known verifiers that are claimed to be sound are guaranteed to be sound when considering the deployed version of the verified network. Due to this, all the known verifiers are vulnerable to certain backdoor attacks, where an adversarial network passes verification but, in reality, it exhibits adversarial behavior in specific deployment environments. So far, it has been suspected that sound verification is prohibitively expensive if we wish to verify all possible executions&mdash;including parallel and stochastic ones&mdash;in deployment. *We are the first to propose an efficient error bounding technique that most known verifiers can apply to become practically sound.* The technique enables both interval bound propagation and symbolic propagation methods to remain sound even if the deployment environment allows for every possible expression tree to compute the network, and even if the expression tree is selected at random. \nWe present a theoretical foundation for our approach and demonstrate empirically that our technique indeed discovers all known deployment-specific attacks, introducing only a limited performance overhead.",
    "key_points": [
      "sound verification",
      "backdoor attacks",
      "deployment",
      "floating point arithmetic"
    ],
    "gold_summary": "Many neural network verifiers operate on a theoretical model, ignoring many practical aspects such as floating point inaccuracies.\nThis paper addresses this by designing verification algorithms that are also sound under these practical aspects."
  },
  {
    "paper_id": "CVqYCYpq75",
    "title": "Dem-HEC: High-Entropy Contrastive Fine-Tuning for Countering Natural Corruptions",
    "domain": "alignment",
    "content": "Neural networks are highly susceptible to natural image corruptions such as noise, blur, and weather distortions, limiting their reliability in real-world deployment. The prime reason to maintain the high integrity against natural corruptions is that these distortions are the primary force of distribution shift intentionally (compression) or unintentionally (blur or weather artifacts). For the first time, through this work, we observe that such corruptions often collapse the network's internal feature space into a high-entropy state, causing predictions to rely on a small subset of fragile features. Inspired by this, we propose a simple yet effective entropy-guided fine-tuning framework, Dem-HEC, that strengthens corruption robustness while maintaining clean accuracy. Our method generates high-entropy samples within a bounded perturbation region to simulate corruption-induced uncertainty and aligns them with clean embeddings using a contrastive loss. In parallel, cross-entropy on both clean and high-entropy samples, combined with knowledge distillation from a teacher snapshot, ensures stable predictions. Dem-HEC is evaluated with numerous neural networks trained on multiple benchmark datasets, demonstrating consistent gains across diverse corruption types and their severities (noise strength), with strong transferability across backbones, including CNNs and Transformers. Our approach highlights entropy regularisation as a scalable pathway to bridging the gap between clean accuracy and real-world robustness.",
    "key_points": [
      "corruption",
      "convolution",
      "transformer",
      "robustness",
      "explainability"
    ],
    "gold_summary": "The paper considers the problem of corrupted image classification, and proposes a contrastive loss to stabilise the predictions of noisy images."
  },
  {
    "paper_id": "yJzMPGtakp",
    "title": "Alignment, Convexity and Completeness: Mechanisms Behind GroupDRO",
    "domain": "alignment",
    "content": "Models trained with Empirical Risk Minimization (ERM) often fail to generalize under spurious correlations. Group Robustness Methods (GRMs)—notably Group DRO (GDRO)—mitigate this by reweighting losses across groups defined by labels and spurious attributes, yet why they work remains only partially understood. We study the learning dynamics of GRMs and their effects on both the classifier head and the representation. Theoretically, in a head-only fine-tuning setting (fixed features), we analyze the classifier learned by GDRO and show: (i) GDRO aligns less with a spurious classifier and more with an oracle non-spurious classifier than ERM; (ii) when group losses are $\\mu$-strongly convex, the alignment gap controls performance, yielding an upper bound on the worst-group performance gap between ERM and GDRO; and (iii) for convex losses, adding L2 regularization induces $\\mu$-strong convexity, so the same guarantees apply—providing an explanation for the empirical gains of GDRO with L2 reported in prior work. Empirically, across standard image and text benchmarks, we confirm the predicted alignment behavior. Beyond the head, under end-to-end training GDRO also reshapes the representation:  through a measure called Completeness, we show that task-relevant information is spread across multiple dimensions in GDRO while ERM tends to concentrate it in fewer, making it more susceptible to rely on spurious attributes for prediction. Together, our theory and measurements clarify the mechanisms by which GroupdDRO outperforms ERM.",
    "key_points": [
      "robustness fairness deep learning"
    ],
    "gold_summary": "Objective of the paper is to theoretically explain the merits of Group-DRO (sagawa et.al.) and motivate the need for strong parameter regularization in Group-DRO."
  },
  {
    "paper_id": "EJIncQ0qmm",
    "title": "Activation Matters: Adaptive and Activated Negative Labels for OOD Detection with Vision-Language Models",
    "domain": "alignment",
    "content": "Out-of-distribution (OOD) detection aims to identify samples that deviate from in-distribution (ID). \nOne popular pipeline addresses this by introducing negative labels distant from ID classes and detecting OOD based on their distance to these labels.\nHowever, such labels may present poor activation on OOD samples, failing to capture the OOD characteristics. \nTo address this, we propose an \\underline{A}daptive and \\underline{A}ctivated \\underline{Neg}ative labels guided approach (AANeg), which dynamically evaluates activation levels across the corpus dataset and selects words with high activation responses as negative labels. Specifically, AANeg identifies high-confidence test images online and accumulates their assignment probabilities over the corpus to construct a label activation metric.\nSuch a metric leverages historical test samples to adaptively align with the test distribution, enabling the selection of distribution-adaptive activated negative labels. \nBy further exploring the activation information within the current testing batch, we introduce a more fine-grained, batch-adaptive variant. \nTo fully utilize label activation knowledge, we propose an activation-aware score function that emphasizes negative labels with stronger activations, boosting performance and enhancing its robustness to the label number.\nOur approach is zero-shot, training-free, test-efficient, highly scalable, and grounded in theoretical justification.\nNotably, on the large-scale ImageNet benchmark, AANeg significantly reduces the FPR95 from 17.5\\% to 9.8\\%.\nCodes will be released.",
    "key_points": [
      "ood detection",
      "vision-language models",
      "negative labels",
      "label activation"
    ],
    "gold_summary": "this paper dynamically evaluates activation levels across the corpus dataset and selects words with high activation responses as negative labels.  On the large-scale ImageNet benchmark, AANeg achieves the SOTA performance"
  },
  {
    "paper_id": "gsf4Sxjec9",
    "title": "On Conformal Machine Unlearning",
    "domain": "alignment",
    "content": "The increasing demand for data privacy has made Machine Unlearning (MU) essential for removing the influence of specific training samples from machine learning models while preserving performance on retained data. However, most existing MU methods lack rigorous statistical guarantees or rely on heuristic metrics such as accuracy. To overcome these limitations, we introduce a new definition for MU based on Conformal Prediction (CP), providing statistically sound, uncertainty-aware guarantees without the need for the concept of naive retraining. We formalize the proposed conformal criteria that quantify how often forgotten samples are excluded from CP sets, and propose empirical metrics—the Efficiently Covered Frequency (ECF at $c$) and its complement, the Efficiently Uncovered Frequency (EuCF at $d$)—to measure the effectiveness of unlearning. We further present a practical unlearning method designed to optimize these conformal metrics. Extensive experiments across diverse forgetting scenarios, datasets and models demonstrate the efficacy of our approach in removing targeted data.",
    "key_points": [
      "machine unlearning",
      "conformal prediction"
    ],
    "gold_summary": "This paper introduces a new definition for machine unlearning based on conformal prediction, providing uncertainty-aware guarantees without the need for the concept of naive retraining. Some comments are provided as follows."
  },
  {
    "paper_id": "wmi6satsIu",
    "title": "DGPO: Mitigating Likelihood Displacement with Bidirectional KL Divergence Gap",
    "domain": "alignment",
    "content": "The current margin-based model alignment method, represented by Direct Preference Optimization (DPO), aims to expand the margin between positive and negative feedback. However, some works point out the log-probability of positive feedback always decreases, thus affecting the likelihood of its generation. This likelihood displacement caused by gradient entanglement is a failure mode for preference optimization and has not been fully resolved. In this paper, we focus on forward and reverse Kullback-Leibler (KL) divergence on the probability distribution of preference pairs to form Divergence Gap Preference Optimization (DGPO). We prove DGPO can stimulate the chosen log-probability increase. Besides, DGPO also maintains a lightweight and automatical way in read-world alignment. The downstream experimental results demonstrate that DGPO maintains competitive performance across various mainstream benchmarks without the reference model and additional key hyperparameters.",
    "key_points": [
      "alignment",
      "likelihood displacement",
      "gradient entanglement"
    ],
    "gold_summary": "This paper proposes a new measure for preference optimization that weights \\log\\pi_w and \\log\\pi_l by the sum (\\pi_w+\\pi_l)."
  },
  {
    "paper_id": "qqWPNiig1Q",
    "title": "One Bad Sample May Spoil the Whole Batch: A Novel Backdoor-Like Attack Towards Large Batch Processing",
    "domain": "fairness",
    "content": "As hardware accelerators like TPUs and large-memory GPUs continue to evolve rapidly, an increasing number of Artificial Intelligence (AI) applications are utilizing extremely large batch sizes to accelerate their Deep Learning (DL) processes. To optimize DL processing, Batch Normalization (BN) layers in DL models rely on batch statistics that are accurate and reliable enough when working with large batch sizes. However, batch statistics allow for knowledge transfer between samples within the same batch. This characteristic can be exploited by adversaries, posing various potential security threats. To reveal the danger of the security threats, in this paper, we introduce a novel Batch-Oriented Backdoor Attack named \\textit{BOBA}, which aims to control the classification results of all the samples in a batch by poisoning only one of them. Specifically, we present an effective trigger derivation mechanism that generates specific triggers for a given trained target model, thereby maximizing the impact of a poisoned sample on the classification results of other clean samples. Meanwhile,  we propose a contrastive contamination-based retraining method for backdoor injection using samples poisoned by the derived triggers. In this way, when dealing with a batch that includes one poisoned sample, the retrained model will predict the given attack target category. Comprehensive experimental results obtained from various well-known datasets demonstrate the effectiveness of BOBA. Notably, for CIFAR-10, BOBA can make 848 of 1024 samples within a batch misclassified when manipulating only 10 poisoned samples, indicating the harmfulness of security risks in the BN layers.",
    "key_points": [
      "backdoor attack",
      "batch processing"
    ],
    "gold_summary": "This paper offers an original and thought-provoking contribution by exposing a batch-level vulnerability in BN layers and designing a corresponding attack mechanism. The experimental validation is thorough, but the clarity of presentation can be improved."
  },
  {
    "paper_id": "MLZLdOwEpA",
    "title": "AI Alignment with Provable Protection of Human Judgements",
    "domain": "fairness",
    "content": "Reinforcement learning from human preference rankings forms the basis for training language models to be helpful and value-aligned. As these powerful AI systems are trained for increasingly high-stakes tasks, the risk of leaking sensitive human training data increases. However, the problem of protecting human preference data is complicated by the fact that reinforcement learning from human feedback is a multistage pipeline involving learning a reward function from human preferences, and subsequently training a language model policy from the learned rewards. To address these issues, we design algorithms for the task of alignment from preference feedback that provably avoid leaking human preference data in both the Bradley-Terry and Plackett-Luce models. Our algorithms satisfy $\\epsilon$-DP while matching the minimax optimal sample complexity for the task of aligning a policy to human preference rankings. These results demonstrate that there is no inherent tradeoff between protecting the privacy of human preferences and efficient alignment with human values.",
    "key_points": [
      "alignment",
      "rlhf",
      "performance guarantees",
      "asymptotic match"
    ],
    "gold_summary": "This paper explores the leakage of human preference data in Reinforcement Learning from Human Feedback (RLHF). The authors design algorithms that satisfy $\\epsilon$-DP while still aligning to the preference data."
  },
  {
    "paper_id": "Ncf2LFDT4e",
    "title": "BiasFreeBench: a Benchmark for Mitigating Bias in Large Language Model Responses",
    "domain": "fairness",
    "content": "Existing studies on bias mitigation methods for large language models (LLMs) use diverse baselines and metrics to evaluate debiasing performance, leading to inconsistent comparisons among them. Moreover, their evaluations are mostly based on the comparison between LLMs' probabilities of biased and unbiased contexts, which ignores the gap between such evaluations and real-world use cases where users interact with LLMs by reading model responses and expect fair and safe outputs rather than LLMs' probabilities. To enable consistent evaluation across debiasing methods and bridge this gap, we introduce **BiasFreeBench**, an empirical benchmark that comprehensively compares eight mainstream bias mitigation techniques (covering four prompting-based and four training-based methods) on two test scenarios (multi-choice QA and open-ended multi-turn QA) by reorganizing existing datasets into a unified query-response setting. We further introduce a response-level metric, **Bias-Free Score**, to measure the extent to which LLM responses are fair, safe, and anti-stereotypical. Debiasing performances are systematically compared and analyzed across key dimensions: the prompting vs. training paradigm, model size, and generalization of different training strategies to unseen bias types. We will publicly release our benchmark, aiming to establish a unified testbed for bias mitigation research.",
    "key_points": [
      "debiasing large language models",
      "bias mitigation",
      "social bias"
    ],
    "gold_summary": "In this paper, the author proposes a benchmark dataset composed of query–answer pairs designed to evaluate both prompt-based and training-based debiasing techniques."
  },
  {
    "paper_id": "Z7Q0C79mhS",
    "title": "Controllable Preference Alignment for Ambiguous Medical Image Segmentation via Text and Dice Guidance",
    "domain": "fairness",
    "content": "In medical imaging, different experts often provide different but equally valid segmentations, making ambiguity an inherent challenge. A good model should therefore capture this variability by producing a distribution of plausible masks, rather than a single deterministic output. Diffusion models are well-suited for this task because of their ability to generate diverse samples, but standard training does not guarantee clinically meaningful segmentations. Prior work in ambiguous segmentation, such as diffusion-based approaches, lacks semantic control. This work introduces a multi-modal framework that makes diffusion-based segmentation both controllable and clinically aligned. The model is conditioned on input images and descriptive text from clinical metadata, and Direct Preference Optimization (DPO) is adapted by using Dice-based signals from multi-rater annotations instead of subjective human feedback. Three preference strategies are explored, with a consensus-based Mean Dice signal proving most effective. With DDIM sampling, inference is accelerated by a factor of three, making the approach practical for clinical use. Experiments on LIDC-IDRI demonstrate state-of-the-art segmentation quality while preserving diversity, and introduce a controllable preference knob that enables practitioners to directly adjust the balance between per-sample accuracy and distributional variability.",
    "key_points": [
      "medical image segmentation",
      "ambiguity",
      "diffusion models",
      "clinical metadata",
      "direct preference optimization",
      "ddim sampling",
      "multi-modal framework"
    ],
    "gold_summary": "The paper introduces TDG-DiffDPO to enable segmentation via text and dice guidance. Experiments are performed on LIDC-IDRI datasets."
  },
  {
    "paper_id": "mLLAc1FhWV",
    "title": "Exact Certification of Neural Networks and Partition Aggregation Ensembles against Label Poisoning",
    "domain": "fairness",
    "content": "Label-flipping attacks, which corrupt training labels to induce misclassifications at inference, remain a major threat to supervised learning models. This drives the need for robustness certificates that provide formal guarantees about a model's robustness under adversarially corrupted labels. Existing certification frameworks rely on ensemble techniques such as smoothing or partition aggregation, but treat the corresponding base classifiers as black boxes—yielding overly conservative guarantees. We introduce EnsembleCert, the first certification framework for partition aggregation ensembles that utilizes white-box knowledge of the base classifiers. Concretely, EnsembleCert yields tighter guarantees than black-box approaches by aggregating per-partition white-box certificates to compute ensemble-level guarantees in polynomial time.  To extract white-box knowledge from the base classifiers efficiently, we develop ScaLabelCert, a method that leverages the equivalence between sufficiently wide neural networks and kernel methods using the Neural Tangent Kernel. ScaLabelCert yields the first exact, polynomial-time calculable certificate for neural networks against label-flipping attacks. EnsembleCert is either on par, or significantly outperforms the existing partition-based black-box certificate. Exemplary, on CIFAR-10, our method can certify upto $\\mathbf{+26.5\\\\%}$ more label flips in median over the test set compared to the existing black-box approach while requiring $\\mathbf{100 \\times}$  fewer partitions, thus challenging the prevailing notion that heavy partitioning is a necessity for strong certified robustness.",
    "key_points": [
      "certified robustness",
      "provable robustness",
      "certificates",
      "neural tangent kernel",
      "partition aggregation",
      "label-flipping",
      "label poisoning",
      "kernel svm",
      "kernel regression",
      "integer program",
      "multiple choice knapsack problem"
    ],
    "gold_summary": "The authors attempt to distinguish between poisoning defences that hold white box knowledge, versus those that don't, and attempt to demonstrate improved defensive utility."
  },
  {
    "paper_id": "05hNleYOcG",
    "title": "PLAGUE: Plug-and-play Framework for Lifelong Adaptive Generation of Multi-turn Exploits",
    "domain": "fairness",
    "content": "Large Language Models (LLMs) are improving at an exceptional rate. With the advent of agentic workflows, multi-turn dialogue has become the de facto mode of interaction with LLMs for completing long and complex tasks. While LLM capabilities continue to improve, they remain increasingly susceptible to jailbreaking, especially in multi-turn scenarios where harmful intent can be subtly injected across the conversation to produce nefarious outcomes. While single-turn attacks have been extensively explored, adaptability, efficiency and effectiveness continue to remain key challenges for their multi-turn counterparts. To address these gaps, we present PLAGUE, a novel plug-and-play framework for designing multi-turn attacks inspired by lifelong-learning agents. PLAGUE dissects the lifetime of a multi-turn attack into three carefully designed phases (Primer, Planner and Finisher) that enable a systematic and information-rich exploration of the multi-turn attack family. Evaluations show that red-teaming agents designed using PLAGUE achieve state-of-the-art jailbreaking results, improving attack success rates (ASR) by more than 30% across leading models in a lesser or comparable query budget. Particularly, PLAGUE enables an ASR (based on StrongReject) of 81.4% on OpenAI's o3 and 67.3% on Claude's Opus 4.1, two models that are considered highly resistant to jailbreaks in safety literature. Our work offers tools and insights to understand the importance of plan initialization, context optimization, and lifelong learning in crafting multi-turn attacks for a comprehensive model vulnerability evaluation.",
    "key_points": [
      "llm red-teaming",
      "agentic ai"
    ],
    "gold_summary": "This paper introduces PLAGUE, a modular, memory-augmented multi-round jailbreak framework that coordinates a three-stage Planner–Primer–Finisher pipeline, achieving state-of-the-art attack-success rates on several mainstream LLMs."
  },
  {
    "paper_id": "Y9TgNFsNyP",
    "title": "FF-Erase : Machine Unlearning and Verification for Forward-Forward Models",
    "domain": "fairness",
    "content": "The Forward-Forward (FF) algorithms present promising and biologically plausible alternatives to backpropagation (BP), enabling efficient model training through layer-wise greedy optimization. However, the critical task of machine unlearning for FF models, which involves efficiently removing specific training data's influence without full retraining, remains a foundational yet unexplored problem. The inherent characteristics of FF models, such as their sensitivity to parameter tuning and layer-wise independent training, pose unique challenges, often causing catastrophic model collapse when applying conventional unlearning methods. To fill this gap, we introduce a novel unlearning framework specifically for FF models, which employs a goodness-guided strategy. This method proposes a stable guidance model to generate target goodness distributions, steering the original model to unlearn forgetting data by shifting its layer-wise goodness scores, thereby effectively adapting gradient-based unlearning for the FF architecture. To enable robust verification on unlearning performance, we also propose a novel goodness-based membership inference attack (G-MIA), a powerful and lightweight black-box attack that leverages the unique properties of FF models' goodness scores. Our experiments demonstrate that our proposed method effectively removes the influence of target forgetting data on FF models while preserving model utility on the remaining data. Critically, our approach accomplishes 1.9 to 3.1$\\times$ faster than retraining from scratch, establishing an efficient foundation for FF unlearning.",
    "key_points": [
      "forward-forward",
      "machine unlearning",
      "machine unlearning verification",
      "backpropagation-free"
    ],
    "gold_summary": "This paper presents the first unlearning method for forward-forward models as well as a membership inference attack for the FF architecture."
  },
  {
    "paper_id": "nz4ZqbrBEi",
    "title": "Searching for Privacy Risks in LLM Agents via Simulation",
    "domain": "fairness",
    "content": "The widespread deployment of LLM-based agents is likely to introduce a critical privacy threat: malicious agents that proactively engage others in multi-turn interactions to extract sensitive information. However, the evolving nature of such dynamic dialogues makes it challenging to anticipate emerging vulnerabilities and design effective defenses. To tackle this problem, we present a search-based framework that alternates between improving attack and defense strategies through the simulation of privacy-critical agent interactions. Specifically, we employ LLMs as optimizers to analyze simulation trajectories and iteratively propose new agent instructions. To explore the strategy space more efficiently, we further utilize parallel search with multiple threads and cross-thread propagation. Through this process, we find that attack strategies escalate from direct requests to sophisticated tactics, such as impersonation and consent forgery, while defenses evolve from simple rule-based constraints to robust identity-verification state machines. The discovered attacks and defenses transfer across diverse scenarios and backbone models, demonstrating strong practical utility for building privacy-aware agents.",
    "key_points": [
      "llm agent",
      "privacy",
      "search",
      "ai risk"
    ],
    "gold_summary": "Paper studies privacy in LLM agents during interaction, i.e. multi-turn settings. However, in absence of real-world data, authors propose a nice way of simulating different scenarios and iteratively improving both defenses and attacks."
  },
  {
    "paper_id": "10gpXxro8z",
    "title": "Evaluating off-the-shell LLMs’  Red-teaming Ability  for Multi-round Jailbreak Attack",
    "domain": "fairness",
    "content": "Safety evaluation of large language models (LLMs) has emerged as a critical re-\nsearch frontier. To ensure comprehensive evaluation, current practices often in-\nvolve curating task-specific benchmark datasets tailored to distinct application\nscenarios. However, such dataset-centric approaches suffer from two fundamental\nlimitations: poor transferability across domains and temporal obsolescence due\nto the evolving nature of LLMs. To overcome these limitations, an intuitive idea\nis to leverage off-the-shelf LLMs as red teams. Yet, a pivotal question remains\nunder-explored: Can off-the-shelf LLMs conduct autonomous and effective secu-\nrity evaluations without specialized red team training? Motivated by this question,\nwe further raise the bar by focusing on multi-round jailbreaking attacks, which de-\nmand deeper strategic reasoning and intent concealment compared to single-round\nadversarial prompts. Unlike traditional red team evaluation methods for LLMs,\nwhich focus on assessing the robustness and security of these models, Our method\naims to leverage the inherent capabilities of off-the-shelf LLMs to evaluate their\npotential for cross-scenario transfer and iterative evolution over time during red\nteam testing. Specifically, we evaluate the red-teaming capabilities of six off-the-\nshelf LLMs across five major and ten secondary harmful categories. Experimental\nresults indicate that these models exhibit non-trivial proficiency in performing ef-\nfective multi-turn attacks, often employing known jailbreaking techniques such\nas role-playing, indirect prompting, and semantic decomposition. Nevertheless,\nsignificant limitations persist. Based on our findings, we discuss actionable direc-\ntions for enhancing the effectiveness of red-team LLMs, as well as implications\nfor strengthening the robustness of victim models.",
    "key_points": [
      "llm",
      "read-teaming",
      "jailbreak"
    ],
    "gold_summary": "How well can LLMs red-team other LLMs in a multi-turn scenario? They evaluate 5 categories Security, Criminal, Harassment, Violence, and Sexual and evaluated Qwen-2.5 7B Instruct, DeepSeek v3 and LLama3 70B."
  },
  {
    "paper_id": "EG6K7ZWOwQ",
    "title": "Revisiting Backdoor Attacks on LLMs: A Stealthy and Practical Poisoning Framework via Harmless Inputs",
    "domain": "fairness",
    "content": "Recent studies have widely investigated backdoor attacks on Large Language Models (LLMs) by inserting harmful question-answer (QA) pairs into their training data. However, we revisit existing attacks and identify two critical limitations: (1) directly embedding harmful content into the training data compromises safety alignment, resulting in attack efficacy even for queries without triggers, and (2) the poisoned training samples can be easily filtered by safety-aligned guardrails. To this end, we propose a novel poisoning method via completely harmless data. Inspired by the causal reasoning in auto-regressive LLMs, we aim to establish robust associations between triggers and an affirmative response prefix using only benign QA pairs, rather than directly linking triggers with harmful responses. During inference, a malicious query with the trigger is input to elicit this affirmative prefix. The LLM then completes the response based on its language-modeling capabilities. Achieving this using only clean samples is non-trivial. We observe an interesting \\textit{resistance} phenomenon where the LLM initially appears to agree but subsequently refuses to answer. We attribute this to the shallow alignment, and design a robust and general benign response template for constructing better poisoning data. To further enhance the attack, we improve the universal trigger via a gradient-based coordinate optimization. Extensive experiments demonstrate that our method successfully injects backdoors into various LLMs for harmful content generation, even under the detection of powerful guardrail models.",
    "key_points": [
      "backdoor attack",
      "large language models"
    ],
    "gold_summary": "This paper introduces a novel and stealthy backdoor attack framework for Large Language Models (LLMs) that, for the first time, relies exclusively on harmless data."
  },
  {
    "paper_id": "vrlj7anjeq",
    "title": "Rao Differential Privacy",
    "domain": "fairness",
    "content": "Differential privacy (DP) has recently emerged as a definition of privacy to release private estimates. DP calibrates noise to be on the order of an individual's contribution. Due to this calibration, a private estimate obscures any individual while preserving the utility of the estimate. Since the original definition, many alternate definitions have been proposed. These alternates have been proposed for various reasons including improvements on composition results, relaxations, and formalizations. Nevertheless, thus far nearly all definitions of privacy have used a divergence of densities as the basis of the definition. In this paper we take an information geometry perspective towards differential privacy. Specifically, rather than define privacy via a divergence, we define privacy via the Rao distance. We show that our proposed definition of privacy shares the interpretation of previous definitions of privacy while improving on sequential composition.",
    "key_points": [
      "differential privacy",
      "information geometry",
      "rao metric"
    ],
    "gold_summary": "The paper introduces a new notion of differential privacy namely Rao DP"
  },
  {
    "paper_id": "G4CN6xgQ3k",
    "title": "Failure Modes of Maximum Entropy RLHF",
    "domain": "fairness",
    "content": "In this paper, we show that Simple Preference Optimization (SimPO) can be derived as Maximum Entropy Reinforcement Learning with length-normalized temperature, providing a theoretical foundation for this reference-free method. Motivated by SimPO's strong performance in offline preference optimization, we investigate whether Maximum Entropy RL can achieve similar results in online RLHF settings. Our experiments find that Maximum Entropy RL consistently exhibits overoptimization and unstable KL dynamics, even at very low learning rates. Unlike KL-constrained methods that maintain stable training, entropy regularization fails to prevent reward hacking and appears to correlate with overoptimization. Lastly, we discuss possible explanations for why SimPO succeeds in offline settings while Maximum Entropy RL struggles in online scenarios. Our findings suggest that reference-free approaches may face distinct challenges when applied to online or offline preference learning.",
    "key_points": [
      "preference learning",
      "rlhf",
      "maximum entropy rl",
      "alignment"
    ],
    "gold_summary": "The paper explores the connection between the SimPO method and maximum entropy reinforcement learning, and examines the effectiveness of maximum entropy RL in online RLHF settings."
  },
  {
    "paper_id": "pJoSE7Cvj0",
    "title": "The Achilles’ Heel of LLMs: How Altering a Handful of Neurons Can Cripple Language Abilities",
    "domain": "fairness",
    "content": "Large Language Models (LLMs) have become foundational tools in natural language processing, powering a wide range of applications and research. Many studies have shown that LLMs share significant similarities with the human brain. Recent neuroscience research has found that a small subset of biological neurons in the human brain are crucial for core cognitive functions, which raises a fundamental question: do LLMs also contain a small subset of critical neurons? In this paper, we investigate this question by proposing a Perturbation-based Causal Identification of Critical Neurons method to systematically locate such critical neurons in LLMs. Our findings reveal three key insights:\n(1) LLMs contain ultra-sparse critical neuron sets. Disrupting these critical neurons can cause a 72B-parameter model with over 1.1 billion neurons to completely collapse, with perplexity increasing by up to 20 orders of magnitude;\n(2) These critical neurons are not uniformly distributed, but tend to concentrate in the outer layers, particularly within the MLP down\\_proj components;\n(3) Performance degradation exhibits sharp phase transitions, rather than a gradual decline, when these critical neurons are disrupted.\nThrough comprehensive experiments across diverse model architectures and scales, we provide deeper analysis of these phenomena and their implications for LLM robustness and interpretability. These findings can offer guidance for developing more robust model architectures and improving deployment security in safety-critical applications. Our code is available at https://anonymous.4open.science/r/The-Achilles-Heel-of-LLMs-7C02.",
    "key_points": [
      "ultra-sparse neuron sets",
      "perturbation-based identification",
      "catastrophic failure"
    ],
    "gold_summary": "The paper identifies a small subset of neurons in language models that, when disrupted, can significantly alter the performance and comprehension of the model. These findings are tested for several model sizes."
  },
  {
    "paper_id": "dOxOX4GF1k",
    "title": "The Robustness-Security Paradox: Channel-Aware Feature Learning for Adversarial Watermark Exploitation",
    "domain": "fairness",
    "content": "Watermarking is crucial for establishing provenance and detecting AI-generated content. While current approaches prioritize robustness against real-world distortions, we explore how the robustness-security tradeoff manifests in deep learning-based watermarks: robust watermarks necessarily increase the redundancy of detectable watermark patterns embedded in images, creating exploitable information leakage. Leveraging this insight, we introduce an attack framework that extracts watermark pattern leakage through multi-channel feature learning using pre-trained vision models. Unlike previous approaches that require extensive data or detector access, our method achieves both watermark removal (detection evasion) and watermark forgery attacks with just a single watermarked image in a no-box setting. Extensive experiments demonstrate our method outperforms state-of-the-art techniques by 74\\% in detection evasion rate and 47\\% in forgery accuracy, while preserving visual quality.",
    "key_points": [
      "image watermarking",
      "watermarking security",
      "ai-generated content detection"
    ],
    "gold_summary": "This paper proposes a method for evading state-of-the-art watermarking approaches and also copying them. The insight is that many of the most robust watermark become more ``detectable'' slash learnable to some degree."
  },
  {
    "paper_id": "vfbeleLBWv",
    "title": "Trust The Typical",
    "domain": "fairness",
    "content": "Current approaches to LLM safety fundamentally rely on a brittle cat-and-mouse game of identifying and blocking known threats via guardrails. We argue for a fresh approach: robust safety comes not from enumerating what is harmful, but from \\emph{deeply understanding what is safe}. We introduce \\textbf{T}rust \\textbf{T}he \\textbf{T}ypical \\textbf{(T3)}, a framework that operationalizes this principle by treating safety as an out-of-distribution (OOD) detection problem. T3 learns the distribution of acceptable prompts in a semantic space and flags any significant deviation as a potential threat. Unlike prior methods, it requires no training on harmful examples, yet achieves state-of-the-art performance across 18 benchmarks spanning toxicity, hate speech, jailbreaking, multilingual harms, and over-refusal, reducing false positive rates by up to 40x relative to specialized safety models. A single model trained only on safe English text transfers effectively to diverse domains and over 14 languages without retraining. Finally, we demonstrate production readiness by integrating a GPU-optimized version into vLLM, enabling continuous guardrailing during token generation with less than 6\\% overhead even under dense evaluation intervals on large-scale workloads.",
    "key_points": [
      "llm safety",
      "out-of-distribution detection",
      "jailbreaking",
      "representation learning",
      "selective generation",
      "anomaly detection"
    ],
    "gold_summary": "The paper proposed to frame LLM safety from OOD perspective which significantly advances the performance of existing methods. The paper also demonstrated potential integration with vLLM for minimum over-head usage."
  },
  {
    "paper_id": "JFaCPwvzGz",
    "title": "Sample-wise Adaptive Weighting for Transfer Consistency in Adversarial Distillation",
    "domain": "fairness",
    "content": "Adversarial distillation aims to transfer robustness from a large, robust teacher network to a compact student. However, existing work often neglects to incorporate state-of-the-art robust teachers. Through extensive analysis, we find that stronger teachers do not necessarily yield more robust students–a phenomenon known as robust saturation. While typically attributed to capacity gaps, we show that such explanations are incomplete. Instead, we identify adversarial transferability–the fraction of student-crafted adversarial examples that remain effective against the teacher–as a key factor in successful robustness transfer. Based on this insight, we propose Sample-wise Adaptive Adversarial Distillation (SAAD), which reweights training examples by their measured transferability without incurring additional computational cost. Experiments on CIFAR-10, CIFAR-100, and Tiny-ImageNet show that SAAD consistently improves AutoAttack robustness over prior methods.",
    "key_points": [
      "adversarial training",
      "adversarial distillation",
      "robust saturation"
    ],
    "gold_summary": "This paper finds that adversarial transferability plays an important role in adversarial robust distillation(ARD), and further proposes a Sample-wise Adaptive Adversarial Distillation to enhance the effectiveness of ARD."
  },
  {
    "paper_id": "J2UFyF9YeD",
    "title": "AutoBackdoor: Automating Backdoor Attacks via LLM Agents",
    "domain": "fairness",
    "content": "Backdoor attacks pose a serious threat to the secure deployment of large language models (LLMs), enabling adversaries to implant hidden behaviors triggered by specific inputs. However, existing methods often rely on manually crafted triggers and static data pipelines, which are rigid, labor-intensive, and inadequate for systematically evaluating modern defense robustness. As AI agents become more capable, there is a growing need for more rigorous, diverse, and scalable attack strategies.\nIn this work, we introduce \\textsc{AutoBackdoor}, a general framework for automating backdoor injection, encompassing trigger generation, poisoned data construction, and model fine-tuning via an autonomous agent-driven pipeline. Unlike prior approaches, AutoBackdoor uses a powerful language model agent to generate semantically coherent, context-aware trigger phrases, enabling scalable poisoning across arbitrary topics with minimal human effort. \nWe evaluate AutoBackdoor under three realistic threat scenarios, including \\textit{Bias Recommendation}, \\textit{Hallucination Injection}, and \\textit{Peer Review Manipulation}, to simulate a broad range of attacks. Experiments on both open-source and commercial models, including LLaMA-3, Mistral, Qwen, and GPT-4o, demonstrate that our method achieves over 90\\% attack success with only a small number of poisoned samples.\nMore importantly, we find that existing defenses often fail to mitigate these attacks, underscoring the need for more rigorous and adaptive evaluation techniques against agent-driven threats as explored in this work.",
    "key_points": [
      "backdoor attacks",
      "llm agent"
    ],
    "gold_summary": "The paper describes an automated technique for backdoor injection, which creates an agent that generates triggers, constructs poisoned data and fine-tunes the model."
  },
  {
    "paper_id": "tVe3qmrH2h",
    "title": "Rethinking LLM Human Simulation: When a Graph is What You Need",
    "domain": "fairness",
    "content": "Large language models (LLMs) are increasingly used to simulate humans, with applications ranging from survey prediction to decision-making. However, are LLMs strictly necessary, or can smaller, domain-grounded models suffice? We identify a large class of simulation problems in which individuals make choices among discrete options, where a graph neural network (GNN) can match or surpass strong LLM baselines despite being three orders of magnitude smaller. We introduce Graph-basEd Models for Human Simulation (GEMS), which casts discrete choice simulation tasks as a link prediction problem on graphs, leveraging relational knowledge while incorporating language representations only when needed. Evaluations across three key settings on two simulation datasets show that GEMS achieves comparable or better accuracy than LLMs, with far greater efficiency, interpretability, and transparency, highlighting the promise of graph-based modeling as a lightweight alternative to LLMs for human simulation.",
    "key_points": [
      "social and human simulation",
      "graphs",
      "large language models",
      "representation learning"
    ],
    "gold_summary": "This paper reframes a classic recommender-style GNN as an alternative to LLMs for discrete choice prediction. While competently executed, it lacks conceptual novelty, overstates its claims about “human simulation,” and provides limited scientific insight."
  },
  {
    "paper_id": "orzX69D5UO",
    "title": "Cognitive Control Architecture (CCA): A Lifecycle Supervision Framework for Robustly Aligned AI Agents",
    "domain": "fairness",
    "content": "Autonomous Large Language Model (LLM) agents exhibit significant vulnerability to Indirect Prompt Injection (IPI) attacks. These attacks hijack agent behavior by polluting external information sources, exploiting fundamental trade-offs between security and functionality in existing defense mechanisms. This leads to malicious and unauthorized tool invocations, diverting agents from their original objectives. The success of complex IPIs reveals a deeper systemic fragility: while current defenses demonstrate some effectiveness, most models are inherently fragmented. Consequently, they fail to provide full integrity assurance across the entire task execution pipeline, forcing unacceptable multi-dimensional compromises among security, functionality, and efficiency. Our method is predicated on a core insight: no matter how subtle an IPI attack, its pursuit of a malicious objective will ultimately manifest as a detectable deviation in the action trajectory, distinct from the expected legitimate plan. Based on this, we propose the Cognitive Control Architecture (CCA), a holistic framework achieving full-lifecycle cognitive supervision. CCA constructs an efficient, dual-layered defense system through two synergistic pillars: (i) proactive and preemptive control-flow integrity enforcement via a pre-generated \"Intent Graph\"; and (ii) an innovative \"Tiered Adjudicator\" that, upon deviation detection, initiates deep reasoning based on multi-dimensional scoring, specifically designed to counter complex conditional attacks. Experiments on the AgentDojo benchmark demonstrate that CCA not only effectively withstands sophisticated attacks that challenge other advanced defense methods but also achieves superior security with outstanding efficiency and enhanced robustness, thereby resolving the aforementioned multi-dimensional trade-off dilemma.",
    "key_points": [
      "cognitive control",
      "lifecycle supervision",
      "injection attacks",
      "adversarial robustness",
      "ai safety",
      "ai agents"
    ],
    "gold_summary": "This paper introduces a new defense approach, Cognitive Control Architecture (CCA), aiming to guard against IPI attacks. They claim that this approach is superior to other existing approaches."
  },
  {
    "paper_id": "6R42MRRs50",
    "title": "Angel or Demon: Investigating the Plasticity-Enhanced Strategies' Impact on Backdoor Threats in Deep Reinforcement Learning",
    "domain": "fairness",
    "content": "Deep Reinforcement Learning (DRL) faces significant threats from backdoor attacks, as indicated by numerous studies.\nHowever, these studies are conducted under idealized scenarios, whereas in practical settings DRL agents typically incorporate intervention strategies to maintain the policy's plasticity.\nSuch discrepancies may lead to misperceptions regarding the severity and nature of DRL backdoor attacks.\nTo bridge this gap, we investigate three research questions: \n(1) How do interventions impact backdoor attacks in DRL? \n(2) What are the underlying causes of these impacts? \n(3) What novel effects emerge when interventions are combined?\nTo answer these questions, we empirically study 10,998 cases covering representative interventions and attack scenarios.\nThe results reveal that most interventions, such as *Weight Clipping* and *Layer Normalization*, mitigate backdoor attacks due to two main mechanisms: disrupting fragile backdoor pathways and expanding the agent's representation space.\nInterestingly, *SAM* exacerbates the backdoor threat (e.g., leading to a 99.51\\% relative increase in attack effectiveness in robotic tasks) as it flattens the loss landscape, which reduces the pathway competition between the backdoor and benign tasks.\nNotably, combining *SAM* with other interventions further amplifies this effect.\nDrawing on these findings, we highlight two novel insights into robust backdoor injection and sharpness-based detection, with the aim of inspiring future research.",
    "key_points": [
      "deep reinforcement learning",
      "backdoor attacks",
      "plasticity"
    ],
    "gold_summary": "This paper focuses on backdoor attacks and deep reinforcement learning plasticity, and  shows that interventions, such as Weight Clipping and Layer Normalization, mitigate backdoor attacks by expanding the agent’s representation space."
  },
  {
    "paper_id": "nBta7psl5J",
    "title": "Uncovering Competing Poisoning Attacks in Retrieval-Augmented Generation",
    "domain": "fairness",
    "content": "Retrieval-Augmented Generation (RAG) systems improve the factual grounding of large language models (LLMs) but remain vulnerable to retrieval poisoning, where adversaries seed the corpus with manipulated content. Prior work largely evaluates this threat under a simplified single-attacker assumption. In practice, however, high-value or high-visibility queries attract multiple adversaries with conflicting objectives. Motivated by real cases, we introduce the setting of competing attacks, in which multiple attackers simultaneously attempt to steer the same (or closely related) query toward different targets. We formalize this threat model and propose competitive effectiveness, a metric that quantifies an attacker’s advantage under competition. Extensive experiments show that many strategies that succeed in the single-attacker regime degrade markedly under competition, revealing performance inversions and highlighting the limits of conventional metrics such as attack success rate and F1. Further more, we present PoisonArena, a standardized framework and benchmark for evaluating poisoning attacks and defenses under realistic, multi-adversary conditions. Our code is included in the supplementary materials.",
    "key_points": [
      "rag poison attack",
      "trustwrothy ai",
      "retrieval system poison attack"
    ],
    "gold_summary": "This paper presents the concept of competing attacks, a multi-adversary threat model for retrieval-augmented generation systems where multiple attackers attempt to influence the same query at the same time."
  },
  {
    "paper_id": "T5hD0as3jb",
    "title": "Toward Universal and Transferable Jailbreak Attacks on Vision-Language Models",
    "domain": "fairness",
    "content": "Vision–language models (VLMs) extend large language models (LLMs) with vision encoders, enabling text generation conditioned on both images and text. However, this multimodal integration expands the attack surface by exposing the model to image-based jailbreaks crafted to induce harmful responses. Existing gradient-based jailbreak methods transfer poorly, as adversarial patterns overfit to a single white-box surrogate and fail to generalise to black-box models. In this work, we propose **U**niversa**l** and **tra**nsferable jail**break** (**UltraBreak**), a framework that constrains adversarial patterns through transformations and regularisation in the vision space, while relaxing textual targets through semantic-based objectives. By defining its loss in the textual embedding space of the target LLM, UltraBreak discovers universal adversarial patterns that generalise across diverse jailbreak objectives. This combination of vision-level regularisation and semantically guided textual supervision mitigates surrogate overfitting and enables strong transferability across both models and attack targets. Extensive experiments show that UltraBreak consistently outperforms prior jailbreak methods. Further analysis reveals why earlier approaches fail to transfer, highlighting that smoothing the loss landscape via semantic objectives is crucial for enabling universal and transferable jailbreaks.",
    "key_points": [
      "vision-language model",
      "jailbreak",
      "transferability"
    ],
    "gold_summary": "The authors propose a new VLM jailbreaking algorithm that tries to develop universal and transferable adversarial attacks on VLMs."
  },
  {
    "paper_id": "ZcxSBLmQm4",
    "title": "TrojanPraise: Jailbreak LLMs via Benign Fine-Tuning",
    "domain": "fairness",
    "content": "The rapid demand of customized large language models (LLMs) in various fields has led to commercial LLMs offering black-box fine-tuning APIs, yet this convenience introduces a critical security loophole: attackers could jailbreak the LLMs by fine-tuning them with malicious data. Though this security issue has recently been exposed, the feasibility of such attacks is questionable as malicious contents are readily detectable by moderation models such as Llama-Guard-3. In this paper, we propose TrojanPraise, a novel finetuning-based attack exploiting benign and thus filter-approved data. Specifically, TrojanPraise introduces a novel, seemingly innocuous word (e.g., ”bruaf”) and fine-tunes the model to associate it with positive, safe connotations. It then uses this new word to praise harmful concepts, subtly shifting the LLM’s attitude from refusal to compliance. To explain the attack’s underlying principle, we decouples the LLM’s internal representation of a concept into two dimensions: its objective knowledge and its safety-aligned attitude, and connect the LLM jailbreak to variations in these two dimensions. To empirically validate this attack, we conduct experiments on five open-source LLMs and two commercial LLMs under strict black-box settings. Results show that TrojanPraise achieves a maximum attack success rate of 95.88% while evading moderation models.",
    "key_points": [
      "llm security",
      "fine-tuning llm"
    ],
    "gold_summary": "This paper propose to replace harmful words with unseen words to bypass dataset detection for malicious finetuning."
  },
  {
    "paper_id": "c1fr8fmiaW",
    "title": "Black-box Attack Robustness with Model Diversity and Randomization",
    "domain": "fairness",
    "content": "Query-based black-box attack algorithms can compute imperceptible adversarial perturbations to misguide learned models, relying only on model outputs. The success of these attack algorithms poses a significant problem, especially for Machine Learning as a Service (MLaaS) providers. Our study explores a new approach to obfuscate information from an attacker. To craft an adversarial example, attacks\nexploit the relationship between successive responses to queries to optimize a perturbation. Our idea to attempt to obfuscate this relationship is to randomly select a model from a diverse set of models to respond to each query. Effectively, this randomization of models violates the attacker’s assumption of model parameters remaining unaltered between queries to extract information. What is unclear is, if model randomization leads to sufficient obfuscation to confuse attacks or how best to build such a method. This study seeks answers to these questions. Our theoretical analysis proves this approach consistently increases robustness. Extensive experiments across 7 state-of-the-art attacks and all major perturbation norms ($l_\\infty$, $l_2$, $l_0$), including adaptive variants, confirm its effectiveness. Importantly, our findings reveal a new avenue for investigating robust methods against black-box attacks, offering theoretical understandings and a practical implementation pathway.",
    "key_points": [
      "adversarial robustness",
      "query-based black-box attacks",
      "adversarial defense"
    ],
    "gold_summary": "They propose a defense against black-box adversarial attacks. The main idea is to train multiple models, randomly select some of them, and output the mean logit."
  },
  {
    "paper_id": "Ng6RfkOm6A",
    "title": "Hi-SAFE: Hierarchical Secure Aggregation for Lightweight Federated Learning",
    "domain": "fairness",
    "content": "Federated learning (FL) faces challenges in ensuring both privacy and communication efficiency, particularly in resource-constrained environments such as Internet of Things (IoT) and edge networks. While sign-based methods, such as sign stochastic gradient descent with majority voting (signSGD-MV), offer substantial bandwidth savings, they remain vulnerable to inference attacks due to exposure of gradient signs. Existing secure aggregation techniques are either incompatible with sign-based methods or incur prohibitive overhead. To address these limitations, we propose *Hi-SAFE*, a lightweight and cryptographically secure aggregation framework for sign-based FL. Our core contribution is the construction of efficient majority vote polynomials for signSGD-MV, derived from Fermat’s Little Theorem. This formulation represents the majority vote as a low-degree polynomial over a finite field, enabling secure evaluation that hides intermediate values and reveals only the final result. We further introduce a hierarchical subgrouping strategy that ensures constant multiplicative depth and bounded per-user complexity, independent of the number of users $n$. Hi-SAFE reduces per-user communication by over 94\\% when $n \\geq 24$, and total cost by up to 52\\% at $n = 24$, while preserving model accuracy. Experiments on benchmark datasets confirm the scalability, robustness, and practicality of Hi-SAFE in bandwidth-constrained FL deployments.",
    "key_points": [
      "hierarchical secure aggregation",
      "federated learning",
      "majority vote polynomial",
      "subgrouping"
    ],
    "gold_summary": "This paper proposes Hi-SAFE, a cryptographic secure-aggregation framework tailored to SIGNSGD-MV in federated learning."
  },
  {
    "paper_id": "4E9uxVIAFP",
    "title": "IOShift: Backdoor Defense via Model Bias Shift in Federated Learning",
    "domain": "fairness",
    "content": "As a privacy-preserving and decentralized machine learning framework, Federated Learning (FL) is vulnerable to backdoor attacks. Current backdoor defenses rely on a strong assumption: defenders have the ability of defining a benign parameter space using gradient information to detect or remove malicious updates. However, in the real-world not-independent-and-identically-distributed (Non-IID) FL scenarios, this is a particularly challenging task, exhibiting inconsistent performance across different systems and settings. In this paper, we reveal the Backdoor-Induced Model Bias Shift phenomenon, where the implantation of backdoor shortcuts shifts the model bias on out-of-distribution (OOD) data toward the target class. Inspired by this insight, we propose IOShift, a novel backdoor detection and removal method based on model bias shift in federated learning. IOShift detects malicious updates by measuring bias shifts on OOD data, using the model bias on in-distribution data as a reference. Furthermore, it employs adaptive weight pruning to maintain high utility on clean tasks. IOShift seamlessly integrates into existing FL frameworks without requiring any modifications, such as altering communication protocols or injecting elaborated tasks. Experimental results on benchmark datasets and backdoor attacks demonstrate that IOShift effectively outperforms state-of-the-art backdoor defenses. Code is available here.",
    "key_points": [
      "federated learning",
      "backdoor defense"
    ],
    "gold_summary": "This paper reveal the backdoor induced model bias shift phenomenon and propose IOShift which utilize the bias shift on OOD data as a reference for backdoor detection."
  },
  {
    "paper_id": "SxhaFybHxp",
    "title": "BEYOND SINGLE-AXIS FAIRNESS: LEARNING TO DETECT INTERSECTIONAL BIASES",
    "domain": "fairness",
    "content": "Large Language Models (LLMs) are increasingly deployed in high-stakes domains, yet they often inherit intersectional biases, prejudices that emerge not from a single axis such as race or gender, but from their intersections (e.g., “Black women are too aggressive for leadership”). Existing bias detection and mitigation methods predominantly address single-axis biases and fail to generalize to their complex interactions. In this paper, we present the first unified framework for detecting and mitigating intersectional bias. We construct two paragraph-level intersectional bias dataset: \\texttt{Indic-Intersect} and \\texttt{Western-Intersect}, aligned to Indian and Western sociocultural contexts, respectively. For detection, we introduce \\textbf{\\textit{BiasRetriever}}, a contrastively trained retriever that learns a bias-aware embedding space by pulling biased text close to canonical stereotypes and pushing it away from unbiased or unrelated examples. BiasRetriever achieves up to $10\\%$ more Jaccard score over LLM-based classifiers on unseen intersectional categories and maintains robust cross-domain generalization.",
    "key_points": [
      "intersectional bias",
      "retriever",
      "actor-critic",
      "bias detection",
      "bias mitigation"
    ],
    "gold_summary": "This paper considers the problem of intersectional bias evaluation and a dataset is created for this purpose. Moreover, a Biasretriever model is trained for detecting social biases."
  },
  {
    "paper_id": "GG7YQnsdhp",
    "title": "Adaptive Social Learning via Mode Policy Optimization for Language Agents",
    "domain": "fairness",
    "content": "Effective social intelligence simulation requires language agents to dynamically adjust reasoning depth, a capability notably absent in current studies. Existing methods either lack explicit reasoning or employ lengthy Chain-of-Thought reasoning uniformly across all scenarios, resulting in excessive token usage and inflexible social behaviors in tasks such as negotiation or collaboration. \nTo address this, we propose an $\\textbf{A}$daptive $\\textbf{S}$ocial $\\textbf{L}$earning ($\\textbf{ASL}$) framework in this paper, aiming to improve the adaptive reasoning ability of language agents in dynamic social interactions. To this end, we first identify the hierarchical reasoning modes under such context, ranging from intuitive response to deep deliberation based on the cognitive control theory. We then develop the $\\textbf{A}$daptive $\\textbf{M}$ode $\\textbf{P}$olicy $\\textbf{O}$ptimization ($\\textbf{AMPO}$) algorithm to learn the context-aware mode adaptation and reasoning. Our framework advances existing research in three key aspects: (1) Multi-granular reasoning mode design, (2) Context-aware mode switching in rich social interaction, and (3) Token-efficient reasoning with depth adaptation. Extensive experiments on the benchmark social intelligence environment verify that ASL achieves 15.6\\% higher task performance than GPT-4o. Notably, our AMPO outperforms GRPO by 7.0\\% with 32.8\\% shorter thinking chains, demonstrating the advantages of our AMPO and the learned adaptive reasoning ability over GRPO's solution.",
    "key_points": [
      "social intelligene",
      "large language models",
      "adaptive social learning"
    ],
    "gold_summary": "This paper introduces ASL with four reasoning modes for LLM agents and an agent training algorithm AMPO with both mode-level advantage and sample-level advantage. Experiments showcase the performance improvement and token savings."
  },
  {
    "paper_id": "imxSI4yUZo",
    "title": "Green Pruning: Layer Interdependence-Aware CNN Pruning for Resource Efficiency",
    "domain": "fairness",
    "content": "The rising computational demands of pruning algorithms have heightened challenges about their energy consumption and carbon footprint in convolutional neural networks. We address these challenges from two perspectives. First, we introduce new evaluation metrics for pruning: a Resource Efficiency (RE) metric, which quantifies the computational cost required to achieve a target accuracy, and a system-agnostic framework for assessing the relative carbon efficiency of pruning algorithms. Together, these metrics enable fair and consistent comparisons of pruning methods with respect to both efficiency and sustainability. Second, we present a \\textbf{green pruning technique}, a data-free method that explicitly models inter-layer dependencies to provide a more reliable filter selection criterion. To further minimize computational overhead, our approach incorporates a low-complexity oblivious algorithm that leverages weak submodularity, ensuring efficiency without requiring iterative dataset passes.",
    "key_points": [
      "convolutional neural networks",
      "structured filter pruning",
      "model compression methods",
      "best approximation",
      "resource efficiency"
    ],
    "gold_summary": "This paper argues that we should also reduce the cost of the pruning method itself for CNN pruning. To this end, the authors propose a resource efficiency metric and a data-free green pruning technique."
  },
  {
    "paper_id": "e4nyUFKEbD",
    "title": "Correlating Cross-Iteration Noise for DP-SGD using Model Curvature",
    "domain": "fairness",
    "content": "Differentially private stochastic gradient descent (DP-SGD) offers the promise of training deep learning models while mitigating many privacy risks. However, there is currently a large accuracy gap between DP-SGD and \n normal SGD training. This has resulted in different lines of research investigating orthogonal ways of improving privacy-preserving training.\nOne such line of work, known as DP-MF,  correlates the privacy noise across different iterations of stochastic gradient descent -- allowing later iterations to cancel out some of the noise added to earlier iterations. In this paper, we study how to improve this noise correlation. We propose a technique called NoiseCurve that uses model curvature, estimated from public unlabeled data, to improve the quality of this cross-iteration noise correlation. Our experiments on various datasets, models, and privacy parameters show that the noise correlations computed by NoiseCurve offer consistent and significant improvements in accuracy over the correlation scheme used by DP-MF.",
    "key_points": [
      "machine learning",
      "differential privacy",
      "private machine learning",
      "matrix factorization"
    ],
    "gold_summary": "This paper proposes using public data to estimate the Hessian's eigenvalues for improving DP matrix factorization."
  },
  {
    "paper_id": "4NtoAVqfhA",
    "title": "Cultivating Pluralism In Algorithmic Monoculture: The Community Alignment Dataset",
    "domain": "safety",
    "content": "How can large language models (LLMs) serve users with varying preferences that may conflict across cultural, political, or other dimensions? To advance this challenge, this paper establishes four key results. First, we demonstrate, through a large-scale multilingual human study with representative samples from five countries (N=15,000), that humans exhibit significantly more variation in preferences than the responses of 21 state-of-the-art LLMs. Second, we show that existing methods for preference dataset collection are insufficient for learning the diversity of human preferences even along two of the most salient dimensions of variability in global values, due to the underlying homogeneity of candidate responses. Third, we argue that this motivates the need for negatively-correlated sampling when generating candidate sets, and we show that simple prompt-based techniques for doing so significantly enhance the performance of alignment methods in learning heterogeneous preferences. Fourth, based on this novel candidate sampling approach, we collect and open-source Community Alignment, the largest and most representative multilingual and multi-turn preference dataset to date, featuring almost 200,000 comparisons from annotators spanning five countries. We hope that the Community Alignment dataset will be a valuable resource for improving the effectiveness of LLMs for a diverse global population.",
    "key_points": [
      "preference datasets",
      "pluralistic alignment",
      "algorithmic monoculture",
      "human feedback"
    ],
    "gold_summary": "This work 1) identifies that general-purpose LMs are in the same \"monoculture\", that they struggle to represent diverse dimensions of preferences; 2) collects a dataset called community alignment, with negative-correlated sampling and human annotations."
  },
  {
    "paper_id": "5coA0SxUua",
    "title": "Safe Reinforcement Learning with ADRC Lagrangian Method",
    "domain": "safety",
    "content": "Safe reinforcement learning (Safe RL) seeks to maximize rewards while satisfying safety constraints, typically addressed through Lagrangian-based methods. However, existing approaches, including PID and classical Lagrangian methods, suffer from oscillations and frequent safety violations due to parameter sensitivity and inherent phase lag. To address these limitations, we propose ADRC-Lagrangian methods that leverage Active Disturbance Rejection Control (ADRC) for enhanced robustness and reduced oscillations. Our unified framework encompasses classical and PID Lagrangian methods as special cases while significantly improving safety performance. Extensive experiments demonstrate that our approach reduces safety violations by up to 74\\%, constraint violation magnitudes by 89\\%, and average costs by 67\\%, establishing superior effectiveness for Safe RL in complex environments.",
    "key_points": [
      "ai safety",
      "safe reinforcement learning",
      "trustworthy"
    ],
    "gold_summary": "This paper introduces an effective method to optimize the Lagrangian multiplier update process in safe RL, reducing oscillation during training."
  },
  {
    "paper_id": "tMRTMdi5Hz",
    "title": "Elo-Evolve: A Co-evolutionary Framework for Language Model Alignment",
    "domain": "safety",
    "content": "Current alignment methods for Large Language Models (LLMs) rely on compressing vast amounts of human preference data into static, absolute reward functions, leading to data scarcity, noise sensitivity, and training instability. We introduce Elo-Evolve a co-evolutionary framework that redefines alignment as dynamic multi-agent competition within an adaptive opponent pool. Our approach makes two key innovations: (1) eliminating Bradley-Terry model dependencies by learning directly from binary win/loss outcomes in pairwise competitions, and (2) implementing Elo-orchestrated opponent selection that provides automatic curriculum learning through temperature-controlled sampling. We ground our approach in PAC learning theory, demonstrating that pairwise comparison achieves superior sample complexity (O(1/ε) vs O(1/ε2)) and empirically validate a 4.5$\\times$ noise reduction compared to absolute scoring approaches. Experimentally, we train a Qwen2.5-7B model using our framework with opponents including Qwen2.5-14B, Qwen2.5-32B, and Qwen3-8B models. Results demonstrate a clear performance hierarchy: point-based methods $<$ static pairwise training $<$ Elo-Evolve across Alpaca Eval 2.0 and MT-Bench, validating the progressive benefits of pairwise comparison and dynamic opponent selection for LLM alignment.",
    "key_points": [
      "co-evolutionary",
      "alignment",
      "language model"
    ],
    "gold_summary": "This work introduces a novel method of preference optimization by using a dynamic elo as the reward for RLHF. The idea is clear and the method is clearly presented. Experiments have shown significant improvement."
  },
  {
    "paper_id": "bYA07SdHoS",
    "title": "Jailbreaking Commercial Black-Box LLMs with Explicitly Harmful Prompts",
    "domain": "safety",
    "content": "Jailbreaking commercial black-box models is one of the most challenging and serious security threats today. Existing attacks achieve certain success on non-reasoning models but perform limitedly on the latest reasoning models. We discover that carefully crafted developer messages can markedly boost jailbreak effectiveness. Building on this, we propose two developer-role-based attacks: D-Attack, which enhances contextual simulation, and DH-CoT, which strengthens attacks with deceptive chain-of-thought. In experiments, we further diccover that current red-teaming datasets often contain samples unsuited for measuring attack gains: prompts that fail to trigger defenses, prompts where malicious content is not the sole valid output, and benign prompts. Such data hinders accurate measurement of the true improvement brought by an attack method. To address this, we introduce MDH, a Malicious content Detection approach combining LLM-based screening with Human verification to balance accuracy and cost, with which we clean data and build the RTA dataset series. Experiments demonstrate that MDH reliably filters low-quality samples and that developer messages significantly improve jailbreak attack success. Codes, datasets, and other results are in appendix.",
    "key_points": [
      "jailbreak attack",
      "malicious content detection",
      "large language model"
    ],
    "gold_summary": "The paper proposes to instruct the attacker LLM with developer-role messages, which improve jailbreak success on target commercial-scale target models. Authors also release a cleaned, attack-oriented RTA dataset for more comprehensive evaluation."
  },
  {
    "paper_id": "tlYSbw5GXY",
    "title": "Closing the Safety Gap: Surgical Concept Erasure in Visual Autoregressive Models",
    "domain": "safety",
    "content": "The rapid progress of visual autoregressive (VAR) models has brought new opportunities for text-to-image generation, but also heightened safety concerns. Existing concept erasure techniques, primarily designed for diffusion models, fail to generalize to VARs due to their next-scale token prediction paradigm. In this paper, we first propose a novel VAR Erasure framework **VARE** that enables stable concept erasure in VAR models by leveraging auxiliary visual tokens to reduce fine-tuning intensity. Building upon this, we introduce **S-VARE**, a novel and effective concept erasure method designed for VAR, which incorporates a filtered cross entropy loss to precisely identify and minimally adjust unsafe visual tokens, along with a preservation loss to maintain semantic fidelity, addressing the issues such as language drift and reduced diversity introduce by na\\\"ive fine-tuning. Extensive experiments demonstrate that our approach achieves surgical concept erasure while preserving generation quality, thereby closing the safety gap in autoregressive text-to-image generation by earlier methods.",
    "key_points": [
      "visual autoregressive model",
      "concept erasure"
    ],
    "gold_summary": "This paper presents the VARE framework and its variant, S-VARE, for concept erasure in visual autoregressive models. The approach stabilizes training and achieves concept erasure through a filtered cross-entropy loss."
  },
  {
    "paper_id": "PL4aPRtr3R",
    "title": "Transferring Jailbreak Attacks from Public to Private LLMs via Local Prompt Optimization",
    "domain": "safety",
    "content": "Large Language Models (LLMs) demonstrate remarkable capabilities across natural language processing tasks but remain vulnerable to jailbreak attacks, where adversarial inputs are crafted to elicit harmful or undesirable responses. Existing optimization-based attacks often achieve high success rates but are impractical in black-box settings.\nWe focus on a practical scenario in which private LLMs are fine-tuned from public models and accessible only via query APIs, reflecting common real-world deployments. To address this, we propose a two-stage local prompt optimization framework that transfers jailbreak attacks from public to private LLMs. Our method introduces an auxiliary adversarial suffix to align output distributions between the public and target private models, enabling gradient-informed optimization in a purely local setup. Experiments show that our approach achieves high attack success rates on both open-source (Vicuna, LLaMA3) and proprietary models (GPT-4, Claude), and remains effective under diverse fine-tuning regimes, including LoRA-based updates.\nThese results highlight the practical security risks of fine-tuning LLMs and the need for robust defenses, while showing that highly transferable black-box attacks can be executed efficiently without accessing private model parameters.",
    "key_points": [
      "jailbreak attack",
      "large language models"
    ],
    "gold_summary": "In this paper, the authors propose a two-stage optimization-based attack to threaten the black-box private LLMs. Experiments have demonstrated their transferability and effectiveness between open-source and closed-source models."
  },
  {
    "paper_id": "VShuGzpK61",
    "title": "Calibrated Uncertainty Sampling for Active Learning",
    "domain": "safety",
    "content": "We study the problem of actively learning a classifier with a low calibration error. One of the most popular Acquisition Functions (AFs) in pool-based Active Learning (AL) is querying by the model's uncertainty. However, we recognize that an uncalibrated uncertainty model on the unlabeled pool may significantly affect the AF effectiveness, leading to sub-optimal generalization and high calibration error on unseen data. Deep Neural Networks (DNNs) make it even worse as the model uncertainty from DNN is usually uncalibrated. Therefore, we propose a new AF by estimating calibration errors and query samples with the highest calibration error before leveraging DNN uncertainty. Specifically, we utilize a kernel calibration error estimator under the covariate shift and formally show that AL with this AF eventually leads to a bounded calibration error on the unlabeled pool and unseen test data. Empirically, our proposed method surpasses other AF baselines by having a lower calibration and generalization error across pool-based AL settings.",
    "key_points": [
      "active learning",
      "trustworthy machine learning",
      "uncertainty estimation",
      "calibration"
    ],
    "gold_summary": "This paper proposes a calibration aimed AL sampling method that estimates unlabeled sample calibration error using a kernel based local averaging estimator and prioritizes samples with the largest estimated calibration error for labeling."
  },
  {
    "paper_id": "97IeQrvSqb",
    "title": "VERA-V: Variational Inference Framework for Jailbreaking Vision-Language Models",
    "domain": "safety",
    "content": "Vision-Language Models (VLMs) extend large language models with visual reasoning capabilities but remain vulnerable to jailbreak attacks. Existing multimodal red-teaming methods largely rely on brittle templates, operate in single-attack settings, and expose only narrow modes of vulnerability. To address these limitations, we introduce VERA-V, a variational inference framework that recasts multimodal jailbreak discovery as learning a joint posterior distribution over paired text-image prompts. This probabilistic view enables the generation of stealthy, coupled adversarial inputs that bypass model guardrails. We train a lightweight attacker to approximate the posterior, allowing efficient sampling of diverse jailbreaks and providing distributional insights into vulnerabilities. VERA-V further integrates three complementary strategies: (i) typography-based text prompts that embed harmful cues, (ii) diffusion-based image synthesis that introduces adversarial signals, and (iii) structured distractors to fragment VLM attention. Experiments on HarmBench and HADES benchmarks show that VERA-V consistently outperforms state-of-the-art baselines on both open-source and frontier VLMs, improving up to 53.75\\% ASR over the best baseline on GPT-4o.",
    "key_points": [
      "vision-language models",
      "jailbreaking",
      "red-teaming"
    ],
    "gold_summary": "This paper introduces VERA-V, a variational-inference-based multimodal jailbreak framework that jointly optimizes typographic text, diffusion-generated images, and distractors to craft composite adversarial inputs, achieving a 67.75 % attack-success rate against GPT-4o."
  },
  {
    "paper_id": "Kd59Qu5hey",
    "title": "Sensitivity as a Shield: Inducing Sensitivity to Prevent Unauthorized Model Merging",
    "domain": "safety",
    "content": "Training large language models (LLMs) from scratch is costly, driving interest in leveraging open-source LLMs for domain-specific tasks without additional training. Model merging has emerged as a solution to integrate knowledge from fine-tuned models efficiently, but it raises security concerns on unauthorized model merging. Existing approaches primarily focus on post-hoc mechanisms to detect malicious exploitation of released models. In contrast, we propose a novel paradigm: safeguarding models against unauthorized merging before misuse occurs. Specifically, after training a model with strong capabilities in a specific domain, we propose an unmergeable}method that preserves a model’s domain-specific performance while preventing malicious users from acquiring its capabilities through model merging. We identify the critical role of neuron-sensitive weight regions in enabling unmerging and propose two complementary operations, global and local sensitivity processing, to enforce protection. Both theoretical analysis and empirical evaluations demonstrate the effectiveness of our approach in maintaining task performance while making models resistant to unauthorized merging.",
    "key_points": [
      "large language models. model merging. unmergeable"
    ],
    "gold_summary": "This paper proposed a method for making the model unmergeable that preserves a model’s domain-specific performance while preventing malicious users from acquiring its capabilities through model merging."
  },
  {
    "paper_id": "ilr07ypuYl",
    "title": "FUSE: Full‑spectrum Unlearnable Examples via Spectral Equalization",
    "domain": "safety",
    "content": "Unlearnable examples (UEs) protect training data by injecting imperceptible perturbations so that models fail to extract exploitable representations. In this paper, we reveal that existing UEs exhibit a critical failure once low-pass filtering is applied, indicating that the effective perturbation signals for unlearnability concentrate predominantly in high frequencies. Hence, we argue that reliable UEs should remain effective across the full spectrum. To this end, we propose **F**ull-spectrum **U**nlearnable Examples via **S**pectral **E**qualization (**FUSE**), which aims to generate spectrum-agnostic perturbations by equalizing the contributions from different bands and enforcing cross-band consistency. Specifically, FUSE adopts a Random Spectral Masking (RSM) strategy during generator training, which randomly removes a contiguous frequency band, forcing the remaining bands to maintain unlearnability. In addition, FUSE further integrates Cross-Band Guidance (CBG), which enforces mutual consistency between high- and low-frequency components, thereby further enhancing low-frequency unlearnability and regulating high-frequency perturbations to preserve the semantic fidelity of images. Extensive experiments across multiple datasets, architectures, and spectral filtering demonstrate the strong protection achieved by FUSE.",
    "key_points": [
      "unlearnable examples",
      "data privacy"
    ],
    "gold_summary": "The paper observes that existing methods for generating unlearnable examples can be defeated by applying a low-pass filter. They then proceed to defeat this defence by making unlearnable examples that work across all frequency bands."
  },
  {
    "paper_id": "t9kQlO9AfI",
    "title": "Cross-Modal Obfuscation for Jailbreak Attacks on Large Vision-Language Models",
    "domain": "safety",
    "content": "Large Vision-Language Models (LVLMs) demonstrate exceptional performance across multimodal tasks, yet remain vulnerable to jailbreak attacks that bypass safety mechanisms. Existing jailbreak methods suffer from two critical limitations: insufficient stealth against input-level defense filters and high computational costs from lengthy prompts or iterative procedures. \nIn this work, we present Cross-modal Adversarial Multimodal Obfuscation (CAMO), a black-box jailbreak framework that decomposes harmful instructions into benign-looking textual and visual clues.\nCAMO leverages LVLMs' cross-modal reasoning to reconstruct attack intent while each component appears harmless in isolation, evading  defense filters.\nOur compositional obfuscation design achieves superior efficiency, using only 12.6\\% of tokens required by existing methods while achieving high attack success rates of 81.82\\% on GPT-4.1-nano and 93.94\\% on DeepSeek-R1. \nCAMO bypasses multiple defense mechanisms with 100\\% evasion rate, demonstrating effectiveness across both open-source and closed-source models. This work exposes critical vulnerabilities in current multimodal safety protocols and underscores the need for more sophisticated defense strategies.",
    "key_points": [
      "large vision-language models",
      "jailbreak attacks",
      "black-box attack methods"
    ],
    "gold_summary": "The paper proposed Cross-modal Adversarial Multimodal Obfuscation (CAMO), a black-box jailbreak method on VLMs, which used cross-modal reasoning to reconstruct attack intent."
  },
  {
    "paper_id": "9dSDLdxfJz",
    "title": "Combinational Backdoor Attack against Customized Text-to-Image Models",
    "domain": "safety",
    "content": "Recently, Text-to-Image (T2I) synthesis technology has made tremendous strides. Numerous representative T2I models have emerged and achieved promising application outcomes, such as DALL-E, Stable Diffusion, Imagen, etc. In practice, it has become increasingly popular for model developers to selectively adopt personalized pre-trained text encoders and conditional diffusion models from third-party platforms, integrating them together to build customized (personalized) T2I models. However, such an adoption approach is vulnerable to backdoor attacks. In this work, we propose a \\textbf{C}ombinational \\textbf{B}ackdoor \\textbf{A}ttack against \\textbf{C}ustomized \\textbf{T2I} models (CBACT2I) targeting this application scenario. Different from previous backdoor attacks against T2I models, CBACT2I embeds the backdoor into the text encoder and the conditional diffusion model separately. The customized T2I model exhibits backdoor behaviors only when the backdoor text encoder is used in combination with the backdoor conditional diffusion model. These properties make CBACT2I more stealthy and controllable than prior backdoor attacks against T2I models. Extensive experiments demonstrate the high effectiveness of CBACT2I with different backdoor triggers and backdoor targets, the strong generality on different combinations of customized text encoders and diffusion models, as well as the high stealthiness against state-of-the-art backdoor detection methods. The code is available at: https://anonymous.4open.science/r/COM_backdoor-2404/.",
    "key_points": [
      "backdoor attack",
      "text-to-image model",
      "customized text-to-image model"
    ],
    "gold_summary": "This paper implements a Combinational Backdoor Attack by simultaneously optimizing the text encoder and the noise denoising module in the text-to-image model."
  },
  {
    "paper_id": "b2ZE4TCiXj",
    "title": "Controllable and Interpretable Multi-Value Alignment For Large Language Model",
    "domain": "safety",
    "content": "Large Language Models (LLMs) are increasingly expected to embody human values in socially consequential contexts, but current alignment methods often lack interpretability, controllability and value diversity. \nWe propose **V**alue-aligned **C**onstitutional **AI** (VCAI), a novel framework for fine-grained value alignment based on Schwartz’s Basic Value. \nThrough VCAI we construct **ML-Values**, a multi-level dataset generated through role-playing, value decomposition, and iterative rewriting, allowing precise control over alignment intensity. \nML-Values captures rich, context-aware expressions of values and supports multi-value alignment. \nBesides, by reformulating traditional value questionnaires into generative formats, we can obtain more accurate values assessment results.\nExperimental results demonstrate that models trained with ML-Values present enhanced controllability and generalization across moral, psychological, and cultural dimensions. \nMoreover, alignment influences not only local response fidelity but also global value structures of LLMs, promoting coherent moral reasoning and structured preference expression. \nOur work offers a robust and interpretable foundation for building trustworthy, human-centered AI systems.",
    "key_points": [
      "values",
      "value alignment",
      "value evaluation",
      "large language model"
    ],
    "gold_summary": "This paper introduces a VCAI framework for achieving multi-value alignment in large language models. The framework constructs the ML-Values dataset, generating multi-dimensional value data."
  },
  {
    "paper_id": "F02KXwqFdQ",
    "title": "Forgetting-MarI: LLM Unlearning via Marginal Information Regularization",
    "domain": "safety",
    "content": "As AI models are trained on ever-expanding datasets, the ability to remove the influence of specific data from trained models has become essential for privacy protection and regulatory compliance, such as the ''right to be forgotten.\" Unlearning addresses this challenge by selectively removing parametric knowledge from the trained models without retraining from scratch, which is critical for resource-intensive models such as Large Language Models (LLMs). Existing unlearning methods often degrade model performance by removing more information than necessary when attempting to ''forget\" specific data. We introduce $\\textit{Forgetting-MarI}$, an LLM unlearning framework that provably removes only the additional (marginal) information contributed by the data to be unlearned, while preserving the information supported by the data to be retained. By penalizing marginal information, our method yields an explicit upper bound on the unlearn dataset’s residual influence in the trained models, providing provable undetectability. Extensive experiments confirm that our approach outperforms current state-of-the-art unlearning methods, delivering reliable forgetting and better preserved general model performance across diverse benchmarks. This advancement represents an important step toward making AI systems more controllable and compliant with privacy and copyright regulations without compromising their effectiveness.",
    "key_points": [
      "machine unlearning",
      "llm unlearning",
      "data privacy",
      "information-theoretic regularization",
      "mutual information"
    ],
    "gold_summary": "This paper presents FORGETTING-MARI, a novel and effective framework for machine unlearning, specifically tailored for Large Language Models (LLMs)."
  },
  {
    "paper_id": "liQueBuFXi",
    "title": "Transferable and Stealthy Adversarial Attacks on Large Vision-Language Models",
    "domain": "safety",
    "content": "Existing adversarial attacks on large Vision-Language Models (VLMs) often struggle with limited transferability to black-box models or produce perceptible artifacts that are easily detected. This paper presents Progressive Semantic Infusion (PSI), a diffusion-based attack that progressively aligns and infuses natural target semantics. To improve transferability, PSI leverages diffusion priors to better align adversarial examples with the natural image distribution and employs progressive alignment to mitigate overfitting on a single fixed surrogate objective. To enhance stealthiness, PSI embeds source-aware cues during denoising to preserve visual fidelity and avoid detectable artifacts. Experiments show that PSI effectively attacks open-source, adversarially trained, and commercial VLMs, including GPT-5 and Grok-4, surpassing existing methods in both transferability and stealthiness. Our findings highlight a critical vulnerability in modern vision-language systems and offer valuable insights towards building more robust and trustworthy multimodal models.",
    "key_points": [
      "adversarial attacks",
      "robustness"
    ],
    "gold_summary": "This paper aims to improve the effectiveness and imperceptibility of adversarial examples against large vision–language models (VLMs) by leveraging diffusion models with progressive alignment. Experiments demonstrate that the proposed method outperforms existing approaches."
  },
  {
    "paper_id": "ZDuyNJI56H",
    "title": "OFMU: OPTIMIZATION-DRIVEN FRAMEWORK FOR MACHINE UNLEARNING",
    "domain": "safety",
    "content": "Large language models deployed in sensitive applications increasingly require the\nability to unlearn specific knowledge, such as user requests, copyrighted materi-\nals, or outdated information, without retraining from scratch to ensure regulatory\ncompliance, user privacy, and safety. This task, known as machine unlearning,\naims to remove the influence of targeted data (forgetting) while maintaining per-\nformance on the remaining data (retention). A common approach is to formu-\nlate this as a multi-objective problem and reduce it to a single-objective prob-\nlem via scalarization, where forgetting and retention losses are combined using\na weighted sum. However, this often results in unstable training dynamics and\ndegraded model utility due to conflicting gradient directions. To address these\nchallenges, we propose OFMU, a penalty-based bi-level optimization framework\nthat explicitly prioritizes forgetting while preserving retention through a hierar-\nchical structure. Our method enforces forgetting via an inner maximization step\nthat incorporates a similarity-aware penalty to decorrelate the gradients of the for-\nget and retention objectives, and restores utility through an outer minimization\nstep. To ensure scalability, we develop a two-loop algorithm with provable conver-\ngence guarantees under both convex and non-convex regimes. We further provide\na rigorous theoretical analysis of convergence rates and show that our approach\nachieves better trade-offs between forgetting efficacy and model utility compared\nto prior methods. Extensive experiments across vision and language benchmarks\ndemonstrate that OFMU consistently outperforms existing unlearning methods in\nboth forgetting efficacy and retained utility.",
    "key_points": [
      "machine unlearning",
      "large language models",
      "privacy",
      "bi-level optimization",
      "convergence analysis",
      "trustworthy machine learning",
      "gradient-based methods"
    ],
    "gold_summary": "This work proposes a bi-level method to tackle the unlearning problem, treating forgetting as inner maximization and retention as outer minimization. A brief convergence theory is provided. Two models and 4 datasets are tested empirically."
  },
  {
    "paper_id": "MWu9EU6nkM",
    "title": "SAGE: A FRAMEWORK FOR SEMANTIC-ALIGNMENT- GUIDED ENGINEERING OF PROMPTS AND FINE- TUNING IN INDUSTRIAL CONTROL TASKS",
    "domain": "safety",
    "content": "Large language models show great potential for code generation tasks, but automatic code generation for industrial control systems still faces challenges such as inaccurate semantic understanding, a lack of alignment evaluation, and a shortage of domain-specific fine-tuning models. Given the stringent requirements for real-time performance, security, logical rigor, and correct execution of industrial control code, existing general-purpose methods struggle to meet these demands. Therefore, this paper proposes a semantic alignment-guided prompt engineering approach for industrial control tasks. The approach consists of three core components: first, a dataset of function prompt formats covering five structured prompt patterns and a selection of 1,500 prompt examples for industrial control tasks is constructed; second, a semantic alignment analysis metric is designed to evaluate the semantic correctness and task consistency of code generated by different models; and third, an alignment-guided fine-tuning strategy is proposed, leveraging prompt-output-intent triples to enhance the model’s generation capabilities for industrial control tasks. Experiments are conducted on five mainstream 7B models: DeepSeek-7B, Qwen2.5-7B, InternLM2-7B, Mistral-7B, and Gemma-7B. Results show that after fine-tuning, the executable performance of Mistral-7B and DeepSeek-7B increased from 0.719 to 0.886 and from 0.676 to 0.837, respectively, and the BLEU scores increased from 3.79 to 7.45 and from 3.45 to 6.62, respectively. All models maintained intent consistency (Intent = 1.000). Gemma-7B and Qwen2.5-7B showed decreases in executable performance, success rate and BLEU, suggesting possible overfitting or distribution mismatch issues. The method proposed in this paper significantly improves the code executable performance and semantic alignment of some models in industrial control scenarios. It also reveals the sensitivity of model architecture to fine-tuning strategies, providing an important reference for subsequent architecture aware alignment optimization.",
    "key_points": [
      "fine-tuning strategy",
      "industrial control code generation",
      "large language model",
      "semantic alignment"
    ],
    "gold_summary": "The authors introduce an automatic code generation framework for industrial control systems. The Functional Framework\nPrompt (FFP) dataset is introduced, the Semantic Alignment Score (SAS) to evaluate the code generation's quality, and the Alignment-Guided Fine-Tuning (AGFT)."
  },
  {
    "paper_id": "KA9StC9l3T",
    "title": "It Hears, It Sees too: Multi-Modal LLM for Depression Detection By Integrating Visual Understanding into Audio Language Models",
    "domain": "safety",
    "content": "Depression is one of the most prevalent mental health disorders globally. In recent years, multi-modal data, such as speech, video, and transcripts, has been increasingly used to develop AI-assisted depression assessment systems. Large language models have further advanced this field due to their strong language understanding and generalization capabilities. However, conventional LLMs remain text-centric and cannot process the rich non-verbal cues found in audio and visual modalities, which are critical components in mental health evaluation. While multi-modal LLMs offer a promising direction, few are tailored for psychological applications. In this study, we propose a novel multi-modal LLM framework for depression detection. Our approach augments an audio language model with visual understanding and aligns audio-visual features at the timestamp level. This fine-grained alignment improves modeling of temporal dynamics across modalities while reducing the need for extensive training data and computational resources. Experiments on the DAIC-WoZ dataset demonstrate that our model outperforms both single-modality approaches and previous multi-modal methods. Moreover, the proposed framework can be extended to incorporate additional physiological signals, paving the way for broader clinical applications beyond mental health.",
    "key_points": [
      "depression detection",
      "multi-modal large language model",
      "audio-language model",
      "audio-visual alignment"
    ],
    "gold_summary": "The paper proposes a multimodal LLM-based framework for depression detection tasks that utilizes audio and visual knowledge."
  },
  {
    "paper_id": "eSf8Sz74IG",
    "title": "Reinforcement Learning for Durable Algorithmic Recourse",
    "domain": "safety",
    "content": "Algorithmic recourse seeks to provide individuals with actionable recommendations that increase their chances of receiving favorable outcomes from automated decision systems (e.g., loan approvals). While prior research has emphasized robustness to model updates, considerably less attention has been given to the temporal dynamics of recourse---particularly in competitive, resource-constrained settings where recommendations shape future applicant pools. In this work, we present a novel time-aware framework for algorithmic recourse, explicitly modeling how candidate populations adapt in response to recommendations. Additionally, we introduce a reinforcement learning (RL)-based recourse algorithm that captures the evolving dynamics of the environment and generates recommendations that are both feasible and valid.\nWe design our recommendations to be durable, supporting validity over a predefined time horizon $T$. This durability allows individuals to confidently reapply after taking time to implement the suggested changes. Through extensive experiments in complex simulation environments, we show that our approach substantially outperforms existing baselines, offering a superior balance between feasibility and long-term validity. \nTogether, these results underscore the importance of incorporating temporal and behavioral dynamics into the design of practical recourse systems.",
    "key_points": [
      "algorithmic recourse",
      "reinforcement learning",
      "trustworthy ai"
    ],
    "gold_summary": "The authors propose a RL approach to address algorithmic recourse in a competitive environment, where the action of each agent influence the chances of achieving recourse for the others."
  },
  {
    "paper_id": "2htuKJ7xO8",
    "title": "Adaptive Jailbreak Defense: A Self-Evolving Framework for Large Language Models",
    "domain": "safety",
    "content": "While (multimodal) large language models (LLMs) have attracted widespread attention due to their exceptional capabilities, they remain vulnerable to jailbreak attacks.\nVarious defense methods have been proposed to mitigate jailbreak attacks.\nThese methods typically incorporate specific defense mechanisms into the model during training or deployment, aiming to enhance the LLM's robustness against jailbreak attacks in advance.\nHowever, as new jailbreak attack methods continue to emerge, defense methods with static resistance mechanisms can frequently be bypassed during testing.\nTo address these limitations, we propose a defense framework, called Test-Time IMmunization (TTIM), which can adaptively defend against various jailbreak attacks through a self-evolving mechanism during testing.\nSpecifically, TTIM first trains a gist token for efficient detection, which is subsequently employed to detect jailbreak activities during inference.\nWhen jailbreak attempts are detected, TTIM implements safety fine-tuning using the identified jailbreak instructions paired with refusal responses.\nFurthermore, to mitigate potential performance degradation of the detector caused by parameter updates during safety fine-tuning, we decouple the fine-tuning process from the detection module.\nExtensive experiments conducted on both LLMs and multimodal LLMs demonstrate that, starting from non-guarded models, TTIM effectively defends against various jailbreaks during testing with few jailbreak samples. Code is attached as supplementary material.",
    "key_points": [
      "jailbreak defense",
      "multimodal large language model"
    ],
    "gold_summary": "This paper proposed a defense technique against jailbreaking attacks in  LLMs, called Test-Time Immunization (TTIM), which can adaptively defend against various jailbreak attacks through a self-evolving mechanism during inference."
  },
  {
    "paper_id": "voqtsqYS6j",
    "title": "Don't Shift the Trigger: Robust Gradient Ascent for Backdoor Unlearning",
    "domain": "safety",
    "content": "Backdoor attacks pose a significant threat to machine learning models, allowing adversaries to implant hidden triggers that alter model behavior when activated. Although gradient ascent (GA)-based unlearning has been proposed as an efficient backdoor removal approach, we identify a critical yet overlooked issue: vanilla GA does not eliminate the trigger but shifts its impact to different classes, a phenomenon we call trigger shifting. To address this, we propose Robust Gradient Ascent (RGA), which introduces a dynamic penalty mechanism to regulate GA's strength and prevent excessive unlearning. Our experiments show that RGA effectively removes backdoors while preserving model utility, offering a more reliable defense against backdoor attacks.",
    "key_points": [
      "gradient ascent",
      "machine unlearning",
      "backdoor defense"
    ],
    "gold_summary": "The authors identify and systematically demonstrate the problem of trigger shifting in traditional gradient ascent, and propose robust gradient ascent algorithm to alleviate the phenomenon."
  },
  {
    "paper_id": "zu02kGyZsw",
    "title": "Quality-constrained Entropy Maximization Policy Optimization for LLM Diversity",
    "domain": "safety",
    "content": "Recent research indicates that while alignment methods significantly improve the quality of large language model(LLM) outputs, they simultaneously reduce the diversity of the models' output. Although some methods have been proposed to enhance LLM output diversity, they often come at the cost of reduced performance. In this work, we first theoretically demonstrate that the alignment task can be decomposed into two distributions: quality and diversity. To enhance the diversity of LLM outputs while ensuring quality, we propose the Quality-constrained Entropy Maximization Policy Optimization (QEMPO). QEMPO aims to maximize the output entropy of the policy while ensuring output quality. By adding different constraints to QEMPO, we obtain different policies. To optimize policies, we propose both online and offline training methods. Experiments validate that QEMPO achieves performance comparable to or even better than RLHF while improving output diversity.",
    "key_points": [
      "llm",
      "diversity",
      "quality",
      "entropy"
    ],
    "gold_summary": "The paper proposes a method that tackles the problem of reduced output diversity in LLM alignment. The proposed approach, QEMPO, directly maximizes the entropy of the output distribution while keeping alignment quality as a constraint."
  },
  {
    "paper_id": "LZwHsK40qW",
    "title": "LatentBreak: Jailbreaking Large Language Models through Latent Space Feedback",
    "domain": "safety",
    "content": "Jailbreaks are adversarial attacks designed to bypass the built-in safety mechanisms of large language models. Automated jailbreaks typically optimize an adversarial suffix or adapt long prompt templates by forcing the model to generate the initial part of a restricted or harmful response. In this work, we show that existing jailbreak attacks that leverage such mechanisms to unlock the model response can be detected by a straightforward perplexity-based filtering on the input prompt. To overcome this issue, we propose LatentBreak, a white-box jailbreak attack that generates natural adversarial prompts with low perplexity capable of evading such defenses.  LatentBreak substitutes words in the input prompt with semantically-equivalent ones, preserving the initial intent of the prompt, instead of adding high-perplexity adversarial suffixes or long templates. These words are chosen by minimizing the distance in the latent space between the representation of the adversarial prompt and that of harmless requests. Our extensive evaluation shows that LatentBreak leads to shorter and low-perplexity prompts, thus outperforming competing jailbreak algorithms against perplexity-based filters on multiple safety-aligned models.",
    "key_points": [
      "large language models",
      "llm jailbreaking",
      "safety alignment"
    ],
    "gold_summary": "This paper introduces LatentBreak (LatB), a white-box jailbreaking method designed to bypass the perplexity defense. This proposed method modifies the original harmful prompt using token-level substitution guided by Latent-Space Feedback."
  },
  {
    "paper_id": "Re3A6vzCTC",
    "title": "Pisces: Cryptography-based Private Retrieval-Augmented Generation with Dual-Path Retrieval",
    "domain": "safety",
    "content": "Retrieval-augmented generation (RAG) enhances the response quality of large language models (LLMs) when handling domain-specific tasks, yet raises significant privacy concerns. This is because both the user query and documents within the knowledge base often contain sensitive or confidential information. To address these concerns, we propose $\\texttt{Pisces}$, the first practical cryptography-based RAG framework that supports dual-path retrieval, while protecting both the query and documents. Along the semantic retrieval path, we reduce computation and communication overhead by leveraging a coarse-to-fine strategy. Specifically, a novel oblivious filter is used to privately select a candidate set of documents to reduce the scale of subsequent cosine similarity computations. For the lexical retrieval path, to reduce the overhead of repeatedly invoking labeled PSI, we implement a multi-instance labeled PSI protocol to compute term frequencies for BM25 scoring in a single execution. $\\texttt{Pisces}$ can also be integrated with existing privacy-preserving LLM inference frameworks to achieve end-to-end privacy. Experiments demonstrate that $\\texttt{Pisces}$ achieves retrieval accuracy comparable to the plaintext baselines, within a 1.14% margin.",
    "key_points": [
      "retrieval-augmented generation",
      "privacy-preserving",
      "cryptography"
    ],
    "gold_summary": "Pisces proposes the first cryptography-based retrieval-augmented generation (RAG) framework that simultaneously protects both user queries and documents through dual-path (semantic and lexical) private retrieval, achieving near-plaintext accuracy with significantly improved efficiency."
  },
  {
    "paper_id": "EPBculZ1Hh",
    "title": "Ready2Unlearn: A Learning-Time Approach for Preparing Models with Future Unlearning Readiness",
    "domain": "safety",
    "content": "This paper introduces Ready2Unlearn, a learning-time optimization approach designed to facilitate future unlearning processes. \nUnlike the majority of existing unlearning efforts that focus on designing unlearning algorithms, which are typically implemented reactively when an unlearning request is made during the model deployment phase, Ready2Unlearn shifts the focus to the training phase, adopting a \"forward-looking\" perspective. Building upon well-established meta-learning principles, Ready2Unlearn proactively trains machine learning models with unlearning readiness, such that they are well prepared and can handle future unlearning requests in a more efficient and principled manner. Ready2Unlearn is model-agnostic and compatible with any gradient ascent-based machine unlearning algorithms. We evaluate the method on both vision and language tasks under various unlearning settings, including class-wise unlearning and random data unlearning. Experimental results show that by incorporating such preparedness at training time, Ready2Unlearn produces an unlearning-ready model state, which offers several key advantages when future unlearning is requested, including reduced unlearning time, improved retention of overall model capability, and enhanced resistance to the inadvertent recovery of forgotten data. We hope this study could inspire future work to explore more proactive strategies for equipping machine learning models with built-in readiness towards more reliable and principled machine unlearning.",
    "key_points": [
      "machine unlearning",
      "meta-learning",
      "data privacy"
    ],
    "gold_summary": "The authors propose Ready2Unlearn (R2U), which prepares models for future unlearning requests proactively during training. They use some MAML inspired dual-loop optimization to optimize for resistance metrics for when unlearning occurs later."
  },
  {
    "paper_id": "Ri3QZJFw5m",
    "title": "Agents Aren't Agents: the Agency, Loyalty and Accountability Problems of AI agents",
    "domain": "safety",
    "content": "The rapid adoption of AI agents marks a shift from predictable digital services to systems entrusted with autonomous, judgment-like tasks. As people delegate more responsibility to these agents, questions of control, loyalty, and accountability become urgent. Yet today’s agents are operated through fragmented layers of control by developers, hosts, and providers, which blur lines of responsibility and divide loyalties before users ever interact with them. Without reconsideration, we risk misallocating responsibility, overstating loyalty, and obscuring who ultimately benefits from these systems. In this paper, we systematically discuss key issues that hinder AI agents from attaining true legal agency. We identify three unresolved problems: Agency—who is the principal and who is the agent in the polyadic governance of AI development and deployment; Loyalty—whether AI agents can serve the principal’s best interests; and Accountability—when AI agents make mistakes, who is responsible for them? We examine the technological foundations that give rise to these problems and highlight key limitations of the current agency law framework in addressing emerging issues related to AI agents. As a position paper, our study offers fresh perspectives on AI agents from a legal standpoint and could inspire new research directions in this domain.",
    "key_points": [
      "ai agents",
      "agency",
      "alignment",
      "fiduciary duties",
      "large language models",
      "loyalty",
      "accountability"
    ],
    "gold_summary": "This position paper investigates why current AI agents don’t fit precisely into the legal category of human agents. The paper analyzes three issues: Agency, Loyalty, and Accountability."
  },
  {
    "paper_id": "mL3uFW2ME9",
    "title": "The Sum Leaks More Than Its Parts: Compositional Privacy Risks and Mitigations in Multi-Agent Collaboration",
    "domain": "safety",
    "content": "As large language models (LLMs) become integral to multi-agent systems, new privacy risks emerge that extend beyond memorization, direct inference, or single-turn evaluations. In particular, seemingly innocuous responses, when composed across interactions, can cumulatively enable adversaries to recover sensitive information, a phenomenon we term compositional privacy leakage. \nWe present the first systematic study of such compositional privacy leaks and possible mitigation methods in multi-agent LLM systems. First, we develop a framework that models how auxiliary knowledge and agent interactions jointly amplify privacy risks, even when each response is benign in isolation. Next, to mitigate this, we propose and evaluate two defense strategies: (1) Theory-of-Mind defense (ToM), where defender agents infer a questioner's intent by anticipating how their outputs may be exploited by adversaries,\nand (2) Collaborative Consensus Defense (CoDef), where responder agents collaborate with peers who vote based on a shared aggregated state to restrict sensitive information spread.\nCrucially, we balance our evaluation across compositions that expose sensitive information and compositions that yield benign inferences.\nOur experiments quantify how these defense strategies differ in balancing the privacy-utility trade-off. \nWe find that while chain-of-thought alone offers limited protection to leakage (39% sensitive blocking rate), our ToM defense substantially improves sensitive query blocking (up to 97%) but can reduce benign task success. CoDef achieves the best balance, yielding the highest Balanced Outcome (79.8%), highlighting the benefit of combining explicit reasoning with defender collaboration. \nTogether, our results expose a new class of risks in collaborative LLM deployments and provide actionable insights for designing safeguards against compositional, context-driven privacy leakage.",
    "key_points": [
      "multi-agent privacy",
      "compositional attacks",
      "collaboration",
      "defense",
      "llm agent"
    ],
    "gold_summary": "Paper defines privacy leakage that accumulates over time through benign outputs and can be inferred by an adversary. The paper uses a game setup and discusses different defenses."
  },
  {
    "paper_id": "TL4cvNviw6",
    "title": "DeRaDiff: Denoising Time Realignment of Diffusion Models",
    "domain": "safety",
    "content": "Recent advances align diffusion models with human preferences to increase aesthetic appeal and mitigate artifacts and biases. Such methods aim to maximize a conditional output distribution aligned with higher rewards whilst not drifting far from a pretrained prior. This is commonly enforced by KL (Kullback–Leibler) regularization. As such, a central issue still remains: how does one choose the right regularization strength? Too high of a strength leads to limited alignment and too low of a strength leads to \"reward hacking\". This renders the task of choosing the correct regularization strength highly non-trivial. Existing approaches sweep over this hyperparameter by aligning a pretrained model at multiple regularization strengths and then choose the best strength. Unfortunately, this is prohibitively expensive. We introduce _DeRaDiff_, a _denoising-time realignment_ procedure that, after aligning a pretrained model once, modulates the regularization strength _during sampling_ to emulate models trained at other regularization strengths—_without any additional training or fine-tuning_. Extending decoding-time realignment from language to diffusion models, DeRaDiff operates over iterative predictions of continuous latents by replacing the reverse-step reference distribution by a geometric mixture of an aligned and reference posterior, thus giving rise to a closed-form update under common schedulers and a single tunable parameter, $\\lambda$, for on-the-fly control. Our experiments show that across multiple text–image alignment and image-quality metrics, our method consistently provides a strong approximation for models aligned entirely from scratch at different regularization strengths. Thus, by enabling very precise inference-time control of the regularization strength, our method yields an efficient way to search for the optimal strength, eliminating the need for expensive alignment sweeps and thereby substantially reducing computational costs.",
    "key_points": [
      "alignment",
      "diffusion models"
    ],
    "gold_summary": "The author presents a classifier‑free guidance–like formulation designed for reward alignment in diffusion models (DDPM).\nThe experimental results support the formulation's validation."
  },
  {
    "paper_id": "kI7kCgcY8Y",
    "title": "Malice in Agentland: Down the Rabbit Hole of Backdoors in the AI Supply Chain",
    "domain": "safety",
    "content": "The practice of fine-tuning AI agents on data from their own interactions—such as web browsing or tool use—, while being a strong general recipe for improving agentic capabilities, also introduces a critical security vulnerability within the AI supply chain. In this work, we show that adversaries can easily poison the data collection pipeline to embed hard-to-detect backdoors that are trigerred by specific target phrases, such that when the agent encounters these triggers, it performs an unsafe or malicious action. We formalize and validate three realistic threat models targeting different layers of the supply chain:\n1) direct poisoning of fine-tuning data, where an attacker controls a fraction of the training traces;\n2) environmental poisoning, where malicious instructions are injected into webpages scraped or tools called while creating training data; and\n3) supply chain poisoning, where a pre-backdoored base model is fine-tuned on clean data to improve its agentic capabilities.\nOur results are stark: by poisoning as few as 2\\% of the collected traces, an attacker can embed a backdoor causing an agent to leak confidential user information with over 80\\% success when a specific trigger is present. This vulnerability holds across all three threat models.\nFurthermore, we demonstrate that prominent safeguards, including two guardrail models and one weight-based defense, fail to detect or prevent the malicious behavior. These findings highlight an urgent threat to agentic AI development and underscore the critical need for rigorous security vetting of data collection processes and end-to-end model supply chains.",
    "key_points": [
      "llm-based agents",
      "ai security",
      "data poisoning",
      "ai agents",
      "red teaming"
    ],
    "gold_summary": "This paper is an experiment report of backdoor attacks on 3 stages of deploying LLM agents. It shows that AI supply chain is vulnerable to backdoor attacks."
  },
  {
    "paper_id": "HqMRCGad5Q",
    "title": "ProSocialAlign: Preference-Conditioned Test-Time Alignment in Language Models",
    "domain": "safety",
    "content": "Current language model safety paradigms often fall short in emotionally charged or high-stakes settings, where refusal-only approaches may alienate users and naive compliance can amplify risk. We propose **ProSocialAlign**, a test-time, parameter-efficient framework that steers generation toward safe, empathetic, and value-aligned responses without retraining the base model. We formalize five human-centered objectives and cast safety as lexicographic constrained generation: first, applying hard constraints to eliminate harmful continuations; then optimizing for prosocial quality within the safe set. Our method combines (i) *directional regulation*, a harm-mitigation mechanism that subtracts a learned \"harm vector\" in parameter space, and (ii) *preference-aware autoregressive reward modeling* trained jointly across attributes with *gradient conflict resolution*, enabling fine-grained, user-controllable decoding. Empirical evaluations across five safety benchmarks demonstrate state-of-the-art performance, reducing unsafe leakage and boosting alignment to human values, with strong gains across multiple evaluation metrics. **ProSocialAlign** offers a robust and modular foundation for generating context-sensitive, safe, and human-aligned responses at inference time. To facilitate reproducibility, we will publicly release the full source code and dataset upon acceptance.",
    "key_points": [
      "pluralistic alignment",
      "personalised alignment"
    ],
    "gold_summary": "This paper introduces ProSocialAlign, a test-time framework for doing better than simply refusing to respond based on safety concerns, encouraging responses aligned to five key prosocial attributes. This"
  },
  {
    "paper_id": "QSxnB2PXJb",
    "title": "Collapse of Irrelevant Representations (CIR) Ensures Robust and Non-Disruptive LLM Unlearning",
    "domain": "privacy",
    "content": "Current unlearning and safety training methods consistently fail to remove dangerous knowledge from language models. We identify the root cause – unlearning targets representations which are too general – and develop a highly selective technique that unlearns robustly while preserving general performance.\n\nOur method performs PCA on activations and module-output gradients to identify subspaces containing common representations, then collapses these subspaces before computing unlearning updates, a technique we term Collapse of Irrelevant Representations (CIR). This avoids unlearning general knowledge and targets only representations specific to the facts being unlearned.\n\nWhen unlearning bio- and cyber-hazardous facts from Llama-3.1-8B, we achieve over 30× greater reduction in post-attack accuracy than the best baseline (Circuit Breakers), while disrupting general performance 30× less, and using less than 3 GPU-seconds per fact.\n\nThus, by disentangling harmful and benign capabilities at the level of representations, CIR enables robust and non-disruptive unlearning.",
    "key_points": [
      "unlearning",
      "representation-engineering",
      "language-models",
      "biosecurity",
      "cybersecurity",
      "fine-tuning",
      "robustness",
      "adversarial-attacks",
      "wmdp",
      "ai-safety",
      "selective-unlearning",
      "neural-representations",
      "evaluation-robustness"
    ],
    "gold_summary": "This paper proposed a novel unlearning method called Collapse of Irrelevant Representations (CIR), which collapses subspaces containing common representations, thus making the unlearning more effective and robust."
  },
  {
    "paper_id": "NdSygrpDPZ",
    "title": "Omni-Modal Large Language Models Jailbreaking with Adaptive Agent",
    "domain": "privacy",
    "content": "The rapid advancement of large language models (LLMs) has led to the emergence of Omni-Modal Large Language Models (Omni-MLLMs), which can process information across textual, visual, and auditory domains. Omni-MLLMs extend language understanding to vision and audio, enabling rich tri-modal interactions across real-world tasks. However, this flexibility broadens the attack surface of jailbreaking, and safety alignment must withstand coordinated inputs across three modalities, where conventional defenses and optimization methods often fail. We frame jailbreaking in Omni-MLLMs as a tri-modal optimization problem and identify three core challenges. \\textit{Gradient shattering} from non-differentiable audio discretization and vanishing cross-modal gradients; \\textit{Optimization instability} in query-only settings, where adversarial prompt search stagnates in highly non-convex, alignment-hardened landscapes; \\textit{Tri-modal coordination}, where queries must be co-designed so that audio, visual, and textual cues reinforce rather than interfere. To address these challenges, we propose AdvOmniAgent, the \\textbf{first} jailbreak attack framework for Omni-MLLMs.\nWe use a two-stage optimization to perform semantic-level updates for multimodal queries, addressing gradient shattering. Our feedback-driven adaptive generator parameter update method alleviates stalling during optimization. Finally, a unified update strategy promotes cross-modal alignment and collaborative improvement. Extensive experiments on multiple Omni-MLLMs demonstrate that our algorithm outperforms strong baselines and achieves a higher average jailbreak success rate. Tri-modal ablation studies also validate its collaborative optimization effect.\n\\textcolor{red}{\\textit{CONTENT WARNING: THIS PAPER CONTAINS HARMFUL MODEL RESPONSES.}}",
    "key_points": [
      "omni-modal large language models(omni-mllms)",
      "jailbreak attacks on llms"
    ],
    "gold_summary": "The paper uses textgrad methods to optimize inputs for omni-modal LLMs. They empirically show this outperforms a set of strong baselines."
  },
  {
    "paper_id": "wIGG5HVGd8",
    "title": "Let me PASS: Formalization Driven Prompt Jailbreaking via Reinforcement Learning",
    "domain": "privacy",
    "content": "Large language models (LLMs) have demonstrated remarkable capabilities, yet they also introduce novel security challenges. For instance, prompt jailbreaking attacks involve adversaries crafting sophisticated prompts to elicit responses from LLMs that deviate from human values. To uncover vulnerabilities in LLM alignment, we propose the PASS framework (Prompt Jailbreaking via Semantic and Structural Formalization). Specifically, PASS employs reinforcement learning to transform initial jailbreak prompts into formalized descriptions, which enhances stealthiness and enables bypassing existing alignment defenses. The jailbreak outputs are then structured into a GraphRAG system that, by leveraging extracted relevant terms and formalized symbols as contextual input alongside the original query, strengthens subsequent attacks and facilitates more effective jailbreaks. We conducted extensive experiments on common open-source models, demonstrating the effectiveness of our attack.",
    "key_points": [
      "prompt jailbreaking attacks",
      "llm security",
      "reinforcement learning",
      "formalization"
    ],
    "gold_summary": "This paper use RL to decomposes a harmful query into formalized symbols to jailbreak the model."
  },
  {
    "paper_id": "PNU9Rj5RDQ",
    "title": "Breaking and Fixing Defenses Against Control Flow Hijacking in Multi-Agent Systems",
    "domain": "privacy",
    "content": "Control-flow hijacking attacks manipulate orchestration mechanisms in multi-agent systems into performing unsafe actions that compromise the system and exfiltrate sensitive information.  Recently proposed defenses, such as LlamaFirewall, rely on alignment checks of inter-agent communications to ensure that all agent invocations are \"related to\" and \"likely to further\" the original objective.   \n\nWe start by demonstrating control-flow hijacking attacks that evade these defenses even if alignment checks are performed by advanced LLMs.  We argue that the safety and functionality objectives of multi-agent systems fundamentally conflict with each other.  This conflict is exacerbated by the brittle definitions of \"alignment\" and the checkers' incomplete visibility into the execution context.\n\nWe then propose, implement, and evaluate ControlValve, a new defense based on the principles of control-flow integrity and least privilege.  ControlValve (1) generates permitted control-flow graphs for multi-agent systems, and (2) enforces that all executions comply with these graphs, along with contextual rules (generated in a zero-shot manner) for each agent invocation.",
    "key_points": [
      "agents",
      "multi-agent systems",
      "security",
      "defenses",
      "control flow hijacking",
      "indirect prompt injection"
    ],
    "gold_summary": "This paper proposes a control-flow-hijacking (CFH) method that can bypass some defenses, and it also proposes a mitigation."
  },
  {
    "paper_id": "1pN7mqygAr",
    "title": "AlignMark: Content-Aligned Audio Watermarking for Robustness Against Neural Transformations",
    "domain": "privacy",
    "content": "Audio watermarking, which embeds identity information into audio for authenticity verification, is an effective approach to protecting the intellectual property of audio content creators. A key unresolved challenge in audio watermarking is the limited robustness of existing methods under real-world neural transformations, such as denoising, codec, and vocoder reconstruction, which can render watermarks removable or undetectable. To better understand this challenge, we introduce the content alignment degree (CAD) metric, which quantifies the extent to which watermarks are integrated into audio, and observe a positive correlation between CAD and watermark robustness. Guided by CAD, we propose AlignMark, a content-aligned audio watermarking method that leverages spectral masking in the embedder, temporal masking in the decoder, and multiple perceptual losses to explicitly align watermark embedding with audio content and improve robustness against diverse attacks while preserving perceptual quality. Furthermore, a feature pyramid-based decoder extracts watermarks across multiple scales, enhancing reliability under pitch shifts and spectral distortions. Extensive experiments on multiple datasets and 21 attack scenarios demonstrate that AlignMark achieves state-of-the-art performance, with an average bit-wise accuracy of 0.98 and false attribution rate of 0.05, while maintaining imperceptible impact on audio quality. See our code and demos at: https://anonymouswatermark.github.io/alignmark/.",
    "key_points": [
      "audio watermarking",
      "speech processing",
      "artificial intelligence security",
      "content-aligned watermarking"
    ],
    "gold_summary": "The authors propose to add watermarking to the region that contains semantic content of the audio to make it more robust under different kinds of distortions."
  },
  {
    "paper_id": "KYqHcVVR92",
    "title": "Fast SDP certification of neural networks : towards large multi-class datasets",
    "domain": "privacy",
    "content": "We present a new quadratic model for the certification problem in adversarial robustness, which simultaneously accounts for all possible target classes. Building on this model, we propose a novel semidefinite programming (SDP) relaxation for incomplete verification. A key advantage of our approach is that it certifies robustness in a single optimization, avoiding the need for a separate resolution per class. This yields a significant computational speed-up and enables scalability to large datasets with many classes. To further gain in efficiency, we also propose an effective pruning strategy of active neurons, thus reducing the problem dimensionality and accelerating convergence.",
    "key_points": [
      "adversarial robustness",
      "sdp relaxation",
      "certification"
    ],
    "gold_summary": "Paper develops an SDP relaxation of neural network verification methods intended to verify a large number of classification/prediction criteria by considering the criteria holistically as a single problem rather than individual problems."
  },
  {
    "paper_id": "8YtL2EVYve",
    "title": "Allusive Adversarial Examples via Latent Space in Multimodal Large Language Models",
    "domain": "privacy",
    "content": "Multimodal large language models (MLLMs) generate text by conditioning on heterogeneous inputs such as images and text. We present allusive adversarial examples, a new class of attacks that imperceptibly encode target instructions into non-textual modalities. Unlike prior adversarial examples, these attacks manipulate model outputs without altering the textual instruction. To construct them, we introduce a practical learning framework that leverages cross-modal alignment and exploits the shared latent space of MLLMs. Empirical evaluation on LLaVA, InternVL, Qwen-VL, and Gemma demonstrates that our method produces efficient and effective adversarial examples, uncovering a critical security risk in multimodal systems.",
    "key_points": [
      "multimodal models; llm; llm security"
    ],
    "gold_summary": "This paper introduces a new class of attacks on Multimodal Large Language Models (MLLMs) that inject hidden instructions into non-text modalities (e.g., images) via latent space alignment, without modifying textual inputs."
  },
  {
    "paper_id": "g0aVCDY3gS",
    "title": "Optimizing Agent Planning for Security and Autonomy",
    "domain": "privacy",
    "content": "Indirect prompt injection attacks threaten AI agents that execute consequential actions, motivating deterministic system-level defenses. Such defenses can provably block unsafe actions by enforcing confidentiality and integrity policies, but currently appear costly: they reduce task completion rates and increase token usage compared to probabilistic defenses. We argue that existing evaluations miss a key benefit of system-level defenses: reduced reliance on human oversight. We introduce autonomy metrics to quantify this benefit: the fraction of consequential actions an agent can execute without human-in-the-loop (HITL) approval while preserving security. To increase autonomy, we design a security-aware agent that (i) introduces richer HITL interactions, and (ii) explicitly plans for both task progress and policy compliance. We implement this agent design atop an existing information-flow control defense against prompt injection and evaluate it on the AgentDojo and WASP benchmarks. Experiments show that this approach yields higher autonomy without sacrificing utility (task completion).",
    "key_points": [
      "ai agents",
      "security",
      "prompt injection attacks",
      "information flow control",
      "autonomy"
    ],
    "gold_summary": "In this paper, they propose two metrics that take human interactions into account, which happens for real-world agents. They also introduce a policy-aware planning method to build a secure agent."
  },
  {
    "paper_id": "civm7zIRvr",
    "title": "Semantic F1 Scores: Fair Evaluation Under Fuzzy Class Boundaries",
    "domain": "privacy",
    "content": "We propose Semantic F1 Scores, novel evaluation metrics for subjective or fuzzy multi‑label classification that quantify semantic relatedness between predicted and gold labels. Unlike the conventional F1 metrics that treat semantically related predictions as complete failures, Semantic F1 incorporates a label similarity matrix to compute soft precision-like and recall-like scores, from which the Semantic F1 scores are derived. Unlike existing similarity-based metrics, our novel two-step precision-recall formulation enables the comparison of label sets of arbitrary sizes without discarding labels or forcing matches between dissimilar labels. By granting partial credit for semantically related but nonidentical labels, Semantic F1 better reflects the realities of domains marked by human disagreement or fuzzy category boundaries. In this way, it provides fairer evaluations: it recognizes that categories overlap, that annotators disagree, and that downstream decisions based on similar predictions lead to similar outcomes.\nThrough theoretical justification and extensive empirical validation on synthetic and real data, we show that Semantic F1 demonstrates greater interpretability and ecological validity. Because it requires only a domain‑appropriate similarity matrix, which is robust to misspecification, and not a rigid ontology, it is applicable across tasks and modalities.",
    "key_points": [
      "evaluation",
      "semantic",
      "f1 score",
      "subjective",
      "fuzzy"
    ],
    "gold_summary": "The paper proposes a semantic F1 metric for multi-label classification. The proposed metric captures the ambiguity of class labels and can provide a fair and interpretable evaluation of the model's performance in the related tasks."
  },
  {
    "paper_id": "mex3rvs2KX",
    "title": "Private Rate-Constrained Optimization with Applications to Fair Learning",
    "domain": "privacy",
    "content": "Many problems in trustworthy ML can be expressed as constraints on prediction rates across subpopulations, including group fairness constraints (demographic parity, equalized odds, etc.). In this work, we study such constrained minimization problems under differential privacy (DP). Standard DP optimization techniques like DP-SGD rely on objectives that decompose over individual examples, enabling per-example gradient clipping and noise addition. Rate constraints, however, depend on aggregate statistics across groups, creating inter-sample dependencies that violate this decomposability. To address this, we develop RaCO-DP, a DP variant of Stochastic Gradient Descent-Ascent (SGDA) that solves the Lagrangian formulation of rate constraint problems. We show that the additional privacy cost of incorporating these constraints reduces to privately estimating a histogram over the mini-batch at each step. We prove convergence of our algorithm through a novel analysis of SGDA that leverages the linear structure of the dual parameter. Empirical results show that our method Pareto-dominates existing private learning approaches under group fairness constraints and also achieves strong privacy–utility–fairness performance on neural networks.",
    "key_points": [
      "differential privacy",
      "fairness",
      "machine learning"
    ],
    "gold_summary": "RaCO-DP is a novel framework for optimizing machine learning models under rate constraints with differential privacy, DP variant of SGDA."
  },
  {
    "paper_id": "X5YiG1YXVT",
    "title": "Accidental Vulnerability: Factors in Fine-Tuning that Shift Model Safeguards",
    "domain": "privacy",
    "content": "As large language models (LLMs) gain popularity, their vulnerability to adversarial attacks emerges as a primary concern. While fine-tuning models on domain-specific datasets is often employed to improve model performance, it can inadvertently introduce vulnerabilities within the underlying model. In this work, we investigate Accidental Vulnerability: unexpected vulnerability arising from characteristics of fine-tuning data. We begin by identifying potential correlation factors such as linguistic features, semantic similarity, and toxicity across multiple experimental datasets. We then evaluate the adversarial robustness of these fine-tuned models, analyzing persona shifts and interpretability traits to understand how dataset factors contribute to attack success rates. Lastly, we explore causal relationships that offer new insights into adversarial defense strategies, highlighting the crucial role of dataset design in preserving model alignment.",
    "key_points": [
      "fine-tuning",
      "red-teaming",
      "safety",
      "alignment",
      "robustness",
      "security"
    ],
    "gold_summary": "The authors perform a variety of experiments all targeting the notion of \"accidental vulnerability\": the fact that finetuning on datasets (whether those datasets are benign and malicious) can make LLMs more susceptible to adversarial attack."
  },
  {
    "paper_id": "3NLF20wthr",
    "title": "3S-Attack: Spatial, Spectral and Semantic Invisible Backdoor Attack Against DNN Models",
    "domain": "privacy",
    "content": "Backdoor attacks implant hidden behaviors into models by poisoning training data or modifying the model directly. These attacks aim to maintain high accuracy on benign inputs while causing misclassification when a specific trigger is present. While existing studies have explored stealthy triggers in spatial and spectral domains, few incorporate the semantic domain. In this paper, we propose 3S-attack, a novel backdoor attack which is stealthy across the spatial, spectral, and semantic domains. The key idea is to exploit the semantic features of benign samples as triggers, using Gradient-weighted Class Activation Mapping (Grad-CAM) and a preliminary model for extraction. Then we embedded the trigger in the spectral domain, followed by pixel-level restrictions in the spatial domain. This process minimizes the distance between poisoned and benign samples, making the attack harder to detect by existing defenses and human inspection. And it exposes a vulnerability at the intersection of robustness and semantic interpretability, revealing that models can be manipulated to act in semantically consistent yet malicious ways. Extensive experiments on various datasets, along with theoretical analysis, demonstrate the stealthiness of 3S-attack and highlight the need for stronger defenses to ensure AI security.",
    "key_points": [
      "artificial intelligence security",
      "backdoor attack",
      "deep neural network",
      "dct transform"
    ],
    "gold_summary": "The paper presents an interesting attempt to achieve multi-domain stealth in backdoor attacks, supported by extensive experiments. However, the methodological novelty is moderate, the semantic analysis remains qualitative, and presentation quality can be improved."
  },
  {
    "paper_id": "WNUDOLYlbh",
    "title": "Learning to Unlearn: Machine Unlearning via Learning the Unlearning Behaviors",
    "domain": "privacy",
    "content": "Various machine unlearning techniques have been developed in response to privacy legislation requirements. These techniques enable individuals to exercise their legal right to have their data $D_f$ removed from a machine learning model. This process, commonly referred to as machine unlearning, is accomplished via the use of an unlearning function denoted as $U$. \nExisting methods design an intricate $U$ to unlearn $D_f\\subset D$ from a previous model $A(D)$ learned on $D$, so that the unlearned model performs as closely as possible to the retrained model $A(D\\setminus D_f)$. However, these methods often take a long time due to the complex structures of $U$.\n\nInspired by Learning to Optimize, in this paper, we introduce the first learning-based model-agnostic approach named Learning-to-UnLearn (or L2UL) based on a distribution perspective, which acquires a simple $U$ via learning. \nOur experimental results demonstrate that the accuracy achieved by L2UL is comparable to that of retraining, while also exhibiting impressive efficiency.",
    "key_points": [
      "machine unlearning",
      "privacy protection",
      "kernel mean embedding"
    ],
    "gold_summary": "Summary:\nThis paper proposes a learning based model-agnostic approach (L2UL) based on a distribution perspective to implement unlearning. Some comments are provided as follows."
  },
  {
    "paper_id": "9JxOVBdwNf",
    "title": "United Minds or Isolated Agents? Exploring Coordination of LLMs under Cognitive Load Theory",
    "domain": "privacy",
    "content": "Large Language Models (LLMs) exhibit a notable performance ceiling on complex, multi-faceted tasks, as they often fail to integrate diverse information or adhere to multiple constraints. \n    We posit that this limitation arises when the demands of a task exceed the LLM's effective cognitive load capacity. This interpretation draws a strong analogy to Cognitive Load Theory (CLT) in cognitive science, which explains similar performance boundaries in the human mind, and is further supported by emerging evidence that reveals LLMs have bounded working memory characteristics.\n    Building upon this CLT-grounded understanding, we introduce ***CoThinker***, a novel LLM-based multi-agent architecture designed to mitigate cognitive overload and enhance collaborative problem-solving abilities. ***CoThinker*** operationalizes CLT principles by distributing intrinsic cognitive load through agent specialization and managing transactional load via structured communication and a collective working memory. We empirically validate *CoThinker* on complex problem-solving tasks and fabricated high cognitive load scenarios, demonstrating improvements over existing multi-agent baselines in solution quality and efficiency. Our analysis reveals characteristic interaction patterns, providing insights into the emergence of collective cognition and effective load management, thus offering a principled approach to overcoming LLM performance ceilings.",
    "key_points": [
      "large language models",
      "llm agents",
      "multi agent systems",
      "cognitive load theory",
      "collective intelligence",
      "collaborative reasoning",
      "working memory",
      "complex problem solving",
      "emergent cognition"
    ],
    "gold_summary": "This paper attempts to connect cognitive load theory with limitations of large language models, and builds a multi-agent framework to mitigate cognitive overload through agent specialization and structured communication."
  },
  {
    "paper_id": "nc28mSbyVG",
    "title": "Swap-guided Preference Learning for Personalized Reinforcement Learning from Human Feedback",
    "domain": "privacy",
    "content": "Reinforcement Learning from Human Feedback (RLHF) is a widely used approach to align large-scale AI systems with human values. However, RLHF typically assumes a single, universal reward, which overlooks diverse preferences and limits personalization. Variational Preference Learning (VPL) seeks to address this by introducing user-specific latent variables. Despite its promise, we found that VPL suffers from posterior collapse. While this phenomenon is well known in VAEs, it has not previously been identified in preference learning frameworks. Under sparse preference data and with overly expressive decoders, VPL may cause latent variables to be ignored, reverting to a single-reward model. To overcome this limitation, we propose Swap-guided Preference Learning (SPL). The key idea is to construct fictitious swap annotators and use the mirroring property of their preferences to guide the encoder. SPL introduces three components: (1) swap-guided base regularization, (2) Preferential Inverse Autoregressive Flow (P-IAF), and (3) adaptive latent conditioning. Experiments show that SPL mitigates collapse, enriches user-specific latents, and improves preference prediction. Our code and data are available at https://anonymous.4open.science/r/SPL-0111",
    "key_points": [
      "ranking and preference learning",
      "latent variable models"
    ],
    "gold_summary": "This paper introduces a new method for personalized RLHF. It includes an experimental evaluation on two Llama variants (3B, 8B), with the proposed method comparing favorably to the baselines."
  },
  {
    "paper_id": "jk7PL8GAV8",
    "title": "Erased but Not Forgotten: How Backdoors Compromise Concept Erasure",
    "domain": "privacy",
    "content": "The expansion of large-scale text-to-image diffusion models has raised concerns about harmful outputs, from fabricated depictions of public figures to sexually explicit imagery. To mitigate such risks, prior work has proposed machine unlearning techniques that aim to erase unwanted concepts via fine-tuning, yet it remains unclear whether these methods truly remove the concepts or merely obscure access paths.\nIn this work, we reveal a critical, unexplored vulnerability, Toxic Erasure (ToxE): an adversary binds a backdoor trigger to a concept slated for removal, and this malicious link survives subsequent unlearning, allowing the regeneration of supposedly removed content. We show how this threat can be realized through known weight-based and data-poisoning backdoors and further introduce a novel, highly effective instance, the Deep Intervention Score-based Attack (ToxE-DISA), which optimizes a score-based objective to embed the malicious link deeply within the diffusion process.\nAcross six state-of-the-art erasure methods, DISA consistently restores erased content: up to 82\\% success (57\\% average) against celebrity-identity unlearning, up to 94\\% (65\\% average) for object erasure, and up to 16$\\times$ (7$\\times$ average) amplification of explicit-content exposure. While ToxE exposes a blind spot in current erasure methods, it also provides a diagnostic tool for stress-testing future defenses, helping to design more resilient unlearning strategies.",
    "key_points": [
      "machine unlearning",
      "concept erasure",
      "model poisoning",
      "backdoor attack",
      "safety"
    ],
    "gold_summary": "This paper proposed a new threat model, where attackers can inject poison into training data and models. Based on that, the authors proposed Toxic Erasure to circumvent concept erasure in text-to-image diffusion models."
  },
  {
    "paper_id": "PKrYc2nyO4",
    "title": "SAID: Empowering Large Language Models with Self-Activating Internal Defense",
    "domain": "privacy",
    "content": "Large Language Models (LLMs), despite advances in safety alignment, remain vulnerable to jailbreak attacks designed to circumvent protective mechanisms. Prevailing defense strategies rely on external interventions, such as input filtering or output modification, which often lack generalizability and compromise model utility while incurring significant computational overhead. In this work, we introduce a new, training-free defense paradigm, Self-Activating Internal Defense (SAID), which reframes the defense task from external correction to internal capability activation. SAID uniquely leverages the LLM's own reasoning abilities to proactively identify and neutralize malicious intent through a three-stage pipeline: model-native intent distillation to extract core semantics, optimal safety prefix probing to activate latent safety awareness, and a conservative aggregation strategy to ensure robust decision-making. Extensive experiments on four open-source LLMs against six advanced jailbreak attacks demonstrate that SAID substantially outperforms state-of-the-art defenses in reducing harmful outputs. Crucially, it achieves this while preserving model performance on benign tasks and incurring minimal computational overhead. Our work establishes that activating the intrinsic safety mechanisms of LLMs is a more robust and scalable path toward building safer and more reliable aligned AI systems.",
    "key_points": [
      "large language models",
      "ai safety",
      "jailbreak attacks",
      "adversarial robustness",
      "internal defense"
    ],
    "gold_summary": "The paper designs an LLM-defense called SAID based on prompt tuning. The evaluation is performed on 5 open-source LLMs against popular attacks such as GCG, AutoDAN, PAIR, etc."
  },
  {
    "paper_id": "xpHiVf0xhf",
    "title": "Learning Better Certified Models from Empirically-Robust Teachers",
    "domain": "privacy",
    "content": "Adversarial training attains strong empirical robustness to specific adversarial attacks by training on concrete adversarial perturbations, but it produces neural networks that are not amenable to strong robustness certificates through neural network verification. On the other hand, earlier certified training schemes directly train on bounds from network relaxations to obtain models that are certifiably robust, but display sub-par standard performance. Recent work has shown that state-of-the-art trade-offs between certified robustness and standard performance can be obtained through a family of losses combining adversarial outputs and neural network bounds. Nevertheless, differently from empirical robustness, verifiability still comes at a significant cost in standard performance. In this work, we propose to leverage empirically-robust teachers to improve the performance of certifiably-robust models through knowledge distillation. Using a versatile feature-space distillation objective, we show that distillation from adversarially-trained teachers consistently improves on the state-of-the-art in certified training for ReLU networks across a series of robust computer vision benchmarks.",
    "key_points": [
      "certified training",
      "adversarial robustness",
      "knowledge distillation",
      "neural network verification"
    ],
    "gold_summary": "This paper proposes CC-Dist, a certified training methods for provable robustness. It augments CC-IBP with a feature-space knowledge distillation objective to achieve a better trade-off between the clean accuracy and the provable robust accuracy."
  },
  {
    "paper_id": "KTsGJzaEPg",
    "title": "BanglaGuard: Benchmarking and Defending Large Language Models for Safety in Low-Resource Languages",
    "domain": "privacy",
    "content": "We present BanglaGuard, the first comprehensive safety framework for Bengali large language models (LLMs). BanglaGuard introduces a curated dataset of 29,950 safe and unsafe Bangla prompts paired with culturally appropriate refusal responses, and a three-tier defense pipeline combining prompt classification, LoRA-based fine-tuning, and response classification. Across multiple Bangla and multilingual LLMs, fine-tuning improved refusal rates by 25–33 points and sharply reduced unsafe completions. The best-performing model, LLaMA-2-7B-Chat, achieved a refusal rate of 61.0\\% and reduced unsafe completions to 5.0\\% with the full framework. These results demonstrate that BanglaGuard provides effective, low-resource safety alignment for Bangla LLMs, offering a scalable blueprint for multilingual safety research.",
    "key_points": [
      "llm safety",
      "alignment"
    ],
    "gold_summary": "The paper introduces BanglaGuard, the safety benchmark and defense pipeline for Bengali LLMs. It builds a dataset of harmful/safe prompts and refusal pairs, and applies a three-layer framework to improve safety."
  },
  {
    "paper_id": "BB1aypUDAF",
    "title": "Two Minds Better Than One: Collaborative Reward Modeling for LLM Alignment",
    "domain": "privacy",
    "content": "Reward models (RMs) play a pivotal role in aligning large language models (LLMs) with human values. \nHowever, noisy preferences in human feedback can lead to reward misgeneralization – a phenomenon where reward models learn spurious correlations or overfit to noisy preferences, which poses important challenges to the generalization of RMs.\nThis paper systematically analyzes the characteristics of preference pairs and aims to identify how noisy preferences differ from human-aligned preferences in reward modeling. \nOur analysis reveals that noisy preferences are difficult for RMs to fit, as they cause sharp training fluctuations and irregular gradient updates.\nThese distinctive dynamics suggest the feasibility of identifying and excluding such noisy preferences.\nEmpirical studies clarify that policy LLM optimized with a reward model trained on the full preference dataset, which includes substantial noise, performs worse than the one trained on a subset of exclusively high-quality data.\nTo address this challenge, we propose an online Collaborative Reward Modeling (CRM) framework to achieve robust preference learning through peer review and curriculum learning. \nIn particular, CRM maintains two RMs that collaboratively filter potential noisy preferences by peer-reviewing each other’s data selections.\nCurriculum learning establishes a well-defined learning trajectory to synchronize the capabilities of two RMs, further promoting the utility of peer review.\nExtensive experiments demonstrate that CRM significantly enhances RM generalization, with up to $9.94$-points improvement on RewardBench under an extreme 40\\% noise. \nMoreover, CRM can seamlessly extend to implicit-reward alignment methods, offering a robust and versatile alignment strategy.",
    "key_points": [
      "preference learning",
      "reward modeling",
      "rlhf"
    ],
    "gold_summary": "The authors present a new collaborative method of reward modelling."
  },
  {
    "paper_id": "S1Z5YmN4mV",
    "title": "Metanetworks as Regulatory Operators: Learning to Edit for Requirement Compliance",
    "domain": "privacy",
    "content": "As machine learning models are increasingly deployed in high-stakes settings, e.g. as decision support systems  in various societal sectors or in critical infrastructure, designers and auditors are facing the need to ensure that models satisfy a wider variety of requirements (e.g. compliance with regulations, fairness, computational constraints) beyond performance. Although most of them are the subject of ongoing studies, typical approaches face critical challenges:  post-processing methods tend to compromise performance, which is often counteracted by fine-tuning or, worse, training from scratch, an often time-consuming or even unavailable strategy. This raises the following question: \"Can we efficiently edit models to satisfy requirements, without sacrificing their utility?\" In this work, we approach this with a unifying framework, in a data-driven manner, i.e. we learn to edit neural networks (NNs), where the editor is an NN itself - a graph metanetwork - and editing amounts to a single inference step. In particular, the metanetwork is trained on NN populations to minimise an objective consisting of two terms: the requirement to be enforced and the preservation of the NN's utility. We experiment with diverse tasks (the data minimisation principle, bias mitigation and weight pruning) improving the trade-offs between performance, requirement satisfaction and time efficiency compared to popular post-processing or re-training alternatives.",
    "key_points": [
      "weight space learning",
      "neural network editing",
      "sociotechnical ai"
    ],
    "gold_summary": "The paper proposes a metanetwork that edits trained models in a single pass to meet requirements (data minimization, fairness, sparsity), replacing intensive optimization loops. Framing compliance as a learned weight-space mapping is well-motivated."
  },
  {
    "paper_id": "kQRjcBmFAD",
    "title": "Chain-of-Thought Hijacking",
    "domain": "privacy",
    "content": "Reasoning models are widely used to improve task performance by allocating\nmore inference-time compute, and prior work suggest it may also strengthen\nsafety by improving refusal. Yet we find the opposite: the same reasoning can\nbe used to bypass safety. We introduce Chain-of-Thought Hijacking, a jailbreak\nattack on reasoning models. The attack pads harmful requests with long sequences\nof harmless reasoning. Across HarmBench, CoT Hijacking reaches a 99% attack\nsuccess rate (ASR) on Gemini 2.5 Pro, far exceeding prior jailbreak methods. Our\nmechanistic analysis shows that mid layers encode the strength of safety checking,\nwhile late layers encode the verification outcome. Long benign CoT dilutes both\nsignals by shifting attention away from harmful tokens. Targeted ablations of at-\ntention heads identified by this analysis causally increased ASR, confirming their\nrole in a safety subnetwork. These results show that the most interpretable form\nof reasoning—explicit CoT—can itself become a jailbreak vector when combined\nwith final-answer cues. We release prompts, outputs, and judge decisions to facil-\nitate replication.",
    "key_points": [
      "safety",
      "jailbreaks",
      "chain-of-thought"
    ],
    "gold_summary": "The authors propose a new reasoning model jailbreak based on smuggling harmful request within a benign reasoning tasks."
  },
  {
    "paper_id": "ytIwlWzo0M",
    "title": "Pro-Trans: Progressive Tensor Ring with Attention Guided Local Smoothing Regularization",
    "domain": "privacy",
    "content": "The generalization of adversarial defense methods remains a critical open challenge, and optimization-based adversarial purification methods employing tensor network representations have recently shown strong potential. However, such tensor-based defense methods operate solely on the given input without relying on prior knowledge, which inevitably leads to overfitting to adversarial perturbations. Moreover, their iterative optimization procedures incur substantial computational overhead during inference. In this paper, we propose Pro-Trans, a novel tensor-based adversarial purification method that integrates progressive tensor ring with attention guided local smoothing regularization. Specifically, our progressive tensor ring avoids redundant upsampling operations, thereby reducing computational overhead and accelerating convergence. In addition, the proposed regularizer adaptively applies varying degrees of local smoothing regularization across different regions, thereby suppressing perturbations while mitigating semantic loss. Experimental results show that Pro-Trans consistently outperforms existing methods across diverse adversarial settings on CIFAR-10, CIFAR-100, and ImageNet, achieving state-of-the-art performance while maintaining low computational cost. The code will be available upon acceptance.",
    "key_points": [
      "tensor networks",
      "adversarial purification",
      "adversarial attack",
      "tensor ring"
    ],
    "gold_summary": "This paper addresses the limited generalization of adversarial purification defenses by proposing a novel coarse-to-fine Progressive Tensor Ring method, building upon tensor-based defense strategies. The approach significantly enhances the adversarial robustness of models."
  },
  {
    "paper_id": "AuzSDvSUzg",
    "title": "Human Aligned Compression for Robust Models",
    "domain": "privacy",
    "content": "Adversarial attacks on image models threaten system robustness by introducing imperceptible perturbations that cause incorrect predictions. \n    We investigate human-aligned learned lossy compression as a defense mechanism, comparing two learned models (HiFiC and ELIC) against traditional JPEG across various quality levels. \n    Our experiments on ImageNet subsets demonstrate that learned compression methods outperform JPEG, particularly for Vision Transformer architectures, by preserving semantically meaningful content while removing adversarial noise. \n    Even in white-box settings where attackers can access the defense, these methods maintain substantial effectiveness. \n    We also show that sequential compression—applying rounds of compression/decompression—significantly enhances defense efficacy while maintaining classification performance. \n    Our findings reveal that human-aligned compression provides an effective, computationally efficient defense that protects the image features most relevant to human and machine understanding.",
    "key_points": [
      "compression",
      "adversarial purification",
      "realism in compression",
      "adversarial defense",
      "adversarial attacks"
    ],
    "gold_summary": "This manuscinvestigate humanaligned learned lossy compression as a defense mechanism, comparing two learned\nmodels (HiFiC and ELIC) against traditional JPEG across various quality levels."
  },
  {
    "paper_id": "XQlcvkzMuv",
    "title": "Split, Not Spilled: Practical Obfuscation-Based Privacy-Preserving Split Learning",
    "domain": "privacy",
    "content": "Split Learning (SL) partitions a deep neural network between client and server, enabling collaborative training while reducing the client’s computational load. However, it has been shown that the intermediate activations (“smashed data”) of the client’s model, shared with the server, leak sensitive information. Existing defenses are limited: many assume only passive adversaries, degrade accuracy significantly, or have already been bypassed by recent reconstruction attacks. In this work, we propose SEAL, a client-side obfuscation framework for SL. By applying secret, client-specific periodic transforms, SEAL creates an exponentially large, unsearchable function space that prevents reconstruction of smashed data. We rigorously characterize the class of periodic functions that yield orthogonal, reversible, and numerically stable transforms, ensuring both security and utility preservation. Extensive experiments on image and text benchmarks show that SEAL withstands state-of-the-art reconstruction attacks while maintaining high accuracy.",
    "key_points": [
      "split learning",
      "discrete periodic transform",
      "collaborative framework"
    ],
    "gold_summary": "The paper proposed a new frequency domain transformation based on obfuscation functions to defend against inversion attacks in split learning. Abundant experiments were evaluated to show the effectiveness of the solution."
  },
  {
    "paper_id": "AMIb7RWnBI",
    "title": "AGENTCON: PRACTICAL ATTACKS ON GENERALIST WEB AGENTS VIA IMPERCEPTIBLE MANIPULATION",
    "domain": "privacy",
    "content": "Recent progress in generalist web agents built on large multimodal models has enabled automation of complex web tasks but also created new security risks. We identify a new attack vector against web agents that does not require manipulating HTML elements, unlike prior work. Our threat model focuses on marketplace websites, a primary target of generalist web agents, where users and sellers can upload images themselves. We propose AGENTCON, a practical attack that crafts adversarial perturbations on listing images, rather than perturbing the entire input as in traditional adversarial attacks, to induce the intended target action by web agents. AGENTCON incorporates real-world constraints from webpage rendering into the optimization so that the attack remains effective when neighboring listings and the attack image’s position vary. Our evaluation on 1,680 tasks against a state-of-the-art web agent framework demonstrates the effectiveness of AGENTCON, with an attack success rate (ASR) of 80.4% on average across four application scenarios and three agent models. AGENTCON is also resilient to common countermeasures, achieving an ASR of 76% on average.",
    "key_points": [
      "privacy",
      "safety",
      "vlm web agents",
      "adversarial examples",
      "web agents",
      "vision-language model"
    ],
    "gold_summary": "This paper proposes an attack strategy to manipulate web agents. The evaluation with three models demonstrates the effectiveness of the approach and validates the design of the algorithm with different ablation studies."
  },
  {
    "paper_id": "hNd5L7WnjC",
    "title": "A Rich Knowledge Space for Scalable Deepfake Detection",
    "domain": "privacy",
    "content": "The proliferation of realistic deepfakes has driven the development of numerous benchmark datasets to support detection research. Despite their increasing volume and diversity, no prior effort has systematically consolidated these resources into a unified framework for large-scale model training, nor has there been a massively pre-trained model tailored to deepfake detection. In this work, we introduce MMI-DD (Multi-modal Multi-type Integrated Deepfake Dataset), a large-scale resource containing 3.6 million facial images, the largest collection to date. It unifies diverse benchmarks with uniform preprocessing, and further provides fine-grained annotations across four deepfake types, as well as VLM-generated descriptions capturing both facial and environmental attributes for each image. By leveraging this comprehensive multi-modal dataset, we construct a foundational deepfake knowledge space that empowers our model to discern a broad spectrum of synthetic media. Our method, SD^2 (Scalable Deepfake Detection), refines CLIP for deepfake detection, optimizing image-text classification with rich, type-specific labels. We enhance this with intermediate visual features capturing low-level cues and text label separation loss for stability. We further leverage VLM-generated descriptions and contrastive learning to expand the scope of forgery knowledge, reducing overfitting and enhancing generalization. Extensive experiments on challenging deepfake datasets and AIGC benchmark demonstrate the effectiveness, scalability, and real-world applicability of our approach. Our dataset and code will be available at https://anonymous.4open.science/r/SDD/.",
    "key_points": [
      "deepfake detection",
      "media forensics",
      "multi-modal learning"
    ],
    "gold_summary": "The paper finetunes CLIP image and text encoder with image-text deepfake pairs by curating all the existing datasets. The text and caltegorical annotation for each image is generated using InternVL and gpt o1 respectively."
  },
  {
    "paper_id": "8F9aMllvWm",
    "title": "DGS: Robust and Diverse Watermarks for Diffusion Models",
    "domain": "privacy",
    "content": "Recent advances in diffusion-based generative models, such as Stable Diffusion, have transformed image generation, making it possible to create high-quality and diverse content from textual prompts. However, these advancements also raise concerns about intellectual property theft and the authenticity of generated content. A promising solution to these issues is watermarking, which embeds hidden information into generated content to ensure traceability and protect intellectual property. In this paper, we propose Dynamic Gaussian Shading (DGS), a novel watermarking method specifically designed for diffusion models. DGS uses a dynamic, distance-aware re-localization approach for watermark embedding that adapts to the latent space of generative models, enhancing both the robustness of the watermark and the diversity of the generated images. We evaluate DGS in terms of its watermarking effectiveness, resistance to various attacks, and the diversity of generated images. Our experimental results show that DGS achieves high watermark accuracy, maintains robustness against attacks, and preserves image quality. Furthermore, we introduce a new metric, Encoded Feature Diversity (EFD), to measure the diversity of generated images across different watermarking methods. Compared to existing baseline methods, DGS strikes a significantly improved balance between watermark reliability and image generation diversity. The proposed method provides a promising approach to embedding watermarks in generative models, supporting the secure use of AI-generated content while maintaining the creative potential of these powerful tools.",
    "key_points": [
      "watermarking",
      "diffusion models"
    ],
    "gold_summary": "Dynamic Gaussian Shading (DGS) is a diffusion model watermarking method that introduces random subspace shifting and distance-weighted voting to achieve both high robustness and enhanced image diversity."
  },
  {
    "paper_id": "vLFqOoMBol",
    "title": "Every Language Model Has a Forgery-Resistant Signature",
    "domain": "privacy",
    "content": "The ubiquity of closed-weight language models with public-facing APIs has generated interest in forensic methods, both for extracting hidden model details (e.g., parameters) and identifying models by their outputs. One successful approach to these goals has been to exploit the geometric constraints imposed by the language model architecture and parameters. In this work, we show that a lesser-known geometric constraint—namely that language model outputs lie on the surface of a high-dimensional ellipse—functions as a signature for the model, which be used to identify which model an output came from. This ellipse signature has unique properties that distinguish it from existing model-output association methods like language model watermarks. In particular, the signature is hard to forge: without direct access to model parameters, it is practically infeasible to produce logprobs on the ellipse. Secondly, the signature is naturally occurring, since all language models have these elliptical constraints. Thirdly, the signature is self-contained, in that it is detectable without access to the model input or full weights. Finally, the signature is exceptionally redundant, as it is independently detectable in every single logprob output from the model. We evaluate a novel technique for extracting the ellipse on small models, and discuss the practical hurdles that make it infeasible for production-size models, making the signature hard to forge. Finally, we use ellipse signatures to propose a protocol for language model output verification, which is analogous to cryptographic symmetric-key message authentication systems.",
    "key_points": [
      "fingerprint",
      "watermark",
      "language model",
      "signature",
      "accountability",
      "cryptography",
      "forgery",
      "security"
    ],
    "gold_summary": "The paper observes that logits output by a typical LLM lie on a high-dimensional ellipse. They argue that this ellipse serves as a sort of \"signature\" that uniquely identifies the model."
  },
  {
    "paper_id": "TfjYKnInym",
    "title": "Consistent Zero-Shot Imitation with Contrastive Goal Inference",
    "domain": "reinforcement learning",
    "content": "In the same way that generative models today conduct most of their training in a self-supervised fashion, how can agentic models conduct their training in a self-supervised fashion, interactively exploring, learning, and preparing to quickly adapt to new tasks? A prerequisite for embodied agents deployed in real world interactions ought to be training with interaction, yet today's most successful AI models (e.g., VLMs, LLMs) are trained without an explicit notion of action. The problem of pure exploration (which assumes no data as input) is well studied in the reinforcement learning literature and provides agents with a wide array of experiences, yet it fails to prepare them for rapid adaptation to new tasks. Today's language and vision models are trained on data provided by humans, which provides a strong inductive bias for the sorts of tasks that the model will have to solve (e.g., modeling chords in a song, phrases in a sonnet, sentences in a medical record). However, when they are prompted to solve a new task, there is a faulty tacit assumption that humans spend most of their time in the most rewarding states. The key contribution of our paper is a method for pre-training interactive agents in a self-supervised fashion, so that they can instantly mimic human demonstrations. Our method treats goals (i.e., observations) as the atomic construct. During training, our method automatically proposes goals and practices reaching them, building off prior work in reinforcement learning exploration. During evaluation, our method solves an (amortized) inverse reinforcement learning problem to explain demonstrations as optimal goal-reaching behavior. Experiments on standard benchmarks (not designed for goal-reaching) show that our approach outperforms prior methods for zero-shot imitation.",
    "key_points": [
      "inverse reinforcement learning",
      "contrastive learning",
      "goal-conditioned reinforcement learning"
    ],
    "gold_summary": "Proposes and practices reaching goals during training time, then attempts to represent behavior to imitate as goal-reaching behavior. Compares this method against IRL and other zero shot RL methods in locomotion and goal reaching domains."
  },
  {
    "paper_id": "qcz3g6mH3L",
    "title": "ROSARL: Reward-Only Safe Reinforcement Learning",
    "domain": "reinforcement learning",
    "content": "An important problem in reinforcement learning is designing agents that learn to solve tasks safely in an environment. A common solution is to define either a penalty in the reward function or a cost to be minimised when reaching unsafe states. However, designing reward or cost functions is non-trivial and can increase with the complexity of the problem. To address this, we investigate the concept of a *Minmax* penalty, the smallest penalty for unsafe states that leads to safe optimal policies, regardless of task rewards. We derive an upper and lower bound on this penalty by considering both environment *diameter* and *controllability*. Additionally, we propose a simple algorithm for agents to estimate this penalty while learning task policies. Our experiments demonstrate the effectiveness of this approach in enabling agents to learn safe policies in high-dimensional continuous control environments.",
    "key_points": [
      "reinforcement learning",
      "deep reinforcement learning",
      "safe rl",
      "constrained rl",
      "reward shaping"
    ],
    "gold_summary": "This work presents a minmax penalty within TRPO algorithm, which applies the smallest penalty for unsafe states to generate safe policies."
  },
  {
    "paper_id": "rFLuaG9Yq6",
    "title": "Use the Online Network If You Can: Towards Fast and Stable Reinforcement Learning",
    "domain": "reinforcement learning",
    "content": "The use of target networks is a popular approach for estimating value functions in deep Reinforcement Learning (RL). While effective, the target network remains a compromise solution that preserves stability at the cost of slowly moving targets, thus delaying learning. Conversely, using the online network as a bootstrapped target is intuitively appealing, albeit well-known to lead to unstable learning. In this work, we aim to obtain the best out of both worlds by introducing a novel update rule that computes the target using the **MIN**imum estimate between the **T**arget and **O**nline network, giving rise to our method, **MINTO**. Through this simple, yet effective modification, we show that MINTO enables faster and stable value function learning, by mitigating the potential overestimation bias of using the online network for bootstrapping. Notably, MINTO can be seamlessly integrated into a wide range of value-based and actor-critic algorithms with a negligible cost. We evaluate MINTO extensively across diverse benchmarks, spanning online and offline RL, as well as discrete and continuous action spaces. Across all benchmarks, MINTO consistently improves performance, demonstrating its broad applicability and effectiveness.",
    "key_points": [
      "deep reinforcement learning",
      "q-learning",
      "actor-critic",
      "function approximation"
    ],
    "gold_summary": "for the bootstrapping target in deep Q-learning, uses the minimum of the online net and target net value estimates, instead of using just the target net value estimate\n\nthey call their algorithm \"MINTO\""
  },
  {
    "paper_id": "WXGb9unEHo",
    "title": "Scalable Offline Model-Based RL with Action Chunks",
    "domain": "reinforcement learning",
    "content": "In this paper, we study whether model-based reinforcement learning (RL), in particular model-based value expansion,\ncan provide a scalable recipe for tackling complex, long-horizon tasks in offline RL. \nModel-based value expansion fits an on-policy value function using length-$n$ imaginary rollouts generated by the current policy and a learned dynamics model.\nWhile larger $n$ reduces bias in value bootstrapping, it amplifies accumulated model errors over long horizons, degrading future predictions.\nWe address this trade-off with \nan *action-chunk* model that predicts a future state from a sequence of actions (an \"action chunk\")\ninstead of a single action, which reduces compounding errors.\nIn addition, instead of directly training a policy to maximize rewards,\nwe employ rejection sampling from an expressive behavioral action-chunk policy,\nwhich prevents model exploitation from out-of-distribution actions.\nWe call this recipe **Model-Based RL with Action Chunks (MAC)**.\nThrough experiments on highly challenging tasks with large-scale datasets of up to $100$M transitions,\nwe show that MAC achieves the best performance among offline model-based RL algorithms,\nespecially on challenging long-horizon tasks.",
    "key_points": [
      "offline rl",
      "world models",
      "model-based rl",
      "action chunking",
      "long-horizon tasks"
    ],
    "gold_summary": "The paper introduces Model-Based RL with Action Chunks (MAC), an offline RL algorithm designed to address two critical challenges: compounding errors in model-based rollouts and action selection that leads to out-of-distribution (OOD) model exploitation."
  },
  {
    "paper_id": "Tcw42NlBdw",
    "title": "Retaining Suboptimal Actions to Follow Shifting Optima in Multi-Agent Reinforcement Learning",
    "domain": "reinforcement learning",
    "content": "Value decomposition has been extensively studied as a core approach for cooperative multi-agent reinforcement learning (MARL) under the CTDE paradigm. Despite this progress, existing methods still rely on a single optimal action and struggle to adapt when the underlying value function shifts during training, often converging to suboptimal policies. To address this limitation, we propose Successive Sub-value Q-learning (S2Q), a framework that successively learns multiple sub-value functions to retain information about alternative high-value actions. By incorporating these sub-value functions into a Softmax-based behavior policy, S2Q encourages persistent exploration and enables $Q^{\\text{tot}}$ to adjust quickly when the optimal action changes. Extensive experiments on challenging MARL benchmarks confirm that S2Q consistently outperforms various MARL algorithms, demonstrating improved adaptability and overall performance.",
    "key_points": [
      "multi-agent reinforcement learning",
      "value decomposition",
      "centralized training with decentralized execution",
      "exploration"
    ],
    "gold_summary": "This paper proposes a method to overcome value function shifts during training in CTDE MARL, named S2Q. The proposed method learns a set of several sub-value functions, where each aims to identify different suboptimal actions."
  },
  {
    "paper_id": "mQfv9Nl2n5",
    "title": "QUAD: Q-Gradient Uncertainty-Aware Guidance for Diffusion policies in Offline Reinforcement Learning",
    "domain": "reinforcement learning",
    "content": "Diffusion-based offline reinforcement learning (RL) leverages Q-gradients of noisy actions to guide the denoising process. Existing approaches fall into two categories: (i) backpropagating the Q-gradient of the final denoised action through all steps, or (ii) directly estimating the Q-gradient of noisy actions. The former suffers from exploding or vanishing gradients as the number of denoising steps increases, while the latter becomes inaccurate when noisy actions deviate substantially from the dataset. In this work, we focus on addressing the limitations of the second category. We introduce QUAD, an uncertainty-aware Q-gradient guidance method. QUAD employs a Q-ensemble to estimate the uncertainty of Q-gradients and uses this uncertainty to constrain unreliable guidance during denoising. By down-weighting unreliable gradients, QUAD reduces the risk of producing suboptimal actions. Experiments on the D4RL benchmark show that QUAD outperforms state-of-the-art methods across most tasks.",
    "key_points": [
      "offline rl",
      "diffusion policy"
    ],
    "gold_summary": "This paper considers offline RL, and proposes to weigh Q-gradient estimates based on their uncertainty. They show that this leads to clear improvements on the D4RL benchmark."
  },
  {
    "paper_id": "msX2KKICRr",
    "title": "Emergence of Exploration in Policy Gradient Reinforcement Learning via Retrying",
    "domain": "reinforcement learning",
    "content": "In reinforcement learning (RL), agents benefit from exploration because they repeatedly encounter the same or similar states, where trying different actions can improve performance or reduce uncertainty; otherwise, a greedy policy would be optimal. We formalize this intuition with ReMax, an objective that evaluates a policy by the expected maximum return over $M$ samples ($M \\in \\mathbb{N}$), while accounting for return uncertainty. Optimizing this objective induces stochastic exploration as an emergent property, without explicit bonus terms. For efficient policy optimization, we derive a new policy-gradient formulation for ReMax and introduce ReMax PPO (RePPO), a PPO variant that optimizes ReMax while generalizing the discrete retry count $M$ to a continuous parameter $m > 0$, enabling fine-grained control of exploration. Empirically, RePPO promotes exploration without bonuses and outperforms entropy-regularized PPO on the MinAtar benchmark.",
    "key_points": [
      "exploration",
      "policy gradient"
    ],
    "gold_summary": "This paper proposes ReMax objective to train explorative reinforcement learning policy. The authors claimed this objective can serve an alternative approach to exhibit exploratory without adding curiosity bonus."
  },
  {
    "paper_id": "tWa7Xhtwk0",
    "title": "Hunting Games",
    "domain": "reinforcement learning",
    "content": "Markov Decision Processes (MDPs) address sequential decision-making under stochastic dynamics, where an agent selects actions, observes transitions, and aims to maximize rewards. Traditional reinforcement learning (RL) approaches assume a reasonably accurate estimate of the operating region in the state space. However, such an assumption rarely holds in real-world domains such as counter-drone defense and algorithmic trading, which  feature environments whose limits of operation are only revealed gradually through interaction. As a result, the stochastic dynamics may push the agent into unfamiliar regions, where incomplete knowledge leads to suboptimal actions and reduced reward accumulation. This paper formulates this new phenomenon as a hunting game between the agent (hunter) and the environment (target). Its key motivation is that environments with heavy-tailed variability introduce rare but impactful surprises that slow down learning and act as implicit defenses, even without explicit adversarial presence. Despite its practical relevance, this setting remains poorly understood. In this paper, we analyze the theoretical limits of such hunting games in a model-based RL framework. Our work reveals that the difficulty of learning is governed by the novelty encountered by the agent, weighted by the eluder dimension of the environment’s true model class. Reducing either factor shifts the balance in favor of the agent.",
    "key_points": [
      "markov decision process",
      "reinforcement learning",
      "theory"
    ],
    "gold_summary": "This paper introduces \"hunting games\". However, there is no clear problem formulation. I had difficulty reading it as explained in the weaknesses in detail."
  },
  {
    "paper_id": "CDtXjZgMZy",
    "title": "Policy-Based Trajectory Clustering in Offline Reinforcement Learning",
    "domain": "reinforcement learning",
    "content": "We introduce the task of clustering trajectories in offline reinforcement learning (RL) datasets to address the multi-modal nature of offline data. Such datasets often contain trajectories from diverse policies, and treating them as a single distribution can obscure structure and increase distributional shift. We formalize trajectory clustering by linking the KL-divergence of offline trajectory distributions with mixtures of policy-induced distributions. \n\nTo solve this, we propose Policy-Guided K-means (PG-Kmeans) and Centroid-Attracted Autoencoder (CAAE). PG-Kmeans iteratively trains behavior cloning policies and assigns trajectories based on generation probabilities, while CAAE adopts a VQ-VAE style objective to guide latent representations toward codebook entries. We prove finite-step convergence of PG-Kmeans and analyze the ambiguity of optimal solutions caused by policy-induced conflicts. Experiments on D4RL and GridWorld show that PG-Kmeans and CAAE partition trajectories into coherent clusters and offer a framework for structuring offline data, with applications in data selection, curriculum learning, and policy transfer.",
    "key_points": [
      "reinforcement learning",
      "offline reinforcement learning",
      "deep learning",
      "machine learning",
      "clustering"
    ],
    "gold_summary": "This paper introduces two policy-based trajectory clustering algorithms, Policy-Guided K-means (PG-Kmeans) for maintaining central policies per cluster and Centroid Attracted Autoencoder (CAAE) for dataset-level clustering."
  },
  {
    "paper_id": "nnN2TKlS5C",
    "title": "Diversity-Aware Online Prompt Assignment to Generative Models",
    "domain": "reinforcement learning",
    "content": "The expansion of generative AI services highlights the growing need for adaptive mechanisms to select an appropriate generative model for responding to a user's prompts. Recent works have proposed offline and online learning formulations to identify the optimal generative model for an input prompt, based solely on maximizing prompt-based fidelity evaluation scores, e.g., CLIP-Score in text-to-image generation. However, such fidelity-based selection methods overlook the diversity of generated outputs, and hence, they can fail to address potential diversity shortcomings in the generated responses. In this paper, we introduce the *Diversity-Aware Kernelized Upper Confidence Bound (DAK-UCB)* method as a contextual bandit algorithm for the online selection of generative models with diversity considerations. The proposed DAK-UCB method incorporates both fidelity and diversity-related metrics into the selection process. We design this framework based on prompt-aware diversity score functions that decompose to a two-sample-based expectation over prompt-output pairs in the previous generation rounds. Specifically, we illustrate the application of our framework using joint kernel distance and kernel entropy measures. Our experimental results demonstrate the effectiveness of DAK-UCB in promoting diversity-aware model selection while maintaining fidelity in the generations for a sequence of prompts.",
    "key_points": [
      "generative models",
      "online learning",
      "diversity"
    ],
    "gold_summary": "The paper proposes DAK-UCB, a contextual-bandit algorithm for the online selection of generative models with diversity considerations. It incorporates fidelity and diversity-related metrics into the selection process. The experimental results demonstrate considerable improvements."
  },
  {
    "paper_id": "dtQxzXILzW",
    "title": "When Does Reward Drive Exploration?",
    "domain": "reinforcement learning",
    "content": "Traditional reinforcement learning (RL) methods encourage exploration by adding incentives such as randomization, uncertainty bonuses, or intrinsic rewards. Interestingly, meta-reinforcement learning (meta-RL) agents can develop exploratory behavior even when trained with a purely greedy objective. This raises the question: under what conditions does greedy reward-seeking behavior lead to information-seeking behavior? We hypothesize that three ingredients are essential: (1) Recurring Environmental Structure, where environments generate repeatable patterns that can be exploited if discovered; (2) Agent Memory, which enables past interactions to guide future performance; and (3) Long-Horizon Credit Assignment, which allows the delayed benefits of exploration to shape present decisions. Experiments in stochastic multi-armed bandits and temporally extended gridworlds demonstrate the need for recurrence, memory, and long-term credit. In short-horizon settings, however, exploration can arise from a Pseudo-Thompson Sampling effect, which mimics posterior sampling and obscures the role of temporal credit. In contrast, long-horizon environments reveal that explicit Long-Horizon Credit Assignment substantially improves returns. Our results suggest that structure, memory, and long horizons are critical for greedy training to induce exploration, highlighting these factors as key design considerations for effective meta-agents.",
    "key_points": [
      "meta-reinforcement learning",
      "exploration–exploitation tradeoff",
      "emergent exploration",
      "transformers in rl",
      "pseudo-thompson sampling"
    ],
    "gold_summary": "The paper empirically studies the emergence of exploratory behavior in policies when they are trained to perform meta-RL. Three criteria are cited and studied to determine whether such behavior will appear."
  },
  {
    "paper_id": "LVXZIWjxbq",
    "title": "Mitigating Think-Answer Mismatch in LLM Reasoning Through Noise-Aware Advantage Reweighting",
    "domain": "reinforcement learning",
    "content": "Group-Relative Policy Optimization (GRPO) is a key technique for training large reasoning models, yet it suffers from a critical vulnerability: the Think-Answer Mismatch, where noisy reward signals corrupt the learning process. This problem is most severe in unbalanced response groups, paradoxically degrading the signal precisely when it should be most informative. To address this challenge, we propose Stable Group-Relative Policy Optimization (S-GRPO), a principled enhancement that derives optimal, noise-aware advantage weights to stabilize training. Our comprehensive experiments on mathematical reasoning benchmarks demonstrate S-GRPO's effectiveness and robustness. On various models, S-GRPO significantly outperforms DR. GRPO, achieving performance gains of +2.5\\% on Qwen-Math-7B-Base, +2.2\\% on Llama-3.2-3B-Base, and +2.4\\% on Qwen-Math-1.5B-Instruct. Most critically, while standard GRPO fails to learn under 20\\% synthetic reward noise, S-GRPO maintains stable learning progress. These results highlight S-GRPO's potential for more robust and effective training of large-scale reasoning models.",
    "key_points": [
      "reasoning model",
      "large language model",
      "group-relative policy optimization",
      "noise model",
      "reinforcement learning"
    ],
    "gold_summary": "This paper proposes Stable Group-Relative Policy Optimization (S-GRPO), a principled method that uses optimal, noise-aware advantage weights to mitigate the \"Think-Answer Mismatch\" vulnerability in GRPO, thereby stabilizing training and significantly improving reasoning model performance."
  },
  {
    "paper_id": "gPL2LNoKIF",
    "title": "Fixing That Free Lunch: When, Where, and Why Synthetic Data Fails in Model-Based Policy Optimization",
    "domain": "reinforcement learning",
    "content": "Synthetic data is a core component of data-efficient Dyna-style model-based reinforcement learning, yet it can also degrade performance. We study when it helps, where it fails, and why, and we show that addressing the resulting failure modes enables policy improvement that was previously unattainable. We focus on Model-Based Policy Optimization (MBPO), which performs actor and critic updates using synthetic action counterfactuals. Despite reports of strong and generalizable sample-efficiency gains in OpenAI Gym, recent work shows that MBPO often underperforms its model-free counterpart, Soft Actor-Critic (SAC), in the DeepMind Control Suite (DMC). Although both suites involve continuous control with proprioceptive robots, this shift leads to sharp performance losses across seven challenging DMC tasks, with MBPO failing in cases where claims of generalization from Gym would imply success. This reveals how environment-specific assumptions can become implicitly encoded into algorithm design when evaluation is limited. We identify two coupled issues behind these failures: scale mismatches between dynamics and reward models that induce critic underestimation and hinder policy improvement during model-policy coevolution, and a poor choice of target representation that inflates model variance and produces error-prone counterfactuals in MBPO rollouts. Addressing these failure modes enables policy improvement where none was previously possible, allowing MBPO to outperform SAC in five of seven tasks while preserving the strong performance previously reported in OpenAI Gym. Rather than aiming only for incremental average gains, we hope our findings motivate the community to develop taxonomies that tie MDP task- and environment-level structure to algorithmic failure modes, pursue unified solutions where possible, and clarify how benchmark choices ultimately shape the conditions under which algorithms generalize.",
    "key_points": [
      "sample efficiency",
      "robustness",
      "generalization",
      "synthetic data",
      "reinforcement learning"
    ],
    "gold_summary": "The authors introduces two targeted modifications: target unit normalization (independent for next-state and rewards) and direct next-state prediction. the result shows good improvement on model based policy optimization"
  },
  {
    "paper_id": "2LpoMDXuJf",
    "title": "Rule-Based Grid World Exploration under Uncertainty",
    "domain": "reinforcement learning",
    "content": "Grid world environments expose core challenges in sequential decision-making, including planning under partial observability and achieving sample-efficient generalization. Current Deep Reinforcement Learning methods often require millions of interactions in these structured domains, struggling to capture causal dependencies critical for efficient adaptation. We present a novel experiential learning agent with causally-informed intrinsic reward that is capable of learning sequential and causal dependencies in a robust and data-efficient way within grid world environments. After reflecting on state-of-the-art Deep Reinforcement Learning algorithms, we provide a relevant discussion of common techniques as well as our own systematic comparison within multiple grid world environments. We also investigate the conditions and mechanisms leading to data-efficient learning and analyze relevant inductive biases that our agent utilizes to effectively learn causal knowledge and to plan for rewarding future states of greatest expected return.",
    "key_points": [
      "intrinsic rewards",
      "inductive biases",
      "planning",
      "uncertainty",
      "deep reinforcement learning",
      "reinforcement learning"
    ],
    "gold_summary": "A new model-based RL method for grid environments. The main contribution is in the introduction of a novel model learning component, which is based in rule learning (rather than the popular alternative of DNNs)."
  },
  {
    "paper_id": "FxGCfnJswW",
    "title": "Surrogate Signals from Format and Length: Reinforcement Learning for Solving Mathematical Problems without Ground Truth Answers",
    "domain": "reinforcement learning",
    "content": "Large Language Models (LLMs) have achieved remarkable success in natural language processing tasks, with Reinforcement Learning (RL) playing a key role in adapting them to specific applications. In mathematical problem solving, however, the reliance on ground truth answers poses significant challenges due to their high collection cost and limited availability.  \nThis work explores the use of simple surrogate signals, format and length, to guide RL training. We find that early training is dominated by format learning, where structural feedback alone accounts for most performance gains. Incorporating length-based rewards further refines outputs by discouraging overly long or short responses, enabling a GRPO approach with format-length signals to match, and in some cases surpass, ground-truth-based optimization. For example, our method achieves 40.0\\% accuracy on AIME2024 with a 7B base model, and generalizes across different model sizes and series.  \nBeyond practical efficiency, these findings provide an inspirational perspective on RL: rather than imparting new knowledge, RL primarily activates reasoning capabilities already embedded in pre-trained models. This insight suggests that lightweight, label-efficient strategies can complement pre-training to unlock LLMs’ latent potential in reasoning-intensive tasks.",
    "key_points": [
      "reinforcement learning from verifiable rewards",
      "large language models",
      "reinforcement learning",
      "grpo",
      "without ground truth",
      "label free"
    ],
    "gold_summary": "This paper proposes using simpler losses that only account for the length and formatting of the answers, as opposed to (just) the correctness, in order to boost RL performance."
  },
  {
    "paper_id": "KQFyRTmROw",
    "title": "Orchestrating Pre-Trained Agents for Multi-Objective Decision Making",
    "domain": "reinforcement learning",
    "content": "Multi-Objective Optimization (MOO) in sequential decision-making tasks is commonly tackled by adapting classical methods (e.g., scalarization, $\\varepsilon$-constraints, Pareto-based evolutionary methods) or by training reinforcement learning (RL) models from scratch. In this paper, we propose a different paradigm: orchestrating AI agents to reuse pre-trained RL policies rather than retraining them for each new MOO task. We formalize this setting and develop several algorithmic variants that leverage three core components of agent orchestration: knowledge, tools, and reflection. To demonstrate the practical impact of our approach, we apply it to the Education domain, where our experiments show that agent orchestration achieves a favorable balance between high performance and reduced computational cost.",
    "key_points": [
      "multi-objective optimization",
      "context engineering",
      "llm-judge",
      "ml reusability"
    ],
    "gold_summary": "This work proposes a model that reuses pre-trained RL policies rather than retraining them for each new tasks in multi-objective decision making, and applies the model to an education system."
  },
  {
    "paper_id": "NA4seLpkPd",
    "title": "Regret Analysis of Hybrid Linear Bandits with Biased Offline Data",
    "domain": "reinforcement learning",
    "content": "Linear bandits have been extensively studied due to their broad applications and solid theoretical foundations. However, purely online algorithms often suffer from high exploration costs, while purely offline approaches critically depend on the quality of offline data. To bridge this gap, we study a hybrid setting where (biased) offline data is available in online learning. We propose Hybrid LinUCB, an algorithm that leverages both offline and online information by constructing two confidence ellipsoids to trade off bias against the size of offline data. \nWe establish an upper bound and a nearly matching lower bound that explicitly capture the dependence on the bias upper bound $V$ and the spectrum of the offline feature matrix $V_{0}$. Compared with existing work, our algorithm requires weaker assumptions on offline data and exhibits stronger adaptability. Moreover, our theoretical analysis recovers and unifies prior guarantees across different settings.",
    "key_points": [
      "multi-armed bandits",
      "linear multi-armed bandits",
      "offline-to-online",
      "hybrid learning"
    ],
    "gold_summary": "This paper consider the hybrid bandit with an offline linear regression before the online decision making using ridge procedure. The paper proposes the hybrid LinUCB algorithm and its regret analysis."
  },
  {
    "paper_id": "FpjH12hcqt",
    "title": "Taming OOD Actions for Offline Reinforcement Learning: An Advantage-Based Approach",
    "domain": "reinforcement learning",
    "content": "Offline reinforcement learning (RL) learns policies from fixed datasets without online interactions, but suffers from distribution shift, causing inaccurate evaluation and overestimation of out-of-distribution (OOD) actions. Existing methods counter this by conservatively discouraging all OOD actions, which limits generalization. We propose Advantage-based Diffusion Actor-Critic (ADAC), which evaluates OOD actions via an advantage-like function and uses it to modulate the Q-function update discriminatively. Our key insight is that the (state) value function is generally learned more reliably than the action-value function; we thus use the next-state value to indirectly assess each action. We develop a PointMaze environment to clearly visualize that advantage modulation effectively selects superior OOD actions while discouraging inferior ones. Moreover, extensive experiments on the D4RL benchmark show that ADAC achieves state-of-the-art performance, with especially strong gains on challenging tasks.",
    "key_points": [
      "offline reinforcement learning",
      "out-of-distribution actions",
      "actor-critic"
    ],
    "gold_summary": "The proposed ADAC improves on existing approaches by using an advantage-like function to evaluate OOD actions and modulate Q-function updates."
  },
  {
    "paper_id": "Z1rVgY4kNp",
    "title": "From Weak Data to Strong Policy: Q-Targets Enable Provable In-Context Reinforcement Learning",
    "domain": "reinforcement learning",
    "content": "Transformers trained with offline expert-level data have shown remarkable success in In-Context Reinforcement Learning (ICRL), enabling effective decision-making in unseen environments. However, the performance of these models heavily depends on optimal or expert-level trajectories, making them expensive in various real-world scenarios. In this work, we introduce Q-Target Pretrained Transformers (QTPT), a novel framework that leverages Q-learning instead of supervised learning during the training stage. In particular, QTPT doesn't require optimal-labeled actions or expert trajectories, and provides a practical solution for real-world applications. We theoretically establish the performance guarantee for QTPT and show its superior robustness to data quality compared to traditional supervised learning approaches. Through comprehensive empirical evaluations, QTPT consistently outperforms existing approaches, especially when trained on data sampled with non-expert policies.",
    "key_points": [
      "in-context reinforcement learning"
    ],
    "gold_summary": "This paper proposes a Q-learning-based Transformer pretraining framework, termed QTPT, which aims to reduce the reliance on high-quality expert data in in-context reinforcement learning."
  },
  {
    "paper_id": "I3W8PynQU0",
    "title": "MEAL: A Benchmark for Continual Multi-Agent Reinforcement Learning",
    "domain": "reinforcement learning",
    "content": "Benchmarks play a crucial role in the development and analysis of reinforcement learning (RL) algorithms, with environment availability strongly impacting research. One particularly underexplored intersection is continual learning (CL) in cooperative multi-agent settings. To remedy this, we introduce **MEAL** (**M**ulti-agent **E**nvironments for **A**daptive **L**earning), the first benchmark tailored for continual multi-agent learning. Existing CL benchmarks run environments on the CPU, leading to computational bottlenecks and limiting the length of task sequences. MEAL leverages JAX for GPU acceleration, enabling continual learning across sequences of up to 100 tasks on a standard desktop PC within a few hours. Evaluating popular CL and MARL methods reveals that naïvely combining them fails to preserve network plasticity or prevent catastrophic forgetting of cooperative behaviors.",
    "key_points": [
      "continual learning",
      "multi-agent",
      "overcooked",
      "benchmark",
      "reinforcement learning",
      "cooperative"
    ],
    "gold_summary": "MEAL is a benchmark for continual multi-agent reinforcement learning. This suite of JAX environments evaluates continual learning methods in 100 tasks and demonstrates that simple combination of MARL and CL, struggle to complex settings."
  },
  {
    "paper_id": "ulTRUwrzt9",
    "title": "Relative Value Learning",
    "domain": "reinforcement learning",
    "content": "In reinforcement learning (RL), critics traditionally learn absolute state values, estimating how good a particular situation is in isolation. Adding any constant to $V(s)$ leaves action preferences unchanged. Thus only value differences are relevant for decision making.\nMotivated by this fact, we ask the question whether these differences can be learned directly. For this, we propose \\emph{Relative Value Learning} (RV), a framework that considers antisymmetric value differences $\\Delta(s_i, s_j) = V(s_i) - V(s_j)$. We define a new pairwise Bellman operator and prove it is a $\\gamma$-contraction with a unique fixed point equal to the true value differences, derive well-posed $1$-step/$n$-step/$\\lambda$-return targets and reconstruct generalized advantage estimation from pairwise differences to obtain an unbiased policy-gradient estimator (R-GAE). Besides rigorous theoretical contributions, we integrate RV with PPO and achieve competitive performance on the Atari benchmark (49 games, ALE) compared to standard PPO, indicating that relative value estimation is an effective alternative to absolute critics. Source code will be made available.",
    "key_points": [
      "relative value learning",
      "on-policy actor-critic",
      "gae",
      "ppo"
    ],
    "gold_summary": "The paper proposes learning relative value differences compared to directly predicting state value. They integrate the proposed idea of relative value learning with PPO and evaluate its performance on the Atari benchmark."
  },
  {
    "paper_id": "O93c9H4SXc",
    "title": "Beyond Softmax and Entropy: $f$-Regularized Policy Gradients with Coupled Parametrizations",
    "domain": "reinforcement learning",
    "content": "We introduce $\\texttt{f-PG}$, a new class of stochastic policy gradient methods regularized by a family of $f$-divergences, including entropy and Tsallis divergences. For each divergence, we employed a $\\textit{coupled}$ parameterization, defined by $f$-softargmax, which allows us to establish the first explicit, non-asymptotic, last-iterate convergence rates for stochastic policy gradient.\nTo derive our analysis, we prove that the $f$-regularized value function is smooth and satisfies a Polyak-Łojasiewicz inequality as a function of $f$-softargmax parameters. To establish the latter, we introduce a general policy improvement operator that restricts optimization to a well-defined policy space that excludes ill-behaved policies. In the case of softmax, this allows to escape the \"gravitational pull\" and yields the first $\\textit{explicit}$ convergence guarantees for this parameterization, closing a gap in the literature.\nFinally, we leverage these rates to derive sample complexity bounds for the unregularized problem and show that $\\texttt{f-PG}$ with Tsallis divergences provides a provably better sample complexity/regularization bias trade-off compared to softmax-based policy gradient with entropy regularization.",
    "key_points": [
      "policy gradient methods",
      "reinforcement learning theory",
      "f-divergence",
      "tsallis entropy",
      "shannon entropy"
    ],
    "gold_summary": "This paper extends the entropy regularized softmax PG in Mei et al. 2020b to the a general regularization based on the coupled parameterization. Convergence guarantees are also established."
  },
  {
    "paper_id": "EKqBgn6bea",
    "title": "Black-Box Combinatorial Optimization with Order-Invariant Reinforcement Learning",
    "domain": "reinforcement learning",
    "content": "We introduce an order-invariant reinforcement learning framework for black-box combinatorial optimization. Classical estimation-of-distribution algorithms (EDAs) often rely on learning explicit variable dependency graphs, which can be costly and fail to capture complex interactions efficiently. In contrast, we parameterize a multivariate autoregressive generative model trained without a fixed variable ordering. By sampling random generation orders during training—a form of information-preserving dropout—the model is encouraged to be invariant to variable order, promoting search-space diversity and shaping the model to focus on the most relevant variable dependencies, improving sample efficiency. We adapt Generalized Reinforcement Policy Optimization (GRPO) to this setting, providing stable policy-gradient updates from scale-invariant advantages. Across a wide range of benchmark algorithms and problem instances of varying sizes, our method frequently achieves the best performance and consistently avoids catastrophic failures.",
    "key_points": [
      "black-box combinatorial optimization",
      "reinforcement learning",
      "estimation-of-distribution algorithm",
      "policy gradient method",
      "autoregressive generation",
      "structural dropout"
    ],
    "gold_summary": "The paper formulates the black-box combinatorial optimization problem as an MDP and reinforcement learning framework."
  },
  {
    "paper_id": "if1Ndb6RWD",
    "title": "Information-based Value Iteration Networks for Decision Making Under Uncertainty",
    "domain": "reinforcement learning",
    "content": "Deep neural networks that incorporate classic reinforcement learning methods, such as value iteration, into their structure significantly outperform randomly structured networks in learning and generalization. These networks, however, are mostly limited to environments with no or very low amounts of uncertainty. In this paper, we propose a new planning module architecture, the VI$^2$N (Value Iteration with Value of Information Network), that learns to act in novel environments with a high amount of perceptual ambiguity. This architecture over-emphasizes reducing uncertainty before exploiting the reward. VI$^2$N can also utilize factorization in environments with mixed observability to decrease the computational complexity of calculating the policy and facilitate learning. Tested on a diverse set of domains, each containing various types of environments, our network outperforms other deep architectures. Moreover, VI$^2$N generates interpretable cognitive maps highlighting both rewarding and informative locations. These maps highlight the key states the agent must visit to achieve its goal.",
    "key_points": [
      "reinforcement learning",
      "value iteration networks",
      "planning under uncertainty"
    ],
    "gold_summary": "The paper seems to extend partially observable VIN, in particular the method QMDP-Net, with a pairwise heuristic for solving POMDP. Experiments on simple gridworld tasks show their approach solves more randomly generated tasks than QMDP-Net."
  },
  {
    "paper_id": "PCuvo9uIXK",
    "title": "Near-Optimal Sample Complexity Bounds for Constrained Average-Reward MDPs",
    "domain": "reinforcement learning",
    "content": "Recent advances have significantly improved our understanding of the sample complexity of learning in average-reward Markov decision processes (AMDPs) under the generative model. However, much less is known about the constrained average-reward MDP (CAMDP), where policies must satisfy long-run average constraints. In this work, we address this gap by studying the sample complexity of learning an $\\epsilon$-optimal policy in CAMDPs under a generative model. We propose a model-based algorithm that operates under two settings: (i) relaxed feasibility, which allows small constraint violations, and (ii) strict feasibility, where the output policy satisfies the constraint. \nWe show that our algorithm achieves sample complexities of $\\tilde{O}\\left(\\frac{S A (B+H)}{ \\epsilon^2}\\right)$ and $\\tilde{O} \\left(\\frac{S A (B+H)}{\\epsilon^2 \\zeta^2} \\right)$ under the relaxed and strict feasibility settings, respectively. Here, $\\zeta$ is the Slater constant indicating the size of the feasible region, $H$ is the span bound of the bias function, and $B$ is the transient time bound. Moreover, a matching lower bound of $\\tilde{\\Omega}\\left(\\frac{S A (B+H)}{ \\epsilon^2\\zeta^2}\\right)$ for the strict feasibility case is established, thus providing the first minimax-optimal bounds for CAMDPs. Our results close the theoretical gap in understanding the complexity of constrained average-reward MDPs.",
    "key_points": [
      "constrained average-reward markov decision process",
      "minimax-optimal bounds",
      "sample complexity"
    ],
    "gold_summary": "This paper introduce a minimax-optimal primal-dual method for constrained AMDPs under the generative setting."
  },
  {
    "paper_id": "gwZ1DacxEk",
    "title": "Investigating Memory in RL with POPGym Arcade",
    "domain": "reinforcement learning",
    "content": "How should we analyze memory in deep RL? We introduce mathematical tools for fairly analyzing policies under partial observability and revealing how agents use memory to make decisions. To utilize these tools, we present POPGym Arcade, a collection of Atari-inspired, hardware-accelerated, pixel-based environments sharing a single observation and action space. Each environment provides fully and partially observable variants, enabling counterfactual studies on observability. We find that controlled studies are necessary for fair comparisons, and identify a pathology where value functions smear credit over irrelevant history. With this pathology, we demonstrate how out-of-distribution scenarios can contaminate memory, perturbing the policy far into the future, with implications for sim-to-real transfer and offline RL.",
    "key_points": [
      "reinforcement learning",
      "memory",
      "recurrent model",
      "pomdp"
    ],
    "gold_summary": "This work presents a POPGym Arcade benchmark and memory evaluation tools in RL. The empirical studies demonstrate that out-of-distribution scenarios can contaminate memory."
  },
  {
    "paper_id": "Ml4AtrrfQT",
    "title": "Peng's Q($\\lambda$) for Conservative Value Estimation in Offline Reinforcement Learning",
    "domain": "reinforcement learning",
    "content": "We propose a model-free offline multi-step reinforcement learning (RL) algorithm, Conservative Peng's Q($\\lambda$) (CPQL).\nOur algorithm adapts the Peng's Q($\\lambda$) (PQL) operator for conservative value estimation as an alternative to the Bellman operator.\nTo the best of our knowledge, this is the first work in offline RL to theoretically and empirically demonstrate the effectiveness of conservative value estimation with the *multi-step* operator by fully leveraging offline trajectories.\nThe fixed point of the PQL operator in offline RL lies closer to the value function of the behavior policy, thereby naturally inducing implicit behavior regularization.\nCPQL simultaneously mitigates over-pessimistic value estimation, achieves performance greater than (or equal to) that of the behavior policy, and provides near-optimal performance guarantees --- a milestone that previous conservative approaches could not achieve.\nExtensive numerical experiments on the D4RL benchmark demonstrate that CPQL consistently and significantly outperforms existing offline single-step baselines.\nIn addition to the contributions of CPQL in offline RL, our proposed method also contributes to the framework of offline-to-online learning.\nUsing the Q-function pre-trained by CPQL in offline settings enables the online PQL agent to avoid the performance drop typically observed at the start of fine-tuning and attain robust performance improvement.",
    "key_points": [
      "offline reinforcement learning",
      "offline-to-online settings",
      "multi-step operator"
    ],
    "gold_summary": "The paper presents Conservative Peng’s $Q(\\lambda)$ (CPQL), a model-free offline multi-step reinforcement learning algorithm that utilizes the Peng’s $Q(\\lambda)$ operator for conservative value estimation. CPQL achieves superior performance on standard benchmarks."
  },
  {
    "paper_id": "k7NhBrsjwn",
    "title": "Rethinking the Role of Dynamic Sparse Training for Scalable Deep Reinforcement Learning",
    "domain": "reinforcement learning",
    "content": "Scaling neural networks has driven breakthrough advances in machine learning, yet this paradigm fails in deep reinforcement learning (DRL), where larger models often degrade performance due to unique optimization pathologies such as plasticity loss. While recent works show that dynamically adapting network topology during training can mitigate these issues, existing studies have three critical limitations: (1) applying uniform dynamic training strategies across all modules despite encoder, critic, and actor following distinct learning paradigms, (2) focusing evaluation on basic architectures without clarifying the relative importance and interaction between dynamic training and architectural improvements, and (3) lacking systematic comparison between different dynamic approaches including sparse-to-sparse, dense-to-sparse, and sparse-to-dense. Through comprehensive investigation across modules and architectures, we reveal that dynamic sparse training strategies provide module-specific benefits that complement the primary scalability foundation established by architectural improvements. We finally distill these insights into Module-Specific Training (MST), a practical framework that further exploits the benefits of architectural improvements and demonstrates substantial scalability gains across diverse RL algorithms without algorithmic modifications.",
    "key_points": [
      "deep reinforcement learning",
      "parameter scalability",
      "dynamic sparse training",
      "plasticity"
    ],
    "gold_summary": "This paper analyzes the performance of sparse training under different DRL components, architectures, and sparsity strategies, and proposes Module-Specific Training (MST) to enhance the scalability of DRL."
  },
  {
    "paper_id": "3owSlsYDQf",
    "title": "A Simple \"Motivation\" Can Enhance Reinforcement Finetuning of Large Reasoning Models",
    "domain": "reinforcement learning",
    "content": "Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as a powerful learn-to-reason paradigm for Large Reasoning Models to tackle complex tasks. \nHowever, current RLVR paradigm is still not efficient enough, as it works in a trial-and-error manner. To perform better, the model needs to explore the reward space by numerously generating responses and learn from fragmented reward signals, blind to the overall reward patterns.\nFortunately, verifiable rewards make the natural language description of the reward function possible, and meanwhile, LLMs have demonstrated strong in-context learning ability.\nThis motivates us to explore if Large Reasoning Models can benefit from a **motivation** of the task, i.e., awareness of the reward function, during the reinforcement finetuning process, as we humans sometimes do when learning.\nIn this paper, we introduce ***M**otivation-**e**nhanced **R**einforcement **F**inetuning* (**MeRF**), an intuitive yet effective method enhancing reinforcement finetuning of LLMs by involving \\emph{``telling LLMs rules of the game''}. \nSpecifically, **MeRF** directly injects the reward specification into the prompt, which serves as an in-context motivation for the model to be aware of the optimization objective. \nThis simple modification leverages the in-context learning ability of LLMs, aligning generation with optimization, thereby incentivizing the model to generate desired outputs from both inner motivation and external reward. \nEmpirical evaluations demonstrate that **MeRF** achieves substantial performance gains over RLVR baseline. \nMoreover, ablation studies show that MeRF performs better with greater consistency between the in-context motivation and the external reward function, while the model also demonstrates an ability to adapt to misleading motivations through reinforcement finetuning.",
    "key_points": [
      "reinforcement finetuning",
      "large language models"
    ],
    "gold_summary": "By providing evaluation criteria with the system prompt (find-grained guideline), RLVR pipeline could be effectively trained."
  },
  {
    "paper_id": "JTw4OTgIYZ",
    "title": "BA2C: Bayesian Advantage Actor Critic for Few Sample Learning using Factor Graph Bayesian Neural Networks",
    "domain": "reinforcement learning",
    "content": "On-policy reinforcement learning (RL) algorithms, such as Proximal Policy Optimization (PPO), are widely used by researchers and practitioners across various tasks. However, these algorithms are known for their lack of sample efficiency, making them challenging to apply when obtaining training samples is costly, particularly in the absence of an effective simulation environment. While some research exists on Bayesian approaches in the context of RL, which promise a better trade-off between exploration and exploitation, to the best of our knowledge, no prior work has explored the implementation of policy-gradient actor-critic algorithms using expectation-propagation for approximate message passing in Bayesian neural networks (BNNs). In this paper, we propose BA2C, an actor-critic algorithm based on networks represented as a factor graph. Since these networks are trained through approximate message passing rather than gradients, we employ a pseudo-target implementation of the policy gradient theorem. We evaluate our algorithm against three popular RL implementations and observe that required training samples can be reduced up to 50\\% to reach desired levels on certain environments during the early stages of training. Furthermore, our findings indicate that the uncertainty-based evaluation using expectation propagation actually helps, and that our algorithm performs better within the expectation-propagation approximation compared to IVON, a state-of-the-art variational inference algorithm.",
    "key_points": [
      "bayesian neural networks",
      "efficient exploration",
      "actor-critic algorithm",
      "reinforcement learning"
    ],
    "gold_summary": "This paper proposes a Bayesian advantage actor-critic algorithm, where the model is trained with expectation propagation for message passing, a gradient-free approach."
  },
  {
    "paper_id": "4t51qDeEq7",
    "title": "Mitigating Hallucinations in Large Language Models via Hybrid Reinforcement Learning",
    "domain": "reinforcement learning",
    "content": "Large Language Models (LLMs) have revolutionized natural language processing by producing text that is coherent, contextually relevant, and often indistinguishable from human writing. However, a major challenge persists: hallucinations—outputs that are linguistically fluent but factually inaccurate or irrelevant—pose significant risks in domains requiring high precision, such as healthcare, law, and finance. In this study, we introduce a Hybrid Reinforcement Learning (HRL) framework that strategically combines Reinforcement Learning from Human Feedback (RLHF) and Reinforcement Learning from AI Feedback (RLAIF). By harmonizing the reliability of human oversight with the scalability of AI-based evaluation, HRL enhances factual accuracy while maintaining text fluency. Experiments on standard benchmarks, including TruthfulQA and MMLU, demonstrate substantial reductions in hallucination rates and marked improvements in factual correctness compared to prior approaches. This framework provides a robust, scalable pathway toward deploying LLMs more reliably in high-stakes applications.",
    "key_points": [
      "large language models",
      "hallucination mitigation",
      "reinforcement learning from human feedback",
      "reinforcement learning from ai feedback",
      "hybrid reinforcement learning",
      "natural language processing",
      "factual accuracy"
    ],
    "gold_summary": "This paper proposes a hybrid reinforcement learning (HRL) framework that combines human and AI feedback to mitigate hallucinations in LLMs."
  },
  {
    "paper_id": "31Mr6wLBeF",
    "title": "OPPO: Accelerating PPO-based RLHF via Pipeline Overlap",
    "domain": "reinforcement learning",
    "content": "Proximal Policy Optimization (PPO)-based reinforcement learning from human feedback (RLHF) is a widely adopted paradigm for aligning large language models (LLMs) with human preferences. However, its training pipeline suffers from substantial inefficiencies due to sequential multi-model dependencies (e.g., reward model depends on actor outputs) and long-tail response lengths, where a few long responses straggle the stage completion. We present OPPO, a novel, lightweight, and model-agnostic PPO-based RLHF framework that improves training efficiency by overlapping pipeline execution. OPPO introduces two novel techniques: (1) Intra-step overlap, which streams upstream model outputs (e.g., actor model) in right-sized chunks, enabling the downstream model (e.g., reward) to begin prefill while the upstream continues decoding; and (2) Inter-step overlap, which adaptively overcommits a few prompts and defers long generations to future steps, mitigating tail latency without discarding partial work. OPPO integrates easily with existing PPO implementations with a few lines of code change. Extensive evaluations show that OPPO accelerates PPO-based RLHF training by $1.8\\times$--$2.8\\times$ and improves GPU utilization by $1.4\\times$--$2.1\\times$ without compromising training convergence.",
    "key_points": [
      "reinforcement learning from human feedback",
      "training efficiency"
    ],
    "gold_summary": "This paper introduces a new pipeline methodology for PPO. The methodology is illustrated for single-node training and results in significantly faster training times."
  },
  {
    "paper_id": "isWKA4rdXx",
    "title": "Multi-Task Sequence Models Generalize in Offline Multi-Agent Reinforcement Learning",
    "domain": "reinforcement learning",
    "content": "Recent sequence model architectures have demonstrated great promise in offline multi-agent reinforcement learning (MARL). However, even for this expressive model class, generalising to tasks unseen in the training data remains a core challenge. A sensible response to this challenge is to simply scale the amount of offline data available for training. Yet, in this work, we find that task diversity has a stronger influence on generalisation than sheer dataset size. To obtain our findings, we study offline MARL sequence models trained on single-task datasets, clearly demonstrating their limited ability to zero-shot transfer to held-out test tasks.\nLeveraging this insight, we train and test multi-task versions of offline sequence modeling architectures. We identify three key design choices for successful offline multi-task training: (i) task-balanced mini-batches, (ii) treating value estimation as classification and (iii) agent masking to handle variable team sizes. Using multi-task datasets from three challenging cooperative environments (Connector, RWARE, and LBF), we investigate generalisation to unseen tasks and the scaling behaviour of our multi-task offline algorithms.\nWe show that our multi-task sequence models generalise better across all environments compared to single-task models, and achieve a mean improvement of 219% on held-out test tasks. Moreover, our offline MARL sequence models consistently outperform behaviour cloning (a surprisingly strong baseline). Our results clearly show that scaling task diversity by increasing the number of tasks used during training leads to improved generalisation gains over simply scaling the dataset size at a fixed level of task diversity.",
    "key_points": [
      "multi-agent reinforcement learning",
      "reinforcement learning",
      "offline reinforcement learning"
    ],
    "gold_summary": "This paper studies offline multi-task reinforcement leaning with sequence models. They demonstrate that scaling task diversity and the number of tasks leads to greater generalisation beyond scaling single task datasets."
  },
  {
    "paper_id": "XBTJnfbDkP",
    "title": "Transitive RL: Value Learning via Divide and Conquer",
    "domain": "reinforcement learning",
    "content": "In this work, we present Transitive Reinforcement Learning (TRL), a new value learning algorithm based on a divide-and-conquer paradigm. TRL is designed for offline goal-conditioned reinforcement learning (GCRL) problems, where the aim is to find a policy that can reach any state from any other state in the smallest number of steps. TRL converts a triangle inequality structure present in GCRL into a practical divide-and-conquer value update rule. This has several advantages compared to alternative value learning paradigms. Compared to temporal difference (TD) methods, TRL suffers less from bias accumulation, as in principle it only requires $O(\\log T)$ recursions (as opposed to $O(T)$ in TD learning) to handle a length-T trajectory. Unlike Monte Carlo methods, TRL suffers less from high variance as it performs dynamic programming. Experimentally, we show that TRL achieves the best performance in highly challenging, long-horizon benchmark tasks compared to previous offline GCRL algorithms.",
    "key_points": [
      "reinforcement learning",
      "goal-conditioned rl",
      "offline rl"
    ],
    "gold_summary": "This paper presents a novel goal-conditioned RL method with D&C updates. The discussion is restricted to discrete, deterministic RL problems, but I still find the work interesting."
  },
  {
    "paper_id": "4lAQBVU2Za",
    "title": "Safe Multi-Objective Reinforcement Learning via Multi-Party Pareto Negotiation",
    "domain": "reinforcement learning",
    "content": "Safe multi-objective reinforcement learning (Safe MORL) seeks to optimize performance while satisfying safety constraints. Existing methods face two key challenges: (i) incorporating safety as additional objectives enlarges the objective space, requiring more solutions to uniformly cover the Pareto front and maintain adaptability under changing preferences; (ii) strictly enforcing safety constraints is feasible for single or compatible constraints, but conflicting constraints prevent flexible, preference-aware trade-offs.\nTo address these challenges, we cast Safe MORL within a multi-party negotiation framework that treats safety as an external regulatory perspective, enabling the search for a consensus-based multi-party Pareto-optimal set. We propose a multi-party Pareto negotiation (MPPN) strategy built on NSGA-II, which employs a negotiation threshold $\\varepsilon$ to represent the acceptable solution range for each party. During evolutionary search, $\\varepsilon$ is dynamically adjusted to maintain a sufficiently large negotiated solution set, progressively steering the population toward the $(\\varepsilon_{\\text{efficiency}}, \\varepsilon_{\\text{safety}})$-negotiated common Pareto set.\nThe framework preserves user preferences over conflicting safety constraints without introducing additional objectives and flexibly adapts to emergent scenarios through progressively guided $(\\varepsilon_{\\text{efficiency}}, \\varepsilon_{\\text{safety}})$. Experiments on a MuJoCo benchmark show that our approach outperforms state-of-the-art methods in both constrained and unconstrained MORL, as measured by multi-party hypervolume and sparsity metrics, while supporting preference-aware policy selection across stakeholders.",
    "key_points": [
      "multi-party multi-objective reinforcement learning; constrained reinforcement learning; multi-objective reinforcement learning"
    ],
    "gold_summary": "The paper proposes a negotiation-based framework for safe multi-objective reinforcement learning, where efficiency and safety are modeled as two decision parties."
  },
  {
    "paper_id": "M4MeBjYiHl",
    "title": "Aligning News and Prices: A Cross-Modal LLM-Enhanced Transformer DRL Framework for Volatility-Adaptive Stock Trading",
    "domain": "reinforcement learning",
    "content": "While Deep Reinforcement Learning (DRL) has shown promise for stock trading, its practical application is constrained by critical gaps that undermine performance in real-world volatile markets, most notably during events like the 2020 COVID-19 market crash. Specifically, existing DRL methods fail to capitalize on textual financial news (a key leading indicator of market sentiment), struggle to model multi-scale temporal dynamics, and lack robustness to extreme volatility, leaving them unable to adapt to sudden shifts in market fundamentals. To address these limitations, we propose a volatility-adaptive, multimodal DRL framework for stock trading integrating pre-trained Large Language Models (LLMs), Transformers, and the Soft Actor-Critic (SAC) algorithm. The framework first uses an LLM-driven module to extract sentiment and event features from financial news, maps price dynamics into the LLM’s semantic space via a multi-head attention reprogramming layer, and fuses these modalities via cross-attention to capture intrinsic news-price interdependencies. To enhance state representation, a Transformer encoder models short/long-term news sentiment trends, price fluctuations, and inter-stock correlations, and merges these heterogeneous features into a compact, unified state via multi-head attention. Finally, we incorporate gradient feedback from SAC’s critic network to the Transformer, enabling end-to-end optimization of feature learning and trading policy. Empirical evaluations on NASDAQ-100 data show our framework outperforms existing DRL methods in multi-stock trading, while surpassing Transformer-based methods in single-stock prediction, with ablations confirming core modules drive performance gains.",
    "key_points": [
      "large language model",
      "automated stock trading",
      "multimodal fusion"
    ],
    "gold_summary": "This paper introduces a multimodal DRL framework involving LLMs, Transformer and SAC for stock trading. Experiments on NASDAQ-100 shows its SOTA performance."
  },
  {
    "paper_id": "aS2o4Gn4CR",
    "title": "Bridging Discrete and Continuous RL: Stable Deterministic Policy Gradient with Martingale Characterization",
    "domain": "reinforcement learning",
    "content": "The theory of discrete-time reinforcement learning (RL) has advanced rapidly over the past decades. Although primarily designed for discrete environments, many real-world RL applications are inherently continuous and complex. A major challenge in extending discrete-time algorithms to continuous-time settings is their sensitivity to time discretization, often leading to poor stability and slow convergence.\nIn this paper, we investigate deterministic policy gradient methods for continuous-time RL. We derive a continuous-time policy gradient formula based on an analogue of the advantage function and establish its martingale characterization. This theoretical foundation leads to our proposed algorithm, CT-DDPG, which enables stable learning with deterministic policies in continuous-time environments.\nNumerical experiments show that the proposed CT-DDPG algorithm offers improved stability and faster convergence compared to existing discrete-time and continuous-time methods, across a wide range of control tasks with varying time discretizations and noise levels.",
    "key_points": [
      "reinforcement learning",
      "continuous time",
      "deterministic policy",
      "stochastic control"
    ],
    "gold_summary": "This paper proposes CT-DDPG, an discrete RL algorithm in the continuous RL paradigm. The main idea is to use the martingale orthogonality characterization. Experiments have been conducted on Pendulum-v1, HalfCheetah-v5, Hopper-v5, and Walker2d-v5."
  },
  {
    "paper_id": "mvLhN0veUd",
    "title": "Breaking Barriers: Do Reinforcement Fine-tuning Gains Transfer To Unseen Domains?",
    "domain": "reinforcement learning",
    "content": "Reinforcement post training (RPT) has recently shown promise in improving the reasoning abilities of large language models (LLMs).\nHowever, it remains unclear how well these improvements generalize to new domains, as prior work evaluates RPT models on data from the same domains used for fine-tuning. \nTo understand the generalizability of RPT, we conduct \ntwo studies.\n(1) Observational: we compare a wide range of open-weight RPT models against their corresponding base models across multiple domains, including both seen and unseen domains in their fine-tuning data. \n(2) Interventional: we fine-tune LLMs with RPT on \nsingle domains and evaluate their performance across multiple domains. Both studies \nconverge on the same conclusion that, although RPT brings substantial gains on \ntasks similar to the fine-tuning data, the gains generalize inconsistently \nand can vanish on domains with different reasoning patterns.",
    "key_points": [
      "large language models",
      "reinforcement learning",
      "supervised fine-tuning",
      "generalizability"
    ],
    "gold_summary": "This paper presents an empirical study that assess to which degree reinforcement learning post-training enables generalizable improvement of reasoning across domains. It is structured into two parts, an observational and an interventional study."
  },
  {
    "paper_id": "Els0yUtxNK",
    "title": "DAL: A Practical Prior-Free Black-Box Framework for Non-Stationary Bandits",
    "domain": "reinforcement learning",
    "content": "We introduce a practical, black-box framework termed Detection Augmented Learning (DAL) for the problem of non-stationary bandits without prior knowledge of the underlying non-stationarity. DAL accepts any stationary bandit algorithm as input and augments it with a change detector, enabling applicability to all common bandit variants. Extensive experimentation demonstrates that DAL consistently surpasses current state-of-the-art methods across diverse non-stationary scenarios, including synthetic benchmarks and real-world datasets, underscoring its versatility and scalability. We provide theoretical insights into DAL's strong empirical performance, complemented by thorough experimental validation.",
    "key_points": [
      "non-stationary bandits",
      "black-box algorithms",
      "non-stationary reinforcement learning"
    ],
    "gold_summary": "This work focus on the regret minimization problem in non-stationary bandits. It proposed the DAL technique to detect unknown changes in the environment. Both numerical experiments and theoretical analysis are presented in this work."
  },
  {
    "paper_id": "StIIArpUZ3",
    "title": "Multi-Agent Cross-Entropy Method with Monotonic Nonlinear Critic Decomposition",
    "domain": "reinforcement learning",
    "content": "Cooperative multi-agent reinforcement learning (MARL) commonly adopts centralized training with decentralized execution (CTDE), where centralized critics leverage global information to guide decentralized actors. However, centralized-decentralized mismatch (CDM) arises when the suboptimal behavior of one agent degrades others’ learning. Prior approaches mitigate CDM through value decomposition, but linear decompositions allow per-agent gradients at the cost of limited expressiveness, while nonlinear decompositions improve representation but require centralized gradients, reintroducing CDM. To overcome this trade-off, we propose the multi-agent cross-entropy method (MCEM), combined with monotonic nonlinear critic decomposition (NCD). MCEM updates policies by increasing the probability of high-value joint actions, thereby excluding suboptimal behaviors. For sample efficiency, we extend off-policy learning with a modified $k$-step return and Retrace. Analysis and experiments demonstrate that MCEM outperforms state-of-the-art methods across both continuous and discrete action benchmarks.",
    "key_points": [
      "multi-agent reinforcement learning",
      "multi-agent cross entropy method"
    ],
    "gold_summary": "This work introduces a MA cross-entropy method, combined with monotonic nonlinear critic decomposition, in order to address the issue of centralised-decentralised mismatch caused by suboptimal behaviours."
  },
  {
    "paper_id": "Fte7TOqnQp",
    "title": "Inter-Agent Relative Representations for Multi-Agent Option Discovery",
    "domain": "reinforcement learning",
    "content": "Temporally extended actions improve the ability to explore and plan in single-agent settings. In multi-agent settings, the exponential growth of the joint state space with the number of agents makes coordinated behaviours even more valuable. Yet, this same exponential growth renders the design of multi-agent options particularly challenging. Existing multi-agent option discovery methods often sacrifice coordination by producing loosely coupled or fully independent behaviors. Toward addressing these limitations, we describe a novel approach for multi-agent option discovery. Specifically, we propose a joint-state abstraction that compresses the state space while preserving the information necessary to discover strongly coordinated behaviours. Our approach builds on the inductive bias that synchronisation over agent states provides a natural foundation for coordination in the absence of explicit objectives. We first approximate a fictitious state of maximal alignment with the team, the Fermat state, and use it to define a measure of spreadness, capturing team-level misalignment on each individual state dimension. Building on this representation, we then employ a neural graph Laplacian estimator to derive options that capture state synchronisation patterns between agents. We evaluate the resulting options across multiple scenarios in two multi-agent domains, showing that they yield stronger downstream coordination capabilities compared to alternative option discovery methods.",
    "key_points": [
      "option discovery",
      "multi-agent reinforcement learning"
    ],
    "gold_summary": "This paper targets at multi-agent option discovery. Specifically, they propose a joint-state abstraction that compresses the state space while preserving the information necessary to discover strongly coordinated behaviors."
  },
  {
    "paper_id": "1WKCTStACl",
    "title": "AlphaZeroES: Direct Score Maximization Can Outperform Planning Loss Minimization in Single-Agent Settings",
    "domain": "reinforcement learning",
    "content": "Planning at execution time has been shown to dramatically improve performance for AI agents.\nA well-known family of approaches to planning at execution time in single-agent settings and two-player zero-sum games are AlphaZero and its variants, which use Monte Carlo tree search together with a neural network that guides the search by predicting state values and action probabilities.\nAlphaZero trains these networks by minimizing a planning loss that makes the value prediction match the episode return, and the policy prediction at the root of the search tree match the output of the full tree expansion.\nAlphaZero has been applied to various single-agent environments that require careful planning, with great success.\nIn this paper, we explore an intriguing question:\nin single-agent settings, can we outperform AlphaZero by directly maximizing the episode score instead of minimizing this planning loss, while leaving the MCTS algorithm and neural architecture unchanged?\nTo directly maximize the episode score, we use evolution strategies, a family of algorithms for zeroth-order blackbox optimization.\nWe compare both approaches across multiple single-agent environments.\nOur experiments suggest that directly maximizing the episode score tends to outperform minimizing the planning loss.",
    "key_points": [
      "reinforcement learning",
      "planning",
      "monte carlo tree search (mcts)"
    ],
    "gold_summary": "The authors demonstrate that one can use evolution strategies with an AlphaZero setup to directly optimize maximizing the reward. This appears to work well--or better than the base version in the tested games."
  },
  {
    "paper_id": "SLGJSecXSw",
    "title": "FPDou: Mastering DouDizhu with Fictitious Play",
    "domain": "reinforcement learning",
    "content": "DouDizhu is a challenging three-player imperfect-information game involving competition and cooperation. Despite strong performance, existing methods are primarily developed with reinforcement learning (RL) without closely examining the stationary assumption. Specifically, DouDizhu's three-player nature entails algorithms to approximate Nash equilibria, but existing methods typically update/learn all players' strategies simultaneously. This creates a non-stationary environment that impedes RL-based best-response learning and hinders convergence to Nash equilibria. Inspired by Generalized Weakened Fictitious Play (GWFP), we propose FPDou. More specifically, to ease the use of GWFP, we adopt a perfect-training-imperfect-execution paradigm: we treat the two Peasants as one player by sharing information during training, which converts DouDizhu into a two-player zero-sum game amenable to GWFP’s analysis. To mitigate the training-execution gap, we introduce a regularization term to penalize the policy discrepancy between perfect and imperfect information. To make learning efficient, we design a practical implementation that consolidates RL and supervised learning into a single step, eliminating the need to train two separate networks. To address non-stationarity, we alternate on-policy/off-policy updates. This not only preserves stationarity for $\\epsilon$-best-response learning but also enhances sample efficiency by using data for both sides. FPDou achieves a new state of the art: it uses a 3$\\times$ smaller model without handcrafted features, outperforms DouZero and PerfectDou in both win rate and score, and ranks first among 452 bots on the Botzone platform. The anonymous demo and code are provided for reproducibility.",
    "key_points": [
      "doudizhu",
      "deep reinforcement learning",
      "fictitious play"
    ],
    "gold_summary": "This paper introduces an algorithm for learning to play DouDizhu. It is an amalgamation of ideas for building a new SOTA."
  },
  {
    "paper_id": "FS1KoskTtD",
    "title": "Fathom-DeepResearch: Unlocking Long Horizon Information Retrieval and Synthesis for SLMs",
    "domain": "reinforcement learning",
    "content": "Tool-integrated reasoning has emerged as a key focus for enabling agentic applications. Among these, DeepResearch Agents have gained significant attention for their strong performance on complex, open-ended information-seeking tasks. We introduce Fathom-DeepResearch, an agentic system composed of two specialized models. The first is Fathom-Search-4B, a DeepSearch model trained from Qwen3-4B and optimized for evidence-based investigation through live web search and targeted webpage querying. Its training combines three advances: (i) DUETQA, a ∼5K-sample dataset generated via multi-agent self-play that enforces strict web-search dependence and heterogeneous source grounding; (ii) RAPO, a zero-overhead extension of GRPO that stabilizes multi-turn Reinforcement Learning with Verifiable Rewards through curriculum pruning, reward-aware advantage scaling, and per-prompt replay buffers; and (iii) a steerable step-level reward that classifies each tool call by cognitive behavior and marginal utility, enabling explicit control over search trajectory breadth, depth, and horizon. These improvements enable reliable extension of tool-calling beyond 20 calls when warranted. The second is Fathom-Synthesizer-4B, trained from Qwen3-4B, which converts multi-turn DeepSearch traces into structured, citation-dense DeepResearch Reports for comprehensive synthesis. Evaluated on DeepSearch benchmarks (SimpleQA, FRAMES, WebWalker, Seal0, MuSiQue) and DeepResearch-Bench, the system achieves state-of-the-art performance in the open-weights category while closely rivaling proprietary\nclosed systems, while also demonstrating strong performance in general reasoning benchmarks: HLE, AIME-25, GPQA-Diamond, and MedQA.",
    "key_points": [
      "deepresearch",
      "reasoning",
      "agentic reasoning"
    ],
    "gold_summary": "This paper presents Fathom-DeepResearch, an open-source framework for long-horizon information retrieval and data synthesis for deep research agents."
  },
  {
    "paper_id": "pye62xAoi4",
    "title": "Value Shaping: Bias Reduction in Bellman Error for Deep Reinforcement Learning",
    "domain": "reinforcement learning",
    "content": "The Bellman error plays a crucial role as an objective function in deep reinforcement learning (DRL), serving as a proxy for the value error. However, this proxy relationship does not guarantee exact equivalence between the two, as the Bellman error inherently contains bias that can lead to unexpected optimization behavior. In this paper, we investigate the relationship between the value error and the Bellman error, and analyze why the Bellman error is not a reliable proxy due to its inherent bias. Leveraging the linear structure of the Bellman equation, we propose a method to compensate for this bias by adjusting the reward function—while ensuring that such modifications do not alter the optimal policy. In practice, we initialize two parallel Bellman iteration processes: one for estimating the bias and the other for updating the value function with minimal bias. Our method effectively learns a low-bias Q-function, making it broadly applicable and easily integrable into existing mainstream RL algorithms. Experimental results across multiple environments demonstrate that our approach improves RL efficiency, achieves superior performance, and holds promise as a fundamental technique in the field of reinforcement learning.",
    "key_points": [
      "bellman error",
      "bias reduction",
      "affine reward transformation"
    ],
    "gold_summary": "This paper propose a MRT method to address the estimation error issue. Experiments across Mujoco environment show that MRT improves sample efficiency, reward, and value estimation."
  },
  {
    "paper_id": "PCKjfdkvsP",
    "title": "Safe Learning Through Controlled Expansion of Exploration Set",
    "domain": "reinforcement learning",
    "content": "Safe reinforcement learning (RL) aims to  maximize expected cumulative rewards  while satisfying safety constraints, making it well-suited for safety-critical applications. In this paper, we address the setting where the safety of state-action pairs is unknown a priori, with the goal of learning an optimal policy while keeping the learning process as safe as possible. To this end, we propose a novel approach that guarantees almost-sure safety by progressively expanding an exploration set, leveraging previously verified safe state-action pairs and a predictive Gaussian Process (GP) model. We provide theoretical guarantees on asymptotic convergence to optimal policy and bound on the online regret. Numerical results on benchmark problems with both discrete and continuous state spaces show that our approach achieves superior safety during  learning and effectively converges to optimal policies.",
    "key_points": [
      "safe reinforcement learning",
      "safe learning",
      "safe exploration"
    ],
    "gold_summary": "This paper proposes a safe exploration method with a predictive Gaussian process model. Asymptotic convergence to the optimal policy and a bound on online regret are provided."
  },
  {
    "paper_id": "j6D83Mf6LG",
    "title": "Intention-Conditioned Flow Occupancy Models",
    "domain": "reinforcement learning",
    "content": "Large-scale pre-training has fundamentally changed how machine learning research is done today: large foundation models are trained once, and then can be used by anyone in the community (including those without data or compute resources to train a model from scratch) to adapt and fine-tune to specific tasks. Applying this same framework to reinforcement learning (RL) is appealing because it offers compelling avenues for addressing core challenges in RL, including sample efficiency and robustness. However, there remains a fundamental challenge to pre-train large models in the context of RL: actions have long-term dependencies, so training a foundation model that reasons across *time* is important. Recent advances in generative AI have provided new tools for modeling highly complex distributions. In this paper, we build a probabilistic model to predict which states an agent will visit in the temporally distant future (i.e., an occupancy measure) using flow matching. As large datasets are often constructed by many distinct users performing distinct tasks, we include in our model a latent variable capturing the user intention. This intention increases the expressivity of our model, and enables adaptation with generalized policy improvement. We call our proposed method **intention-conditioned flow occupancy models (InFOM)**. Comparing with alternative methods for pre-training, our experiments on $36$ state-based and $4$ image-based benchmark tasks demonstrate that the proposed method achieves $1.8 \\times$ median improvement in returns and increases success rates by $36\\\\%$.",
    "key_points": [
      "reinforcement learning",
      "flow matching",
      "latent variable model",
      "pre-training and fine-tuning"
    ],
    "gold_summary": "The present work leverages flow-matching models to predict trajectories of future states for RL tasks to help the actor finding better policies.\nExtensive experiments shows on gym and robotic manipulation benchmarks  shows promissing results."
  },
  {
    "paper_id": "deSF7BrNli",
    "title": "Efficient and Stable Grouped RL Training for Large Language Models",
    "domain": "reinforcement learning",
    "content": "Group-based reinforcement learning algorithms such as Group Reward Policy Optimization (GRPO) have proven effective for fine-tuning large language models (LLMs) with human feedback. However, generating and storing multiple responses per prompt incurs substantial memory overhead, especially as the sample group size increases, limiting scalability under constrained hardware.\nWe propose Infinite Sampling, a framework that enables efficient and stable GRPO training by decoupling group size from GPU memory usage. It consists of: (1) micro sampling groups that decomposes large groups into memory-feasible rounds; (2) continuous sampling that interleaves generation across groups to improve utilization; and (3) a length-aware scheduler combining token-conditioned sequence length prediction with a two-stage plan: global grouping via fixed-point approximation scheme (FPTAS)  and runtime refill via shortest-job-first (SJF).\nExperiments show that our micro sampling groups reduce peak memory usage by over 50% compared to full-group decoding (e.g., from 21.55 GB to 10.64 GB on Qwen3-1.7B).\nBuilding on this, Infinite Sampling improves throughput by over 25% compared to the naive micro sampling group method, reducing decoding steps while maintaining full-length completions and memory usage. Our hybrid scheduling ensures efficient and stable GRPO training with larger groups under realistic GPU memory constraints.",
    "key_points": [
      "reinforcement learning",
      "large language models",
      "efficiency"
    ],
    "gold_summary": "This paper proposes Infinite Sampling, a memory-efficient decoding framework for enabling large-group GRPO (Group Reward Policy Optimization) training under constrained GPU memory."
  },
  {
    "paper_id": "6wd38R8L0Z",
    "title": "Flow Matching with Injected Noise for Offline-to-Online Reinforcement Learning",
    "domain": "reinforcement learning",
    "content": "Generative models have recently demonstrated remarkable success across diverse domains, motivating their adoption as expressive policies in reinforcement learning (RL).\nWhile they have shown strong performance in offline RL, particularly where the target distribution is well defined, their extension to online fine-tuning has largely been treated as a direct continuation of offline pre-training, leaving key challenges unaddressed.\nIn this paper, we propose Flow Matching with Injected Noise for Offline-to-Online RL (FINO), a novel method that leverages flow matching-based policies to enhance sample efficiency for offline-to-online RL.\nFINO facilitates effective exploration by injecting noise into policy training, thereby encouraging a broader range of actions beyond those observed in the offline dataset.\nIn addition to exploration-enhanced flow policy training, we combine an entropy-guided sampling mechanism to balance exploration and exploitation, allowing the policy to adapt its behavior throughout online fine-tuning.\nExperiments across diverse, challenging tasks demonstrate that FINO consistently achieves superior performance under limited online budgets.",
    "key_points": [
      "reinforcement learning",
      "offline-to-online reinforcement learning",
      "flow matching",
      "noise injection"
    ],
    "gold_summary": "This paper introduces a new approach for offline-to-online RL via injecting noise into the flow matching objective for improved exploration."
  },
  {
    "paper_id": "kokgg2qqUU",
    "title": "PVPO: Pre-Estimated Value-Based Policy Optimization for Agentic Reasoning",
    "domain": "reinforcement learning",
    "content": "Critic-free reinforcement learning methods, particularly group policies, have attracted considerable attention for their efficiency in complex tasks. However, these methods rely heavily on multiple sampling and comparisons within the policy to estimate advantage, which may cause the policy to fall into local optimum and increase computational cost. To address these issues, we propose PVPO, an efficient reinforcement learning method enhanced by an  advantage reference anchor and data pre-sampling. Specifically, we use the reference model to rollout in advance and employ the calculated reward score as a reference anchor. Our approach effectively corrects the cumulative bias introduced by intra-group comparisons and significantly reduces reliance on the number of rollouts during training. Meanwhile, the reference model can assess sample difficulty during data pre-sampling, enabling effective selection of high-gain data to improve training efficiency. Moreover, PVPO is orthogonal to other advanced critic-free RL algorithms, making it compatible with and complementary to these methods. Experiments conducted on nine datasets across two domains demonstrate that PVPO achieves State-Of-The-Art (SOTA) performance. Our approach not only demonstrates robust generalization across multiple tasks, but also exhibits scalable performance across models of varying scales.",
    "key_points": [
      "critic-free reinforcement learning",
      "group sampling",
      "advantage reference anchor",
      "policy optimization",
      "agentic reasoning"
    ],
    "gold_summary": "This paper describes a novel RL method using reference anchors and data pre-sampling."
  },
  {
    "paper_id": "USeo1EvvEq",
    "title": "The Stability and Convergence of Two-Timescale Stochastic Approximation with Markovian Noise for Reinforcement Learning",
    "domain": "reinforcement learning",
    "content": "Stochastic approximations (SA)--algorithms which derive their power through the use of random, incremental updates--are at the heart of reinforcement learning (RL). Expanding the theory of SA has established rigorous results concerning the most important algorithms in RL, including stochastic gradient descent and temporal difference learning. In this work, we focus on two-timescale stochastic approximations, a class which notably includes temporal difference learning with gradient correction (TDC) and actor-critic methods. Prior work has developed stability (boundedness) and convergence criteria for two-timescale SA under i.i.d. noise, but analogous results for Markovian noise have remained elusive--a critical issue since RL data are generated by a Markov chain, making i.i.d. assumptions unrealistic. To address this gap, we present the first stability result and the first asymptotic convergence result for two-timescale schemes with Markovian noise under general, verifiable conditions--notably, without resorting to projected variants of the schemes or requiring the noise to be in a compact space. As a key application, we contribute the first asymptotic convergence proof of TDC, an off-policy prediction algorithm with linear approximation and eligibility traces. Together, our results extend SA theory, establishing the first theoretical foundation for analysis of two-timescale algorithms with the realistic noise models inherent to RL.",
    "key_points": [
      "stochastic approximation",
      "reinforcement learning"
    ],
    "gold_summary": "This paper establishes theoretical guarantees for stability and convergence of two-timescale stochastic approximation (SA) under Markovian noises. It then applied the results to temporal difference learning with gradient correction (TDC)"
  },
  {
    "paper_id": "hSjjVXWPS5",
    "title": "Sliding Window–Based Q-Ensemble for Offline Reinforcement Learning",
    "domain": "reinforcement learning",
    "content": "Offline reinforcement learning aims to learn optimal policies from static datasets, which brings the key challenge of accurately estimating values for out-of-distribution actions. Ensemble-based methods address this issue by aggregating multiple Q-networks to reduce the uncertainty in Q-value estimates. However, previous related studies suffer from the inevitably high correlation among Q-functions, driven by identical architectures, shared inputs, and synchronized Bellman targets. Such correlation reduces the robustness of Q-ensembles, ultimately leading to degraded policy performance. In this paper, we propose sliding window delayed gradient (SWDG), a novel ensemble-based offline RL algorithm that leverages the temporal asynchrony induced by the sliding-window mechanism to dynamically maintain diversity among Q-functions. Meanwhile, to further reduce extrapolation error and correlation, SWDG uses Q-networks tied to the sliding window as delayed-gradient target to compute the temporal-difference (TD) error. We theoretically show that the sliding window mechanism tightens the pessimistic lower bound and enhances temporal decorrelation among Q-functions, while the use of delayed-gradient target further strengthens this guarantee. Our experiments on the D4RL benchmark show that SWDG achieves state-of-the-art performance.",
    "key_points": [
      "offline rl",
      "q-ensemble",
      "sliding window",
      "uncertainty estimation"
    ],
    "gold_summary": "The paper considers offline reinforcement learning and proposes to decorrelate Q-ensembles through a sliding window approach. The claimed contributions include state-of-the-art results on D4RL, backed up with theoretical results."
  },
  {
    "paper_id": "1spOYCVPPg",
    "title": "It’s Not You, It’s Clipping: A Soft Trust-Region via Probability Smoothing for LLM RL",
    "domain": "reinforcement learning",
    "content": "Training large language models (LLMs) with reinforcement learning (RL) methods such as PPO and GRPO commonly relies on ratio clipping to stabilise updates. While effective at preventing instability, clipping discards information and introduces gradient discontinuities. We propose Probability Smoothing Policy Optimisation (PSPO), which smooths the current policy’s probabilities toward the old (behaviour) policy before computing the importance ratio, analogous to label smoothing. Unlike clipping, PSPO preserves gradient signal, while interpolation toward the old policy creates a soft trust region that discourages large, destabilising updates, with formal guarantees.\n\nWe instantiate PSPO within GRPO (GR-PSPO) and fine-tune Qwen2.5-0.5B/1.5B on GSM8K, evaluating on GSM8K test and the cross-dataset generalisation on SVAMP, ASDiv, and MATH-500. Relative to unclipped GRPO (single iteration; no data reuse, ratio always = 1), GR-PSPO attains similar accuracy but produces clearer, more concise, and more logically coherent responses (LLM-as-Judge). Compared to clipped GRPO, GR-PSPO substantially improves performance in both the 0.5B and 1.5B models, with a boost of over 20% on GSM8K (39.7% vs. 17.6% for 0.5B, 59.4% vs. 37.8% for 1.5B).",
    "key_points": [
      "policy optimization",
      "ppo",
      "grpo",
      "clipping",
      "trust region",
      "probability smoothing",
      "soft trust region",
      "llm",
      "reasoning",
      "mathematical problem solving",
      "grpo",
      "fine-tuning."
    ],
    "gold_summary": "The paper presents PSPO a methodology that smooths the importance sampling ratio with respect to the old policy, allowing for gradients to flow even outside the trust region."
  },
  {
    "paper_id": "9PWyFDedjx",
    "title": "Adaptive Policy Backbone via Shared Network",
    "domain": "reinforcement learning",
    "content": "Reinforcement learning (RL) has achieved impressive results across domains, yet learning an optimal policy typically requires extensive interaction data, limiting practical deployment. A common remedy is to leverage priors—such as pre-collected datasets or reference policies—but their utility degrades under task mismatch between training and deployment. While prior work has sought to address this mismatch, it has largely been restricted to in-distribution settings. To address this challenge, we propose $\\textbf{A}$daptive $\\textbf{P}$olicy $\\textbf{B}$ackbone (APB), a meta-transfer RL method that inserts lightweight linear layers before and after a shared backbone, thereby enabling parameter-efficient fine-tuning (PEFT) while preserving prior knowledge during adaptation. Our results show that APB improves sample efficiency over standard RL and adapts to out-of-distribution (OOD) tasks where existing meta-RL baselines typically fail.",
    "key_points": [
      "reinforcement learning",
      "meta reinforcement learning",
      "transfer meta reinforcement learning"
    ],
    "gold_summary": "Authors propose Adaptive Policy Backbone, a method that does Meta RL adaptation by only tuning two task-specific linear layers (on the inputs, and on the outputs)."
  },
  {
    "paper_id": "eySyCrQ5zU",
    "title": "Provably Safe Representation Learning in CMDPs: A Primal-Dual Approach",
    "domain": "reinforcement learning",
    "content": "We study representation learning in low-rank  Constrained Markov Decision Processes (CMDPs) with unknown dynamics, where the agent must maximize rewards under safety constraints. While representation learning has significantly advanced for unconstrained MDPs, its extension to CMDPs remains open due to the critical challenge of safe exploration under learned features, particularly concerning the management of soft constraint violation. In this work, we propose REP-PD, the first algorithm that provably integrates representation learning with policy optimization in low-rank CMDPs. By iteratively learning a low-rank transition representation via MLE and utilizing a composite Q-function tied to the unconstrained Lagrangian, REP-PD guides policy updates to balance reward maximization, exploration, and robust constraint adherence. Through this approach, REP-PD achieves a near-optimal policy with a sampling complexity bound independent of the state space dimension without prior feature knowledge. Notably, REP-PD's regret matches the lower bounds for unconstrained low-rank MDPs, achieving strong performance concerning soft constraint violation. We then consider a stronger hard constraint violation metric, where the agent must strictly satisfy constraints at all times, and propose REP-PD-hard by designing a novel policy optimization\nmodule. Our work thus provides a robust and theoretically grounded approach to representation learning in constrained reinforcement learning, with guarantees on bounded soft and hard constraint violation.",
    "key_points": [
      "representation learning; safe representation learning; constrained markov decision process"
    ],
    "gold_summary": "This paper studies constrained markov decision process (CMDP) under low-rank assumption. It proposed two algorithms for learning CMDP under soft-constraint and hard-constraint separately. The paper also theoretically proved the regret and constraint violation."
  },
  {
    "paper_id": "DbrefyDn8R",
    "title": "Architectural Inductive Biases Can Be Enough for State Abstraction in Deep Reinforcement Learning",
    "domain": "reinforcement learning",
    "content": "The ability to ignore irrelevant sensory information is central to intelligent behavior. In reinforcement learning (RL), existing methods typically rely on auxiliary objectives to achieve similar forms of abstraction. Such objectives tend to add significant complexity to the base RL algorithm. In this work, we take a step back and ask: can selective abstraction emerge naturally from reward optimization alone, without any additional objectives? Following prior work, we show that standard deep RL learns slowly or not at all in the presence of distracting, task-irrelevant state variables, failing to learn meaningful state abstractions. We then introduce a surprisingly simple neural network architecture change: a learnable, observation-independent attention mask applied to the inputs of the policy and value networks and trained end-to-end using only the RL objective. Despite its simplicity, this architectural modification consistently improves sample efficiency and learns to mask out distracting input variables across 12 continuous control tasks. We analyze the dynamics of gradient descent using this method on a linear regression task and demonstrate improved feature credit assignment. Finally, we conduct experiments on toy MDPs and show that the attention mask leads to accurate Q-value estimation and induces soft abstractions over a factored state space. Our findings challenge the need for complex auxiliary objectives to learn state abstractions in deep RL and suggest a simple baseline for future research.",
    "key_points": [
      "deep reinforcement learning",
      "state abstraction",
      "representation learning"
    ],
    "gold_summary": "The authors show that architectural choices and RL objective alone are sufficient to learn abstract state representations. Specifically, they mask the inputs to the policy and value networks."
  },
  {
    "paper_id": "MExRopJDwZ",
    "title": "Cross-Domain Offline Policy Adaptation via Selective Transition Correction",
    "domain": "reinforcement learning",
    "content": "It remains a critical challenge to adapt policies across domains with mismatched dynamics in reinforcement learning (RL). In this paper, we study cross-domain offline RL, where an offline dataset from another similar source domain can be accessed to enhance policy learning upon a target domain dataset. Directly merging the two datasets may lead to suboptimal performance due to potential dynamics mismatches. Existing approaches typically mitigate this issue through source domain transition filtering or reward modification, which, however, may lead to insufficient exploitation of the valuable source domain data. Instead, we propose to modify the source domain data into the target domain data. To that end, we leverage an inverse dynamics model and a reward model to correct the actions and rewards of source transitions, explicitly achieving alignment with the target dynamics. Since limited data may result in inaccurate model training, we further employ a forward dynamics model to retain corrected samples that better match the target dynamics than the original transitions. Consequently, we propose the Selective Transition Correction (STC) algorithm which enables reliable usage of source domain data for policy adaptation. Experiments on various environments with dynamics shifts demonstrate that STC achieves superior performance against existing baselines.",
    "key_points": [
      "reinforcement learning",
      "cross-domain",
      "off-dynamics"
    ],
    "gold_summary": "STC is a novel method for cross-domain offline RL, which modifies the source domain data into the target domain data."
  },
  {
    "paper_id": "ktXW9g2i8r",
    "title": "Directional Ensemble Aggregation for Actor-Critics",
    "domain": "reinforcement learning",
    "content": "Reliable $Q$-value estimation is central to off-policy reinforcement learning in continuous control. Standard actor-critic methods often address overestimation bias by aggregating ensembles of $Q$-values conservatively, for example by taking their minimum. While effective at reducing bias, these static rules discard useful information, cannot adapt to training dynamics, and generalize poorly across learning regimes. We propose Directional Ensemble Aggregation (DEA), a fully learnable aggregation method that replaces static aggregation with a dynamic mechanism capable of interpolating between conservative and explorative strategies as training progresses. DEA introduces two learnable directional parameters, one regulating critic conservatism and the other guiding actor exploration. Both are learned using disagreement-weighted Bellman errors, where updates depend only on the sign of each sample’s error. This decoupled design allows DEA to adjust automatically to task-specific uncertainty, ensemble size, and update frequency in a data-driven manner. Empirically, DEA generalizes across MuJoCo and DeepMind Control Suite benchmarks in both interactive and sample-efficient learning regimes.",
    "key_points": [
      "reinforcement learning",
      "off-policy",
      "actor-critic",
      "adaptive ensemble learning"
    ],
    "gold_summary": "This paper proposes Directional Ensemble Aggregation (DEA), a fully learnable aggregation method that replaces static aggregation with a dynamic mechanism, allowing interpolation between conservative and explorative strategies as training progresses."
  },
  {
    "paper_id": "Yu1ZsRlqeK",
    "title": "MARFT: Multi-Agent Reinforcement Fine-Tuning",
    "domain": "reinforcement learning",
    "content": "The rapid rise of LLM-based agents has led to the emergence of LLM-based Multi-Agent Systems (LaMAS), which show strong potential in complex, collaborative tasks such as presentation generation and even scientific research. While Reinforcement Learning is well-established in enhancing LLM-based agent performance, its success has largely focused on single-agent settings. In contrast, applying Multi-Agent Reinforcement Learning to LaMAS remains limited. This is due to fundamental mismatches between traditional MARL assumptions and the unique dynamics of LaMAS, including action asynchronicity, dynamic organization, characteristic profiles, etc., which present significant new challenges. To address these challenges, we first formalize LaMAS optimization as a Flex-MG, capturing agent heterogeneity and interdependence, and then propose a novel paradigm termed Multi-Agent Reinforcement Fine-Tuning (MARFT), introducing a new optimization framework for LaMAS. Two naive instantiations of MARFT are implemented on the action-level and token-level, and experiments on math problem-solving and coding environments and benchmarks demonstrate MARFT’s effectiveness in improving accuracy and efficiency, establishing it as a principled and generalizable approach for tuning LaMAS. As this work establishes a new paradigm, we conclude by highlighting the limitations of current research and pinpointing promising directions for future work.",
    "key_points": [
      "multi-agent systems",
      "large language models",
      "reinforcement fine-tuning",
      "multi-agent reinforcement learning"
    ],
    "gold_summary": "The paper proposes Multi-Agent Reinforcement Fine Tuning (MARFT), which is a framework for optimizing LLM-based multi-agent systems. The authors develop two algorithms: MARFT-A (action-level) and MARFT-T (token-level). The method is theoretically supported and empirically validated."
  },
  {
    "paper_id": "HUsmdUgBoY",
    "title": "Probability-based Reward Value Combination Method for Multi-Objective Alignment",
    "domain": "reinforcement learning",
    "content": "Reinforcement Learning from Human Feedback (RLHF) is a fundamental approach for aligning large language models (LLMs) with human values. While alignment with a single preference has become relatively mature, current Multi-Objective RLHF (MORLHF) pipelines still face several challenges, such as interference among preference signals, scale inconsistencies, and high sensitivity to hyperparameters. These limitations hinder the scalability and stability of MORLHF. Taking the Bradley-Terry (BT) model as the mathematical foundation for reward modeling, we analyze how existing linear reward combination methods distort its preference probability structure and identify the root causes of signal interference across different preferences. To address these challenges, we propose an improved reward computation method that utilizes BT preference probabilities and comparison samples to construct a unified reward signal for multi-objective alignment. Our approach preserves the BT probabilistic structure, harmonizes the scale across diverse preferences, reduces signal interference, and enables more effective use of additional generated samples—leading to superior performance gains as the number of samples increases. Moreover, our method generalizes to various RLHF algorithms, including PPO and GRPO. Experimental results on safety alignment tasks show that our approach facilitates the training of LLMs aligned with diverse human preferences, achieving a stronger Pareto frontier than existing methods and yielding greater improvements as sample generation scales.",
    "key_points": [
      "value alignment",
      "rlhf"
    ],
    "gold_summary": "The authors provide a novel method of combining multiple rewards to ensure the combination remains a BT model"
  },
  {
    "paper_id": "2bbqHOWFTU",
    "title": "Robust Adaptive Multi-Step Predictive Shielding",
    "domain": "reinforcement learning",
    "content": "Reinforcement learning for safety-critical tasks requires policies that are both high-performing and safe throughout the learning process. While model-predictive shielding is a promising approach, existing methods are often computationally intractable for the high-dimensional, nonlinear systems where deep RL excels, as they typically rely on a patchwork of local models. We introduce **RAMPS**, a scalable shielding framework that overcomes this limitation by leveraging a learned, linear representation of the environment's dynamics. This model can range from a linear regression in the original state space to a more complex operator learned in a high-dimensional feature space. The key is that this linear structure enables a robust, look-ahead safety technique based on a *multi-step Control Barrier Function (CBF)*. By moving beyond myopic one-step formulations, **RAMPS** accounts for model error and control delays to provide reliable, real-time interventions. The resulting framework is minimally invasive, computationally efficient, and built upon robust control-theoretic foundations. Our experiments demonstrate that **RAMPS** significantly reduces safety violations compared to existing safe RL methods while maintaining high task performance in complex control environments.",
    "key_points": [
      "safe reinforcement learning",
      "control barrier functions",
      "model predictive shielding"
    ],
    "gold_summary": "This paper proposes a scalable model-predictive shielding framework that enables safe policy learning for complex, high-dimensional systems."
  },
  {
    "paper_id": "hxrTmEuMrP",
    "title": "Pruning Cannot Hurt Robustness: Certified Trade-offs in Reinforcement Learning",
    "domain": "reinforcement learning",
    "content": "Reinforcement learning (RL) policies deployed in real-world environments must remain reliable under adversarial perturbations. At the same time, modern deep RL agents are heavily overparameterized, raising costs and fragility concerns. While pruning has been shown to improve robustness in supervised learning, its role in adversarial RL remains poorly understood. We develop the first theoretical framework for \\emph{certified robustness under pruning} in state-adversarial Markov decision processes (SA-MDPs). For Gaussian and categorical policies with Lipschitz networks, we prove that elementwise pruning can only tighten certified robustness bounds; pruning never makes the policy less robust. Building on this, we derive a novel three-term regret decomposition that disentangles clean-task performance, pruning-induced performance loss, and robustness gains, exposing a fundamental performance--robustness frontier. Empirically, we evaluate magnitude and micro-pruning schedules on continuous-control benchmarks with strong policy-aware adversaries. Across tasks, pruning consistently uncovers reproducible ``sweet spots'' at moderate sparsity levels, where robustness improves substantially without harming---and sometimes even enhancing---clean performance. These results position pruning not merely as a compression tool but as a structural intervention for robust RL.",
    "key_points": [
      "reinforcement learning",
      "adversarial robustness",
      "state-adversarial mdps",
      "neural network pruning",
      "robust policy optimization",
      "lipschitz bounds",
      "certified robustness",
      "robustness–performance trade-off",
      "long-horizon stability",
      "magnitude pruning",
      "micro-pruning",
      "policy compression",
      "robust control",
      "robust deep rl"
    ],
    "gold_summary": "This paper focuses on adversarial reinforcement learning and pruning. This paper provides experiments in the MuJoCo environment solely on two tasks, Hopper and Half-Cheetah, and shows that pruning does not make the policy less robust."
  },
  {
    "paper_id": "4vmm8mlHkS",
    "title": "Relative Entropy Pathwise Policy Optimization",
    "domain": "reinforcement learning",
    "content": "Score-function based methods for policy learning, such as REINFORCE and PPO, have delivered strong results in game-playing and robotics, yet their high variance often undermines training stability. Using pathwise policy gradients, i.e. computing a derivative by differentiating the objective function, alleviates the variance issues. However, they require an accurate action-conditioned value function, which is notoriously hard to learn without relying on replay buffers for reusing past off-policy data. We present an on-policy algorithm that trains Q-value models purely from on-policy trajectories, unlocking the possibility of using pathwise policy updates in the context of on-policy learning. We show how to combine stochastic policies for exploration with constrained updates for stable training, and evaluate important architectural components that stabilize value function learning. The result, Relative Entropy Pathwise Policy Optimization (REPPO), is an efficient on-policy algorithm that combines the stability of pathwise policy gradients with the simplicity and minimal memory footprint of standard on-policy learning. Compared to state-of-the-art on two standard GPU-parallelized benchmarks, REPPO provides strong empirical performance at superior sample efficiency, wall-clock time, memory footprint, and hyperparameter robustness.",
    "key_points": [
      "reinforcement learning",
      "parallel simulation",
      "value function",
      "ppo",
      "policy gradients",
      "policy optimization"
    ],
    "gold_summary": "This paper proposes the REPPO algorithm that optimizes the policy by directly differentiating the Q function in a completely on-policy setting."
  },
  {
    "paper_id": "hm8b9CQQQY",
    "title": "On Computation and Generalization of Group Relative Policy Optimization",
    "domain": "reinforcement learning",
    "content": "Group Relative Policy Optimization (GRPO)~\\citep{shao2024deepseekmath,guo2025deepseek} has rapidly become a critic-free default for aligning LLMs, yet its statistical and computational foundations remain unclear. We close this gap by providing the first unified theory of GRPO that simultaneously addresses generalization and optimization in the original, practitioner-used formulation and over multiple outer iterations. On the generalization side, we derive sequential (multi-iteration) PAC-Bayes–Bernstein bounds under Markov mixing that concentrate the \\emph{empirical GRPO surrogate} around its population counterpart across all iterations; a Transformer path-norm corollary yields substantially tighter capacity terms than spectral norms. We further prove a TRPO-style return bridge showing that ascent in the population GRPO surrogate provably improves true return, with explicit, controllable bias from clipping and KL regularization. On the optimization side, we establish non-PL \\emph{stationarity} guarantees for SGDM and AdamW (both $\\tilde O(1/\\sqrt{K})$) and provide complementary PL-based rates, with variance controlled by $t_{\\mathrm{mix}}/(G\\sqrt{K})$. Together with interactive information-theoretic lower bounds, our results deliver the first end-to-end, multi-iteration statistical and computational guarantees for GRPO with function approximation. Experiments corroborate the predicted trends and offer practical guidance on group size, clipping, and KL weight; code will be released.",
    "key_points": [
      "llm",
      "reinforcement learning"
    ],
    "gold_summary": "The paper’s “unified” theory leans on unobservable or unjustified quantities—mixing time, transformer path norms, data-dependent PAC-Bayes posteriors, and PL/AdamW assumptions—so the guarantees are elegant."
  },
  {
    "paper_id": "s9Ej5SQs5z",
    "title": "Learning What to Remember for Non-Markovian Reinforcement Learning",
    "domain": "reinforcement learning",
    "content": "Recent success in developing increasingly general purpose agents based on sequence models has led to increased focus on the problem of deploying computationally limited agents within the vastly more complex real-world. A key challenge experienced in these more realistic domains is highly non-Markovian dependencies with respect to the agent's observations, which are less common in small controlled domains. The predominant approach for dealing with this in the literature is to stack together a window of the most recent observations (Frame Stacking), but this window size must grow with the degree of non-Markovian dependencies, which results in prohibitive computational and memory requirements for both action inference and learning. In this paper, we are motivated by the insight that in many environments that are highly non-Markovian with respect to time, the environment only causally depends on a relatively small number of observations over that time-scale. A natural direction would then be to consider meta-algorithms that maintain relatively small adaptive stacks of memories such that it is possible to express highly non-Markovian dependencies with respect to time while considering fewer observations at each step and thus experience substantial savings in both compute and memory requirements. Hence, we propose a meta-algorithm (Adaptive Stacking) for achieving exactly that with convergence guarantees and quantify the reduced computation and memory constraints for MLP, LSTM, and Transformer-based agents. Our experiments utilize the classic T-Maze domain, which gives us direct control over the degree of non-Markovian dependencies in the environment. This allows us to demonstrate that an appropriate meta-algorithm can learn the removal of memories not predictive of future rewards and achieve convergence in the stack management policy without excessive removal of important experiences.",
    "key_points": [
      "reinforcement learning",
      "non-markovian",
      "partial observation",
      "state abstraction",
      "bounded agents",
      "memory"
    ],
    "gold_summary": "A new framework, Adaptive Stacking, is proposed, allowing selective retention of observations in a fixed-size working memory."
  },
  {
    "paper_id": "GV87Kv70EN",
    "title": "Combinatorial Dueling Bandits",
    "domain": "reinforcement learning",
    "content": "We introduce the \\emph{Contextual Combinatorial Dueling Bandits (CDB)} problem, a novel framework for modeling complex online decision-making under relative and binary feedback. In each round, the learner observes contextual information for a set of arms and selects two subsets of $k$ arms, termed \\emph{super arms}. The feedback consists of pairwise binary preferences between the arms in the two chosen super arms. For example, in recommendation systems, a user might be shown two competing sets of items and provide preference feedback for each pair of items. We propose two algorithms to address this problem: \\emph{LinCDB} for linear score functions and \\emph{NCDB} for nonlinear cases. Both algorithms leverage the Hungarian algorithm for efficient selection of the second super arm. We theoretically demonstrate that LinCDB achieves a regret bound of $\\widetilde{O}\\left( \\frac{d}{\\kappa_\\mu} \\sqrt{Tk} \\right)$, while NCDB achieves $\\widetilde{O}\\left( \\left(\\frac{1}{\\kappa_\\mu} \\sqrt{\\widetilde{d}} + B \\sqrt{\\frac{\\lambda}{\\kappa_\\nu}} \\right) \\sqrt{Tk\\widetilde{d} } \\right)$. Here, $d$ represents the dimension of the context for each arm, $k$ is the size of the super arm, and $\\widetilde{d}$ denotes the effective dimension. To our knowledge, this is the first work to study combinatorial bandits with preference feedback.",
    "key_points": [
      "combinatorial bandits",
      "dueling bandits"
    ],
    "gold_summary": "The paper introduces the combinatorial dueling bandit, studying the preference feedback. It proposes algorithms in both linear and neural settings and provides theoretical guarantees."
  },
  {
    "paper_id": "FVLiw2g0n3",
    "title": "Sample Efficient Offline RL via T-Symmetry Enforced Latent State-Stitching",
    "domain": "reinforcement learning",
    "content": "Offline reinforcement learning (RL) has achieved notable progress in recent years. However, most existing offline RL methods require a large amount of training data to achieve reasonable performance and offer limited out-of-distribution (OOD) generalization capability due to conservative data-related regularizations. This seriously hinders the usability of offline RL in solving many real-world applications, where the available data are often limited. In this study, we introduce TELS, a highly sample-efficient offline RL algorithm that enables state-stitching in a compact latent space regulated by the fundamental time-reversal symmetry (T-symmetry) of dynamical systems. Specifically, we introduce a T-symmetry enforced inverse dynamics model (TS-IDM) to derive well-regulated latent state representations that greatly facilitate OOD generalization. A guide-policy can then be learned entirely in the latent space to optimize for the reward-maximizing next state, bypassing the conservative action-level behavioral regularization adopted in most offline RL methods. Finally, the optimized action can be extracted using the learned TS-IDM, together with the optimized latent next state from the guide-policy. We conducted comprehensive experiments on both the D4RL benchmark tasks and a real-world industrial control test environment, TELS achieves superior sample efficiency and OOD generalization performance, significantly outperforming existing offline RL methods in a wide range of challenging small-sample tasks.",
    "key_points": [
      "sample efficiency",
      "representation learning",
      "fundamental symmetry for dynamic modeling"
    ],
    "gold_summary": "This paper introduces a T-symmetry enforced inverse dynamics model (TS-IDM) that can learn well-behaved and OOD generalizable latent representations, and facilitate action inference. The proposed method outperforme existing offline RL algorithms on small datasets."
  },
  {
    "paper_id": "hFqq79xwGV",
    "title": "Finite‑Time Bounds for Distributionally Robust TD Learning with Linear Function Approximation",
    "domain": "reinforcement learning",
    "content": "Distributionally robust reinforcement learning (DRRL) focuses on designing policies that achieve good performance under model uncertainties. In particular, we are interested in maximizing the worst-case long-term discounted reward, where the data for RL comes from a nominal model while the deployed environment can deviate from the nominal model within a prescribed uncertainty set. Existing convergence guarantees for robust temporal‑difference (TD) learning for policy evaluation are limited to tabular MDPs or are dependent on restrictive discount‑factor assumptions when function approximation is used. We present the first robust TD learning with linear function approximation, where robustness is measured with respect to the total‑variation distance uncertainty set. Additionally, our algorithm is both model-free and does not require generative access to the MDP. Our algorithm combines a two‑time‑scale stochastic‑approximation update with an outer‑loop target‑network update. We establish an $\\tilde{O}(1/\\epsilon^{2})$ sample complexity to obtain an $\\epsilon$-accurate value estimate. Our results close a key gap between the empirical success of robust RL algorithms and the non-asymptotic guarantees enjoyed by their non-robust counterparts. The key ideas in the paper also extend in a relatively straightforward fashion to robust Q-learning with function approximation.",
    "key_points": [
      "reinforcement learning theory",
      "distributionally robust reinforcement learning",
      "finite-time convergence guarantee",
      "two-time-scale stochastic approximation",
      "function approximation"
    ],
    "gold_summary": "The paper provides finite-time convergence guarantees for distributionally robust TD learning with linear function approximation. It analyzes a model-free, two time scale scheme. The paper derives a non-asymptotic error bound showing $O(1/\\epsilon^2)$ sample complexity."
  },
  {
    "paper_id": "mJ5jxzRqVF",
    "title": "Reward Inflation Paradigm Through the Lens of Monetary Economics",
    "domain": "reinforcement learning",
    "content": "Reward is fundamental to reinforcement learning (RL), where the agent treats it as an incentive to maximize.\nThis appearance is akin to a rational human who maximizes their income.\nHowever, in the real economy, money expands to stimulate economic growth.\nInspired by this principle of monetary economics, we introduce a novel RL paradigm, reward inflation, which gradually increases the reward scale during training.\nAnalogous to inflationary policies used by central banks to stimulate economic growth, reward inflation acts as an incentive stimulus for agents to accelerate policy learning.\nReward inflation can be applied in two ways: fixed or adaptive.\nMotivated by the Fed's monetary policy, we propose FedeRL, a dynamic controller for adaptive inflation.\nTheoretical analysis suggests that the effect of reward inflation is threefold: (1) induces recency bias in temporal-difference learning, (2) amplifies policy gradients, and (3) enhances neural activation.\nEmpirical results corroborate these insights, showing that moderate inflation improves performance on continuous control tasks.\nMoreover, FedeRL performed even better than fixed inflation and outperformed comparable baselines.\nBy translating economic growth principles into RL, our approach offers a novel perspective that strengthens policy optimization and addresses fundamental RL objectives.\nThe implementation code will be made publicly available.",
    "key_points": [
      "reinforcement learning",
      "reward inflation",
      "money supply",
      "monetary economics",
      "economic growth",
      "monetary policy"
    ],
    "gold_summary": "This paper introduce a reward inflation method that increase the reward scale during training.  Theoretical analysis suggests three main effects: (1) recency bias, (2) gradient norm amplification, and (3) enhanced neural activation."
  },
  {
    "paper_id": "fEhJNjUeNG",
    "title": "Wasserstein Policy Gradient: Implicit Policies, Entropy Regularization and Linear Convergence",
    "domain": "reinforcement learning",
    "content": "We revisit Wasserstein Proximal Policy Gradient (WPPG) for continuous control in infinite-horizon discounted reinforcement learning. By projecting the iterate of Wasserstein proximal gradient onto a parametric policy family with respect to the Wasserstein distance, we derive a new WPPG update that eliminates the need for policy densities or score functions. This makes our method directly applicable to implicit stochastic policies. We prove a linear convergence rate for the WPPG iterate under entropy regularization and a log-Sobolev condition on the policy class, for both exact and approximate value function estimates. Empirically, our algorithm is simple to implement and achieves competitive performance on standard benchmarks.",
    "key_points": [
      "reinforcement learning",
      "continuous control",
      "global convergence"
    ],
    "gold_summary": "The paper proposes a projected wasserstein proximal policy gradient method and analyzed its global convergence behavior under various assumptions on the policy class. Numerical experiments accompanied the theoretical framework proposed."
  },
  {
    "paper_id": "eM8Db7ukSB",
    "title": "LLM-Driven Policy Diffusion: Enhancing Generalization in Offline Reinforcement Learning",
    "domain": "reinforcement learning",
    "content": "Reinforcement Learning (RL) is known for its strong decision-making capabilities and has been widely applied in various real-world scenarios. However, with the increasing availability of offline datasets and the lack of well-designed online environments from human experts, the challenge of generalization in offline RL has become more prominent. Due to the limitations of offline data, RL agents trained solely on collected experiences often struggle to generalize to new tasks or environments. To address this challenge, we propose LLM-Driven Policy Diffusion (LLMDPD), a novel approach that enhances generalization in offline RL using task-specific prompts. Our method incorporates both text-based task descriptions and trajectory prompts to guide policy learning. We leverage a large language model (LLM) to process text-based prompts, utilizing its natural language understanding and extensive knowledge base to provide rich task-relevant context. Simultaneously, we encode trajectory prompts using a transformer model, capturing structured behavioral patterns within the underlying transition dynamics. These prompts serve as conditional inputs to a context-aware policy-level diffusion model, enabling the RL agent to generalize effectively to unseen tasks. Our experimental results demonstrate that LLMDPD outperforms state-of-the-art offline RL methods on unseen tasks, highlighting its effectiveness in improving generalization and adaptability in diverse settings.",
    "key_points": [
      "reinforcement learning",
      "offline reinforcement learning",
      "generalization in reinforcement learning"
    ],
    "gold_summary": "This paper proposes LLM-Driven Policy Diffusion, a unified framework that integrates large language models with diffusion-based policy learning to achieve generalist decision-making across diverse multimodal tasks."
  },
  {
    "paper_id": "Bj4BOmgesO",
    "title": "Mutual Information Dynamics Learning: A New Paradigm for Unsupervised Reinforcement Learning",
    "domain": "reinforcement learning",
    "content": "Unsupervised reinforcement learning (URL) aims to develop general-purpose agents that can adapt to unseen downstream tasks without relying on task-specific supervision. Existing approaches predominantly focus on learning diverse skills by maximizing mutual information, but they are often limited to simple navigation tasks and fail to scale to more complex domains such as robotic manipulation, where prior knowledge is typically required. In this work, we demonstrate that mutual information-based objectives can be leveraged far beyond skill learning. We propose a novel URL framework that trains exploratory skills to collect diverse transition data with distinct dynamics. This diverse dataset enables the training of a mixture of dynamic models, where each model captures the dynamics of a specific region. Collectively, these models provide comprehensive coverage of the dynamics required for a wide range of downstream tasks. Our straightforward and prior-free learning objective outperforms existing state-of-the-art skill discovery approaches in URL. Our results advocate a paradigm shift in URL, from skill learning toward dynamics learning, to acquire fully generalizable knowledge during pretraining.",
    "key_points": [
      "unsupervised",
      "reinforcement learning",
      "mutual information skill learning"
    ],
    "gold_summary": "This paper proposes a new paradigm, MIDL, which shifts from unsupervised skill learning to unsupervised dynamic learning, addressing the limitations of MISL approaches in capturing complex behaviors."
  },
  {
    "paper_id": "zFkopTvclB",
    "title": "AutoTool: Automatic Scaling of Tool-Use Capabilities in RL via Decoupled Entropy Constraints",
    "domain": "reinforcement learning",
    "content": "Tool use represents a critical capability for AI agents, with recent advances focusing on leveraging reinforcement learning (RL) for test-time scaling to achieve better performance through more deliberate reasoning. \nHowever, there are some key challenges in current RL-based scaling approaches: \n(a) direct RL training often struggles to scale up thinking length sufficiently to solve complex problems, \nand (b) scaled-up models tend to overthink simpler problems, resulting in substantial token inefficiency.\nTo address these challenges, we propose a novel training paradigm that first employs warm-up supervised fine-tuning to help models distinguish between simple and complex problems, followed by end-to-end RL that enable models to automatically determine appropriate reasoning trajectories. \nFurthermore, to tackle the issue of automatic thinking-length scaling, we discover that entropy-based optimization objectives effectively maintain model diversity while successfully unlocking the model's scaling capabilities.\nBased on this insight, we introduce an entropy-based long-short reasoning fusion RL strategy. \nOur experiments on three benchmarks demonstrate that model successfully achieves auto-scaling for efficient tool use, achieving significant 9.8\\% accuracy improvements while reducing computational overhead by ~81\\%.",
    "key_points": [
      "llm",
      "rl",
      "tool use",
      "auto think"
    ],
    "gold_summary": "This paper aims to improve Tool-use LLMs' performance through the control of thinking length. It proposes applying distinct entropy constraints to long and short trajectories during RL."
  },
  {
    "paper_id": "a19MA0ksbc",
    "title": "DR-SAC: Distributionally Robust Soft Actor-Critic for Reinforcement Learning under Uncertainty",
    "domain": "reinforcement learning",
    "content": "Deep reinforcement learning (RL) has achieved remarkable success, yet its deployment in real-world scenarios is often limited by vulnerability to environmental uncertainties. Distributionally robust RL (DR-RL) algorithms have been proposed to resolve this challenge, but existing approaches are largely restricted to value-based methods in tabular settings. In this work, we introduce Distributionally Robust Soft Actor-Critic (DR-SAC), the first actor–critic based DR-RL algorithm for offline learning in continuous action spaces. DR-SAC maximizes the entropy-regularized rewards against the worst possible transition models within an KL-divergence constrained uncertainty set. We derive the distributionally robust version of the soft policy iteration with a convergence guarantee and incorporate a generative modeling approach to estimate the unknown nominal transition models. Experiment results on five continuous RL tasks demonstrate our algorithm achieves up to $9.8\\times$ higher average reward than the SAC baseline under common perturbations. Additionally, DR-SAC significantly improves computing efficiency and applicability to large-scale problems compared with existing DR-RL algorithms.",
    "key_points": [
      "distributionally robust optimization",
      "robust reinforcement learning"
    ],
    "gold_summary": "The paper introduce a new  Distributionally Robust SAC algorithm. Theoretical analysis and numerical examples are given to show the advantages of the proposed methods."
  },
  {
    "paper_id": "dfoN64vP4Q",
    "title": "Lipschitz Bandits with Stochastic Delayed Feedback",
    "domain": "reinforcement learning",
    "content": "The Lipschitz bandit problem extends stochastic bandits to a continuous action set defined over a metric space, where the expected reward function satisfies a Lipschitz condition. In this work, we introduce a new problem of Lipschitz bandit in the presence of stochastic delayed feedback, where the rewards are not observed immediately but after a random delay. We consider both bounded and unbounded stochastic delays, and design algorithms that attain sublinear regret guarantees in each setting. For bounded delays, we propose a delay-aware zooming algorithm that retains the optimal performance of the delay-free setting up to an additional term that scales with the maximum delay $\\tau_{\\max}$. For unbounded delays, we propose a novel phased learning strategy that accumulates reliable feedback over carefully scheduled intervals, and establish a regret lower bound showing that our method is nearly optimal up to logarithmic factors.\nFinally, we present experimental results to demonstrate the efficiency of our algorithms under various delay scenarios.",
    "key_points": [
      "bandit",
      "lipschitz bandit"
    ],
    "gold_summary": "The paper studies the standard Lipschitz bandit with stochastic delayed feedback. The paper gives theoretical results in bounded delay and unbounded delay scenarios. The paper conducts experiments to show the effectiveness of the proposed algorithms."
  },
  {
    "paper_id": "27AArQArBG",
    "title": "MRVF: Multi-Round Value Factorization with Guaranteed Iterative Improvement for Multi-Agent Reinforcement Learning",
    "domain": "reinforcement learning",
    "content": "Value factorization restricts the joint action value in a monotonic form to enable efficient search for its optimum. However, the representational limitation of monotonic forms often leads to suboptimal results in cases with highly non-monotonic payoff. Although recent approaches introduce additional conditions on factorization to address the representational limitation, we propose a novel theory for convergence analysis to reveal that single-round factorizations with elaborated conditions are still insufficient for global optimality. To address this issue, we propose a novel Multi-Round Value Factorization (MRVF) framework that refines solutions round by round and finally obtains the global optimum. To achieve this, we measure the non-negative incremental payoff of a solution relative to the preceding solution. This measurement enhances the monotonicity of the payoff and highlights solutions with higher payoff, enabling monotonic factorizations to identify them. We evaluate our method in three challenging environments: non-monotonic one-step games, predator-prey tasks, and StarCraft II Multi-Agent Challenge (SMAC). Experiment results demonstrate that our MRVF outperforms existing value factorization methods, particularly in scenarios highly non-monotonic payoff.",
    "key_points": [
      "multi-agent reinforcement learning",
      "value factorization"
    ],
    "gold_summary": "The paper proposes MRVF, a framework for cooperative MARL that iteratively monotonizes a non-monotonic joint payoff landscape by training with non-negative payoff increments relative to the previous round’s greedy action."
  },
  {
    "paper_id": "tOxPaWiA18",
    "title": "The Effect of Temporal Resolution in Offline Temporal Difference Estimation",
    "domain": "reinforcement learning",
    "content": "Temporal Difference (TD) algorithms are the most widely employed methods in Reinforcement Learning. Notably, previous theoretical analysis on these algorithms consider the sampling time as fixed a priori, while it has been shown that the temporal resolution can impact data efficiency (Burns et al., 2023). In this work, we provide an analysis of the performance of mean-path semi-gradient TD(0) for offline value estimation, emphasizing the dependence on the temporal resolution, a factor that indeed proves to be of crucial importance. In particular, by considering the continuous-time stochastic linear quadratic dynamical systems with a fixed data-budget, the behaviour of the Mean Squared Error on value estimation shows an optimal non-trivial value for the time discretization, and that the latter impacts the reliability of the algorithm. We also show that this behavior differs from that of the Monte Carlo algorithm (Zhang et al., 2023). We verify the theoretical characterization in numerical experiments in linear quadratic system instances.",
    "key_points": [
      "reinforcement learning",
      "temporal difference",
      "temporal discretization",
      "continuous time",
      "value estimation",
      "lqr"
    ],
    "gold_summary": "The paper analyzes how temporal discretization affects TD(0) value estimation for continuous-time linear quadratic systems. Main claim is there's an optimal discretization step h*. Specific special cases are analyzed."
  },
  {
    "paper_id": "Uhn4iTnaUJ",
    "title": "Actor-Critic without Actor",
    "domain": "reinforcement learning",
    "content": "Actor-critic methods constitute a central paradigm in reinforcement learning (RL), coupling policy evaluation with policy improvement. While effective across many domains, these methods rely on separate actor and critic networks, which makes training vulnerable to architectural decisions and hyperparameter tuning. Such complexity limits their scalability in settings that require large function approximators. Recently, diffusion models have recently been proposed as expressive policies that capture multi-modal behaviors and improve exploration, but they introduce additional design choices and computational burdens, hindering efficient deployment. We introduce Actor-Critic without Actor (ACA), a lightweight framework that eliminates the explicit actor network and instead generates actions directly from the gradient field of a noise-level critic. This design removes the algorithmic and computational overhead of actor training while keeping policy improvement tightly aligned with the critic’s latest value estimates. Moreover, ACA retains the ability to capture diverse, multi-modal behaviors without relying on diffusion-based actors, combining simplicity with expressiveness. Through extensive experiments on standard online RL benchmarks, ACA achieves more favorable learning curves and competitive performance compared to both standard actor-critic and state-of-the-art diffusion-based methods, providing a simple yet powerful solution for online RL.",
    "key_points": [
      "online reinforcement learning",
      "diffusion models"
    ],
    "gold_summary": "This paper presents an Actor-Critic without Actor, a lightweight framework that removes the explicit actor network and directly generates actions from the gradient field of a noise-level critic."
  },
  {
    "paper_id": "RUzxUqTpzW",
    "title": "Does “Do Differentiable Simulators Give Better Policy Gradients?” Give Better Policy Gradients?",
    "domain": "reinforcement learning",
    "content": "In policy gradient reinforcement learning, access to a differentiable model enables 1st-order gradient estimation that accelerates learning compared to relying solely on derivative-free 0th-order estimators. However, discontinuous dynamics cause bias and undermine the effectiveness of 1st-order estimators. Prior work addressed this bias by constructing a confidence interval around the REINFORCE 0th-order gradient estimator and using these bounds to detect discontinuities. However, the REINFORCE estimator is notoriously noisy, and we find that this method requires task-specific hyperparameter tuning and has low sample efficiency. This paper asks whether such bias is the primary obstacle and what minimal fixes suffice. First, we re-examine standard discontinuous settings from prior work and introduce DDCG, a lightweight test that switches estimators in nonsmooth regions; with a single hyperparameter, DDCG achieves robust performance and remains reliable with small samples. Second, on differentiable robotics control tasks, we present IVW-H, a per-step inverse-variance implementation that stabilizes variance without explicit discontinuity detection and yields strong results. Together, these findings indicate that while estimator switching improves robustness in controlled studies, careful variance control often dominates in practical deployments.",
    "key_points": [
      "differentiable simulation",
      "reinforcement learning",
      "policy gradient",
      "model-based reinforcement learning",
      "monte carlo gradient estimation",
      "reparameterization gradient",
      "likelihood ratio gradient",
      "score function gradient estimator",
      "inverse variance weighting",
      "randomized smoothing"
    ],
    "gold_summary": "The paper re-examines when analytic policy gradients from differentiable simulators truly help, proposing a lightweight statistical check to safely integrate analytic gradient with model-free gradient estimates via inverse-variance mixing"
  },
  {
    "paper_id": "TntCH2maP7",
    "title": "Model-Based Reinforcement Learning under Random Observation Delays",
    "domain": "reinforcement learning",
    "content": "Delays frequently occur in real-world environments, yet standard reinforcement learning (RL) algorithms often assume immediate feedback from the environment. We study random feedback delays in POMDPs, where observations may arrive out-of-sequence, a setting that has not been previously addressed in RL. We analyze the structure of such delays and demonstrate that naive approaches, such as stacking past observations, are insufficient for reliable performance. To address this, we propose a filtering process within a model-based RL context that recursively updates the belief state based on incoming observations. We then introduce a simple delay-aware framework that incorporates this idea into RL, enabling agents to effectively handle random delays. Applying this framework to Dreamer, we compare our approach with delay-aware baselines developed for MDPs. Our method consistently outperforms these baselines and demonstrates robustness to unseen delays during deployment. Additionally, we present experiments on more realistic robotic tasks, evaluating our method against common practical heuristics and emphasizing the importance of explicitly modeling observation delays.",
    "key_points": [
      "reinforcement learning",
      "model based",
      "delays",
      "pomdps"
    ],
    "gold_summary": "In this paper, authors propose a novel model-based delayed RL framework targeting the POMDP setting. Specifically, author leverage Dreamer RSSM framework to sequentially update the belief state and handle random delays."
  },
  {
    "paper_id": "vvyVDF4Xf4",
    "title": "Provably Efficient Policy-Reward Co-Pretraining for Adversarial Imitation Learning",
    "domain": "reinforcement learning",
    "content": "Adversarial imitation learning (AIL) achieves superior expert sample efficiency compared to behavioral cloning (BC) but requires extensive online environment interactions. Recent empirical works have attempted to mitigate this limitation by augmenting AIL with BC---for instance, initializing AIL algorithms with BC-pretrained policies. Despite certain empirical successes, systematic theoretical analysis of the provable efficiency gains remains lacking. This paper provides rigorous theoretical guarantees and develops effective algorithms to accelerate AIL. First, we develop a theoretical analysis for AIL with policy pretraining alone, revealing a critical but theoretically unexplored limitation: the absence of reward pretraining. Building on this insight, we derive a principled reward pretraining method grounded in reward-shaping-based analysis. Crucially, our analysis reveals a fundamental connection between the expert policy and shaping reward, naturally giving rise to CoPT-AIL, an approach that jointly pretrains policies and rewards through a single BC procedure. Theoretical results demonstrate that CoPT-AIL achieves an improved imitation gap bound compared to standard AIL without pretraining, providing the first theoretical guarantee for the benefits of pretraining in AIL. Experimental evaluation confirms CoPT-AIL's superior performance over prior AIL methods.",
    "key_points": [
      "imitation learning",
      "adversarial imitation learning",
      "sample efficiency"
    ],
    "gold_summary": "This paper proposes a theoretical analysis on the effects of pre-training both policy and reward function before using AIL."
  },
  {
    "paper_id": "V2MqnCNgZi",
    "title": "Concise Reasoning via Reinforcement Learning",
    "domain": "reinforcement learning",
    "content": "A major drawback of reasoning models is their excessive token usage, inflating computational cost, resource demand, and latency. We show this verbosity stems not from deeper reasoning but from reinforcement learning loss minimization when models produce incorrect answers. With unsolvable problems dominating training, this effect compounds into a systematic tendency toward longer outputs. Through theoretical analysis of PPO and GRPO, we prove that incorrect answers inherently drive policies toward verbosity \\textit{even when} $\\gamma=1$, reframing response lengthening as an optimization artifact. We further uncover a consistent correlation between conciseness and correctness across reasoning and non-reasoning models. Building on these insights, we propose a two-phase RL procedure where a brief secondary stage, trained on a small set of solvable problems, significantly reduces response length while preserving or improving accuracy. Finally, we show that while GRPO shares properties with PPO, it exhibits collapse modes, limiting its reliability for concise reasoning. Our claims are supported by extensive experiments.",
    "key_points": [
      "concise reasoning",
      "reasoning",
      "reinforcement learning",
      "rl",
      "llm",
      "language models",
      "reasoning models"
    ],
    "gold_summary": "This paper tackles the problem of excessive verbosity in LLMs. The authors observe that state-of-the-art reasoning models often produce unnecessarily long chains of thought, incurring high computational cost and latency."
  },
  {
    "paper_id": "pW3xAzdmVs",
    "title": "SLA-v3: Spatial Linkability-Aware and Novelty-Encouraging State Heuristic for Exploration",
    "domain": "reinforcement learning",
    "content": "Efficient exploration continues to be a pivotal challenge in reinforcement learning (RL), particularly in environments characterized by sparse rewards. While intrinsic motivation (IM) has proven effective for tackling hard exploration tasks, current IM approaches often struggle with the detachment-derailment (D-D) problem. This issue significantly curtails their effectiveness, especially in settings with extremely sparse rewards. Although methods like Go-Explore address D-D by explicitly archiving states to ensure revisitation, their dependency on state restoration limits their practical application in procedurally generated environments. In this paper, we argue that the root cause of the D-D problem lies in the underlying topological transition structure of the environment. Specifically, we observe that certain states become persistently difficult to traverse and revisit reliably when subjected to exploratory noise. To overcome this, we introduce a novel IM framework centered on state traversal difficulty. Within this framework, we propose the $\\textbf{S}$patial $\\textbf{L}$inkability-$\\textbf{A}$ware $\\textbf{a}$nd $\\textbf{N}$ovelty-$\\textbf{E}$ncouraging $\\textbf{S}$tate $\\textbf{H}$euristic ($\\textbf{SLAANESH}$), abbreviated as $\\textbf{SLA-v3}$. SLA-v3 tackles the D-D problem by utilizing the shortest-path quasi-metric from the initial state ($S_0$) as a heuristic for traversal difficulty. This mechanism generates sustainable exploratory incentives, particularly encouraging visit to hard-to-traverse states. Furthermore, SLA-v3 integrates a novelty detector, which serves to warm up the heuristic and effectively prevent stagnation in unproductive dead-end paths. Our extensive experimental evaluations on MiniGrid and challenging Atari environments (PitFall! and Montezuma's Revenge) robustly demonstrate the superior efficacy of SLA-v3.",
    "key_points": [
      "rl",
      "exploration",
      "intrinsic motivation",
      "sparse reward"
    ],
    "gold_summary": "The paper shows that an intrinsic reward based on a model of the time distance from the start can be very effective on some really sparse-reward games such as Montezuma's revenge and Pitfall."
  },
  {
    "paper_id": "IwiwmY3Mzz",
    "title": "A Reward-Free Viewpoint on Multi-Objective Reinforcement Learning",
    "domain": "reinforcement learning",
    "content": "Many sequential decision-making tasks involve optimizing multiple conflicting objectives, requiring policies that adapt to different user preferences. Multi-objective reinforcement learning (MORL) typically addresses this by training a single policy conditioned on preference-weighted rewards. In this paper, we explore a novel perspective: leveraging reward-free reinforcement learning (RFRL) for MORL. While RFRL has historically been studied independently of MORL, it learns optimal policies for any possible reward function, making it a natural fit for MORL's challenge of handling unknown user preferences. We propose using RFRL's training objective as an auxiliary task to enhance MORL, enabling more effective knowledge sharing beyond the multi-objective reward function given at training time. To this end, we adapt a state-of-the-art RFRL algorithm to the MORL setting and introduce a preference-guided exploration strategy that focuses learning on relevant part of the environment. Our approach significantly outperforms state-of-the-art MORL methods across diverse MO-Gymnasium tasks, achieving superior performance and data efficiency, especially in settings with limited preference samples. This work is the first to explicitly adapt RFRL for MORL, demonstrating its potential as a scalable and effective solution.",
    "key_points": [
      "multi-objective reinforcement learning",
      "reward-free reinforcement learning"
    ],
    "gold_summary": "This paper proposes a reward-free viewpoint for MORL and an approach, MORL-FB, that integrates reward-free RL methods into MORL. Extensive experiments are conducted to show the effectiveness and generalization of the proposed method."
  },
  {
    "paper_id": "KUlPxDQF3T",
    "title": "Convergence of Actor-Critic gradient flow for entropy regularised MDPs in general spaces",
    "domain": "reinforcement learning",
    "content": "We prove the stability and global convergence of a coupled Actor-Critic gradient flow for infinite-horizon and entropy-regularised Markov decision processes (MDPs) in continuous state and action space with linear function approximation under Q-function realisability.\nWe consider a version of actor critic where the critic is updated using temporal difference (TD) learning while the policy is updated using a policy mirror descent method on a separate timescale. We demonstrate stability and exponential convergence of the actor critic flow to the optimal policy. Finally, we address the interplay of the timescale separation and entropy regularisation and its effect on stability and convergence.",
    "key_points": [
      "reinforcement learning",
      "gradient flow",
      "markov decision process",
      "entropy regularization",
      "non-convex optimization",
      "mirror descent method",
      "fisher–rao gradient flow",
      "global convergence",
      "function approximation",
      "actor critic"
    ],
    "gold_summary": "The paper studies infinite state-action space actor-critic with policy iteration and entropy regularization. It proves stability of the system and proves exponential convergence."
  },
  {
    "paper_id": "T9B2nlQXRD",
    "title": "Clip Your Sequences Fairly: Enforcing Length Fairness for Sequence‑Level RL",
    "domain": "reinforcement learning",
    "content": "We propose FSPO (Fair Sequence Policy Optimization), a sequence-level reinforcement learning method for LLMs that enforces length-fair clipping on the importance-sampling (IS) weight. We study RL methods with sequence-level IS and identify a mismatch when PPO/GRPO-style clipping is transplanted to sequences: a fixed clip range systematically reweights short vs. long responses, distorting the optimization direction. FSPO introduces a simple remedy: we clip the sequence log-IS ratio with a band that scales as $\\sqrt{L}$. Theoretically, we formalize length fairness via a Length Reweighting Error (LRE) and prove that small LRE yields a cosine directional guarantee between the clipped and true updates. Empirically, FSPO flattens clip rates across length bins, stabilizes training, and outperforms baselines across model sizes and evaluation datasets, with the largest gains on the Qwen3‑8B‑Base model.",
    "key_points": [
      "reinforcement learning",
      "llms",
      "policy gradient",
      "rlvr"
    ],
    "gold_summary": "This paper introduces FSPO which  propose a length-scaled clipping band in log-IS space to equalize acceptance rates across sequence lengths. Empirical results on math benchmarks (MATH500, AIME24/25) show FSPO outperforms existing methods."
  },
  {
    "paper_id": "y2kkiNXVHU",
    "title": "Reinforcement Learning for Evidence-Seeking Diagnostic Reasoning with Large Language Models",
    "domain": "reinforcement learning",
    "content": "Recent large language models (LLMs) excel at reasoning but often assume complete information, whereas real-world tasks, such as medical diagnosis, require iterative collections of evidence. Existing research rarely reflects this process, treating diagnosis as a one-turn task. This work explicitly formalizes this as a two-turn diagnostic paradigm and proposes reinforcement learning with diagnostic evidence-seeking rewards to guide LLMs in requesting and using evidence. We further introduce Retrieval-Augmented Generation-based Examination Simulation (RAGES), which generates realistic and plausible follow-up evidence to facilitate the process. Experiments on multilingual datasets show that (1) LLMs significantly improve diagnostic accuracy with additional evidence, (2) our model outperforms or matches larger and reasoning-enhanced baselines, and (3) RAGES generates more plausible results than pure LLM generation.",
    "key_points": [
      "reasoning llm",
      "reinforcement learning with verifiable rewards",
      "computational pathology"
    ],
    "gold_summary": "This work designs a two-turn diagnostic paradigm for medical diagnosis and proposes a new reinforcement learning reward to train a diagnosing reasoning model."
  },
  {
    "paper_id": "IjMfTINVcq",
    "title": "SuperRL: Reinforcement Learning with Supervision to Boost Language Model Reasoning",
    "domain": "reinforcement learning",
    "content": "Large language models are increasingly used for complex reasoning tasks where high-quality offline data such as expert-annotated solutions and distilled reasoning traces are often available. However, in environments with sparse rewards, reinforcement learning struggles to sample successful trajectories, leading to inefficient learning. At the same time, these offline trajectories that represent correct reasoning paths are not utilized by standard on-policy reinforcement learning methods. We introduce SuperRL, a unified training framework that adaptively alternates between RL and SFT. Whenever every rollout for a given instance receives zero reward, indicating the absence of a learning signal, SuperRL falls back to SFT on the curated offline data. Extensive experiments across diverse reasoning benchmarks show that SuperRL surpasses vanilla RL by delivering higher sample efficiency, stronger generalization, and improved robustness under sparse rewards.",
    "key_points": [
      "large language model",
      "reasoning",
      "question answering"
    ],
    "gold_summary": "This paper proposes SuperRL, a framework blending RL and SFT adaptively. It uses RL for non-zero rewards, SFT for zero rewards, outperforming baselines in sample efficiency, generalization, and stability across reasoning benchmarks"
  },
  {
    "paper_id": "gIOtRMxLxE",
    "title": "Exploring the Trade-off between Quality and Diversity of Language Models during Reinforcement Learning",
    "domain": "reinforcement learning",
    "content": "Reinforcement learning (RL) has become the dominant approach for post-training autoregressive language models, but a recurring challenge is that improvements in quality often come at the expense of diversity, which is a practical concern in exploratory domains such as scientific discovery. Although this trade-off is widely acknowledged, it has lacked a quantitative characterization. In this work, we systematically investigate the quality-diversity dynamics of RL finetuning of language models on molecular generation, a domain where diversity is both essential for discovery and quantitatively measurable. \n\nAcross RL checkpoints, we observe that mean quality ($\\mathcal{R}$) and diversity ($\\mathcal{D}$) trace a smooth trajectory captured by a robust exponential law, $\\mathcal{R}=-a\\cdot\\exp(c\\cdot\\mathcal{D})+b$, independent of step indexing. Extending prior work on quality-entropy trade-offs, we further show that quality also follows an exponential relation with sampling entropy ($\\mathcal{H}$), $\\mathcal{R}=-a_0\\cdot\\exp(c_0\\cdot\\mathcal{H})+b_0$, with $c_0$ quantifying exploratory progress. An approximately linear link between entropy and diversity explains why the two laws compose, and an information-theoretic illustration clarifies the role of the exponential form. We validate these findings across multiple generation objectives and also conduct ablations on influencing factors, including model scaling, reward shaping, and training setup. Finally, we demonstrate how the fitted laws provide actionable guidance for RL finetuning of language models on exploratory tasks. Overall, our study moves beyond qualitative accounts of diversity collapse, offering a compact quantitative model, an underlying entropy-based mechanism, and practical tools for exploratory RL with language models.",
    "key_points": [
      "language models",
      "reinforcement learning",
      "diversity",
      "entropy"
    ],
    "gold_summary": "This paper explores the relationship between quality and diversity in molecular generation, proposing an exponential law between the two."
  },
  {
    "paper_id": "2kutK2Y8Sv",
    "title": "How to Lose Inherent Counterfactuality in Reinforcement Learning",
    "domain": "reinforcement learning",
    "content": "Learning in high-dimensional MDPs with complex state dynamics became possible with the progress achieved in reinforcement learning research. \nAt the same time, deep neural policies have been observed to be highly unstable with respect to the minor variations in their state space, causing volatile and unpredictable behaviour. \nTo alleviate these volatilities, a line of work suggested techniques to cope with this problem via explicitly regularizing the temporal difference loss to ensure local $\\epsilon$-invariance in the state space.\nIn this paper,  we provide theoretical foundations on the impact of $\\epsilon$-local invariance training on the deep neural policy manifolds.\nOur comprehensive theoretical and experimental analysis reveals that standard reinforcement learning inherently learns counterfactual values while recent training techniques that focus on explicitly enforcing $\\epsilon$-local invariance cause policies to lose counterfactuality, and further result in learning misaligned and inconsistent values. \nIn connection to this analysis, we further highlight that this line of training methods break the core intuition and the true biological inspiration of reinforcement learning, and introduce an intrinsic gap between how natural intelligence understands and interacts with an environment in contrast to AI agents trained via $\\epsilon$-local invariance methods. The misalignment, inaccuracy and the loss of counterfactuality revealed in our paper further demonstrate the need to rethink the approach in establishing truly reliable and generalizable reinforcement learning policies.",
    "key_points": [
      "counterfactuality",
      "inherent skills",
      "reinforcement learning"
    ],
    "gold_summary": "The authors study recently developed methods for RL training that enforce ϵ-local invariance using theoretical and empirical analysis. They show that such methods have significant problems when compared to more traditional methods."
  },
  {
    "paper_id": "ion4VYJWvo",
    "title": "On the Tension Between Optimality and Adversarial Robustness in Policy Optimization",
    "domain": "reinforcement learning",
    "content": "Achieving optimality and adversarial robustness in deep reinforcement learning has long been regarded as conflicting goals. Nonetheless, recent theoretical insights presented in CAR suggest a potential alignment, raising the important question of how to realize this in practice.\nThis paper first identifies a key gap between theory and practice by comparing standard policy optimization (SPO) and adversarially robust policy optimization (ARPO). Although they share theoretical consistency, *a fundamental tension between robustness and optimality arises in practical policy gradient methods*. SPO tends toward convergence to vulnerable first-order stationary policies (FOSPs) with strong natural performance, whereas ARPO typically favors more robust FOSPs at the expense of reduced returns. Furthermore, we attribute this tradeoff to the *reshaping effect of the strongest adversaries* in ARPO, which significantly complicates the global landscape by inducing *deceptive sticky FOSPs*. This improves robustness but makes navigation more challenging. To alleviate this, we develop the *BARPO*, a bilevel framework unifying SPO and ARPO by modulating adversary strength, thereby facilitating navigability while preserving global optima. Extensive empirical results demonstrate that BARPO consistently outperforms vanilla ARPO, providing a practical approach to reconcile theoretical and empirical performance.",
    "key_points": [
      "reinforcement learning",
      "adversarial robustness",
      "policy optimization",
      "theory-practice gap",
      "bilevel optimization"
    ],
    "gold_summary": "This paper introduced the Bilevel ARPO (BARPO) that balances the optimality-robustness trade-off, by adjusting the adversary strength to promote traversable optimization paths which smoothed the optimization landscape."
  },
  {
    "paper_id": "T8Dev99qnz",
    "title": "Hierarchy-of-Groups Policy Optimization for Long-Horizon Agentic Tasks",
    "domain": "reinforcement learning",
    "content": "Group-based reinforcement learning (RL), such as GRPO, has advanced the capabilities of large language models on long-horizon agentic tasks. To enable more fine-grained policy updates, recent research has increasingly shifted toward stepwise group-based policy optimization, which treats each step in a rollout trajectory independently while using a memory module to retain historical context. However, we find a key issue in estimating stepwise relative advantages, namely context inconsistency, where steps within the same group may differ in their historical contexts. Empirically, we reveal that this issue can lead to severely biased advantage estimation, thereby degrading policy optimization significantly. To address the issue, in this paper, we propose Hierarchical-of-Groups Policy Optimization (HGPO) for long-horizon agentic tasks. Specifically, within a group of rollout trajectories, HGPO assigns each step to multiple hierarchical groups according to the consistency of historic contexts. Then, for each step, HGPO computes distinct advantages within each group and aggregates them with an adaptive weighting scheme. In this way, HGPO can achieve a favorable bias-variance trade-off in stepwise advantage estimation, without extra models or rollouts. Evaluations on two challenging agentic tasks, ALFWorld and WebShop with Qwen2.5-1.5B-Instruct and Qwen2.5-7B-Instruct, show that HGPO significantly outperforms existing agentic RL methods under the same computational constraints.",
    "key_points": [
      "reinforcement learning",
      "policy optimization",
      "long-horizon agent",
      "hierarchical group"
    ],
    "gold_summary": "This paper proposes HGPO, a herarichical extension of group-based RL designed to address context inconsistency in long-horizon LLM-based agents. Empirical results on ALFWorld and WebShop show consistent improvements over GRPO and GiGPO."
  },
  {
    "paper_id": "t61E9Mc85V",
    "title": "Learning to Distinguish: Behavior Gap Optimization for Goal-Conditioned Policy Learning",
    "domain": "reinforcement learning",
    "content": "Goal-conditioned reinforcement learning (GCRL) trains agents to accomplish a wide variety of tasks by optimizing goal-conditioned policies to achieve desired goals. However, a critical challenge in GCRL is the insufficient separation between the value estimates of optimal and suboptimal actions, a phenomenon we refer to as the Insufficient Behavior Gap, which can significantly degrade policy performance. To address this issue, we propose Behavior Gap Optimization Goal-Conditioned RL (BG2RL), a method that explicitly maximizes this gap through a contrastive optimization framework. Specifically, BG2RL samples reachable future states as target goals, which are considered positive examples, and strategically selects challenging, unachieved states from other trajectories as non-target goals, regarded as negative examples. By maximizing the value disparity between actions leading to these distinct outcomes, BG2RL learns a more discriminative value function and a more robust policy. Theoretical analysis shows that enlarging the policy gap between target and non-target goals directly tightens the suboptimality bound, providing a formal guarantee for the effectiveness of our contrastive objective. Finally, extensive experiments on challenging MuJoCo-based robotic manipulation tasks demonstrate that BG2RL significantly outperforms existing GCRL baselines in terms of success rate and exhibits more stable performance in environments with added obstacles, validating its robustness for goal-directed policy learning.",
    "key_points": [
      "goal-conditioned reinforcement learning",
      "behavior gap",
      "ddpg",
      "reinforcement learning"
    ],
    "gold_summary": "This paper presents a novel goal-conditioned RL method, BG2RL, which aims to enhance the performance and robustness of the policy by explicitly increasing the action-value gap between target goals and non-target goals."
  }
]