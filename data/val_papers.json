[
  {
    "paper_id": "gQPD83DrGp",
    "title": "Measuring the Intrinsic Dimension of Earth Representations",
    "domain": "self-supervised",
    "content": "Within the context of representation learning for Earth observation, geographic Implicit Neural Representations (INRs) embed low-dimensional location inputs (longitude, latitude) into high-dimensional embeddings, through models trained on geo-referenced satellite, image or text data. Despite the common aim of geographic INRs to distill Earth's data into compact, learning-friendly representations, we lack an understanding of how much information is contained in these Earth representations, and where that information is concentrated. The intrinsic dimension of a dataset measures the number of degrees of freedom required to capture its local variability, regardless of the ambient high-dimensional space in which it is embedded. This work provides the first study of the intrinsic dimensionality of geographic INRs. Analyzing INRs with ambient dimension between 256 and 512, we find that their intrinsic dimensions fall roughly between 2 and 10 and are sensitive to changing spatial resolution and input modalities during INR pre-training. Furthermore, we show that the intrinsic dimension of a geographic INR correlates with downstream task performance and can capture spatial artifacts, facilitating model evaluation and diagnostics. More broadly, our work offers an architecture-agnostic, label-free metric of information content that can enable unsupervised evaluation, model selection, and pre-training design across INRs.",
    "key_points": [
      "intrinsic dimension",
      "implicit neural representations",
      "location encoding",
      "positional encoding",
      "earth observation"
    ],
    "gold_summary": "This paper presents a framework for quantifying the intrinsic dimension of Earth representations and studying the correlation between ID with the model performance on downstream tasks."
  },
  {
    "paper_id": "k1GqOBx9l1",
    "title": "Multi-Modality Brain Disease Prediction with  Progressive Curriculum Graph Learning",
    "domain": "self-supervised",
    "content": "Recently, graph-based multi-modality learning approaches have been studied to handle multi-modality medical brain data analysis. \nAlthough they have achieved some promising performance, they still suffer from two main issues. First, current works generally fail to capture the inherent relationships of subjects (samples) from both feature and semantic/label perspectives. Second, for brain disease prediction tasks, the number of modalities is usually large (usually more than 4) and existing methods generally employ simple multi-modal fusion techniques that fail to carefully capture the dependencies of different modalities. To address these issues, this paper proposes a novel approach for multi-modality brain disease prediction by developing curriculum multi-modality learning. Our approach stems from observing that multi-modality learning becomes more challenging as the number of modalities increases, while recognizing curriculum learning as providing an explicit mechanism for tackling easy-to-hard learning tasks. This motivates us to propose a new progressive multi-modality learning strategy by leveraging the curriculum learning pipeline. Specifically, we first propose to dynamically learn a context-graph representation by jointly modeling the relationships of subjects from both feature and semantic label cues. Then, we propose a new multi-modality brain data representation by employing progressive curriculum learning. Experiments demonstrate the advantages of the proposed curriculum multi-modality learning strategy.  The code of our method will be released upon acceptance.",
    "key_points": [
      "multi-modality learning",
      "multi-modality brain disease prediction",
      "context-graph representation",
      "curriculum learning"
    ],
    "gold_summary": "This paper proposes a curriculum based learning + multimodal graph based framework (using both feature and label graphs) for brain disease prediction. Experiments demonstrate slight advantages over previous techniques."
  },
  {
    "paper_id": "0VVdai71xb",
    "title": "Mechanistic Independence: A Principle for Identifiable Disentangled Representations",
    "domain": "self-supervised",
    "content": "*Disentangled representations* seek to recover latent factors of variation underlying observed data, yet their *identifiability* is still not fully understood. We introduce a unified framework in which disentanglement is achieved through *mechanistic independence*, which characterizes latent factors by how they act on observed variables rather than by their latent distribution. This perspective is invariant to changes of the latent density, even when such changes induce statistical dependencies among factors. Within this framework, we propose several related independence criteria -- ranging from support-based and sparsity-based to higher-order conditions -- and show that each yields identifiability of latent subspaces, even under nonlinear, non-invertible mixing. We further establish a hierarchy among these criteria and provide a graph-theoretic characterization of latent factors as connected components. Together, these results clarify the conditions under which disentangled representations can be identified without relying on statistical assumptions.",
    "key_points": [
      "identifiability",
      "disentangled representation",
      "mechanistic independence"
    ],
    "gold_summary": "This paper proposes mechanistic independence, which enables identifiable disentangled representations without strong statistical assumptions."
  },
  {
    "paper_id": "I6xjMoLY3j",
    "title": "Disentangled representation learning through unsupervised symmetry group discovery",
    "domain": "self-supervised",
    "content": "Symmetry-based disentangled representation learning leverages the group structure of environment transformations to uncover the latent factors of variation. Prior approaches to symmetry-based disentanglement have required strong prior knowledge of the symmetry group's structure, or restrictive assumptions about the subgroup properties. In this work, we remove these constraints by proposing a method whereby an embodied agent autonomously discovers the group structure of its action space through unsupervised interaction with the environment. We prove the identifiability of the true action group decomposition under minimal assumptions, and derive two algorithms: one for discovering the group decomposition from interaction data, and another for learning Linear Symmetry-Based Disentangled (LSBD) representations without assuming specific subgroup properties. Our method is validated on three environments exhibiting different group decompositions, where it outperforms existing LSBD approaches.",
    "key_points": [
      "representation learning",
      "disentanglement",
      "group theory"
    ],
    "gold_summary": "They propose an algorithm to learn and disentangle the group structure underlying an environment, through interactions with this environment. Unlike previous methods, their method does not assume specific subgoup properties."
  },
  {
    "paper_id": "uq6nIOoPGG",
    "title": "Learning Coarse-Grained Representations: An Exploration of Mutual Information via Hyperspherical Density",
    "domain": "self-supervised",
    "content": "We revisit InfoMax for representation learning, using hyperspherical geometry with a non-parametric von Mises-Fisher kernel density estimator and differential entropy. This method is minimal with no asymmetry and trains stably. Results are competitive on smaller datasets such as CIFAR-10, STL-10 and LC25000, but lags behind modern baselines on ImageNet-1000. Experiments show that weakening the global entropy term consistently helps classification accuracy, suggesting that strict mutual information classification favors coarse grouping over fine discrimination.",
    "key_points": [
      "self-supevised learning",
      "mutual information",
      "kernel density estimation",
      "von misses-fisher distribution",
      "representation learning"
    ],
    "gold_summary": "This paper revisits the InfoMax principle for self-supervised representation learning, proposing a simple implementation based on hyperspherical geometry and non-parametric von Mises-Fisher (vMF) kernel density estimation to compute global and local differential entropies."
  },
  {
    "paper_id": "0BkvUY61MX",
    "title": "ATLAS: Adaptive Transfer Scaling Laws for Multilingual Pretraining, Finetuning, and Decoding the Curse of Multilinguality",
    "domain": "self-supervised",
    "content": "Scaling laws research has focused overwhelmingly on English—yet the most prominent AI models explicitly serve billions of international users. In this work, we undertake the largest multilingual scaling laws study to date, totaling 774 multilingual training experiments, spanning 10M-8B model parameters, 400+ training languages and 48 evaluation languages. We introduce the Adaptive Transfer Scaling Law (ATLAS) for both monolingual and multilingual pretraining, which outperforms existing scaling laws' out-of-sample generalization often by more than 0.3 R². Our analyses of the experiments shed light on multilingual learning dynamics, transfer properties between languages, and the curse of multilinguality. First, we derive a cross-lingual transfer matrix, empirically measuring mutual benefit scores between 38 × 38 = 1444 language pairs. Second, we derive a language-agnostic scaling law that reveals how to optimally scale model size and data when adding languages without sacrificing performance. Third, we identify the computational crossover points for when to pretrain from scratch versus finetune from multilingual checkpoints. We hope these findings provide the scientific foundation for democratizing scaling laws across languages, and enable practitioners to efficiently scale models—beyond English-first AI.",
    "key_points": [
      "scaling laws",
      "multilinguality"
    ],
    "gold_summary": "This paper studies the scaling law of multi-lingual models w.r.t. model size, data size and computation budgets."
  },
  {
    "paper_id": "05uq3XUJaT",
    "title": "Fine-tuning large language models for text ranking with listwise constraints",
    "domain": "self-supervised",
    "content": "With the rapid adoption of large language models (LLMs) across diverse applications, retrieval augmentation has become a key factor for improving downstream performance. Recent advances show that LLM-based retrieval can substantially enhance ranking quality. In this work, we present a novel LLM-based retrieval framework optimized along three complementary dimensions: (1) a customized attention-based fusion of hidden-layer representations, (2) a dedicated multi-layer perceptron (MLP) module for enriched feature transformation, and (3) a new list-wise learning objective, ListRank loss, to capture fine-grained relevance order. Experimental results demonstrate that our model achieves state-of-the-art performance. The model is publicly available for download on HuggingFace.",
    "key_points": [
      "feature fusion",
      "listwise",
      "llm",
      "rank"
    ],
    "gold_summary": "This paper introduces a listwise fine-tuning method for LLM-based text reranking. The method improves three limitations of existing LLM rankers (single-token compression, shallow scoring heads, and pairwise objectives)."
  },
  {
    "paper_id": "kitV8uipV2",
    "title": "Incorruptible Neural Networks: Training Models that can Generalize to Large Internal Perturbations",
    "domain": "self-supervised",
    "content": "Flat regions of the neural network loss landscape have long been hypothesized to correlate with better generalization properties. A closely related but distinct problem is training models that are robust to internal perturbations to their weights, which may be an important need for future low-power hardware platforms. Several methods have been proposed to guide optimization toward improved generalization, such as sharpness-aware minimization (SAM) and random-weight perturbation (RWP), which rely on either adversarial or random perturbations, respectively. In this paper, we explore how to adapt these approaches to find minima robust to a wide variety of random corruptions to weights. First, we evaluate SAM/RWP across a wide variety of noise settings, and in doing so establish that over-regularization during training is key to finding optimally-robust minima. At the same time, we also observe that large perturbations lead to a vanishing gradient effect caused by unevenness in the loss landscape, an effect particularly pronounced in SAM. Quantifying this effect, we map out a general performance trend of SAM and RWP, determining that SAM works best for robustness to small perturbations, whereas RWP works best for large perturbations. Lastly, to overcome the deleterious vanishing gradient effect during training, we propose a dynamic perturbation schedule which matches the natural evolution of the loss landscape and produces minima more noise-robust than otherwise possible.",
    "key_points": [
      "noise robustness",
      "sharpness-aware minimization",
      "weight perturbations"
    ],
    "gold_summary": "This work empirically studies SAM and RWP against weight perturbations, and design a  dynamic scheme for enhancement."
  },
  {
    "paper_id": "JdbqDiguyO",
    "title": "Noise-Robust Density Estimation for Tabular Data Anomaly Detection",
    "domain": "self-supervised",
    "content": "Density-based anomaly detection methods often provide accurate and interpretable predictions but their performance can be severely affected by the inherent noise of data. In this paper, we present a noise-robust density estimation (NRDE) method for tabular data anomaly detection. We aim to estimate density of pure data with influence of noise isolated, which is a non-trivial task since data-generating process is completely unknown. NRDE learns a Jacobian-regularized normalizing flow to estimate the sources of data and categorizes sources into two groups, where one group generates  pure data and the other generates noise. Then we can estimate the density of pure data and use it to detect anomalies caused by the sources of pure data rather than the changes caused by the sources of noise. Therefore, compared with other density based methods, our NRDE is much more robust to noise. Besides the new algorithm, we also provide theoretical results to support the effectiveness of NRDE. We compare NRDE with $15$ baselines on $47$ benchmark datasets under different settings, including vanilla anomaly detection, anomaly detection with anomaly contamination, anomaly detection on noisy data and transductive outlier detection. The results demonstrate effectiveness and superiority of NRDE.",
    "key_points": [
      "anomaly detection"
    ],
    "gold_summary": "a normalizing flow method for anomaly detection that separates the signal part from the noise part."
  },
  {
    "paper_id": "m2MeiYOJED",
    "title": "PRISM: Partial-label Relational Inference with Spatial and Spectral Cues",
    "domain": "self-supervised",
    "content": "In many real-world scenarios, precisely labeling graph data is costly or impractical, especially in domains like molecular biology or social networks, where annotation requires expert effort. This challenge motivates partial-label graph learning, where each graph is weakly annotated with a candidate label set containing the true label. However, such ambiguous supervision makes it hard to extract reliable semantics and increases the risk of overfitting to noisy candidates. To address these challenges, we propose PRISM, a unified framework that performs relational inference with spatial and spectral cues to resolve label ambiguity. PRISM captures discriminative spatial cues by aligning prototype-guided substructures across graphs and extracts global spectral cues by decomposing graph signals into multiple frequency bands with attention, preserving frequency-specific semantics. These complementary views are integrated into a hybrid relational graph, which supports confidence-aware label propagation under candidate constraints. A closed-loop refinement mechanism further stabilizes supervision via masked updates and momentum-based confidence estimation. Extensive experiments across diverse benchmarks demonstrate that PRISM consistently outperforms strong baselines under various noise settings, establishing a new paradigm for weakly supervised graph classification.",
    "key_points": [
      "weak supervised learning",
      "graph neural networks",
      "relational inference"
    ],
    "gold_summary": "This paper proposes a novel graph classification method in partial-label setting, which captures relations between graphs from both spatial and spectral views."
  },
  {
    "paper_id": "ZCCK901R9i",
    "title": "Unsupervised Prompt Learning with Few-shot Examples for Answering Objective Questions",
    "domain": "self-supervised",
    "content": "Large language models (LLMs) have been highly successful on diverse tasks, while some applications require specializing general purpose LLMs to meet stricter accuracy or latency targets; here we focus on objective question answering, an important real-world setting in which a nontrivial subset benefits from such specialization. Most existing methods require parameter retraining or human supervision, both entailing high computational and data collection burdens. To handle these challenges, a direct approach is to generate ``high-confidence'' data from unsupervised downstream tasks and use them for prompt learning or in-context learning to efficiently refine pseudo-supervision. We consider combining the two approaches for better performance; however, a naive strategy that learns the prompt first and selects pseudo-supervised examples only at inference creates a mismatch between prompt learning and usage. In this paper, we propose unsupervised few-shot prompt learning (UFPL), which jointly learns the prompt and refines the overall pseudo-supervision. The learning objective aligns prompt training with usage by requiring the learned prompt to produce consistent answers when pseudo-supervised data from the downstream task are used as in-context examples. We optimize the prompt by translating gradient signals into textual critiques, which serve as feedback to iteratively refine the prompt and the pseudo supervision. Theoretical analysis in a simplified classification setting shows that the algorithm implicitly introduces a regularization, supporting its design. Empirical results on diverse benchmarks and a real world molecule optimization task show the effectiveness of our approach.",
    "key_points": [
      "large language models",
      "prompt optimization",
      "in-context learning",
      "test-time alignment"
    ],
    "gold_summary": "This paper proposes UFPL, which selects high-confident answers as pseudo labels and uses few-shot demonstrations in the prompt optimization stage."
  },
  {
    "paper_id": "mljFOs1n2S",
    "title": "EBind: a Practical Approach to Space Binding",
    "domain": "self-supervised",
    "content": "We simplify space binding by focusing on two core components, a single encoder per modality and high-quality data; enabling training state-of-the-art models on a single GPU in a few hours as opposed to multiple days.  We present EBind, an Easy, data-centric, and parameter-efficient method to Bind the embedding spaces of multiple contrastive models.  We demonstrate that a simple 1.8B-parameter image-text-video-audio-3D model can outperform models 4 to 17x the size. The key to achieving this is a carefully curated dataset of three complementary data sources: i) 6.7M fully-automated multimodal quintuples sourced via SOTA retrieval models, ii) 1M diverse, semi-automated triples annotated by humans as negative, partial, or positive matches, and iii) 3.4M pre-existing captioned data items. We use 13 different evaluations to demonstrate the value of each data source. Due to limitations with existing benchmarks, we further introduce the first high-quality, consensus-annotated zero-shot classification benchmark between audio and 3D point clouds. In contrast to related work, we will open-source our code, model weights, _and_ the datasets.",
    "key_points": [
      "representation learning",
      "contrastive learning",
      "space binding",
      "zero shot learning",
      "image retrieval",
      "video retrieval",
      "3d point cloud retrieval",
      "joint embedding"
    ],
    "gold_summary": "Compared with ImageBind and similar methods, EBind achieves strong cross-modal alignment within **<6 hours on a single GPU** by prioritizing **high-quality training data**. Its effectiveness is validated across multimodal retrieval and classification tasks."
  },
  {
    "paper_id": "tktzkmqIfm",
    "title": "Order Matters: Improving Domain Adaptation by Reordering Data",
    "domain": "self-supervised",
    "content": "Domain shift remains a key challenge in deploying machine learning models to the real world. Unsupervised domain adaptation (UDA) aims to address this by minimising domain discrepancy during training, but the discrepancy estimates suffer from high variance in stochastic settings, which can stifle the theoretical benefits of the method. This paper proposes Optimal Reordering of Data for Error-Reduced Estimation of Discrepancy (ORDERED), a novel unbiased stochastic variance reduction technique which reduces the discrepancy estimation error by optimising the order in which the training data are sampled. We consider two specific domain discrepancy losses (correlation alignment and the maximum mean discrepancy), formulate their stochastic estimation error as a function of the data sampling order, and propose a practical optimisation algorithm. Our simulations demonstrate reduced variance compared to related methods, and experiments on a domain shift image classification benchmark show improved target domain accuracy.",
    "key_points": [
      "stochastic variance reduction",
      "unsupervised domain adaptation",
      "maximum mean discrepancy",
      "correlation alignment"
    ],
    "gold_summary": "The paper builds upon [Anonymous 2025] which proposed stratified sampling (as opposed to random sampling) of mini-batches during training to reduce the variance in estimation of domain discrepancy that arises when training with mini-batches."
  },
  {
    "paper_id": "p2E7haeXxa",
    "title": "OVRD: Open-Vocabulary Relation DINO with Text-guided Salient Query Selection",
    "domain": "self-supervised",
    "content": "Open-Vocabulary Detection (OVD) trains on base categories and generalizes to novel categories with the aid of text embeddings from Vision-Language Models (VLMs).\nHowever, existing methods are insufficient in utilizing semantic cues from the text embeddings to guide visual perception, which hinders the performance of zero-shot object detection.\nIn this paper, we propose OVRD, an Open-Vocabulary Relation DINO with text-guided salient selections.\nSpecifically, we introduce text-guided salient query selection to choose image features most relevant to the text embeddings, along with their \ncorresponding reference points and masks, thereby providing additional semantic cues for guiding visual perception. \nBuilding upon this, the salient reference points are used to recover the relative spatial structure of the selected features, \nenhancing positional awareness in the salient transformer decoder. \nMoreover, to fully leverage both the semantic cues and the recovered spatial structure, we develop a self-attention model of semantic relationships to model sparse semantic relations in OVD scenarios to further guide visual perception.\nWe evaluate OVRD on public benchmarks in a zero-shot setting, achieving 37.0 AP on LVIS Minival, which performs favorably against the state-of-the-art methods.\nThe code is available at https://anonymous.4open.science/r/OVRD.",
    "key_points": [
      "multi-modal learning",
      "open-vocabulary",
      "object detection"
    ],
    "gold_summary": "This paper introduces OVRD, which improves open-vocabulary object detection performance by utilizing semantic cues from text embeddings to guide the model's visual perception."
  },
  {
    "paper_id": "zu2BjeEwRJ",
    "title": "How Predictable is AI Progress?",
    "domain": "self-supervised",
    "content": "Benchmarks only serve to measure what models are capable of now, not what they will be capable of in the future. We find that the ordering of acquired capabilities is remarkably consistent across large populations of AI models, which begs the question of whether one can forecast which specific examples and capabilities future models will solve next. We propose formalizing this problem into a new evaluation task called progress prediction: Can we forecast which unsolved problems will be solved next as future models improve? We find that progress is, in fact, predictable. Through an empirical study of hundreds of millions of predictions made by 1,000+ vision models and 1,600+ language models, we find that this predictability is possible due to the consistent order in which models acquire capabilities across architectures, datasets, and modalities.",
    "key_points": [
      "deep learning"
    ],
    "gold_summary": "The paper claims to be able to predict capabilities of future AI"
  },
  {
    "paper_id": "Mr9a9XuLTI",
    "title": "A Few Large Shifts: Layer-Inconsistency Based Minimal Overhead Adversarial Example Detection",
    "domain": "self-supervised",
    "content": "Deep neural networks (DNNs) are highly susceptible to adversarial examples—subtle, imperceptible perturbations that can lead to incorrect predictions. While detection-based defenses offer a practical alternative to adversarial training, many existing methods depend on external models, complex architectures, or adversarial data, limiting their efficiency and generalizability. We introduce a lightweight, plug-in detection framework that leverages internal layer-wise inconsistencies within the target model itself, requiring only benign data for calibration. Our approach is grounded in the **A Few Large Shifts Assumption**, which posits that adversarial perturbations induce large, localized violations of *layer-wise Lipschitz continuity* in a small subset of layers. Building on this, we propose two complementary strategies—**Recovery Testing (RT)** and **Logit-layer Testing (LT)**—to empirically measure these violations and expose internal disruptions caused by adversaries. Evaluated on CIFAR-10, CIFAR-100, and ImageNet under both standard and adaptive threat models, our method achieves state-of-the-art detection performance with negligible computational overhead. Furthermore, our system-level analysis provides a practical method for selecting a detection threshold with a formal lower-bound guarantee on accuracy.",
    "key_points": [
      "adversarial detection",
      "deep learning",
      "layer inconsistency",
      "robust defense",
      "adaptive attacks."
    ],
    "gold_summary": "This paper is on detection of adversarial inputs.\nEvaluations of the proposed method are given on\nCIFAR-10, CIFAR-100, and ImageNet datasets."
  },
  {
    "paper_id": "xiKtlg1jED",
    "title": "PartCo: Part-Level Correspondence Priors Enhance Category Discovery",
    "domain": "semi-supervised",
    "content": "Generalized Category Discovery (GCD) aims to identify both known and novel categories within unlabeled data by leveraging a set of labeled examples from known categories. Existing GCD methods primarily depend on semantic labels and global image representations, often overlooking the detailed part-level cues that are crucial for distinguishing closely related categories. In this paper, we introduce PartCo, short for Part-Level Correspondence Prior, a novel framework that enhances category discovery by incorporating part-level visual feature correspondences. By leveraging part-level relationships, PartCo captures finer-grained semantic structures, enabling a more nuanced understanding of category relationships. Importantly, PartCo seamlessly integrates with existing GCD methods without requiring significant modifications. Our extensive experiments on multiple benchmark datasets demonstrate that PartCo significantly improves the performance of current GCD approaches, achieving state-of-the-art results by bridging the gap between semantic labels and part-level visual compositions, thereby setting new benchmarks for GCD. Code will be made publicly available.",
    "key_points": [
      "generalized category discovery"
    ],
    "gold_summary": "This paper introduces PartCo, a framework that enhances Generalized Category Discovery (GCD) by incorporating part-level correspondence priors extracted from ViT patch tokens."
  },
  {
    "paper_id": "hi6opqxk5X",
    "title": "Provably Fast Density-Based Clustering in High Dimensions",
    "domain": "semi-supervised",
    "content": "DBSCAN is a celebrated algorithm for density-based clustering, but its quadratic runtime hinders scalability to large datasets. In recent years, there has been considerable interest in accelerating DBSCAN. However, existing methods either impose additional structure on the data (e.g., low-dimensionality), or lack rigorous runtime and approximation guarantees. Building on a recent work of Okkels et al. (2025), we propose an LSH-based algorithm that achieves the first provably subquadratic runtime for approximate DBSCAN on arbitrary high-dimensional datasets. Empirically, our algorithm delivers a significant speedup over the standard DBSCAN on a variety of benchmarks while incurring only small error. We also show that our approach naturally yields a subquadratic-time approximation of HDBSCAN (a popular hierarchical variant). Complementing our algorithms, we prove quadratic-time lower bounds for exact DBSCAN and HDBSCAN, showing that subquadratic runtimes are only possible with approximation.",
    "key_points": [
      "dbscan",
      "locality-sensitive hashing",
      "clustering"
    ],
    "gold_summary": "The paper presents fast algorithms for estimating DBSCAN* and HDBSCAN using LSH calculations."
  },
  {
    "paper_id": "bZqCBgm2N0",
    "title": "Beyond DAGs: A Latent Partial Causal Model for Multimodal Learning",
    "domain": "semi-supervised",
    "content": "Directed Acyclic Graphs (DAGs) are a standard tool in causal modeling, but their suitability for capturing the complexity of large-scale multimodal data is questionable. In practice, real-world multimodal datasets are often collected from heterogeneous generative processes that do not conform to a single DAG. Instead, they may involve multiple, and even opposing, DAG structures with inverse causal directions. To address this gap, in this work, we first propose a novel latent partial causal model tailored for multimodal data representation learning, featuring two latent coupled variables parts connected by an undirected edge, to represent the transfer of knowledge across modalities. Under specific statistical assumptions, we establish an identifiability result, demonstrating that representations learned by MultiModal Contrastive Learning (MMCL) correspond to the latent coupled variables up to a trivial transformation. This result deepens our understanding of the why MMCL works, highlights its potential for representation disentanglement, and expands the utility of pre-trained models like CLIP. Synthetic experiments confirm the robustness of our findings, even when the assumptions are partially violated. Most importantly, experiments on a pre-trained CLIP model embodies disentangled representations, enabling few-shot learning and improving domain generalization across diverse real-world datasets. Together, these contributions push the boundaries of MMCL, both in theory and in practical applications.",
    "key_points": [
      "multimodal representation learning",
      "latent variable model",
      "disentangled representation learning"
    ],
    "gold_summary": "The paper proposes a latent partial causal model to generalize beyond traditional DAGs, capturing undirected multimodal dependencies and proving identifiability in contrastive learning frameworks like CLIP."
  },
  {
    "paper_id": "nxcevynv08",
    "title": "Thicker and Quicker: The Jumbo Token for Fast Plain Vision Transformers",
    "domain": "semi-supervised",
    "content": "ViTs are general and accurate, and address many tasks, but ViTs are slow, and\nare not always practical when efficiency is key. Existing methods for faster ViTs\ndesign hybrid non-ViT architectures, losing generality, or shrink their tokens,\nsacrificing accuracy. While many non-ViT architectures are both fast and accurate,\nthey cannot flexibly process other input shapes, pre-train by SOTA self-supervised\nlearning, reduce computation by dropping tokens, and more like ViTs can. We\nmake ViTs faster by reducing patch token width while increasing global token\nwidth by adding a new Jumbo token. Our wider Jumbo token is processed by its\nown wider FFN to increase model capacity. Yet our Jumbo FFN is efficient: it\nprocesses a single token, for speed, and its parameters are shared across all layers,\nfor memory. Crucially, our Jumbo is attention-only and non-hierarchical, like a\nplain ViT, so it is simple, scalable, flexible, and compatible with ViT methods new\nand old. Jumbo improves over ViT baselines with Registers from Nano to Large\nscales while maintaining speed/throughput on ImageNet-1K (↑0.1−13%). Jumbo\nalso improves MAE pre-training (↑4.9% linear probing on ImageNet-1K), test-time\nadaptation (↑5.2% on ImageNet-C), and time series modeling. Our Jumbo models\neven achieve better speed-accuracy trade-offs than specialized non-ViT compute-efficient models, while maintaining plain-ViT compatibility for practicality.",
    "key_points": [
      "efficient deep learning",
      "computer vision",
      "vision transformers"
    ],
    "gold_summary": "This paper proposes adding a jumbo token to ViTs, demonstrating good efficiency compared to ViT register baselines. The paper is well-written and the idea is intuitive."
  },
  {
    "paper_id": "ERJd7dMN6U",
    "title": "Riemannian Optimization on Relaxed Indicator Matrix Manifold",
    "domain": "semi-supervised",
    "content": "The indicator matrix plays an important role in machine learning, but optimizing it is an NP-hard problem. We propose a new relaxation of the indicator matrix and compared with other existing relaxations, it can flexibly incorporate class information. We prove that this relaxation forms a manifold, which we call the Relaxed Indicator Matrix Manifold (RIM manifold). Based on Riemannian geometry, we develop a Riemannian toolbox for optimization on the RIM manifold. Specifically, we provide several methods of Retraction, including a fast Retraction method to obtain geodesics. We point out that the RIM manifold is a generalization of the double stochastic manifold, and it is much faster than existing methods on the double stochastic manifold, which has a complexity of \\( \\mathcal{O}(n^3) \\), while RIM manifold optimization is \\( \\mathcal{O}(n) \\) and often yields better results. We conducted extensive experiments, including image denoising, with millions of variables to support our conclusion, and applied the RIM manifold to Ratio Cut, we provide a rigorous convergence proof and achieve clustering results that outperform the state-of-the-art methods. Our Code in here.",
    "key_points": [
      "optimization",
      "clustering",
      "graph cut"
    ],
    "gold_summary": "A new relaxation is introduced for the indicator matrix optimization problem, leading to a manifold with a simple structure. Algorithms are designed based on this manifold."
  },
  {
    "paper_id": "fwMEqaKgTd",
    "title": "Unlabeled Data vs. Pre-trained Knowledge: Rethinking SSL in the Era of Large Models",
    "domain": "semi-supervised",
    "content": "Semi-supervised learning (SSL) alleviates the cost of data labeling\nprocess by exploiting unlabeled data and has achieved promising results. Meanwhile, with the development of large foundation models, exploiting pre-trained models becomes a promising way to address the label scarcity in the downstream tasks, such as various parameter-efficient fine-tuning techniques. This raises a natural yet critical question: When labeled data is limited, should we rely on unlabeled data or pre-trained models? To investigate this issue, we conduct a fair comparison between SSL methods and pre-trained models (e.g., CLIP) on representative image classification tasks under a controlled supervision budget. \nExperiments reveal that SSL has met its \"Waterloo\" in the era of large models, as pre-trained models show both high efficiency and strong performance on widely adopted SSL benchmarks. This underscores the urgent need for SSL researchers to explore new avenues, such as deeper integration between the SSL and pre-trained models. Furthermore, we investigate the potential of Multi-Modal Large Language Models (MLLMs) in image classification tasks. Results show that, despite their massive parameter scales, MLLMs still face significant performance limitations, highlighting that even a seemingly well-studied task remains highly challenging.",
    "key_points": [
      "semi-supervised learning",
      "large multimodal models"
    ],
    "gold_summary": "This paper investigates traditional self-supervised learning (SSL) methods and CLIP-based prompt-tuning approaches. The authors conduct experiments across various image classification settings and present several empirical findings."
  },
  {
    "paper_id": "8cwaRXwpFf",
    "title": "Vision Transformers Secretly Crave Noise",
    "domain": "semi-supervised",
    "content": "Data augmentation and regularization have proven to be fundamental techniques for enhancing the generalization of deep neural networks. While canonical methods such as RandAug, CutMix, Mixup, RandErase, and DropPath offer diverse regularization effects, their combined use appears to have reached a saturation point, leaving little room for further performance gains. In this work, we introduce DiffNoise, a novel data augmentation strategy that injects smooth noise-based perturbations into the input embedding space rather than directly into the raw input. Contrary to the conventional belief, DiffNoise performs orthogonally to existing data augmentations, improving the standard recipe that has largely reached saturation. This improvement may be interpreted as expanding the augmentation space along a previously unexplored axis, without any architectural modifications or auxiliary objectives. Furthermore, DiffNoise implicitly benefits from a more improved localization capability and learn generalized, robust representations across various models. Extensive experiments across a wide spectrum of model families—including ViTs, CLIP, and self-supervised architectures—show that DiffNoise consistently enhances performance across multiple downstream tasks. Code is available in the Supplementary Material.",
    "key_points": [
      "self-supervised learning",
      "vision transformer",
      "fine-tuning",
      "transfer learning"
    ],
    "gold_summary": "The authors proposed a new augmentation strategy termed as DiffNoise, that add noise to tokens instead of pixels, and claimed to have orthogonal augmentation effect on ImageNet-1k with ViT/ResNet and downstream tasks."
  },
  {
    "paper_id": "MZDkttBUEd",
    "title": "Learning Population-Level Representations with Joint Embedding Predictive Architectures",
    "domain": "semi-supervised",
    "content": "Multivariate population data is ubiquitous across scientific and real-world domains, arising in settings where the identity of a system is revealed through the composition of its constituent samples. For example, a patient’s clinical state can be inferred from the joint analysis of their blood cells, while the properties of a galaxy can be characterized from the distribution of its stars and their spectra. To our knowledge, attempts to learn representations of such data remain limited, largely because its inductive structure is subtle, making feature extraction particularly challenging. Inspired by recent advances in joint embedding predictive architectures, we challenge the prevailing assumption that population-level data lacks sufficient signal for representation learning, and show that by leveraging both the compositional structure of the data and the properties of individual samples, rich and expressive representations can indeed be learned. We demonstrate our approach in the biomedical domain, addressing the long-standing challenge of scaling machine learning to large single-cell transcriptomics datasets for patient representation.",
    "key_points": [
      "representation learning",
      "jepa",
      "single cell transcriptomics",
      "patient representation"
    ],
    "gold_summary": "This paper proposes a new method for learning population-level representations with a joint embedding method."
  },
  {
    "paper_id": "i57dQomaoE",
    "title": "Divergence-Induced Contrastive Unlearning via Directed Representation Shifts",
    "domain": "semi-supervised",
    "content": "Unauthorized data collection has become widespread, raising the need for defenses that prevent exploitation of personal data. Unlearnable Examples (UEs) address this by embedding imperceptible perturbations that preserve visual quality while making data unusable for training. Recent work has shown that contrastive learning can be poisoned to generate UEs, but existing methods lack theoretical grounding and fail to exploit the geometric structure of learned representations. In this work, we present the first principled analysis of contrastive poisoning and reveal why it is effective. Building on this understanding, we propose Divergence-Induced Contrastive Unlearning (DICU), a framework that introduces direction-aware divergence regularization into the poisoning objective. This design amplifies intra-class sparsity, pushes samples beyond class manifold boundaries, and enables free mixing across classes, producing stealthy and robust perturbations. Our approach is especially effective in high class-count settings, reducing linear probing accuracy at significant level.",
    "key_points": [
      "unlearning",
      "data poisoning",
      "indiscriminate attack",
      "contrastive learning"
    ],
    "gold_summary": "This paper introduces the direction-aware divergence regularization into the contrastive poisoning framework to create unlearnable datasets against contrastive learning."
  },
  {
    "paper_id": "zOgvgw5sia",
    "title": "Efficient Compression of Time-Series Foundation Models via Consensus Subspace Distillation",
    "domain": "semi-supervised",
    "content": "Compressing universal time-series foundation models (TSFMs) significantly reduces computational and storage overhead, thereby facilitating their widespread adoption. In TSFM compression techniques, knowledge distillation stands out by transferring knowledge from teacher models to student models. However, existing distillation methods often overlook the inherent consensus representation spaces in TSFMs and the imbalance in hierarchical contributions, leading to inefficient knowledge transfer. To address this, we propose a novel approach that reformulates distillation as a consensus subspace optimization task, leveraging the observation that high-level embeddings autonomously converge across different model scales, along with the long-tail distribution of hierarchical contributions. We tackle the consensus subspace problem by identifying and extracting scale-invariant low-rank subspaces: on local data subsets, we perform singular value decomposition on embeddings from offline-selected consensus layers to derive consensus projection matrices, which are then used to fine-tune the student model, ensuring representation alignment and accelerated convergence. Additionally, we introduce a scalable uncertainty injection mechanism to enhance generalization to unseen data, modeling subset biases as frequency-domain gaps to inflate covariances. Extensive experiments demonstrate that our framework excels on multiple standard time-series datasets, with student models even surpassing teacher performance in time-series forecasting tasks. Compared to state-of-the-art methods, our approach achieves over 90% parameter reduction and 100x distillation speedup while retaining comparable performance across various time-series tasks. Code and compressed model weights are available via an anonymous link: anonymous.4open.science/r/CSD-13C3.",
    "key_points": [
      "time-series foundation models",
      "time-series forecasting",
      "model compression",
      "knowledge distillation",
      "consensus subspace optimization",
      "uncertainty injection"
    ],
    "gold_summary": "Consensus subspace distillation for TSFM compression: interesting idea, but weak theoretical grounding and questionable evaluation validity."
  },
  {
    "paper_id": "bs7m1LbRKT",
    "title": "Training with Dynamic Sparse Heads as the Key to Effective Ensembling",
    "domain": "semi-supervised",
    "content": "Model ensembles have long been a cornerstone for improving generalization and robustness in deep learning. However, their effectiveness often comes at the cost of substantial computational overhead. To address this issue, state-of-the-art methods aim to replicate ensemble-class performance without requiring multiple independently trained networks. Unfortunately, these algorithms often still demand considerable compute at inference. In response to these limitations, we introduce _NeuroTrails_, a sparse multi-head architecture with dynamically evolving topology. This unexplored model-agnostic training paradigm improves ensemble performance while reducing the required parameter count. We analyze the underlying reason for its effectiveness and observe that the various neural trails induced by dynamic sparsity attain a _Goldilocks zone_ of prediction diversity. NeuroTrails displays efficacy with convolutional and transformer-based architectures on vision, language, and reinforcement learning tasks. Experiments on ResNet-50/ImageNet, LLaMA-350M/C4, DQN/Atari demonstrate increased performance and stronger robustness in zero-shot generalization, while requiring significantly fewer resources.",
    "key_points": [
      "deep learning",
      "ensembles",
      "sparsity",
      "dynamic sparse training",
      "computer vision",
      "language modeling"
    ],
    "gold_summary": "This work applies dynamic sparse training to the TreeNet architecture."
  },
  {
    "paper_id": "vCmnu4q8C3",
    "title": "Adaptive Conformal Prediction via Mixture-of-Experts Gating Similarity",
    "domain": "semi-supervised",
    "content": "Prediction intervals are essential for applying machine learning models in real applications, yet most conformal prediction (CP) methods provide coverage guarantees that overlook the heterogeneity and domain knowledge that characterize modern multimodal datasets. We introduce Mixture-of-Experts Conformal Prediction (MoE-CP), a flexible and scalable framework that uses the gating probability vectors of Mixture-of-Experts (MoE) models as soft domain assignments to guide similarity-weighted conformal calibration. MoE-CP weights calibration residuals according to the similarity between gating vectors of calibration and test points, producing prediction intervals that adapt to latent subpopulations without requiring explicit domain labels. We provide theoretical justification showing that MoE-CP preserves nominal marginal validity under common similarity measures and improves conditional adaptivity when the gating captures domain structure. Empirical results on synthetic and real-world datasets demonstrate that MoE-CP yields more domain-aware, interpretable, and often tighter intervals than existing conformal baselines while maintaining target coverage. MoE-CP offers a practical route to reliable uncertainty quantification in latent heterogeneous, multi-domain environments.",
    "key_points": [
      "conformal prediction; mixture of experts; distribution-free inference."
    ],
    "gold_summary": "The authors introduce Mixture-of-Experts Conformal Prediction (MoE-CP), a flexible method that uses the gating probability vectors of Mixture-of-Experts (MoE) models to estimate the similarity between test sample and calibration samples, thereby achieve adaptive conformal prediction."
  },
  {
    "paper_id": "uULz773iBN",
    "title": "The Order Matters: Sequential Fine-Tuning of LLaMA for Coherent Automated Essay Scoring",
    "domain": "semi-supervised",
    "content": "Automated Essay Scoring (AES) systems must judge interdependent discourse elements (e.g., lead, claim, evidence, conclusion), yet most approaches treat these in isolation, harming coherence and generalization. We investigate task-aware fine-tuning of LLaMA-3.1-8B for AES using parameter-efficient LoRA with 4-bit quantization and compare three training curricula: (i) Sequential (progressively fine-tuning on lead, then position, then claim, then evidence, then conclusion), (ii) Independent (task-specific models), and (iii) Randomized (shuffled multi-task). Experiments on the PERSUADE~2.0 corpus show that modeling task dependencies matters: Sequential fine-tuning yields the strongest overall results, including F1 scores of 65\\% (evidence) and 87\\% (conclusion) and corresponding accuracies of 63\\% and 85\\%, surpassing Independent training and outperforming a general-purpose LLaMA-70B baseline on conclusion despite its far larger capacity. Randomized training improves position scoring (57\\% F1) but is less consistent elsewhere. These findings indicate that (1) curriculum design aligned with discourse structure can materially improve AES, and (2) small, task-optimized models can be competitive with substantially larger LLMs, offering a practical path to scalable, cost-effective assessment. We release templates and implementation details to facilitate reproduction and future work on curriculum design for educational NLP.",
    "key_points": [
      "automated essay scoring (aes)",
      "task dependency",
      "parameter-efficient fine-tuning (peft)",
      "lora"
    ],
    "gold_summary": "This paper presents a curriculum-based fine-tuning approach to classify the effectiveness of discourse elements in an essay."
  },
  {
    "paper_id": "k9CzIvzfaA",
    "title": "On the Theoretical Limitations of Embedding-Based Retrieval",
    "domain": "semi-supervised",
    "content": "Vector embeddings have been tasked with an ever-increasing set of retrieval tasks over the years, with a nascent rise in using them for reasoning, instruction-following, coding, and more. These new benchmarks push embeddings to work for any query and any notion of relevance that could be given. While prior works have pointed out theoretical limitations of vector embeddings, there is a common assumption that these difficulties are exclusively due to unrealistic queries, and those that are not can be overcome with better training data and larger models. In this work, we demonstrate that we may encounter these theoretical limitations in realistic settings with extremely simple queries. We connect known results in learning theory, showing that the number of top-k subsets of documents capable of being returned as the result of some query is limited by the dimension of the embedding. We empirically show that this holds true even if we restrict to k=2, and directly optimize on the test set with free parameterized embeddings. We then create a realistic dataset called LIMIT that stress tests models based on these theoretical results, and observe that even state-of-the-art models fail on this dataset despite the simple nature of the task. Our work shows the limits of embedding models under the existing single vector paradigm and calls for future research to develop methods that can resolve this fundamental limitation.",
    "key_points": [
      "retrieval",
      "embeddings",
      "limitations",
      "theoretical",
      "dataset",
      "evaluation"
    ],
    "gold_summary": "This paper provides fundamental limitation analysis of embedding models for IR, and shows that the such analysis results hold for many dataset instantiation."
  },
  {
    "paper_id": "ZKYPoPn0fP",
    "title": "Differentiable JPEG-based Input Perturbation for Knowledge Distillation Amplification via Conditional Mutual Information Maximization",
    "domain": "semi-supervised",
    "content": "Maximizing conditional mutual information (CMI) has recently been shown to enhance the effectiveness of teacher networks in knowledge distillation (KD). Prior work achieves this by fine-tuning a pretrained teacher to maximize a proxy of its CMI. However, fine-tuning large-scale teachers is often impractical, and proxy-based optimization introduces inaccuracies.\n To overcome these limitations, we propose Differentiable JPEG-based Input Perturbation (DJIP), a plug-and-play framework that improves teacher–student knowledge transfer without modifying the teacher. DJIP employs a trainable differentiable JPEG layer inserted before the teacher to perturb teacher inputs in a way that directly increases CMI. We further introduce a novel alternating optimization algorithm to efficiently learn the coding parameters of the JPEG layer to maximize the perturbed CMI. Extensive experiments on CIFAR-100 and ImageNet, across diverse distillers and architectures, demonstrate that DJIP consistently improves student accuracy-achieving up to 4.11% gains-while remaining computationally lightweight and fully compatible with standard KD pipelines.",
    "key_points": [
      "knowledge distillation",
      "jpeg",
      "conditional mutual information"
    ],
    "gold_summary": "This paper proposes DJIP, a plug-and-play framework to enhance KD without modifying teacher model weights. Experiments show that this method has certain effectiveness. Experiments show that this method has certain effectiveness."
  },
  {
    "paper_id": "3AyriKQDTd",
    "title": "Decrypt Modality Gap in Multimodal Contrastive Learning: From Convergent Representation  to Pair Alignment",
    "domain": "semi-supervised",
    "content": "Multimodal contrastive learning (MCL) aims to embed data from different modalities in a shared embedding space. However, empirical evidence shows that representations from different modalities occupy completely separate regions of embedding space, a phenomenon referred to as the modality gap. Moreover, experimental findings on how the size of the modality gap influences downstream performance are inconsistent. These observations raise two key questions: (1) What causes the modality gap? (2) How does it affect downstream tasks? To address these questions, this paper introduces the first theoretical framework for analyzing the convergent optimal representations of MCL and the modality alignment when training is optimized. Specifically, we prove that without any constraint or under the cone constraint, the modality gap converges to zero. Under the subspace constraint (i.e., representations of two modalities fall into two distinct hyperplanes due to dimension collapse), the modality gap converges to the smallest angle between the two hyperplanes. This result identifies \\emph{dimension collapse} as the fundamental origin of the modality gap. Furthermore, our theorems demonstrate that paired samples cannot be perfectly aligned under the subspace constraint. The modality gap influences downstream performance by affecting the alignment between sample pairs. We prove that, in this case, perfect alignment between two modalities can still be achieved via two ways: hyperplane rotation and shared space projection.",
    "key_points": [
      "clip",
      "modality gap",
      "multimodal",
      "representation learning",
      "contrastive learning",
      "vision-language models",
      "vlm"
    ],
    "gold_summary": "The paper tries to understand how the representations converge in multimodal settings."
  },
  {
    "paper_id": "s3ausR8BjZ",
    "title": "DGSM-SCAM-GAT and MMT-ViT: Multimodal and Graph-Based Malware Detection",
    "domain": "applications to computer vision",
    "content": "Malware detection encounters substantial challenges in real-time and multi-class tasks, as single-modality methods struggle to capture intricate behavioral patterns. To mitigate these limitations, we introduce two complementary models: DGSM-SCAM-GAT and MMT-ViT. The DGSM-SCAM-GAT model integrates dynamic gating, contextual aggregation mechanisms, and graph attention networks (GAT) to enhance temporal and structural modeling of API call sequences. Trained on a dynamic API call sequence dataset, it attains an accuracy of 99.31\\% and an F1-score of 99.64\\%, surpassing CNN-LSTM (accuracy: 98.92\\%). The MMT-ViT model employs multi-modal attention mechanisms and the pre-trained ViT architecture to effectively fuse features from assembly instruction sequences, binary grayscale images, and binary wavelet sequence features. Evaluated on a public dataset, it achieves 99.54\\% accuracy and 99.55\\% F1-score, outperforming Malcse (accuracy: 98.94\\%). Furthermore, ablation studies validate the critical contributions of individual modules, while comparative experiments underscore the superiority of our proposed models over state-of-the-art baselines. The detection frameworks developed in this study facilitate robust dynamic and static malware identification, with code available in the supplementary materials.",
    "key_points": [
      "malware detection*graph attention networks*dynamic gating mechanisms*multi-modal fusion*transfer learning"
    ],
    "gold_summary": "This paper introduces two innovative models, DGSM-SCAM-GAT and MMT-ViT, for malware detection. These models excel in capturing intricate behavioral patterns in API call sequences and fusing features from multiple modalities for effective malware identification."
  },
  {
    "paper_id": "SEjxNfQTHN",
    "title": "PSC: Efficient Grammar-Constrained Decoding via Parser Stack Classification",
    "domain": "applications to computer vision",
    "content": "LLMs are widely used to generate structured output like source code or JSON. Grammar-constrained decoding (GCD) can guarantee the syntactic validity of the generated output, by masking out tokens that violate rules specified by a context-free grammar. However, the online computational overhead of existing GCD methods, with latency typically scaling linearly with vocabulary size, limits the throughput of LLMs, especially for models with large vocabularies. To address this issue, we propose PSC, a novel grammar-constrained decoding method. By combining acceptance conditions of all vocabulary tokens into a single classifier of the parser stack during preprocessing, PSC can compute the complete vocabulary mask by checking the parser stack exactly once per decoding step, with time complexity independent of the vocabulary size. Experiments show that PSC computes masks up to 770× faster than baselines on complex programming language grammars, and up to 30× faster for schema-conformant JSON; end-to-end LLM throughput with PSC approaches that of unconstrained decoding.",
    "key_points": [
      "constrained decoding",
      "structured generation",
      "llm inference",
      "context-free grammars"
    ],
    "gold_summary": "The paper proposes PSC, a GCD method that precomputes a finite-state automaton mapping parser stacks to valid tokens, reducing decoding time complexity."
  },
  {
    "paper_id": "vphWR1NwGW",
    "title": "REVOLUTIONIZING EVENT DETECTION: A NOVEL PROMPT-DRIVEN METHOD ENHANCED BY RETRIEVAL-AUGMENTED PARADIGM",
    "domain": "applications to computer vision",
    "content": "Event Detection (ED) task involves extracting event triggers from sentences and classifying them into predefined event types. While large language models (LLMs) have become widely adopted across various NLP tasks, their application to ED remains relatively unexplored. All existing LLM-based approaches follow a traditional prompt-based paradigm, which requires designing distinct prompts for each event type. This strategy, however, suffers from a fundamental limitation: as the number of event types grows, the number of prompts needed increases linearly, resulting in significant manual effort and computational costs. To overcome this limitation, we propose a novel approach that integrates a retrieval-augmented mechanism with a redesigned cascading prompt-based framework. Specifically, the prompt-based component is employed to extract candidate triggers, while the retrieval-augmented module applies heuristic filtering strategies to coarsely eliminate irrelevant candidates. In addition, we put forward an innovative automated prompt-design method to accurately match valid triggers with their corresponding event types based on retrieved information. Experimental results on ACE-05 benchmark demonstrate the state-of-the-art performance under our scheme. Furthermore, the approach remains highly effective when using lightweight LLMs, indicating its strong potential for efficient large-scale data processing. This capability may have profound implications and become a fundamental work for future research.",
    "key_points": [
      "event detection",
      "large language models(llms)",
      "lightweight llms",
      "cascading prompt-based framework",
      "automated prompt-design"
    ],
    "gold_summary": "This paper presents REVO-ED, an event detection framework combining a multi-step cascading prompt strategy with a dual retrieval mechanism, aiming to reduce manual prompt design and improve scalability."
  },
  {
    "paper_id": "VpsqfCac2B",
    "title": "SpatialHand: Generative Object Manipulation from 3D Prespective",
    "domain": "applications to computer vision",
    "content": "We introduce SpatialHand, a novel framework for generative object insertion with precise 3D control. Current generative object manipulation methods primarily operate within the 2D image plane, but often fail to grasp 3D scene complexities, leading to ambiguities in an object's 3D position, orientation, and occlusion relations. SpatialHand addresses this by conceptualizing object insertion from a true ``3D perspective,\" enabling manipulation with a complete 6 Degrees-of-Freedom (6DoF) controllability. Specifically, our solution naturally and implicitly encodes the 6DoF pose condition by decomposing it into 2D location (via masked image), depth (via composited depth map), and 3D orientation (embedded into latent features). To overcome the scarcity of paired training data, we develop an automated data construction pipeline using synthetic 3D assets, rendering, and subject-driven generation, complemented by visual foundation models for pose estimation. We further design a multi-stage training scheme to progressively drive SpatialHand to robustly follow multiple complex conditions. Extensive experiments reveal our approach's superiority over existing alternatives and its great potential for enabling more versatile and intuitive AR/VR-like object manipulation within images.",
    "key_points": [
      "aigc application; image editing"
    ],
    "gold_summary": "This paper presents a method that enable object insertion with 3D control.\nThe main contribution from my point of view is the dataset curation pipeline and the ability to achieve better result of 3D control."
  },
  {
    "paper_id": "jHhTEYy0lb",
    "title": "StoryCoder: Bridging Narratives and Formality for Code Generation in LLMs",
    "domain": "applications to computer vision",
    "content": "The code generation capabilities of large language models stem largely from pretraining on structured code patterns and their strong context-based reasoning abilities. However, previous research on code generation has primarily focused on using short, fragmented, instruction-like prompts, which often fail to encourage contextual understanding. Inspired by the way humans organize fragmented information into coherent explanations, we propose a new method that reformulates coding problems as natural language narratives to promote integrative thinking. To this end, we introduce StoryCoder, a framework that reformulates code generation prompts into narrative text. Our results show that rich contextual expressions in natural language can enhance code generation performance and lead models to adopt consistent and structured problem-solving strategies. We quantitatively demonstrate that our method provides integrative information not captured by simple rephrasings and guides models to adopt correct algorithms and implementation strategies, thereby improving code generation performance. Experiments on three benchmarks, HumanEval, CodeForces, and LiveCodeBench, show an average improvement of 28.3% in the precision of zero-shot pass@10.",
    "key_points": [
      "natural language processing",
      "large language models",
      "code generation"
    ],
    "gold_summary": "The paper introduces StoryCoder, a framework to reformulate code generation prompts into richer, contextual expression. The experiments show that this translation leads to performance improvements across various benchmarks."
  },
  {
    "paper_id": "JeqXsxUTkn",
    "title": "SPOT: Structured Prompting with Object-centric Tokens for open-world scene graphs",
    "domain": "applications to computer vision",
    "content": "Scene graphs provide a compact and structured representation of visual scenes by capturing objects and their relationships, making them valuable for downstream tasks in vision-language reasoning and robotics. While early work focused on closed-vocabulary settings, newer efforts have shifted toward open-world scene graph generation (SGG) to better handle diverse real-world scenarios. Recent works explore leveraging VLMs and LLMs in open-world settings for their broad, openvocabulary knowledge. However, existing approaches often rely on proprietary models like GPT-4o and are limited by the unstructured output behavior and weak spatial and object-level reasoning capabilities of pretrained models. We introduce SPOT, a structured prompting framework that augments open-source VLMs with spatial reasoning abilities for scene graph generation with minimal training. By combining object-centric visual features with the model’s knowledge priors, SPOT achieves competitive or superior relation prediction compared to large proprietary models. Additionally, SPOT demonstrates strong cross-domain generalization, including extension to 3D scenes. Our approach is built upon open-source models, offering a scalable and accessible framework for harnessing VLMs for SGG.",
    "key_points": [
      "scene graph generation",
      "open-vocabulary learning",
      "spatial reasoning"
    ],
    "gold_summary": "Authors propose SPOT, an open-source novel structured prompting framework leveraging vision language models for scene graph generation. It demonstrates effective spatial and semantic reasoning, outperforming proprietary baselines like GPT-4o on open-world benchmarks."
  },
  {
    "paper_id": "NugrqeNGjp",
    "title": "HybridSketchNet: Sketch-based 3D Human Mesh Reconstruction via Hybrid Point-Image Networks",
    "domain": "applications to computer vision",
    "content": "Sketches are an efficient and effective tool for generating 3D human meshes with arbitrary body shapes and poses. However, current mesh reconstruction methods are mainly designed for natural images, which are hard to apply to sketches due to the abstract and sparse characteristics of the latter. Moreover, there is no dataset with sufficient sketch-meshes pairs for developing and evaluating relevant methods. To tackle these issues, we introduce a hybrid framework that fits parametric human models (e.g., skinned multi-person linear model) to sketches in a coarse-to-fine manner. Specifically, the proposed framework consists of three core components: (i) Given a sketch image as the input, a vision transformer-based Local Image Encoder (LIE) is introduced to model the local structures of the sketch and yields a coarse mesh estimation. (ii) A Global Point Encoder (GPE) taking the 2D coordinates of sketch contours as inputs, is also utilized to obtain the global representation of the sketch. (iii) As the local presentation can depict human poses more precisely while the global representation is more suitable for body shapes, we propose a graph-based refiner (GRefiner) to leverage the advantages of both representations and generate the final well-fitted mesh. Furthermore, we collect a large-scale dubbed Sketch3DS, containing approximately 10,000 paired sketches and human meshes with diverse poses and shapes. Extensive experiments on Sketch3DS demonstrate that the proposed approach outperforms existing methods, achieving accurate alignment between input sketches and constructed human meshes.",
    "key_points": [
      "sketch",
      "3d human",
      "mesh reconstruction",
      "parametric mode"
    ],
    "gold_summary": "This paper proposed a sketch-based 3D human mesh reconstruction method. 3D human reconstruction from sketches is interesting. The experimental results demonstrate the effectiveness of the proposed method."
  },
  {
    "paper_id": "5EDWoVfmDH",
    "title": "SATS : Scenario-Anchored Topological Scoring in Figurative Expression",
    "domain": "applications to computer vision",
    "content": "Figurative expressions remain challenging for language models, which often default to literal interpretations rather than capturing implicit meaning. This vulnerability affects the understanding of everyday dialogue and increases the exposure to adversarial prompts that exploit figurative or indirect phrasing. We integrate a topology-based algorithm into encoder-only architectures to strengthen signals relevant to figurative meaning and observe consistent improvements across multiple benchmarks. We further propose SATS, which achieves low latency and matches or exceeds most open-source LLMs while using 9.6× fewer parameters (within 0.8%p of Qwen3). Our approach is lightweight and model-agnostic, and complements instruction-tuned LLMs by improving the robustness of detecting and interpreting figurative and implicit meaning.",
    "key_points": [
      "figurative expression",
      "topology data analysis",
      "attention analysis"
    ],
    "gold_summary": "The paper introduces a new method for figurative language understanding based on topological data analysis. The approach complements existing LLMs by increasing their robustness and achieves performance gains on fig lang understanding benchmarks."
  },
  {
    "paper_id": "tMzp5mr5jN",
    "title": "CLARA: Convex Low-resource Accent-Robust Language Detection in ASR",
    "domain": "applications to computer vision",
    "content": "Globalization and multiculturalism have produced diverse speech varieties (e.g., Singaporean-accented English and regional Hindi dialects) that remain underrepresented even in high-resource language data. As a result, spoken dialogue systems frequently misidentify the user’s input language up to 49.33\\% of the time, degrading response accuracy regardless of language model capability. \nWe propose a robust ASR framework for handling low-resource dialectal variance with reduced computational overhead, and lightweight training costs. Our Convex Language Detection (CLD) algorithm integrates a convex reformulation of NN, and is solved efficiently with ADMM in JAX. This provides human-level sub-500ms inference latency, strong convergence guarantees and reduced sample complexity. As a motivating case study, CLD significantly improves transcription accuracy on mixed-dialect inputs when integrated with Whisper encoders. This demonstrates promising directions for principled statistical generalization in spoken dialogue systems for low-resource languages.",
    "key_points": [
      "convex neural networks",
      "asr",
      "spoken dialogue systems",
      "low-resource languages"
    ],
    "gold_summary": "This paper introduces a convex language detection framework for integration into ASR systems. The aim is to improve the performance of these systems for diverse dialects."
  },
  {
    "paper_id": "l9MqBHCb91",
    "title": "RoRecomp: Enhancing Reasoning Efficiency via Rollout Response Recomposition in Reinforcement Learning",
    "domain": "applications to computer vision",
    "content": "Reinforcement learning with verifiable rewards (RLVR) has proven effective in eliciting complex reasoning in large language models (LLMs). However, standard RLVR training often leads to excessively verbose processes (in reasoning tasks) and inefficient exploration trajectories (in agentic settings), as outcome-only rewards provide no incentive for efficiency and the high variance in response length within relatively small rollout groups results in noisy optimization signals.\nTo address this, we propose Rollout Response Recomposition (RoRecomp), a plug-and-play method that guides models toward concise reasoning by strategically recomposing the training data.\nRoRecomp separates responses into two distinct batch types: 1) priority batches, which combine the short-correct and long-incorrect responses selected from online batches to provide a clear gradient signal for brevity, and 2) compensation batches, which utilize the remaining responses stored in a replay buffer to maintain training stability and prevent model collapse.\nTo comprehensively evaluate effectiveness, we test RoRecomp across three settings where results demonstrate substantial efficiency gains: reducing reasoning length by 27.7\\% in zero RL training, reducing unnecessary tool calls by 46.8\\% while improving accuracy in agentic RL, \nand achieving up to 52.5\\% length reduction in thinking compression, all with minimal performance impact.",
    "key_points": [
      "large language model",
      "reasoning model",
      "reinforcement learning",
      "efficient ai"
    ],
    "gold_summary": "This paper proposes a method called RoRecomp to improve the reasoning efficiency of LLMs under the RLVR framework, i.e., reducing verbosity in the reasoning process while maintaining accuracy."
  },
  {
    "paper_id": "Hhr220TJFh",
    "title": "Temporally Aligned Relation Modeling for Panoptic Video Scene Graph Generation",
    "domain": "applications to computer vision",
    "content": "Panoptic Video Scene Graph Generation (PVSG) aims to achieve a comprehensive video understanding by segmenting entities and predicting their temporal relations. These temporal relations vary in duration and evolve dynamically over time. However, existing methods model relations over the entire video sequence, making it difficult to align the perception scope with actual interaction intervals and often introducing irrelevant context. To address this, we propose TempFocusNet (TFNet), a new framework that first localizes the intervals where relations occur and then performs focused context modeling within them, enabling temporally aligned and more accurate relation prediction. Specifically, we extract visual and category semantic features for each entity to construct temporally continuous entity feature tubes. Then, multiple temporal queries interact with paired entity tubes to capture diverse temporal cues and generate candidate relation intervals, which are represented as Gaussian masks to model their temporal structure. Finally, the Gaussian masks guide the temporal focus attention to attend to relevant intervals for relation classification. Extensive experiments show that our TFNet achieves state-of-the-art performance on OpenPVSG and ImageNet-VidVRD datasets. The code of our TFNet will be made available.",
    "key_points": [
      "panoptic video scene graph generation; scene understanding; activity analysis"
    ],
    "gold_summary": "The paper tackles Scene Graph Generation by predicting interaction intervals as 2D Gaussian mask, differentiating itself from perframe prediction of previous works."
  },
  {
    "paper_id": "y5zEWTT1O0",
    "title": "GaussianLens: Localized High-Resolution Reconstruction via On-Demand Gaussian Densification",
    "domain": "applications to computer vision",
    "content": "We perceive our surrounding environments with an active focus, paying more attention to regions of interest, such as the shelf labels in a grocery store or a family photo on the wall. When it comes to scene reconstruction, this human perception trait calls for spatially varying degrees of detail ready for closer inspection in critical regions, preferably reconstructed on demand as users shift their focus. While recent approaches in 3D Gaussian Splatting (3DGS) can achieve fast, generalizable scene reconstruction from sparse views, their uniform resolution output leads to high computational costs, making them unscalable to high-resolution training. As a result, they cannot leverage available image captures at their original high resolution for detail reconstruction. Per-scene optimization methods reconstruct finer details with heuristic-based adaptive density control, yet require dense observations and lengthy offline optimization. To bridge the gap between the prohibitive cost of high-resolution holistic reconstructions and the user needs for localized fine details, we propose the problem of localized high-resolution reconstruction through on-demand generalizable Gaussian densification. Given an initial low-resolution 3DGS reconstruction, the goal is to learn a generalizable network that densifies the reconstruction to capture fine details in a user-specified local region of interest (RoI), based on sparse high-resolution observations of the RoI. This formulation avoids the high cost and redundancy of uniformly high-resolution reconstructions and enables the full leverage of high-resolution observations in critical regions. To address the problem, we propose GaussianLens, a feed-forward densification framework that fuses multi-modal information from the initial 3DGS and multi-view images. We further propose a pixel-guided densification mechanism that effectively captures details under significant resolution increases. Experiments demonstrate our method's superior performance in local high-fidelity detail reconstruction and strong scalability to images of up to $1024\\times1024$ resolution.",
    "key_points": [
      "3d gaussian splatting",
      "3d reconstruction"
    ],
    "gold_summary": "This paper introduces GaussianLens, a framework for efficient, localized high-resolution 3D reconstruction. It avoids the cost of uniform high-resolution models by starting with a coarse scene and then densifying only a user-specified ROI."
  },
  {
    "paper_id": "XVonoE8dWs",
    "title": "LSMSeg: Unleashing the Power of Large-Scale Models for Open-Vocabulary Semantic Segmentation",
    "domain": "applications to computer vision",
    "content": "Open-vocabulary semantic segmentation requires precise pixel-level alignment of visual and textual representations, leveraging text as a universal reference to address visual disparities across diverse datasets. \nWhile prior efforts have primarily focused on enhancing visual representations or alignment models, the contribution of textual representations remains underexplored. \nMoreover, although CLIP excels at capturing image-level features, its limited capacity for fine-grained pixel-level representation poses a major challenge for semantic segmentation.\nTo address these challenges, we propose LSMSeg that employs large language models (LLMs) to generate enriched text prompts incorporating diverse visual attributes such as color, shape, size, and texture, thereby replacing simplistic templates with semantically rich descriptions.\nIn addition, we propose a Feature Refinement Module that adapts visual features from the Segment Anything Model (SAM) to the CLIP space using a lightweight adapter, followed by a learnable weighting strategy to fuse them with CLIP features, enhancing pixel-to-text alignment.\nTo further reduce computational overhead, we introduce a Category Filtering Module to accelerate training and decrease parameter complexity. \nExtensive experiments demonstrate that LSMSeg significantly enhances cross-modal alignment and achieves strong performance while maintaining efficiency, offering a robust advancement for open-vocabulary semantic segmentation.",
    "key_points": [
      "open-vocabulary semantic segmentation",
      "large language models",
      "visual attributes"
    ],
    "gold_summary": "This paper enhances expressiveness of the text prompts by levering the LLM, thereby enhancing the performance in 2D open-vocabulary semantic segmentation."
  },
  {
    "paper_id": "tAfew5gRmm",
    "title": "AMLRIS: Alignment-aware Masked Learning for Referring Image Segmentation",
    "domain": "applications to computer vision",
    "content": "Referring Image Segmentation (RIS) aims to segment the object in an image uniquely referred to by a natural language expression. However, RIS training often contains hard-to-align and instance-specific visual signals; optimizing on such pixels injects misleading gradients and drives the model in the wrong direction. By explicitly estimating pixel-level vision–language alignment, the learner can suppress low-alignment regions, concentrate on reliable cues, and acquire more generalizable alignment features.\nIn this paper, we propose Alignment-Aware Masked Learning (AML), a simple yet effective training strategy that quantifies region–referent alignment (PMME) and filters out unreliable pixels during optimization (AFM). Specifically, each sample first computes a similarity map between visual and textual features, and then masks out pixels falling below an adaptive similarity threshold, thereby excluding poorly aligned regions from the training process. AML does not require architectural changes and incurs no inference overhead, directing attention to the areas aligned with the textual description. Experiments on the RefCOCO (vanilla/+/g) datasets show that AML achieves state-of-the-art results across all 8 splits, and beyond improving RIS performance, AML also enhances the model’s robustness to diverse descriptions and scenarios.",
    "key_points": [
      "reference image segmentation， masked learning， vlm"
    ],
    "gold_summary": "- This work proposes Alignment-Aware Masked Learning (AML), a training strategy that quantifies region–referent alignment (PMME) and filters out unreliable pixels during optimization (AFM), which is validated to improve RIS performance."
  },
  {
    "paper_id": "Cd1tpJv2Df",
    "title": "FrePhys: Frequency-aware Diffusion Model for Remote Physiological Measurement",
    "domain": "applications to computer vision",
    "content": "Remote photoplethysmography (rPPG) enables non-contact physiological monitoring by capturing subtle skin color variations in facial videos. Existing approaches predominantly rely on time-domain modeling to extract cardiac-related periodic signals, but they are highly vulnerable to motion artifacts and illumination changes, where physiological clues are easily obscured by noise. To address these challenges, we propose a Frequency-aware Physiological diffusion model, dubbed FrePhys, that integrates physiological frequency priors into rPPG estimation. Specifically, it first employs a \\textit{physiological bandpass filter} to suppress out-of-band noise, followed by \\textit{physiological spectrum modulation} and \\textit{adaptive spectrum selection} for in-band noise suppression and pulse-related clues enhancement. A \\textit{cross-domain representation learning} module then fuses frequency-domain insights with the deep time-domain features to capture spatial–temporal dependencies. Finally, a frequency-aware conditional diffusion process iteratively reconstructs high-fidelity rPPG signals. Extensive experiments on multiple datasets demonstrate that our method significantly outperforms existing state-of-the-art methods, particularly under challenging motion conditions, highlighting the effectiveness of incorporating frequency priors. The source code is available at \\url{https://anonymous.4open.science/r/FrePhys}.",
    "key_points": [
      "remote physiological measurement"
    ],
    "gold_summary": "The paper propose a frequency-aware diffusion model for remote PPG estimation from face videos. Results on UBFC, PURE, VIPL-HR, and MMPD show state-of-the-art heart rate and HRV performance."
  },
  {
    "paper_id": "4S0yZPVxex",
    "title": "TR-MERGING: TRAINING-FREE ROUTER FOR MODEL MERGING",
    "domain": "applications to computer vision",
    "content": "With the rapid advancement of deep learning, a wide variety of open-source models for different tasks have emerged. However, a single fine-tuned model often fails to meet users' diverse requirements. To address this limitation, model merging has been proposed as an effective approach to integrate the capabilities of existing models into a unified one. Among existing approaches, router-based methods have become representative baselines due to their strong performance; however, their reliance on a trainable router compromises the appealing advantage of traditional model merging—being completely training-free.In this paper, we propose a training-free router from a similarity-based perspective. Our method achieves performance on par with router-based approaches while eliminating the need for any additional training. We demonstrate the effectiveness of TR-Merging across multiple tasks in both computer vision (CV) and natural language processing (NLP), and demonstrate its flexibility in adapting to diverse requirements.",
    "key_points": [
      "model merging",
      "router",
      "llm",
      "training free"
    ],
    "gold_summary": "The paper proposes TR-Merging, a training-free router framework for model merging that integrates multiple fine-tuned models (experts) without additional training."
  },
  {
    "paper_id": "OKoHklMUVs",
    "title": "TCI: Mitigating Hallucination in LVLMs Via Text Contrastive Intervention",
    "domain": "applications to computer vision",
    "content": "Large Vision-Language Models (LVLMs) have achieved remarkable progress across a wide range of tasks by integrating visual and textual information. Yet they still suffer from a common issue: hallucination, where the generated text fails to accurately align with visual inputs. Existing contrastive methods primarily intervene on the visual modality, perturbing images to indirectly amplify language priors, but fail to directly target text to expose and mitigate text bias. To address this, we propose \\textbf{T}ext \\textbf{C}ontrastive \\textbf{I}ntervention (TCI), a training-free approach that amplifies visual information in those attention layers most susceptible to language bias. Our method is inspired by a key observation: the \\textit{repetition phenomenon}, where LVLMs tend to verbatim repeat text when conflicts arise between the images and accompanying text. We hypothesize this behavior stems from language priors—a critical cause of hallucinations. TCI operates in two steps: first quantifying per‑layer attention shifts under text perturbation to identify the layers where visual attention is most compromised; then we selectively boost the corresponding visual‑attention weights during generation, steering the model away from text bias. Extensive experiments demonstrate that TCI significantly reduces hallucinations while requiring only a small amount of data, demonstrating its effectiveness and efficiency.",
    "key_points": [
      "hallucination",
      "lvlms"
    ],
    "gold_summary": "This paper proposes a simple mechanism that strengthens the attention weights of visual tokens, which the authors claim helps reduce hallucination."
  },
  {
    "paper_id": "qQImgBwlDA",
    "title": "Proto-SaGa: Prototype-based 3D Scene Segmentation with Semantic-aware Gaussian Grouping",
    "domain": "applications to computer vision",
    "content": "Segment anything models (SAM), trained with lots of ground-truth labels, have achieved strong performance in 2D scene segmentation. Compared to this, accurate 3D scene segmentation remains challenging, since annotating consistent segmentation masks across multiple views is highly labor-intensive. To address this, many approaches have been proposed using inconsistent masks predicted by SAM as pseudo labels. They typically build on 3D Gaussian splatting (3DGS) to synthesize and segment novel views in a 3D scene simultaneously. To be specific, several 3DGS-based methods focus on associating the inconsistent masks across training views so that a classifier is trained with the associated masks. They however have two limitations: (1) the association process considers only the location of each 3D Gaussian in the scene and (2) training a classifier with the associated masks is prone to overfitting to incorrect labels of the associated masks. We introduce in this paper Proto-SaGa, a novel 3DGS-based framework that addresses the aforementioned limitations. Specifically, we present a semantic-aware mask association strategy that exploits both location and high-level semantics of each Gaussian to improve the consistency of the associated masks. We also propose a novel inference scheme that alleviates the influence of possibly incorrect results within the associated masks. Specifically, we obtain a set of prototypes by averaging features with the consistent masks, and use it as a classifier at test time without further training. Extensive experiments on Replica, LERF-Mask, ScanNet, and Mip-NeRF 360 demonstrate the effectiveness of our approach. We will make our code publicly available upon acceptance.",
    "key_points": [
      "3d scene understanding",
      "3d scene segmentation",
      "multi-view segmentation",
      "3d gaussian splatting"
    ],
    "gold_summary": "The manuscript introduces a semantic-aware mask association and prototype-based inference framework that jointly leverages geometric and semantic cues within the 3D Gaussian Splatting representation to produce more consistent object segmentation."
  },
  {
    "paper_id": "Rr98fNjOlT",
    "title": "LightAgent: Lightweight and Cost-Efficient Mobile Agents",
    "domain": "applications to computer vision",
    "content": "With the advancement of multimodal large language models (MLLMs), building GUI agent systems has become an increasingly promising direction—especially for mobile platforms, given their rich app ecosystems and intuitive touch interactions. Yet mobile GUI agents face a critical dilemma: truly on-device models (4B or smaller) lack sufficient performance, while capable models (starting from 7B) are either too large for mobile deployment or prohibitively costly (e.g., cloud-only closed-source MLLMs). To resolve this, we propose LightAgent, a mobile GUI agent system that leverages device-cloud collaboration to tap the cost-efficiency of on-device models and the high capability of cloud models, while avoiding their drawbacks. Specifically, LightAgent enhances Qwen2.5-VL-3B via two-stage SFT→GRPO training on synthetic GUI data for strong decision-making, integrates an efficient long-reasoning mechanism to utilize historical interactions under tight resources, and defaults to on-device execution—only escalating challenging subtasks to the cloud via real-time complexity assessment. Experiments on the online AndroidLab benchmark and diverse apps show LightAgent matches or nears larger models, with a significant reduction in cloud costs.",
    "key_points": [
      "gui agent",
      "llm",
      "reinforcement learning"
    ],
    "gold_summary": "This paper designs a device-cloud collaboration framework to solve mobile\ninteraction tasks efficiently and effectively. The exhibited results are\npromising. However, the paper is not perfectly polished, holds obvious symbol\ninconsistency and typos."
  },
  {
    "paper_id": "Prni6X1V8Z",
    "title": "Multi-Modal Point Cloud Completion with Intra- and Inter-Graph Transformer",
    "domain": "applications to computer vision",
    "content": "Multi-modal point cloud completion aims to leverage complementary image information to assist point cloud completion. Existing multi-modal approaches predominantly employ Transformers to facilitate interactions between different modalities. However, fully-connected attention-based Transformers lead to high computational cost and redundancy, and often fail to fully capture the complex relations between these modalities. To address these issues, we propose the Intra- and Inter-Graph Transformer (I$^{2}$GraphFormer), which leverages sparse graph connections to restrict attention to neighboring nodes both within and across modalities. I$^{2}$GraphFormer enhances interactions in terms of efficiency and expressiveness. Specifically, we model relations from both intra-graph and inter-graph perspectives, obtaining more expressive representations and producing higher-quality completion results. Extensive quantitative and qualitative experiments demonstrate that I$^{2}$GraphFormer outperforms state-of-the-art multi-modal approaches across various evaluation scenarios with low complexity.",
    "key_points": [
      "graph transformer; multi-modal point cloud completion"
    ],
    "gold_summary": "This paper proposes I2GraphFormer, an Intra- and Inter-Graph Transformer for multi-modal point cloud completion, which aims to leverage complementary image information to enhance 3D completion quality."
  },
  {
    "paper_id": "h5KLpGoqzC",
    "title": "Hierarchical Semantic-Acoustic Modeling via Semi-Discrete Residual Representations for Expressive End-to-End Speech Synthesis",
    "domain": "applications to computer vision",
    "content": "Generative models for speech synthesis face a fundamental trade-off: discrete tokens ensure stability but sacrifice expressivity, while continuous signals retain acoustic richness but suffer from error accumulation due to task entanglement. This challenge has driven the field towards multi-stage pipelines that rely on pre-trained speech tokenizers, but these create a semantic-acoustic divide, limiting holistic and expressive speech generation.  We resolve these dilemma through hierarchical semantic-acoustic modeling with semi-discrete residual representations.Our framework introduces a differentiable quantization bottleneck that induces natural specialization: a Text-Semantic Language Model (TSLM) generates semantic-prosodic plans, while a Residual Acoustic Model (RALM) recovers fine-grained acoustic details.This hierarchical semantic-acoustic representation guides a local diffusion-based decoder to generate high-fidelity speech latents. \nCritically, the entire architecture is trained end-to-end under a simple diffusion objective, eliminating dependency on external speech tokenizers. Trained on over 1 million hours of speech, our 0.5B-parameter model achieves state-of-the-art zero-shot TTS performance among open-source systems, demonstrating that our approach delivers expressive and stable synthesis. Audio samples are available at: https://voxcpm.github.io/VoxCPM-demopage/.",
    "key_points": [
      "text-to-speech synthesis",
      "diffusion language model",
      "semi-discrete representations",
      "voice cloning"
    ],
    "gold_summary": "The paper proposes a cascaded TTS model that predicts semantic tokens, refine with added residual latents and finally decoded into speech latents with a latent diffusion model."
  },
  {
    "paper_id": "5EHjQYOVjn",
    "title": "Align Your Query: Representation Alignment for Multimodality Medical Object Detection",
    "domain": "applications to computer vision",
    "content": "Medical object detection suffers when a single detector is trained on mixed medical modalities (e.g., CXR, CT, MRI) due to heterogeneous statistics and disjoint representation spaces. To address this challenge, we turn to representation alignment, an approach that has proven effective for bringing features from different sources into a shared space. Specifically, we target the representations of DETR-style object queries and propose a simple, detector-agnostic framework to align them with modality context. First, we define modality tokens: compact, text-derived embeddings encoding imaging modality that are lightweight and require no extra annotations. We integrate the modality tokens into the detection process via Multimodality Context Attention (MoCA), mixing object-query representations via self-attention to propagate modality context within the query set. This preserves DETR-style architectures and adds negligible latency while injecting modality cues into object queries. We further introduce QueryREPA, a short pretraining stage that aligns query representations to their modality tokens using a task-specific contrastive objective with modality-balanced batches. Together, MoCA and QueryREPA produce modality-aware, class-faithful queries that transfer effectively to downstream training. Across diverse modalities trained altogether, the proposed approach consistently improves AP with minimal overhead and no architectural modifications, offering a practical path toward robust multimodality medical object detection.",
    "key_points": [
      "medical object detection",
      "representation alignment"
    ],
    "gold_summary": "The paper proposes a DETR-based object detection framework tailored for multimodal medical imaging, introducing two key components, MoCA  and Query REPA, that reportedly enhance the performance of existing detection models in medical scenarios."
  },
  {
    "paper_id": "SuLp0J2uan",
    "title": "Stylized Handwriting Generation of Arbitrary Structures and OOV Expressions: A Decoupled Approach via Layout-Offsets",
    "domain": "applications to computer vision",
    "content": "To truly understand human handwriting, machines must not only recognize glyphs but also generate them. However, most existing approaches are limited to synthesizing isolated characters or handwritten texts of linear sequences, whereas the stylized synthesis of handwriting with arbitrary layout structures remains largely underexplored, such as handwritten mathematical expression generation (HMEG). Existing approaches have failed to address such cases, as it is challenging to simultaneously generate complex layout structures and imitate calligraphic styles, especially for out-of-vocabulary (OOV) expressions. Inspired by how humans write, where layout structuring and glyph shaping are inherently separated, we therefore propose a glyph-layout decoupled paradigm for stylized HMEG. To better facilitate the generation of arbitrary layout structures,  we leverage printed layouts as strong prior guidance and propose generating layout offsets instead of absolute positions. To achieve stylized glyph-layout synthesis, we further incorporate implicit context adaptation via cross-attention to jointly mimic structured layouts and calligraphic glyphs from reference examples. By treating reference layouts and glyphs as external implicit contexts, our model selectively attends to relevant stylistic features of each symbol and its bounding box. Experiments demonstrate that our method outperforms previous SoTA approaches in terms of visual quality, semantic and structural correctness, and style consistency for stylized HMEG.",
    "key_points": [
      "handwriting generation",
      "handwritten mathematical expressions."
    ],
    "gold_summary": "This paper presents a significant advancement in handwriting generation, pioneering stylized handwriting with arbitrary layout structures. This highly novel contribution addresses a critical gap in the field."
  },
  {
    "paper_id": "PVooP3d7cI",
    "title": "The Price of a Second Thought: On the Evaluation of Reasoning Efficiency in Large Language Models",
    "domain": "applications to computer vision",
    "content": "Recent thinking models trained with reinforcement learning and backwardchecking CoT often suffer from overthinking: they produce excessively long outputs even on simple problems, wasting computation. Existing evaluations, based on token efficiency, give an incomplete view as they neglect problem difficulty and intermediate computation costs. We formalize reasoning efficiency as a relative measure between thinking and instruct models, treating instruct models as the minimal-effort baseline. A systematic study across four thinking models and multiple benchmarks reveals two consistent patterns: (i) instruct models achieve higher efficiency overall, and (ii) problem difficulty affects efficiency, with thinking models wasting computation on easy problems but providing value on harder ones. Building on this insight, we propose COTHINK, a simple two-stage pipeline: an instruct model drafts a brief outline, and a thinking model expands it. On GSM8K, MATH500, and AIME24, COTHINK cuts token usage by 21.1% while keeping accuracy on four thinking models, and remains competitive with strong efficiency baselines.",
    "key_points": [
      "reasoning efficiency",
      "test-time scaling",
      "large language models",
      "chain-of-thought"
    ],
    "gold_summary": "this paper focuses on reasoning efficiency in thinking models, providing a clean definition of thinking efficiency, analyzing thinking and non-thinking models, and provide a two-stage prompting method to enhance efficiency"
  },
  {
    "paper_id": "CL5D33stq1",
    "title": "OViP: Online Vision-Language Preference Learning for VLM Hallucination",
    "domain": "applications to computer vision",
    "content": "Large vision-language models (LVLMs) remain vulnerable to hallucination, often generating content misaligned with visual inputs. \n  Although recent training-based approaches aim to mitigate hallucination, they typically rely on predefined or randomly edited negative samples that do not reflect actual model errors, thus limiting training efficacy.\n  In this work, we propose an Online Vision-language Preference Learning (OViP) framework that dynamically constructs contrastive training data based on the model’s own hallucinated outputs. By identifying semantic differences between sampled response pairs and synthesizing negative images using a diffusion model, OViP generates more relevant supervision signals in real time. This failure-driven training enables adaptive alignment of both textual and visual preferences. Moreover, we refine existing evaluation protocols to better capture the trade-off between hallucination suppression and expressiveness. Experiments on hallucination and general benchmarks demonstrate that OViP not only reduces hallucinations while preserving core multi-modal capabilities, but also substantially improves training efficiency.",
    "key_points": [
      "online learning",
      "multimodal",
      "hallucination"
    ],
    "gold_summary": "In this paper, the authors propose an online preference tuning method to reduce hallucination in LVLMs by using diffusion models to generate paired images."
  },
  {
    "paper_id": "lFn1Bb1ZMD",
    "title": "Adaptable Symbolic Music Infilling with MIDI-RWKV",
    "domain": "applications to computer vision",
    "content": "Existing work in automatic music generation has mostly focused on end-to-end systems that generate either entire compositions or continuations of pieces, which are difficult for composers to iterate on. The area of computer-assisted composition, where generative models integrate into existing creative workflows, remains comparatively underexplored. In this study, we address the tasks of model style adaptation and multi-track, long-context, and controllable symbolic music infilling to enhance the process of computer-assisted composition. We present MIDI-RWKV, a small foundation model based on the RWKV-7 linear architecture, to enable efficient and coherent musical cocreation on edge devices. We also demonstrate that MIDI-RWKV admits an effective method of finetuning its initial state for style adaptation in the very-low-sample regime. We evaluate MIDI-RWKV and its state tuning on several quantitative and qualitative metrics with respect to existing models, and release model weights and code in the supplementary materials.",
    "key_points": [
      "generative models",
      "music modeling and analysis",
      "symbolic music",
      "musical infilling",
      "state tuning"
    ],
    "gold_summary": "This paper proposes a new training pipeline for symbolic music generation using RWKV and state tuning."
  },
  {
    "paper_id": "0wwcANeTjd",
    "title": "Variable-Length Audio Fingerprinting",
    "domain": "applications to computer vision",
    "content": "Audio fingerprinting converts audio to much lower-dimensional representations, allowing distorted recordings to still be recognized as their originals through similar fingerprints. Existing deep learning approaches rigidly fingerprint fixed-length audio segments, thereby neglecting temporal dynamics during segmentation. To address limitations due to this rigidity, we propose Variable-Length Audio FingerPrinting (VLAFP), a novel method that supports variable-length fingerprinting. To the best of our knowledge, VLAFP is the first deep audio fingerprinting model capable of processing audio of variable length, for both training and testing. Our experiments show that VLAFP outperforms existing state-of-the-arts in live audio identification and audio retrieval across three real-world datasets.",
    "key_points": [
      "audio fingerprinting",
      "audio retrieval",
      "variable-length segmentation",
      "signal representation",
      "audio representation"
    ],
    "gold_summary": "The paper proposes an attention-based audio fingerprinting method capable of handling variable-length input audio."
  },
  {
    "paper_id": "OkNxZGenYr",
    "title": "ReFocusEraser: Refocusing for Small Object Removal with Robust Context-Shadow Repair",
    "domain": "applications to computer vision",
    "content": "Existing diffusion-based object removal and inpainting methods often fail to recover the fine structural and textural details of small objects. This is primarily due to the VAE encoder’s downsampling, which inevitably compresses small masked regions and causes significant detail loss, while the decoder’s upsampling alone cannot fully restore the lost fine details.\nHowever, the adverse effects of this fixed compression can be mitigated by enlarging the perspective of these regions.\nTo this end, we propose ReFocusEraser, a two-stage framework for small object removal that combines camera-adaptive zoom-in inpainting with robust context- and shadow-aware repair. In Stage I, a camera-adaptive refocus mechanism magnifies masked regions, and a LoRA-tuned diffusion model ensures precise semantic alignment for accurate reconstruction. However, reintegrating these magnified inpainted regions into the original image introduces challenges due to VAE asymmetry, such as color shifts and seams. Stage II addresses these issues by fine-tuning an additional decoder to create a seam- and shadow-aware module that eliminates residual artifacts while preserving background consistency. \nExtensive experiments demonstrate that our proposed RefocusEraser achieves state-of-the-art performance, outperforming existing methods across benchmark datasets.",
    "key_points": [
      "diffusion-based object removal， image inpainting"
    ],
    "gold_summary": "This paper proposes ReFocusEraser, an innovative two-stage framework for small masked object removal with robust context and shadow repair."
  },
  {
    "paper_id": "YXGMrLdqBY",
    "title": "CoDiffSplat: Sparse-View Generalizable 3D Gaussian Splatting with Single-Step Conditional Diffusion",
    "domain": "applications to computer vision",
    "content": "Generalizable 3D Gaussian Splatting (G-3DGS) has emerged as a promising approach for novel view synthesis under sparse-view settings.\nHowever, existing frameworks remain restricted by pixel-aligned Gaussian estimation, which struggles in regions that are partially observed or occluded, often resulting in incomplete geometry and structural collapse. \nTo overcome these challenges, we propose CoDiffSplat, a new framework that couples semantic-conditioned latent diffusion with 3D Gaussian splatting. \nOur design departs from conventional diffusion applied on image feature maps: instead, a lightweight single-step diffusion directly refines Gaussian parameters, ensuring efficiency while preserving geometric consistency. \nIn addition, we introduce a Cross-View Entropy-Aware (CEA) module that aggregates multi-view semantics and geometry into robust conditional embeddings, enabling diffusion to resolve ambiguities under occlusion and sparse overlap. \nComprehensive experiments on multiple benchmarks demonstrate that CoDiffSplat consistently improves geometric quality and structural completeness, especially under challenging extrapolation settings.\nOur study establishes conditional diffusion as a scalable refinement mechanism for sparse-view 3D reconstruction, advancing the reliability of generalizable Gaussian splatting.",
    "key_points": [
      "sparse-view",
      "g-3dgs",
      "conditional diffusion",
      "novel view synthesis"
    ],
    "gold_summary": "This work proposes introducing semantic-conditioned latent diffusion to enhance the reconstruction performance of Generalizable 3D Gaussian Splatting under sparse views. The authors claim that this method achieves better performance compared to previous works."
  },
  {
    "paper_id": "7b4bHY4dxJ",
    "title": "Towards Few-Shot Adaptation for Dense Cross-Modality Image Matching",
    "domain": "applications to computer vision",
    "content": "Cross-modality image matching aims to establish correspondences between images captured under different sensing modalities. Recent advances in transformer-based dense matchers and large-scale synthetic training data have led to foundation models with strong generalization to unseen modalities. However, their performance degrades when the target modality diverges substantially from the pretraining distribution, making domain-specific adaptation essential. Since annotated data is often costly and limited, while unlabelled data is plentiful, we address this challenge by adapting pretrained dense matchers with a combination of few-shot labelled and abundant unlabelled samples. Specifically, we exploit the multi-scale architecture of dense matchers by using the finest-scale predictions to guide learning at coarser scales on unlabelled data. Extensive experiments across diverse modalities demonstrate that our approach consistently outperforms both foundation models and purely supervised adaptation, achieving up to 40% improvement in matching accuracy.",
    "key_points": [
      "cross-modality image matching",
      "few-shot adaptation"
    ],
    "gold_summary": "This work proposes a few-shot framework for enabling cross-modality matching. The key idea is to have few-shot labeled data plus unlabeled data for semi-supervised learning. It uses fine-grained high-confidence pseudo-labels to supervise course-grained predictions."
  },
  {
    "paper_id": "ytowjGMISZ",
    "title": "A Reason-then-Describe Instruction Interpreter for Controllable Video Generation",
    "domain": "applications to computer vision",
    "content": "Diffusion Transformers have significantly improved video fidelity and temporal coherence; however, practical controllability remains limited. \nConcise, ambiguous, and compositionally complex user inputs contrast with the detailed prompts used in training, yielding an intent–output mismatch. We propose ReaDe, a universal, model-agnostic interpreter that converts raw instructions into precise, actionable specifications for downstream video generators. ReaDe follows a reason-then-describe paradigm: it first analyzes the user request to identify core requirements and resolve ambiguities, then produces detailed guidance that enables faithful, controllable generation. We train ReaDe via a two-stage optimization: (i) reasoning-augmented supervision imparts analytic parsing with stepwise traces and dense captions; (ii) a multi-dimensional reward assigner enables stable, feedback-driven refinement for natural-style captions. Experiments across single- and multi-condition scenarios show consistent gains in instruction fidelity, caption accuracy, and downstream video quality, with strong generalization to reasoning-intensive and unseen inputs. ReaDe offers a practical route to aligning controllable video generation with accurately interpreted user intent.",
    "key_points": [
      "multimodal content understanding",
      "instruction interpretion",
      "controllable video generation"
    ],
    "gold_summary": "The paper propose a model-agnostic interpreter that converts raw instructions into precise, actionable specifications for downstream video generators."
  },
  {
    "paper_id": "z7V6wDn32y",
    "title": "Personalized Vision via Visual In-Context Learning",
    "domain": "applications to computer vision",
    "content": "Modern vision models, trained on large-scale annotated datasets, excel at predefined tasks but struggle with personalized vision—tasks defined at test time by users with customized objects or novel objectives. Existing personalization approaches rely on costly fine-tuning or synthetic data pipelines, which are inflexible and restricted to fixed task formats. Visual in-context learning (ICL) offers a promising alternative, yet prior methods confine to narrow, in-domain tasks and fail to generalize to open-ended personalization.  We introduce Personalized In-Context Operator (PICO), a simple four-panel framework that repurposes diffusion transformers as visual in-context learners. Given a single annotated exemplar, PICO infers the underlying transformation and applies it to new inputs without retraining. To enable this, we construct VisRel, a compact yet diverse tuning dataset, showing that task diversity, rather than scale, drives robust generalization. We further propose an attention-guided seed scorer that improves reliability via efficient inference scaling. Extensive experiments demonstrate that PICO (i) surpasses fine-tuning and synthetic-data baselines, (ii) flexibly adapts to novel user-defined tasks, and (iii) generalizes across both recognition and generation.",
    "key_points": [
      "personalization",
      "visual in-context learning",
      "diffusion models"
    ],
    "gold_summary": "This paper proposes PICO, a unified framework for visual in-context learning using a four-panel image format and a diffusion-based generative backbone."
  },
  {
    "paper_id": "6P5sAycAQr",
    "title": "DefNTaxS: The Inevitable Need for Context in Classification",
    "domain": "applications to computer vision",
    "content": "To successfully use generalized vision-language models (VLMs) like CLIP for zero-shot image classification, the semantics of the target classes must be well defined and easily differentiated. However, test datasets rarely meet either criterion, implicitly encoding ambiguity in class labels, even when adding individual descriptors. Existing literature focuses on improving text inputs by using class-specific descriptors to further refine taxonomic granularity, but largely fails to leverage higher-order semantic relationships among classes. We introduce Defined Taxonomic Stratification (DefNTaxS): a fully automated, procedural, training-free framework that leverages large language models (LLMs) to cluster related classes into hierarchical subcategories and augment CLIP prompts with this taxonomic context. By sculpting text prompts to boost both semantic content and inter-class differentiability, DefNTaxS disambiguates semantically similar classes and improves classification accuracy. Across seven standard benchmarks, including ImageNet, CUB, and Food101, DefNTaxS achieves up to +12.9\\% absolute accuracy gain (average +5.5\\%) over vanilla ViT-B/32 CLIP and consistent improvement over other recent SOTA, all while enhancing semantic interpretability without any model retraining/modification, manual prompt alteration, or additional optimization data.",
    "key_points": [
      "zero-shot",
      "clip",
      "classification",
      "waffleclip",
      "chils",
      "cupl",
      "scale",
      "accessible",
      "low compute",
      "training-free",
      "automated",
      "semantics"
    ],
    "gold_summary": "This paper organically integrates two lines of zero-shot CLIP enhancement methods—text prompt augmentation and hierarchy-based approaches—into a unified workflow to improve CLIP’s zero-shot classification performance."
  },
  {
    "paper_id": "vXt4OFsw6j",
    "title": "Representation Learning of Ancient Greek Letterforms across Time",
    "domain": "applications to computer vision",
    "content": "Learning representations that remain robust across centuries of variation in handwriting is a key challenge in diachronic representation learning of ancient Greek manuscripts. We introduce three datasets of ancient Greek handwriting for diachronic representation learning: Hell-Char, a curated training set spanning the 3rd–1st centuries BCE, and two evaluation sets, PaLit-Char (1st–5th c. CE) and Med-Char (9th–14th c. CE). To address challenges of symbolic variation, scarce data, and systematic degradation, we propose two methodological innovations: a similarity-weighted supervised contrastive loss that biases embeddings by human-perceived confusability, and a lacuna-driven augmentation scheme that simulates realistic manuscript corruptions. Trained with these strategies, both a lightweight CNN and a pretrained ResNet achieve strong recognition performance and produce embeddings that more coherently separate character classes than PCA or generic pretrained models. These embeddings enable clustering, identification of stylistic subgroups, and construction of prototype images that visualize diachronic evolution and transitional letterforms. Our results demonstrate that incorporating expert priors and domain-specific corruptions yields robust, interpretable representations, offering a transferable paradigm for representation learning under scarce, temporally evolving, and noisy conditions.",
    "key_points": [
      "representation learning",
      "clustering",
      "supervised classification",
      "diachronic analysis",
      "handwritten character recognition",
      "paleography",
      "cultural heritage data"
    ],
    "gold_summary": "This paper addresses the challenge of diachronic representation learning for ancient Greek handwriting by introducing three datasets. Temporal generalization tests show strong performance on PaLit-Char (84% accuracy) but limited performance on Med-Char."
  },
  {
    "paper_id": "MBt9cEAdLb",
    "title": "CapTalk: Text-Guided Stylization and Speech-Driven 3D Head Animation",
    "domain": "applications to computer vision",
    "content": "Audio-driven 3D facial animation aims to generate synchronized lip movements and vivid facial expressions from arbitrary audio clips. \nWhile existing methods can produce synchronized lip motions, they often rely on predefined identity or style latent features, which limits users’ ability to freely control speaking styles. \nMoreover, applying a fixed style or identity to an entire audio segment typically results in facial animation styles that do not adapt to the emotional content of the audio.\nTo address these challenges, we revisit the entanglement between style and emotion, construct a large-scale dataset with textual descriptions of both style and emotion, and propose a novel talking head generation framework that enables separate control over style and emotion. \nOur model takes as input both textual descriptions of speaking style and character emotion, as well as the driving audio stream, enabling real-time generation of highly synchronized lip movements and facial expressions that match the provided descriptions.\nFurthermore, our model supports dynamic emotion control during inference, allowing it to handle scenarios where the target emotion changes throughout the speech.",
    "key_points": [
      "speech-driven generation",
      "head animation",
      "text-driven generation"
    ],
    "gold_summary": "The paper proposes CapTalk, a facial animation generation method that can control speaking style with text. The paper also propose a dataset for the generation task."
  },
  {
    "paper_id": "2mkGaRxtfK",
    "title": "EvoIR: Towards All-in-One Image Restoration via Evolutionary Frequency Modulation",
    "domain": "applications to computer vision",
    "content": "All-in-One Image Restoration (AiOIR) tasks often involve diverse degradations that require robust and versatile strategies. However, most existing approaches typically lack explicit frequency modeling and rely on fixed or heuristic optimization schedules, which limit the generalization across heterogeneous degradations. To address these limitations, we propose EvoIR, a novel framework that introduces evolutionary frequency modulation for dynamic and adaptive image restoration. Specifically, EvoIR employs the Frequency-Modulated Module (FMM) that decomposes features into high- and low-frequency branches in an explicit manner and adaptively modulates them to enhance both structural fidelity and fine-grained details. Central to EvoIR, an Evolutionary Optimization Strategy (EOS) iteratively adjusts frequency-aware objectives through a population-based evolutionary process, dynamically balancing structural accuracy and perceptual fidelity. Its evolutionary guidance further mitigates gradient conflicts across degradations and accelerates convergence. By synergizing FMM and EOS, EvoIR yields greater improvements than using either component alone, underscoring their complementary roles. Extensive experiments on multiple benchmarks demonstrate that EvoIR outperforms state-of-the-art AiOIR methods.",
    "key_points": [
      "low level",
      "image restoration",
      "all-in-one image restoration"
    ],
    "gold_summary": "The authors propose a novel AiOIR framework with adaptive frequency modulation and evolutionary loss optimization. The method is well designed with detailed experiments. Experimental results reveal the effectiveness and efficiency of the proposed EvoIR."
  },
  {
    "paper_id": "KQBjUQMmPo",
    "title": "Beyond Weight-Only: Mixed-Precision Quantization for BERT Weights, Activations and Embeddings",
    "domain": "applications to computer vision",
    "content": "Pre-trained language models deliver strong performance across various Natural Language Processing (NLP) tasks but remain costly to deploy due to memory and compute demands. To address this, model compression techniques such as pruning, knowledge distillation, and quantization have emerged, with quantization gaining traction due to hardware support for low precision. While uniform and extremely low-precision quantization have shown promise, mixed-precision approaches that assign variable bit-widths to weights/activations across the model offer a superior balance between compression and accuracy. In this work, we aim to evaluate the impact of mixed-precision quantization for inference on BERT language model. Unlike prior work that often neglects activation quantization, our study systematically explores both weights and activations in mixed-precision configurations. To further improve performance, we integrate knowledge distillation into the mixed-precision pipeline. We also evaluate the impact of quantization on the embedding layer, which is generally restricted solely to quantizing token weights. Evaluated on SQuAD and GLUE benchmarks, our results achieve substantial memory and computational reductions without sacrificing accuracy.",
    "key_points": [
      "quantization",
      "mixed-precision",
      "inference",
      "embedding quantization",
      "quantization-aware training",
      "nlp",
      "bert"
    ],
    "gold_summary": "This paper applies existing AdaQAT method to quantize BERT model, covering weights, activations, and embedding layers. The authors integrate layer-wise mixed precision and knowledge distillation into the framework and evaluate on GLUE and SQuAD."
  },
  {
    "paper_id": "3U2XxbhAyz",
    "title": "Q-Mirror: Unlocking the Multi-Modal Potential of Scientific Text-Only QA Pairs",
    "domain": "applications to computer vision",
    "content": "High-quality, multi-modal benchmarks are crucial for advancing scientific reasoning in large models yet their manual creation is costly and unscalable. To address this bottleneck, we explore the potential for transforming Text-Only QA Pairs (TQAs) into high-quality Multi-Modal QA Pairs (MMQAs), which include three parts: 1) Task Definition & Evaluation Rubric: We develop a TQA-to-MMQA framework and establish a comprehensive, multi-dimensional MMQA quality rubric that provides principles for the transformation. 2) Benchmark Construction: Then we construct two extensive benchmarks to rigorously evaluate state-of-the-art generation & understanding models on the distinct tasks of MMQA generation & MMQA quality evaluation. 3) Preliminary Solution: We develop an agentic system Q-Mirror, which operationalizes our framework by integrating MMQA generation and evaluation into a closed loop for iterative refinement. Our experiments show that while state-of-the-art models can generate MMQAs, their outputs still leave substantial gaps, underscoring the need for reliable evaluation. We further demonstrate that top-tier understanding models align closely with human judgment in MMQA quality assessment. Leveraging both insights, the Q-Mirror agent raises average scores from 78.90 to 85.22 and pass rates from 72% to 95%, offering a practical path to large-scale scientific benchmarks.",
    "key_points": [
      "large model",
      "text-only qa pairs",
      "multi-modal qa pairs"
    ],
    "gold_summary": "This paper proposes a framework and an agentic system, Q-Mirror, to scalably generate high-quality multimodal benchmarks by transforming text-only QA pairs through a closed-loop process of iterative generation and evaluation."
  },
  {
    "paper_id": "zxito57J6x",
    "title": "Segment Any Events with Language",
    "domain": "applications to computer vision",
    "content": "Scene understanding with free-form language has been widely explored within diverse modalities such as images, point clouds, and LiDAR. However, related studies on event sensors are scarce or narrowly centered on semantic-level understanding. We introduce **SEAL**, the first Semantic-aware Segment Any Events framework that addresses Open-Vocabulary Event Instance Segmentation (OV-EIS). Given the visual prompt, our model presents a unified framework to support both event segmentation and open-vocabulary mask classification at multiple levels of granularity, including instance-level and part-level. To enable thorough evaluation on OV-EIS, we curate four benchmarks that cover *label granularity* from coarse to fine class configurations and *semantic granularity* from instance-level to part-level understanding. Extensive experiments show that our SEAL largely outperforms proposed baselines in terms of performance and inference speed with a parameter-efficient architecture. In the Appendix, we further present a simple variant of our SEAL achieving generic spatiotemporal OV-EIS that does not require any visual prompts from users in the inference. The code will be publicly available.",
    "key_points": [
      "event sensor",
      "event-based scene understanding",
      "open-vocabulary"
    ],
    "gold_summary": "Authors propose the first text-guided instance segmentation framework for event streams, achieving open-vocabulary segmentation, and introduce four benchmark levels to validate the effectiveness of the proposed model."
  },
  {
    "paper_id": "NE1yczn1Qz",
    "title": "ArtHOI: Articulated Human-Object Interaction Synthesis via Dynamics Distillation",
    "domain": "applications to computer vision",
    "content": "Synthesizing realistic articulated human-object interactions is challenging, especially when explicit 3D/4D supervision is unavailable. Recent zero-shot methods distill dynamics priors from pretrained video diffusion models, but this setting inherently provides only monocular evidence. That makes articulated part motion highly ambiguous and tightly coupled with human actions, so prior work falls back to rigid-object assumptions and fails on everyday articulated scenes (e.g., containing doors, fridges, cabinets). We introduce **ArtHOI**, the first zero-shot framework for synthesizing articulated human-object interactions via dynamics distillation from monocular video priors. We make two critical designs: **1)** *Flow-based part segmentation*: we use optical-flow cues to separate dynamic from static regions, because motion is the most reliable signal when multi-view information is absent. **2)** *Decoupled dynamics distillation*: joint optimization of human motion and object articulation is unstable under monocular ambiguity, so we first recover object articulation, then synthesize human motion conditioned on the reconstructed object states. ArtHOI distills dynamics from monocular 2D video priors without any 3D/4D ground truth. Across diverse scenes, ArtHOI yields physically plausible articulated interactions, improving contact quality and reducing penetration while enabling behaviors beyond rigid-only baselines. This extends zero-shot HOI synthesis from rigid manipulation to articulated dynamics. Code will be available.",
    "key_points": [
      "articulated human-object interaction",
      "zero-shot synthesis",
      "dynamics distillation"
    ],
    "gold_summary": "This paper proposes ArtHOI, a zero-shot method for 3D human–articulated object interaction without 3D supervision, using optical flow + SAM part segmentation and a two-stage optimization to improve motion realism and physical plausibility over baselines."
  },
  {
    "paper_id": "BEOq3YB5WM",
    "title": "MUOT-CLIP: Enhancing Few-Shot Adaptation of CLIP via Inter- and Intra- Modality Unbalanced Optimal Transport",
    "domain": "applications to computer vision",
    "content": "Contrastive Language-Image Pre-training (CLIP)  has demonstrated remarkable zero-shot capabilities across a variety of domains. To enhance its performance in data-scarce settings, few-shot adaptation methods have been developed. Other than fine-tuning the parameters (e.g., the adapter-based approach), prompt learning methods learn proper prompts to minimize the distance between the visual feature and the textual feature. Optimal Transport (OT) has proven highly effective as a measurement metric for evaluating the feature space of CLIP. However, classical OT, which forces equality constraints on both the source and target weights of the transport plan, is susceptible to noises (e.g., the misleading local regions in images and unrelated words in prompts). Furthermore, both the adapter-based and prompt learning methods usually overlook the modality gap existing in the feature space and thus risk to obtain suboptimal performance. In this paper, we extend the formulation of classical OT to unbalanced optimal transport (UOT) for better measurement. The UOT based distance measure can filter out noises adaptively. To boost the few-shot adaptation performance, a framework that measures both the inter- and intra- **M**odality distance based on **UOT** for **CLIP** is proposed, which is termed **MUOT-CLIP**. In addition, a scalable UOT solver with entropy regularization term is used for the efficient optimization of the model. Compared with the state-of-the-art methods, MUOT-CLIP consistently exhibits favorable performance on the few-shot classification benchmark of 11 datasets.",
    "key_points": [
      "vision-language models",
      "few-shot classification",
      "prompt learning"
    ],
    "gold_summary": "See Questions"
  },
  {
    "paper_id": "LUopdQeiz1",
    "title": "End-to-End On-Device Quantization-Aware Training for LLMs at Inference Cost",
    "domain": "applications to computer vision",
    "content": "Quantization is an effective technique to reduce the deployment cost of large language models (LLMs), and post-training quantization (PTQ) has been widely studied due to its efficiency. However, existing PTQ methods are limited by their inability to fine-tune model parameters and often suffer significant accuracy loss in low-bit scenarios. Quantization-aware training (QAT) provides a more principled solution, but its reliance on backpropagation incurs prohibitive memory costs, limiting its practicality for LLM deployment. To address these challenges, we propose ZeroQAT, a zeroth-order optimization-based QAT framework that supports both weight and activation quantization. ZeroQAT leverages forward-only gradient estimation to eliminate backpropagation, substantially reducing computational and memory overhead while retaining the benefits of end-to-end optimization. We further introduce a lightweight variant of ZeroQAT for quantized fine-tuning, which freezes and pre-quantizes most parameters to further cut memory usage. Experiments show that ZeroQAT consistently outperforms representative PTQ and QAT baselines while requiring significantly less memory. For example, ZeroQAT enables fine-tuning of a 13B model at extremely low bit-widths (e.g., 2-4 bits) on a single 8GB GPU, and even allows fine-tuning a 6.7B model on a OnePlus 12 smartphone, demonstrating its practicality for end-to-end QAT on resource-limited edge devices. Our code is released at \\url{https://anonymous.4open.science/r/ZO_quantization-2DEB}.",
    "key_points": [
      "quantization-aware training; efficient ai;"
    ],
    "gold_summary": "This paper proposes an efficient Quantization-Aware Training (QAT) framework that estimates gradients using forward-only finite-difference (FD) approximation, achieving stable and resource-efficient training even under low-bit quantization."
  },
  {
    "paper_id": "FDuN3F1K9X",
    "title": "InsCal: Calibrated Multi-Source Fully Test-Time Prompt Tuning for Object Detection",
    "domain": "applications to computer vision",
    "content": "Test-time prompt tuning (TPT) has emerged as a powerful technique for adapting pre-trained vision-language models (VLMs) to diverse downstream tasks, including image classification and visual reasoning. With the rise of text-driven object detectors, we extend TPT to object detection, unlocking new capabilities for cross-domain adaptation. However, a critical challenge in TPT is the inherent miscalibration caused by entropy minimization: domain shifts often lead to incorrect predictions, and enforcing high confidence exacerbates miscalibration, ultimately degrading performance. To tackle this, we introduce InsCal, a novel framework designed to enhance cross-domain object detection through three key innovations: (1) extending TPT to a multi-source paradigm, enabling knowledge aggregation across diverse domains; (2) reducing domain gaps via a novel text-driven style transfer strategy that aligns features to the source domain without requiring reference images; and (3) refining the entropy minimization objective with instance-specific calibration, ensuring robust and well-calibrated adaptation. Our approach not only mitigates miscalibration but also significantly improves cross-domain object detection performance, setting a new benchmark for test-time adaptation in VLMs.",
    "key_points": [
      "source-free zero-shot learning",
      "model calibration"
    ],
    "gold_summary": "In this paper, the authors propose InsCal to enhance the performance of multi-domain object detection. Utilizing text-driven style transfer strategy to align features from different domains, InsCal mitigates miscalibration caused by domain shifts."
  },
  {
    "paper_id": "pYMd0tRzPP",
    "title": "Memory Forcing: Spatio-Temporal Memory for Consistent Scene Generation on Minecraft",
    "domain": "applications to computer vision",
    "content": "Autoregressive video diffusion models have proved effective for world modeling and interactive scene generation, with Minecraft gameplay as a representative application. To faithfully simulate play, a model must generate natural content while exploring new scenes and preserve spatial consistency when revisiting explored areas. Under limited computation budgets, it must compress and exploit historical cues within a finite context window, which exposes a trade-off: \nTemporal-only memory lacks long-term spatial consistency, whereas adding spatial memory strengthens consistency but may degrade new scene generation quality when the model over-relies on insufficient spatial context.\nWe present Memory Forcing, a learning framework that pairs training protocols with a geometry-indexed spatial memory. Hybrid Training exposes distinct gameplay regimes, \nguiding the model to rely on temporal memory during exploration and incorporate spatial memory for revisits.\nChained Forward Training extends autoregressive training with model rollouts, where chained predictions create larger pose variations and encourage reliance on spatial memory for maintaining consistency.\nPoint-to-Frame Retrieval efficiently retrieves history by mapping currently visible points to their source frames, while Incremental 3D Reconstruction maintains and updates an explicit 3D cache.\nExtensive experiments demonstrate that Memory Forcing achieves superior long-term spatial consistency and generative quality across diverse environments, while maintaining computational efficiency for extended sequences.",
    "key_points": [
      "autoregressive video models",
      "world models",
      "minecraft",
      "interactive gameplay"
    ],
    "gold_summary": "The method in this paper combines Long-term Spatial Memory and Short-term Temporal Memory context learning to achieve long-term consistent video generation in Minecraft."
  },
  {
    "paper_id": "yZaTmUOW1o",
    "title": "A Bridge from Audio to Video: Phoneme-Viseme Alignment Allows Every Face to Speak Multiple Languages",
    "domain": "applications to computer vision",
    "content": "Speech-driven talking face synthesis (TFS) focuses on generating lifelike facial animations from audio input. Current TFS models perform well in English but unsatisfactorily in non-English languages, producing wrong mouth shapes and rigid facial expressions. The terrible performance is caused by the English-dominated training datasets and the lack of cross-language generalization abilities. Thus, we propose Multilingual Experts (MuEx), a novel framework featuring a Phoneme-Guided Mixture-of-Experts (PG-MoE) architecture that employs phonemes and visemes as universal intermediaries to bridge audio and video modalities, achieving lifelike multilingual TFS. To alleviate the influence of linguistic differences and dataset bias, we extract audio and video features as phonemes and visemes respectively, which are the basic units of speech sounds and mouth movements. To address audiovisual synchronization issues, we introduce the Phoneme-Viseme Alignment Mechanism (PV-Align), which establishes robust cross-modal correspondences between phonemes and visemes. In addition, we build a Multilingual Talking Face Benchmark (MTFB) comprising 12 diverse languages with 95.04 hours of high-quality videos for training and evaluating multilingual TFS performance. Extensive experiments demonstrate that MuEx achieves superior performance across all languages in MTFB and exhibits effective zero-shot generalization to unseen languages without additional training.",
    "key_points": [
      "talking face synthesisd",
      "phoneme",
      "viseme",
      "multilingual"
    ],
    "gold_summary": "The paper proposes MuEx that uses phonemes and visemes as intermediaries to improve multilingual talking head generation performance. The paper proposes MTFB dataset that comprises talking head data in diverse languages."
  },
  {
    "paper_id": "viX7rUMzwg",
    "title": "AnyLayout: Versatile Advertising Poster Layout Generation with MLLMs",
    "domain": "applications to computer vision",
    "content": "Layout design is a fundamental aspect of visual communication, widely used in advertising, publishing, and digital media. Recent datasets and methods, including content-agnostic and content-aware approaches, have advanced automatic layout generation, and large language models (LLMs) and multi-modal LLMs (MLLMs) have further improved performance. However, most existing methods focus on predicting bounding boxes for limited design elements on fixed backgrounds, which restricts their capability to tackle diverse instruction-driven tasks in real-world applications. To address these limitations, we introduce **AnyLayout-120K**, a large-scale instruction-driven dataset for multimodal layout generation. It offers: (1) *Task Diversity*—comprising four instruction-driven sub-tasks that encompass multimodal design elements such as multi-lingual text, visual/textual product, logos and background underlays; (2) *Rich Annotations*—including user instructions, multimodal inputs and spatial annotations; (3) *Downstream Compatibility*—where, in addition to the layout of individual elements, we propose composite layouts that capture the overall design, integrating both details and semantics. These composite layouts can be seamlessly incorporated into text-to-image (T2I) models for end-to-end generation. Alongside this dataset, we develop 7 geometry-aware evaluation metrics that assess spatial precision and adherence to design principles, ensuring a more comprehensive evaluation. Furthermore, utilizing this dataset, we establish a strong baseline based on MLLMs, achieving state-of-the-art performance. The dataset, metrics, and baseline will be released to support future research in instruction-driven layout design.",
    "key_points": [
      "multi-modal vision",
      "large multimodal models",
      "mining of visual",
      "multimedia and multimodal data"
    ],
    "gold_summary": "This paper proposes AnyLayout-120K, a large-scale instruction-driven dataset for multimodal advertising poster layout generation, along with 7 geometry-aware evaluation metrics and a unified baseline model based on multi-modal large language models (MLLMs)."
  },
  {
    "paper_id": "br3p10VNoA",
    "title": "BoundRL: Efficient Structured Text Segmentation through Reinforced Boundary Generation",
    "domain": "applications to computer vision",
    "content": "As structured texts become increasingly complex across diverse domains -- from technical reports to generative AI prompts -- the need for text segmentation into semantically meaningful components becomes critical. Such texts often contain elements beyond plain language, including tables, code snippets, and placeholders, which conventional sentence- or paragraph-level segmentation methods cannot handle effectively. To address this challenge, we propose BoundRL, a novel and efficient approach that jointly performs token-level text segmentation and label prediction for long structured texts. Instead of generating complete contents for each segment, it generates only a sequence of starting tokens and reconstructs the complete contents by locating these tokens within the original texts, thereby reducing inference costs by orders of magnitude and minimizing hallucination. To adapt the model for the output format, BoundRL performs reinforcement learning with verifiable rewards (RLVR) with a specifically designed reward that jointly optimizes document reconstruction fidelity and semantic alignment. To mitigate entropy collapse, it further constructs intermediate candidates by systematically perturbing a fraction of generated sequences of segments to create stepping stones toward higher-quality solutions. To demonstrate BoundRL's effectiveness on particularly challenging structured texts, we focus evaluation on complex prompts used for LLM applications. Experiments show that BoundRL enables small language models (1.7B parameters) to outperform few-shot prompting of much larger models. Moreover, RLVR with our designed reward yields significant improvements over supervised fine-tuning, and incorporating intermediate candidates further improves both performance and generalization.",
    "key_points": [
      "text segmentation",
      "reinforcement learning"
    ],
    "gold_summary": "The paper applies a variant of RLVR to boundary detection in language model prompts. It shows that its method of only generating tokens that indicate boundaries is faster than using a prompt-based approach."
  },
  {
    "paper_id": "w20Gqdlr6k",
    "title": "Adaptive Identification of Blurred Regions for Accurate Image Deblurring",
    "domain": "applications to computer vision",
    "content": "Image deblurring aims to restore high-quality images from blurred ones. While existing deblurring methods have made significant progress, most overlook the fact that the degradation degree varies across different regions. In this paper, we propose AIBNet, a network that adaptively identifies the blurred regions, enabling differential restoration of these regions.  Specifically, we design a spatial feature differential handling block (SFDHBlock), with the core being the spatial domain feature enhancement module (SFEM). Through the feature difference operation, SFEM not only helps the model focus on the key information in the blurred regions but also eliminates the interference of implicit noise. Additionally, based on the fact that the difference between sharp and blurred images primarily lies in the high-frequency components, we propose a high-frequency feature selection block (HFSBlock). The HFSBlock first uses learnable filters to extract high-frequency features and then selectively retains the most important ones. To fully leverage the decoder's potential, we use a pre-trained model as the encoder and incorporate the above modules only in the decoder. Finally, to alleviate the resource burden during training, we introduce a progressive training strategy. Extensive experiments demonstrate that our AIBNet achieves superior performance in image deblurring.",
    "key_points": [
      "image restoration",
      "image deblurring",
      "adaptive identification"
    ],
    "gold_summary": "This paper proposed to solve the spatial variant motion blurs with high frequency enhancement module and non-blurred region filtering module."
  },
  {
    "paper_id": "pzXAS6Tf2r",
    "title": "HiViBiX: Hierarchical Visually-informed Binaural Audio Generation using Ambisonics",
    "domain": "applications to computer vision",
    "content": "Binaural audio, a specialized form of stereo sound, provides depth and spatial localization for highly immersive listening experiences, making it fundamental in modern entertainment. Prior research has largely relied on visual cues to directly adapt mono signals into binaural or to estimate transfer functions that induce spatiality. In contrast, we introduce HiViBiX, a novel framework that redefines the audio representation by predicting first-order Ambisonics channels, which explicitly control the spatial positioning of audio components in the generated binaural signal. Unlike existing multimodal approaches that extract spatial cues exclusively from full-frame RGB images, HiViBiX incorporates a hierarchical visual encoder that jointly models local sound sources and their spatial depth with global environmental context. This design enables richer multimodal grounding and more precise spatialization. Extensive experiments on three widely used benchmarks: FAIR-Play, Music-Stereo, and YT-Music demonstrate that HiViBiX establishes new state-of-the-art performance for mono-to-binaural generation. Samples are available in the following repository: \\href{https://hivibix.vercel.app}{https://hivibix.vercel.app}.",
    "key_points": [
      "binaural audio",
      "hierarchical vision encoding",
      "ambisonics decoding"
    ],
    "gold_summary": "The authors introduce HiViBiX, a novel framework that redefines the audio representation by predicting first-order Ambisonics channels, which explicitly control the spatial positioning of audio components in the generated binaural signal."
  },
  {
    "paper_id": "KCWAcEnXhy",
    "title": "Compression of Vision Transformer by Reduction of Kernel Complexity",
    "domain": "applications to computer vision",
    "content": "Self-attention and transformer architectures have become foundational components in modern deep learning. Recent efforts have integrated transformer blocks into compact neural architectures for computer vision, giving rise to various efficient vision transformers. In this work, we introduce Transformer with Kernel Complexity Reduction, or KCR-Transformer, a compact transformer block equipped with differentiable channel selection, guided by a novel and sharp theoretical generalization bound. To reduce the substantial computational cost of the MLP layers, the KCR-Transformer performs channel selection on the outputs of its self-attention layer.\nFurthermore, we provide a rigorous theoretical analysis establishing a tight generalization bound for networks equipped with KCR-Transformer blocks. Leveraging such strong theoretical results, the channel pruning by KCR-Transformer is conducted in a generalization-aware manner, ensuring that the resulting network retains a provably small generalization error.\nOur KCR-Transformer is compatible with many popular and compact transformer networks, such as ViT and Swin, and it reduces the FLOPs of the vision transformers while maintaining or even improving the prediction accuracy. In the experiments, we replace all the transformer blocks in the vision transformers with KCR-Transformer blocks, leading to KCR-Transformer networks with different backbones. The resulting KCR-Transformers achieve superior performance on various computer vision tasks, achieving even better performance than the original models with even less FLOPs and parameters. The code of the KCR-Transformer is available at \\url{https://anonymous.4open.science/status/KCR-Transformer}.",
    "key_points": [
      "kernel complexity",
      "channel selection",
      "vision transformer"
    ],
    "gold_summary": "This paper introduces the KCR-Transformer, a method that compresses Vision Transformers by using a Kernel Complexity (KC) generalization bound to guide the differentiable channel pruning of its MLP layers."
  },
  {
    "paper_id": "wJgaHyJaDD",
    "title": "TPOUR: Temporal Preference Optimization for Unsupervised Retrieval",
    "domain": "applications to computer vision",
    "content": "Unsupervised retrievers offer scalability by learning semantic similarity from unlabeled documents via contrastive learning. However, they struggle to capture the temporal relevance, often retrieving semantically related but temporally misaligned documents--an important aspect when a document collection spans multiple time periods (e.g., For the query \"Who is the president in 2019?\" retrieving from related documents spanning 2018–2025 introduces temporal ambiguity if relying solely on semantics). Existing methods rely on supervised training with explicit timestamps, which are not always feasible. We propose TPOUR (Temporal Preference Optimization for Unsupervised Retriever), which integrates our novel training method Temporal Retrieval Preference Optimization (TRPO). TRPO reinterprets preference learning in the temporal dimension, guiding the retriever to favor temporally aligned documents. TPOUR constructs temporally aligned and misaligned document pairs by leveraging document corpora collected at different times and trains the retriever without supervision to prioritize temporally aligned over misaligned documents. Furthermore, TPOUR generalizes to unseen time periods by interpolating time vectors, enabling continuous temporal alignment. Experiments on temporal QA with a mixed-timestamp document collection show that TPOUR outperforms both unsupervised and supervised baselines. Compared to Nomic Embed v2 MoE, TPOUR Contriever improves nDCG@5 by +7.13 (+23.5%) on explicit and +7.76 (+25.5%) on implicit queries on average.",
    "key_points": [
      "temporal retrieval",
      "information retrieval",
      "unsupervised learning",
      "contrastive learning",
      "preference optimization",
      "time vector"
    ],
    "gold_summary": "This paper proposes an unsupervised retrieval framework called TPOUR to address the “temporal misalignment” problem in traditional retrieval models when handling time-sensitive queries."
  },
  {
    "paper_id": "ue8twOwF1o",
    "title": "Motion-Guided Prior Support and Polarity Interaction for Event Stream Super-Resolution",
    "domain": "applications to computer vision",
    "content": "In this paper, we aim to enhance the representation of spatio-temporal semantics during the Event stream Super-resolution (ESR) reconstruction by leveraging inter-frame motion information.\nTo this end, we propose a Motion-Guided Prior Support and Polarity Interaction Network (MPS-PI Net). The MPS-PI Net takes event frames as the primary input, while incorporating positive and negative event streams as auxiliary inputs. The MPS-PI Net contains two novel designs: Motion-Guided Semantic Prior (MGSP) Module and Bipolar Semantic Interaction and Fusion (B-SIF) Module. In the MGSP module, we capitalize on inter-frame optical flow information to seamlessly integrate semantic cues derived from previously reconstructed frames into the super-resolution reconstruction process of the current frame. This integration provides valuable prior support for reconstructing the content of the current frame with greater accuracy. Building upon the prior semantic information introduced by the MGSP module, within the B-SIF Module, we initially undertake self-representational enhancement for both positive and negative polarity semantics independently. Following this, we conduct an interactive fusion of these two polarity semantics to fully harness their unique advantages. Experimental results unequivocally demonstrate that our proposed MPS-PI Net achieves competitive performance on many ESR datasets.",
    "key_points": [
      "event stream super-resolution;  semantic interaction and fusion;   event camera"
    ],
    "gold_summary": "The paper introduces a Motion-Guided Prior Support and Polarity Interaction Network for event stream super-resolution.\n Reported results on synthetic and real datasets show quantitative gains over selected baselines."
  },
  {
    "paper_id": "zJaqyxO7K7",
    "title": "CodePlot-CoT: Mathematical Visual Reasoning by Thinking with Code-Driven Images",
    "domain": "applications to computer vision",
    "content": "Recent advances in Large Language Models (LLMs) and Vision Language Models (VLMs) have shown significant progress in mathematical reasoning, yet they still face a critical bottleneck with problems requiring visual assistance, such as drawing auxiliary lines or plotting functions to solve the problems. Most LLMs and VLMs are constrained to text-only reasoning chains, while multimodal unified models that can generate interleaved text and images lack the necessary precision and controllability for such tasks. To address this, we propose CodePlot-CoT, a code-driven Chain-of-Thought paradigm for \"thinking with images\" in mathematics. Our approach leverages the VLM to generate text reasoning as well as executable plotting code, which is then rendered into images as \"visual thought\", to solve mathematical problems. To achieve this, we first construct Math-VR, the first large-scale, bilingual dataset and benchmark for Mathematics problems with Visual Reasoning, comprising 178K samples. Second, to create high-quality training data, we develop a state-of-the-art image-to-code converter specialized for parsing complex mathematical figures into codes. Finally, using these training data, we train the CodePlot-CoT model for solving mathematical problems. Experimental results show that our model achieves up to 21% increase over base model on our new benchmark, fully validating the efficacy of our proposed code-driven reasoning paradigm. Our work opens a new direction for multimodal mathematical reasoning and provides the community with the first large-scale dataset, comprehensive benchmark, and strong approach for such problems.",
    "key_points": [
      "multimodal large language models",
      "mathematical reasoning",
      "thinking with images",
      "multimodal benchmark"
    ],
    "gold_summary": "This paper presents an interesting and well-motivated approach to code-driven visual reasoning in mathematics, but its limited generalization scope and insufficient evaluation details weaken its overall impact."
  },
  {
    "paper_id": "nsmow1yhEE",
    "title": "Is Extending Modality The Right Path Towards Omni-Modality?",
    "domain": "applications to computer vision",
    "content": "Omni-modal language models (OLMs) aim to integrate and reason over diverse input modalities—such as text, images, video, and audio—while maintaining strong language capabilities. Despite recent advancements, existing models, especially open-source ones, remain far from true omni-modality, struggling to generalize beyond the specific modality pairs they are trained on or to achieve strong performance when processing multi-modal inputs.\nWe study the effect of extending modality, the dominant technique for training multimodal models, where an off-the-shelf language model is fine-tuned on target-domain and language data.\nSpecifically, we investigate three key questions: (1) Does modality extension compromise core language abilities? (2) Can model merging effectively integrate independently fine-tuned modality-specific models to achieve omni-modality? (3) Does omni-modality extension lead to better knowledge sharing and generalization compared to sequential extension?\nThrough extensive experiments, we analyze these trade-offs and provide insights into the feasibility of achieving true omni-modality using current approaches.",
    "key_points": [
      "omni-modality",
      "modality extension",
      "model merge"
    ],
    "gold_summary": "The paper investigates three questions for multi-modal models, 1) whether language capabilities are compromised with modality extension, 2) whether model merging preserves the language capabilities, 3) impact of omni-modality fine-tuning."
  },
  {
    "paper_id": "nKCrn6ZMIz",
    "title": "Benchmarking MLLM-based Web Understanding: Reasoning, Robustness and Safety",
    "domain": "applications to computer vision",
    "content": "Multimodal large language models (MLLMs) are increasingly positioned as AI collaborators for building complex web-related applications like GUI agents and front-end code generation. However, existing benchmarks largely emphasize visual perception or UI code generation, showing insufficient evaluation on the reasoning, robustness and safety capability required for end-to-end web applications.  To bridge the gap, we introduce a comprehensive web understanding benchmark, named WebRSSBench, that jointly evaluates Reasoning, Robustness, and Safety across eight tasks, such as position relationship reasoning, color robustness, and safety critical detection, etc. The benchmark is constructed from 729 websites and contains 3799 question–answer pairs that probe multi-step inference over page structure, text, widgets, and safety-critical interactions. To ensure reliable measurement, we adopt standardized prompts, deterministic evaluation scripts, and multi-stage quality control combining automatic checks with targeted human verification. We evaluate 12 MLLMs on WebRSSBench. The results reveal significant gaps: models still struggle with compositional and cross-element reasoning over realistic layouts, show limited robustness when facing perturbations in user interfaces and content such as layout rearrangements or visual style shifts, and are rather conservative in recognizing and avoiding safety critical or irreversible actions. Our code is available at https://anonymous.4open.science/r/WebRSSBench/.",
    "key_points": [
      "mllms",
      "benchmark",
      "robustness"
    ],
    "gold_summary": "Propose WebRSSBench, evaluating the web understanding ability of MLLM from three dimensions: Reasoning / Robustness / Safety, covering 8 subtasks. It covers 729 websites and 3,799 QA."
  },
  {
    "paper_id": "TwUeP9uUJT",
    "title": "HHW-Ego: DSLR-Quality Enhancement for Multi-Source Wearable Ego Imaging",
    "domain": "applications to computer vision",
    "content": "Wearable ego-centric images are now in high demand for scenarios ranging from daily smart glass usage to embodied intelligence. But the image quality is far behind smart phone due to the lacking paired high-quality reference images and the dedicated enhancement systems. To solve this, a customized degradation pipeline is designed to generate paired samples matching wearable camera images, boosting the upper limit of enhancement performance. Besides a two-stage enhancement framework is further built: first, tuning an efficient model on the paired dataset to enhance real wearable images; second, using hyperspectral data to refine color temperature for better quality. Moreover we present HHW-Ego, a multi-source paired dataset integrating with Hyperspectral, High-dynamic range and Wearable Ego-centric data, which includes hundreds of image groups spanning indoor/outdoor and day/night scenes. Experiments show the framework effectively enhances images of varying quality, and matches DSLR camera quality in specific scenarios.",
    "key_points": [
      "wearable ego imaging; multi-source dataset; hyperspectral enhancement"
    ],
    "gold_summary": "A custom degradation pipeline generates matching paired samples, raising enhancement limits.\nA two-stage enhancement framework is proposed.\nHHW-Ego is proposed, a multi-source paired dataset integrating Hyperspectral, HDR, and Wearable data.\nExperiments show the framework effectively enhances images."
  },
  {
    "paper_id": "LxjdknhUen",
    "title": "DualFusion: Dual Adaptive Fusion for Multi-View Pedestrian Detection via View Reliability Modeling and Channel Reweighting",
    "domain": "applications to computer vision",
    "content": "Multi-view pedestrian detection methods project feature maps from multiple cameras onto a unified bird’s-eye view (BEV), enabling spatially aligned cross-view feature fusion. However, existing methods often adopt uniform fusion strategies, ignoring differences in view reliability—such as occlusion severity and projection distortion—and neglecting semantic correlations across feature channels (e.g., contours or foot-level cues). These limitations lead to noisy feature aggregation and suboptimal detection accuracy. To overcome these challenges, we propose a Dual Adaptive Fusion framework (DualFusion) that enhances BEV representations through two targeted modules: the Cross-View Feature Selector (CVFS) and the View-Channel Graph Attention (VCGA). CVFS, inspired by recent advances in Vision Transformers, employs a Transformer encoder to perform dynamic view-aware fusion in the BEV space, enabling spatially reliable feature aggregation across views. VCGA models joint view-channel dependencies using global-local context pooling and a graph-inspired multilayer perceptron, allowing adaptive channel-wise reweighting of the fused features. Extensive experiments on public benchmarks demonstrate that our method consistently outperforms recent multi-view fusion approaches. Ablation studies further confirm the effectiveness of each component. Our code will be released upon acceptance.",
    "key_points": [
      "information fusion",
      "pedestrian detection",
      "adaptive fusion"
    ],
    "gold_summary": "This paper proposes two new modules for soft view selection and GNN-based channel reweighting on BEV space. Experiments demonstrate its effectiveness on two benchmark multi-view detection datasets."
  },
  {
    "paper_id": "7j85GkcPX1",
    "title": "MEDSPIKEFORMER: All Neurons Matter for Medical Image Segmentation",
    "domain": "applications to computer vision",
    "content": "Spiking self-attention (SSA) has emerged as a promising approach for medical image segmentation due to its event-driven and energy-efficient nature. However, segmentation performance still degrades in complex scenarios where salient and non-salient regions coexist. Two fundamental issues remain: i) existing SSA mechanisms rely only on activated neurons, overlooking the contextual cues carried by inactivated neurons, and ii) the binary spike representation causes distribution distortions that make spiking self-attention lag behind their ANN-based self-attention (SA) in spatial discriminability. To overcome these challenges, we propose MedSpikeFormer, a spiking transformer built on the principle that all neurons matter, both activated and inactivated. MedSpikeFormer introduces a Spike-based Decomposed Self-Attention (SDSA) that explicitly models four types of neuronal interactions: activated–activated, activated–inactivated, inactivated–activated, and inactivated–inactivated, thus recovering rich contextual dependencies ignored by conventional SSA. Furthermore, we employ a distribution alignment loss that minimizes the divergence between SDSA and ANN-based self-attention (SA), significantly closing the performance gap to improve spatial feature discriminability while maintaining the binary nature of spiking neural networks. Extensive experiments on five medical segmentation benchmarks demonstrate that MedSpikeFormer consistently outperforms 14 state-of-the-art\nmethods, achieving up to +2.4% mIoU on ISIC2018 and +8.7% on COVID-19. These results confirm that leveraging both fired and non-fired neurons is crucial for robust spike-driven medical image segmentation. Code is available at https://github.com/AnonymousPaper2026/MedSpikeFormer.",
    "key_points": [
      "medical image segmentation",
      "spiking self-attention",
      "self-attention",
      "spike neural network"
    ],
    "gold_summary": "This paper proposes MedSpikeFormer, a spiking transformer architecture for medical image segmentation."
  },
  {
    "paper_id": "PvWHzAf9qp",
    "title": "Falcon: Fast Proximal Linearization of Normalized Cuts for Unsupervised Image Segmentation",
    "domain": "applications to computer vision",
    "content": "Current zero-shot unsupervised segmentation methods based on normalized cuts (NCut) face three key limitations. First, they rely on recursive bipartitions with repeated eigen-decompositions, making them prohibitively expensive at scale. Second, each split requires spectral relaxation followed by rounding, introducing layers of approximation where the final partition may diverge from the true NCut objective. Third, existing heuristics lack convergence guarantees, and recursive bipartitioning offers no principled assurance of producing a stable $K$-way segmentation. We propose \\textbf{Falcon}, a proximal-gradient solver that directly optimizes the discrete $K$-way NCut objective without spectral relaxation. We prove linear convergence in the number of tokens. Falcon computes closed-form gradient scores weighted by cluster volumes and performs row-wise one-hot proximal updates stabilized by inertia. A monotone backtracking scheme adaptively tunes the proximal parameter, ensuring non-decreasing NCut values. This design preserves discrete feasibility, removes repeated eigen-decomposition, and guarantees convergence under the \\text{Kurdyka--\\L{}ojasiewicz} framework. Across six benchmarks, Falcon outperforms the strongest official baseline (DiffCut) by wide margins, e.g., +13.2 mIoU on VOC, +27.7 on COCO-Object, and +3.1 on Cityscapes, while remaining competitive on Pascal Context. It also runs up to an order of magnitude faster than recursive NCut. By pairing pretrained foundation models with a principled NCut solver, Falcon sets a new state of the art across six benchmarks and achieves the best performance on 17 of 18 benchmark–encoder pairs, underscoring both its robustness and its generality in bridging the gap between unsupervised and supervised segmentation.",
    "key_points": [
      "unsupervised segmentation",
      "graph cut",
      "normalized cut",
      "proximal gradient method",
      "kurdyka–łojasiewicz (kl) convergence"
    ],
    "gold_summary": "This paper presents a new pseudo-mask generation framework, Falcon, which incorporates fast proximal linearization and adaptive mask refinement to achieve better or the same unsupervised segmentation performance with much faster generation."
  },
  {
    "paper_id": "jqLqBG6d2q",
    "title": "CAST: Contrastive Adaptation and Distillation for Semi-Supervised Instance Segmentation",
    "domain": "applications to computer vision",
    "content": "Instance segmentation demands costly per-pixel annotations and computationally expensive models. We introduce CAST, a semi-supervised knowledge distillation (SSKD) framework that compresses pre-trained vision foundation models (VFM) into compact experts using limited labeled and abundant unlabeled data. CAST unfolds in three stages: (1) domain adaptation of the VFM(s) via self-training with contrastive calibration, (2) knowledge transfer through a unified multi-objective loss, and (3) student refinement to mitigate residual pseudo-label bias. Central to CAST is an \\emph{instance-aware pixel-wise contrastive loss} that fuses mask and class scores to extract informative negatives and enforce clear inter-instance margins. By maintaining this contrastive signal across both adaptation and distillation, we align teacher and student embeddings and fully leverage unlabeled images. On Cityscapes and ADE20K, our 11X smaller student improves over its zero-shot VFM teacher(s) by +8.5 and +7.1 AP, surpasses adapted teacher(s) by +3.4 and +1.5 AP, and further outperforms state-of-the-art SSKD methods on both benchmarks.",
    "key_points": [
      "knowledge distillation",
      "semi-supervised knowledge distillation",
      "vision foundation models",
      "instance segmentation"
    ],
    "gold_summary": "This paper introduces CAST, a semi-supervised knowledge distillation framework designed to compress large pre-trained vision foundation models (VFMs) into much smaller, efficient models. Experiments demonstrate the effectiveness of the method."
  },
  {
    "paper_id": "pZQvv5C7WL",
    "title": "GUI-R1: A Generalist R1-Style Vision-Language Action Model For GUI Agents",
    "domain": "applications to computer vision",
    "content": "Existing efforts in building graphical user interface (GUI) agents largely rely on the training paradigm of supervised fine-tuning (SFT) on large vision-language models (LVLMs). However, this approach not only demands extensive amounts of training data but also struggles to effectively understand GUI screenshots and generalize to unseen interfaces. The issue significantly limits its application in real-world scenarios, especially for high-level tasks. Inspired by reinforcement fine-tuning (RFT) in large reasoning models (e.g., DeepSeek-R1), which efficiently enhances the problem-solving capabilities of large language models in real-world settings, we propose GUI-R1, the first reinforcement learning framework designed to enhance the GUI capabilities of LVLMs in high-level real-world task scenarios, through unified action space rule modeling. By leveraging a small amount of carefully curated high-quality data across multiple platforms (including Windows, Linux, MacOS, Android, and Web) and improved policy optimization algorithms to update the model, GUI-R1 achieves superior performance using only 0.02\\% of the data (3K vs. 13M) compared to previous state-of-the-art methods like OS-Atlas across eight benchmarks spanning three different platforms (mobile, desktop, and web). These results demonstrate the immense potential of reinforcement learning based on unified action space rule modeling in improving the execution capabilities of LVLMs for real-world GUI agent tasks. We will fully open-source GUI-R1 to benefit the research field.",
    "key_points": [
      "gui grounding",
      "reinforcement learning"
    ],
    "gold_summary": "This paper proposes GUI-R1, a rule-based reinforcement learning framework for training generalist GUI agents. They also introduce a rule-based unified action space and a crafted high-quality dataset."
  },
  {
    "paper_id": "QXrZ0Y3yGJ",
    "title": "CurES: From Gradient Analysis to Efficient Curriculum Learning for Reasoning LLMs",
    "domain": "applications to computer vision",
    "content": "Curriculum learning plays a crucial role in enhancing the training efficiency of large language models (LLMs) on reasoning tasks. However, existing methods often fail to adequately account for variations in prompt difficulty or rely on simplistic filtering mechanisms to select prompt datasets within a narrow criterion range, resulting in significant computational waste.  In this work, we approach the problem from the perspective of reinforcement learning gradient optimization, offering a systematic and theoretical investigation into how to improve the training efficiency of LLMs. We identify two key factors influencing training efficiency: the selection of training prompts and the allocation of rollout quantities across different prompts. Our theoretical analysis reveals that the sampling distribution of prompts dictates the convergence rate of gradient descent, while the allocation of the rollout quantity influences the consistency and stability of overall gradient updates. Based on these insights, we propose CurES, an efficient training method that accelerates convergence and employs Bayesian posterior estimation to minimize computational overhead. Experiments demonstrate that our CurES outperforms Group Relative Policy Optimization (GRPO) by \\textbf{+3.3} points and \\textbf{+4.82} points with 1.5B and 7B models, respectively, and exceeds the best prior sample efficient methods by \\textbf{+2.12} points on average across eight math reasoning benchmarks. Our CurES also improves convergence speed compare to baselines such as GRPO.",
    "key_points": [
      "reinforcement learning",
      "llm reasoning",
      "curriculum learning"
    ],
    "gold_summary": "The paper introduces CurES that selects prompts and determines the number of rollouts associated with each prompt during post-training based on the difficulty of the prompt in order to improve training efficiency."
  },
  {
    "paper_id": "c0QRZMKwSb",
    "title": "NOVA3R: Non-pixel-aligned Visual Transformer for Amodal 3D Reconstruction",
    "domain": "applications to computer vision",
    "content": "We present NOVA3R, an effective approach for non-pixel-aligned 3D reconstruction from a set of unposed images, in a feed-forward manner. Unlike pixel-aligned methods that tie geometry to per-ray predictions, our formulation learns a global, view-agnostic scene representation that decouples reconstruction from pixel alignment. This addresses two key limitations in pixel-aligned 3D: (1) it recovers both visible and invisible regions with a complete scene representation, and (2) it produces physically plausible geometry with fewer duplicated structures in overlapping regions. To achieve this, we introduce a scene-token mechanism that aggregates information across unposed images and a diffusion-based 3D decoder that reconstructs complete, non-pixel-aligned point clouds. Extensive experiments on both scene-level and object-level datasets demonstrate that \\method~outperforms state-of-the-art methods in terms of reconstruction accuracy and completeness.",
    "key_points": [
      "feed-forward 3d reconstruction",
      "non-pixel-aligned 3d reconstruction",
      "3d completion"
    ],
    "gold_summary": "This paper proposes NOVA3R, a non-pixel-aligned 3D reconstruction method that effectively improves occluded region completion through a scene-token mechanism and flow-matching loss. It provides a feasible solution for the non-pixel-aligned paradigm."
  },
  {
    "paper_id": "JWY5vIMGeG",
    "title": "SFA-KAN: Spatial-Frequency Aggregation Kolmogorov-Arnold Network for OCT Segmentation",
    "domain": "applications to computer vision",
    "content": "Current medical image segmentation methods exhibit significant limited robustness in optical coherence tomography (OCT) images, primarily attributable to incomplete representation of organ structures and the illumination heterogeneity during image acquisition. To this end, we propose an efficient approach for extracting complete structure and fine-grained details of OCT images, the Spatial-Frequency Aggregation Kolmogorov-Arnold Network (SFA-KAN). Specifically, our method introduces the Spatial-Frequency Aggregation (SFA) module, which operates in the latent space of a convolutional encoder-decoder architecture. This module hierarchically aggregates features from both the spatial and frequency domains. For spatial-domain feature extraction, we propose the Spatial-Shift KAN (S2KA) block, which employs width and height directions channel-mixing KAN linear layers combined with spatial-shift operations. This design facilitates patch-wise communication and captures long-distance multi-directional dependencies across the entire image within a single computational pass. For frequency-domain feature extraction, we introduce the Spatial-Shift Frequency Transform (S2FT) block, which employs the same spatial operations as the S2KA block followed by multi-scale fast Fourier transform to isolate clinically-relevant frequency components, enhancing segmentation of anatomically diverse structures. Subsequently, the features from these two different domains are channel-wise concatenated and aggregated via cross attention, enabling the model to reconstruct high-frequency details while preserving global structural integrity. Experiments conducted on two privately collected OCT image datasets employing pixel-based metrics and clinical metrics demonstrated that SFA-KAN achieves state-of-the-art performance for OCT image segmentation.",
    "key_points": [
      "oct image",
      "kolmogorov-arnold network",
      "dual-domain"
    ],
    "gold_summary": "This paper proposes a Spttial-Frequency Aggregation KA Network (SFA-KAN) for segmentation of OCT images. This framework involoves S2KA for partial dependency modeling and S2FT for frequency-domain analysis."
  },
  {
    "paper_id": "7vHUQCMAzG",
    "title": "Language Agents for Hypothesis-driven Clinical Decision Making with Reinforcement Learning",
    "domain": "applications to computer vision",
    "content": "Clinical decision-making is a dynamic, interactive, and cyclic process where doctors have to repeatedly decide on which clinical action to perform and consider newly uncovered information for diagnosis and treatment. Large Language Models (LLMs) have the potential to support clinicians in this process, however, most applications of LLMs in clinical decision support suffer from one of two limitations: Either they assume the unrealistic scenario of immediate availability of all patient information and do not model the interactive and iterative investigation process, or they restrict themselves to the limited \"out-of-the-box\" capabilities of large pre-trained models without performing task-specific training. In contrast to this, we propose to model clinical decision-making for diagnosis with a hypothesis-driven uncertainty-aware language agent, LA-CDM, that converges towards a diagnosis via repeatedly requesting and interpreting relevant tests. Using a hybrid training paradigm combining supervised and reinforcement learning, we train LA-CDM with three objectives targeting critical aspects of clinical decision-making: accurate hypothesis generation, hypothesis uncertainty estimation, and efficient decision-making. We evaluate our methodology on MIMIC-CDM, a real-world dataset covering four abdominal diseases containing various clinical tests and show the benefit of explicitly training clinical decision-making for increasing diagnostic performance and efficiency. We will release our code upon acceptance.",
    "key_points": [
      "clinical decision making",
      "large language models"
    ],
    "gold_summary": "This paper proposes LA-CDM, a two-agent system combining hypothesis generation and decision-making modules trained with hybrid supervised and reinforcement learning for iterative clinical diagnosis."
  },
  {
    "paper_id": "hzOF3d0Cyd",
    "title": "RegionUDF: Region-Aware Unsigned Distance Fields for Surface Reconstruction from Point Clouds",
    "domain": "applications to computer vision",
    "content": "Distance fields offer a powerful representation for continuous geometry, yet current learning-based neural unsigned distance fields (UDFs) remain limited in their ability to capture data patterns and generalize to real-world open surfaces. Point-Based methods mitigate grid quantization errors but current work often oversmooth local details, as query features are obtained solely through interpolation of point-wise features which are aggregated over large receptive fields. To address this, we propose a $\\textit{discriminative region representation}$ that fuses narrow neighborhood features with broader contextual point-wise features, and a $\\textit{primitive-based region representation}$ that decomposes neighborhoods into triplet-defined primitives to capture complex surface structures. Building on these designs, we propose $\\textit{RegionUDF}$, a region-aware UDF framework that achieves state-of-the-art open-surface reconstruction on both object- and room-level scenes, with additional validation on watertight shapes. Extensive experiments on synthetic and real-world datasets demonstrate superior accuracy and robust cross-domain generalization. Our source code will be available at $\\textit{[no-name-for-blind-review]}$.",
    "key_points": [
      "surface reconstruction",
      "unsigned distance filelds",
      "point clouds"
    ],
    "gold_summary": "This paper proposes a region-aware unsigned distance function representation for surface reconstruction from point clouds. The key idea is to incorporate region-level and primitive-based features into the query function, aiming to enhance local geometric representation."
  },
  {
    "paper_id": "ioGQhr1lhZ",
    "title": "Model-aware Counterfactual Data based Contrastive Decoding for Video-LLM",
    "domain": "applications to computer vision",
    "content": "Video language models (Video-LLMs) are prone to hallucinations, often generating plausible but ungrounded content when visual evidence is weak, ambiguous, or biased. Existing decoding methods, such as contrastive decoding (CD), rely on random perturbations to construct contrastive data for mitigating hallucination patterns. However, such a way is hard to control the visual cues that drive hallucination or well align with model weaknesses. \nWe propose Model-aware Counterfactual Data based Contrastive Decoding (GeWu), a new inference strategy that combines model-guided counterfactual construction with decoding. Our approach uses the Video-LLM’s own feedback to identify object regions most responsible for hallucination, generating targeted counterfactual inputs at the object level rather than arbitrary frame or temporal modifications. These model-aware counterfactual data is then integrated into CD to enforce evidence-grounded token selection during decoding. Experiments on EventHallusion, MVBench, and Perception-test show that GeWu consistently reduces hallucination while maintaining or improving task accuracy across diverse Video-LLMs, including InternVL3, Qwen2.5-VL and Qwen2-VL families. The method is especially effective in challenging scenarios involving small, occluded, or co-occurring objects. Our code and data will be publicly released.",
    "key_points": [
      "video-language models",
      "hallucination mitigation",
      "contrastive decoding",
      "object-level data augmentation",
      "counterfactual inputs"
    ],
    "gold_summary": "GeWu reduces Video-LLM hallucination by optimizing model-aware spatial/temporal masks to form counterfactual views and contrasting logits between original and masked videos at inference—no retraining, improved metrics across benchmarks."
  },
  {
    "paper_id": "yOxb03ThcW",
    "title": "Polyglot-R1: Reinforcement Learning for Multilingual Multi-Perspective Reasoning in LLMs",
    "domain": "applications to computer vision",
    "content": "Multilingual reasoning has recently emerged as a powerful strategy for extending the reach and impact of large language models (LLMs). By enabling models to operate effectively across diverse languages and modalities, it broadens access to advanced reasoning capabilities for a wider range of users and linguistic communities. Yet reliably activating such behaviours through training remains difficult. Existing approaches rely heavily on supervised fine-tuning over synthetic data, which tends to encourage imitation of teacher signals rather than genuine exploration or robust generalisation.\nTo address this gap, we introduce, we propose \\textbf{Polyglot-R1}, the first reinforcement learning framework designed to cultivate multilingual, multi-perspective reasoning behaviours for complex, real-world tasks. Our framework introduces a progressive curriculum that directly tackles the cold-start problem in training with reinforcement learning. We begin with supervised fine-tuning on trajectories from more straightforward multilingual prompts to instil the foundations of this reasoning style. We then transition to reinforcement learning, enabling the model to actively explore and generalise this skill on more challenging multilingual and multimodal problems. Experiments demonstrate that Polyglot-R1 not only improves accuracy but also reshapes the way models reason. At earlier stages of training, multilingual reasoning functions as an exploration strategy, encouraging the model to test diverse lines of thought. At later stages, the same capacity is repurposed as a mechanism for multi-perspective verification, strengthening confidence in the final answer. Most importantly, we validate multilingual reasoning as an intermediate exploration scaffold: a temporary but crucial phase that unlocks more robust, transferable reasoning capabilities across languages.",
    "key_points": [
      "llms",
      "reasoning",
      "multilingual"
    ],
    "gold_summary": "This paper proposes Polyglot-R1, a reinforcement learning framework designed to cultivate multilingual, multi-perspective reasoning in LLMs"
  },
  {
    "paper_id": "bQyPTtOBoM",
    "title": "MoDA: Multi-modal Diffusion Architecture for Talking Head Generation",
    "domain": "applications to computer vision",
    "content": "Talking head generation with arbitrary identities and speech audio remains a crucial problem in the realm of the virtual metaverse. Despite progress, current methods still struggle to synthesize diverse facial expressions and natural head movements while generating synchronized lip movements with the audio. The main challenge is stylistic discrepancies between speech audio, individual identity and portrait dynamics. To address the challenge of inter-modal inconsistency, we introduce MoDA, a multi-modal diffusion architecture with two well-designed technologies. First, MoDA models the interaction among motion, audio, and auxiliary conditions explicitly, enhancing overall facial expressions and head dynamics. In addition, a coarse-to-fine fusion strategy is employed to progressively integrate different conditions, ensuring effective feature fusion. Experimental results demonstrate that MoDA improves video diversity, realism, and efficiency, making it suitable for real-world applications.",
    "key_points": [
      "talking head generation",
      "diffusion model",
      "data-driven animation"
    ],
    "gold_summary": "This paper introduces MoDA, a two-stage framework for generating high-fidelity talking heads. The proposed approach surpasses existing methods in visual realism and lip-sync accuracy while maintaining strong temporal consistency, enabling long-duration video generation."
  },
  {
    "paper_id": "3rJaHWanTm",
    "title": "Efficient and Effective Dynamic Hair Reconstruction via Strand Gaussians",
    "domain": "applications to computer vision",
    "content": "Reconstructing dynamic human hair is a crucial way to acquire high quality 3D assets that empowers downstream tasks such as human avatars and animation. Recently, several research works propose using strand gaussians to model human hair, leading to superior reconstruction quality. However, their optimization algorithms admit significant computational burden and typically take hours to days reconstruct dynamic human hair from multi-view videos. We propose an efficient and effective optimization method that is significantly faster compared to state-of-the-art dynamic human hair reconstruction methods, while achieving comparable reconstruction quality. The performance of our algorithm is demonstrated both qualitatively and quantitatively on the public NeRSemble dataset.",
    "key_points": [
      "dynamic hair reconstruction",
      "efficient hair reconstruction"
    ],
    "gold_summary": "This paper proposes a pipeline for dynamic hair reconstruction using strand gaussians. The authors' biggest contribution is to improve training efficiency by optimizing the training process through methods such as sparsity-driven."
  },
  {
    "paper_id": "QU8raq5UhG",
    "title": "Fast Text-to-Audio Generation with One-Step Sampling via Energy-Scoring and Auxiliary Contextual Representation Distillation",
    "domain": "applications to computer vision",
    "content": "Autoregressive (AR) models with diffusion heads have recently achieved strong text-to-audio performance, yet their iterative decoding and multi-step sampling process introduce high-latency issues. To address this bottleneck, we propose a one-step sampling framework that combines an energy-distance training objective with representation-level distillation. An energy-scoring head maps Gaussian noise directly to audio latents in one step, eliminating the need for a costly recursive diffusion sampling process, while distillation from a masked autoregressive (MAR) text-to-audio model preserves the strong conditioning learned during diffusion training. On the AudioCaps benchmark, our method consistently outperforms prior one-step baselines on both objective and subjective metrics while substantially narrowing the quality gap to AR diffusion systems with multi-step sampling. Compared to the state-of-the-art AR diffusion system, IMPACT, our approach achieves up to $25$× faster inference with highly competitive audio quality. These results demonstrate that combining energy-distance training with representation-level distillation provides an effective recipe for fast, high-quality text-to-audio synthesis.",
    "key_points": [
      "energy-scoring",
      "representation distillation",
      "low-latency",
      "autoregressive",
      "text-to-audio"
    ],
    "gold_summary": "The paper proposes a one-step text-to-audio (TTA) generation framework that replaces multi-step diffusion with energy-distance training and representation-level distillation from a diffusion-based teacher. This approach achieves up to 25× faster inference than state-of-the-art models (IMPACT)."
  },
  {
    "paper_id": "76flfkkawe",
    "title": "LongScape: Advancing Long-Horizon Embodied World Models with Context-Aware MoE",
    "domain": "applications to computer vision",
    "content": "Video-based world models hold significant potential for generating high-quality embodied manipulation data. However, current video generation methods struggle to achieve stable long-horizon generation: classical diffusion-based approaches often suffer from temporal inconsistency and visual drift over multiple rollouts, while autoregressive methods tend to compromise on visual detail. To solve this, we introduce LongScape, a hybrid framework that adaptively combines intra-chunk diffusion denoising with inter-chunk autoregressive causal generation. Our core innovation is an action-guided, variable-length chunking mechanism that partitions video based on the semantic context of robotic actions. This ensures each chunk represents a complete, coherent action, enabling the model to flexibly generate diverse dynamics. We further introduce a Context-aware Mixture-of-Experts (CMoE) framework that adaptively activates specialized experts for each chunk during generation, guaranteeing high visual quality and seamless chunk transitions. Extensive experimental results demonstrate that our method achieves stable and consistent long-horizon generation over extended rollouts. Our code is available at: https://anonymous.4open.science/r/AMSVVD-fdg245.",
    "key_points": [
      "embodied world model",
      "long-horizon video generation"
    ],
    "gold_summary": "This paper presents an autoregressive video diffusion model with an internal structure designed using MoE. The experimental section mainly tests on robot datasets, with video lengths reaching up to 200 frames."
  },
  {
    "paper_id": "haXPUuOG4F",
    "title": "Instance Data Condensation for Image Super Resolution",
    "domain": "applications to computer vision",
    "content": "Deep learning based image Super-Resolution (ISR) relies on large training datasets to optimize model generalization; this requires substantial computational and storage resources during training. While dataset condensation has shown potential in improving data efficiency and privacy for high-level computer vision tasks, it has not yet been fully exploited for ISR. In this paper, we propose a novel Instance Data Condensation (IDC) framework specifically for ISR, which achieves instance-level data condensation through Random Local Fourier Feature Extraction and Multi-level Feature Distribution Matching. This aims to optimize feature distributions at both global and local levels and obtain high-quality synthesized training content with fine detail. This framework has been utilized to condense the most commonly used training dataset for ISR, DIV2K, with a 10\\% condensation rate. The resulting synthetic dataset offers comparable or (in certain cases) even superior performance compared to the original full dataset and excellent training stability when used to train various popular ISR models. To the best of our knowledge, this is the first time that a condensed/synthetic dataset (with a 10\\% data volume) has demonstrated such performance. The associated code and synthetic dataset are available here.",
    "key_points": [
      "dataset distillation",
      "image super resolution"
    ],
    "gold_summary": "This paper proposes a new dataset condensation framework for image super-resolution, by designing a Multi-level Feature Distribution Matching approach and Random Local Fourier Features. The conducted experiments show that the condensed datasets give promising performance."
  },
  {
    "paper_id": "yOMeLIvpXq",
    "title": "FusionFormer: Multi-Window Fusion for Efficient Real-Time Segmentation with Vision Foundation Models",
    "domain": "applications to computer vision",
    "content": "Recent advances in real-time segmentation has been driven by lightweight Transformer variants. To address the limitations of such designs, state-of-the-art (SOTA) methods employ bidirectional architectures with training-only Transformer branch for long-range contextual guidance. However, these approaches typically depend on task-specific pre-trained models with limited scalability, potentially limiting their maximum performance.\nIn this paper, we introduce the \\textit{Multi-Window Fusion Transformer} (\\textbf{\\textit{FusionFormer}}) to effectively leverage vision foundation models (VFMs). Specifically, we constrain self-attention computation within different window sizes and aggregate tokens within each window using varying fusion ratios. Our attention mechanism approximates attended fields from local to global while maintaining linear computational complexity, enabling better utilization of global attention guidance in Vision Transformer (ViT)-based VFMs. We first evaluate FusionFormer on the ImageNet-1k classification task, demonstrating its potential as a versatile efficient backbone. Further,extensive experiments on the ADE20K and Cityscapes datasets, coupling FusionFormer with a simple light head and DINOv2-B/14, demonstrate its excellent trade-off between segmentation accuracy and computational cost. Compared to previous methods, FusionFormer achieves a more efficient utilization of global guidance from VFMs. Our code will be released soon after the paper is accepted.",
    "key_points": [
      "real-time semantic segmentation",
      "vision foundation models",
      "efficient transformer",
      "fusionformer",
      "multi-window fusion attention"
    ],
    "gold_summary": "This paper introduces FusionFormer, a lightweight Transformer architecture tailored for real-time semantic segmentation. The primary contribution is the Multi-Window Fusion Attention (MWFA) module."
  },
  {
    "paper_id": "RMKi6nwubp",
    "title": "Physically Grounded Avatar Generation",
    "domain": "applications to computer vision",
    "content": "Recent advances in diffusion transformer (DiT) models have greatly improved audio-driven video avatar generation, enabling the synthesis of realistic avatars from a single reference image and an audio clip. However, generating avatars with $\\textit{physically grounded human behaviors}$ remains challenging, primarily due to ($\\textbf{i}$) overreliance on shallow audio-visual correlations and ($\\textbf{ii}$)  misalignment between semantic intent and behavioral expression. Consequently, existing methods often produce facial expressions and gestures that appear constrained, lack emotional depth, and fail to capture realistic human dynamics. In this paper, we present a $\\textbf{Phys}$ically grounded DiT model for $\\textbf{Avatar}$ generation, termed $\\textbf{PhysAvatar}$, which can produce realistic, contextually coherent,  long-form avatars with human-like behavioral fidelity. PhysAvatar introduces three key innovations: ($\\textbf{i}$) physical state supervision, embedding human behavioral dynamics into the video DiT model via discrete diffusion; ($\\textbf{ii}$) physical planning guidance, which leverages a multimodal language model to jointly analyze audio and visual inputs and direct the avatar behaviors according to semantic intent; and ($\\textbf{iii}$) efficient long-form inference with interleaved video interpolation, improving temporal coherence and identity preservation. Extensive experiments on our in-house dataset, as well as PATS and Vlogger, demonstrate that PhysAvatar outperforms state-of-the-art baselines in both generative quality and behavioral realism, consistently producing avatars that are more physically grounded, expressive, and lifelike.",
    "key_points": [
      "video generation",
      "audio-driven avatar",
      "physically grounded human behaviors"
    ],
    "gold_summary": "This paper presents PhysAvatar, a physically grounded DiT model for avatar generation that produces realistic, contextually coherent, long-form avatars with human-like behavioral fidelity. The approach is well-motivated and shows promising results."
  },
  {
    "paper_id": "L0dORRnUhu",
    "title": "SeViCES: Unifying Semantic-Visual Evidence Consensus for Long Video Understanding",
    "domain": "applications to computer vision",
    "content": "Long video understanding remains challenging due to its complex, diverse, and temporally scattered content. Although video large language models (Video-LLMs) can process videos lasting tens of minutes, applying them to truly long sequences is computationally prohibitive and often leads to unfocused or inconsistent reasoning. A promising solution is to select only the most informative frames, yet existing approaches typically ignore temporal dependencies or rely on unimodal evidence, limiting their ability to provide complete and query-relevant context. We propose a  **Se**mantic–**Vi**sual **C**onsensus **E**vidence **S**election (SeViCES) framework for effective and reliable long video understanding. SeViCES is training-free and model-agnostic, and introduces two key components. The Semantic–Visual Consensus Frame Selection (SVCFS) module selects frames through (1) a temporal-aware semantic branch that leverages LLM reasoning over captions, and (2) a cluster-guided visual branch that aligns embeddings with semantic scores via mutual information. The Answer Consensus Refinement (ACR) module further resolves inconsistencies between semantic- and visual-based predictions by fusing evidence and constraining the answer space. Extensive experiments on long video understanding benchmarks show that SeViCES consistently outperforms state-of-the-art methods in both accuracy and robustness, demonstrating the importance of consensus-driven evidence selection for Video-LLMs.",
    "key_points": [
      "long video understanding",
      "semantic-visual consistency",
      "frame selection"
    ],
    "gold_summary": "This paper introduces SeViCES, a training-free and model-agnostic framework that enhances long video understanding by selecting key frames through a semantic-visual consensus mechanism and refining final answers by resolving inconsistencies between different evidence sources."
  },
  {
    "paper_id": "3RqhL4yEJn",
    "title": "UQ: Assessing Language Models on Unsolved Questions",
    "domain": "datasets and benchmarks",
    "content": "Benchmarks shape progress in AI research. A useful benchmark should be both difficult and realistic---questions should challenge frontier models while also reflecting real-world usage. Yet, current paradigms face a difficulty-realism tension: exam-style benchmarks are often made artificially difficult with limited real-world value, while benchmarks based on real user interaction often skew toward easy, high-frequency problems. In this work, we explore a radically different paradigm: assessing models on unsolved questions. Rather than a static benchmark scored once, we curate unsolved questions and evaluate models asynchronously over time with validator-assisted screening and community verification. We introduce UQ, a testbed of 500 challenging, diverse questions sourced from Stack Exchange, spanning topics from CS theory and math to sci-fi and history, probing capabilities including reasoning, factuality, and browsing. UQ is difficult and realistic by construction: unsolved questions are often hard and naturally arise when humans seek answers, thus solving them yields direct real-world value. Our contributions are threefold: (1) UQ-Dataset and its collection pipeline combining rule-based filters, LLM judges, and human review to ensure question quality (e.g., well-defined and difficult); (2) UQ-Validators, compound validation strategies that leverage the generator-validator gap to provide evaluation signals and pre-screen candidate solutions for human review; and (3) UQ-Platform, an open platform where experts collectively verify questions and solutions, enabling ongoing, asynchronous, and community-driven evaluation. The top-performing model passes UQ-validation on only 15% of questions, and preliminary human verification has already identified correct answers among those that passed. UQ charts a path for evaluating frontier models on real-world, open-ended challenges, where success pushes the frontier of human knowledge.",
    "key_points": [
      "benchmark",
      "evaluations",
      "language models",
      "verifiers",
      "generator-validator gap",
      "platform"
    ],
    "gold_summary": "The paper proposes a benchmark including unsolved problems from CS, math, science, and history. Also, provide a complete pipeline including data filtering, evaluation, and building a platform for experts to continuously update the dataset"
  },
  {
    "paper_id": "hKhJcKc0Yv",
    "title": "Automotive-ENV: Benchmarking Multimodal Agents in Vehicle Interface Systems",
    "domain": "datasets and benchmarks",
    "content": "Multimodal agents have demonstrated strong performance in general GUI interactions, but their application in automotive systems has been largely unexplored. In-vehicle GUIs present distinct challenges: drivers' limited attention, strict safety requirements, and complex location-based interaction patterns. To address these challenges, we introduce Automotive-ENV, the first high-fidelity benchmark and interaction environment tailored for vehicle GUIs. This platform defines 185 parameterized tasks spanning explicit control, implicit intent understanding, and safety-aware tasks, and provides structured multimodal observations with precise programmatic checks for reproducible evaluation. Building on this benchmark, we propose ASURADA, a geo-aware multimodal agent that integrates GPS-informed context to dynamically adjust actions based on location, environmental conditions, and regional driving norms. Experiments show that geo-aware information significantly improves success on safety-aware tasks, highlighting the importance of location-based context in automotive environments. We will release Automotive-ENV, complete with all tasks and benchmarking tools, to further the development of safe and adaptive in-vehicle agents.",
    "key_points": [
      "benchmark",
      "gui agent"
    ],
    "gold_summary": "This paper provides a multi-modal agent benchmark to evaluate Automotive graphic user interface. It is powered by GPT based model and it supports reproduicible benchmark over auto UI."
  },
  {
    "paper_id": "K5t8PfzwFR",
    "title": "Towards Human Inverse Dynamics from Real Images: A Dataset and Benchmark for Joint Torque Estimation",
    "domain": "datasets and benchmarks",
    "content": "Human inverse dynamics is an important technique for analyzing human motion. Previous studies have typically estimated joint torques from joint pose images, marker coordinates, or EMG signals, which severely limit their applicability in real-world scenarios. In this work, we aim to directly predict joint torques during human movements from real human images. To address this gap, we present the vision-based inverse dynamics dataset (VID), the first dataset tailored for the joint torque prediction from real human images. VID comprises 63,369 frames of synchronized monocular images, kinematic data, and dynamic data of real human subjects. All data are carefully synchronized, refined, and manually validated to ensure high quality. In addition, we introduce a comprehensive benchmark for the vision-based inverse dynamics of real human images, consisting of a new baseline method and a new evaluation criteria with three levels of difficulty: (i) overall joint torque estimation, (ii) joint-specific analysis, and (iii) action-specific prediction. We further compare the baseline result of our VID-Network with other representative approaches, our baseline method achieves the state-of-the-art performance on almost all the evaluation criteria. By releasing VID and the accompanying evaluation protocol, we aim to establish a foundation for advancing biomechanics from real human images and to facilitate the exploration of new approaches for human inverse dynamics in unconstrained environments.",
    "key_points": [
      "vision inverse dynamics",
      "human biomechanics"
    ],
    "gold_summary": "The authors proposed the VID as a vision-based human inverse dynamics dataset. VIDNet is further designed to directly regress human joint torque from images. Experiments show the efficacy of the proposed pipeline."
  },
  {
    "paper_id": "ae6bKeffGZ",
    "title": "Arithmetic-Bench: Evaluating Multi-Step Reasoning in LLMs with Basic Arithmetic",
    "domain": "datasets and benchmarks",
    "content": "We propose Arithmetic-Bench, a benchmark designed to evaluate the multi-step reasoning ability of large language models (LLMs) through basic arithmetic operations. The benchmark covers fundamental mathematical operations such as addition, subtraction, multiplication, and division, while also incorporating subtasks like copying, reversing, counting, and base conversion.\nExperimental results show that the accuracy of current LLMs drops sharply when performing arithmetic operations involving more than 10 digits, implying a failure of generalization in multi-step reasoning.\nWe further analyze the root causes of these failures. While LLMs can achieve a certain degree of arithmetic generalization through training on limited-length sequences, they fail to generalize to arbitrary lengths. This is due to the inherent complexity of arithmetic tasks: achieving true arithmetic generalization cannot rely on memorization alone but requires the acquisition of genuine reasoning mechanisms.\nCompared to other math benchmarks, Arithmetic-Bench provides a simple and fair framework. Because the tasks are purely synthetic, they are easy to generate and largely free from human biases. We believe that arithmetic tasks are both fundamental and necessary for advancing reasoning models, and Arithmetic-Bench offers a principled way to evaluate them.",
    "key_points": [
      "reasoning",
      "arithmetic benchmark"
    ],
    "gold_summary": "In the paper, the authors provide an arithmetic benchmark to evaluate the fundamental mathematical operations and some sub-tasks. They test current LLMs on the benchmark and show the length generalization problem."
  },
  {
    "paper_id": "Q78kLO9rfB",
    "title": "CoCoPIF: Benchmarking Conversational Coding and Programmatic Instruction Following",
    "domain": "datasets and benchmarks",
    "content": "Code generation with large language models (LLMs) has become popular to software development, yet existing benchmarks like HumanEval and LBPP focus on single-turn task completion. In real-world scenarios, users often engage in multi-turn interactions, iteratively refining code through instruction-following feedback to meet complex requirements or constraints. Current benchmarks fail to capture the dynamic, instruction-driven nature of such workflows. To address this, we introduce CoCoPIF, a new evaluation pipeline for evaluating LLMs in multi-turn, instruction-following code generation, by emulating real-world interaction data from ShareGPT and problems from LiveCodeBench. Our framework dynamically transforms code problems into multi-turn tasks with verifiable instructions. It features an evaluation protocol that mirrors user-LLM interaction by iteratively refining model outputs through targeted feedback. Furthermore, our assessment approach evaluates both instruction adherence and functional correctness, delivering a reliable measurement of model performance. CoCoPIF reflects practical coding scenarios, providing a tool to assess LLMs in realistic, interactive programming contexts.",
    "key_points": [
      "large language models (llms)",
      "multi-turn benchmark",
      "instruction-following",
      "code generation"
    ],
    "gold_summary": "This paper presents a benchmark for conversational coding as multi-turn, instruction-following tasks. \nBoth functional correctness and programmatic instruction adherence are evaluated to reflect multi-turn development workflows."
  },
  {
    "paper_id": "rjhF7b7n6g",
    "title": "Evaluating Dataset Watermarking for Fine-tuning Traceability of Customized Diffusion Models: A Comprehensive Benchmark and Removal Approach",
    "domain": "datasets and benchmarks",
    "content": "Recently, numerous fine-tuning techniques for diffusion models have been developed, enabling diffusion models to generate content that closely resembles a specific image set, such as specific facial identities and artistic styles. However, this advancement also poses potential security risks. The primary risk comes from copyright violations due to using public domain images without authorization to fine-tune diffusion models. Furthermore, if such models generate harmful content linked to the source images, tracing the origin of the fine-tuning data is crucial to clarify responsibility. To achieve fine-tuning traceability of customized diffusion models, dataset watermarking for diffusion model has been proposed, involving embedding imperceptible watermarks into images that require traceability. Notably, even after using the watermarked images to fine-tune diffusion models, the watermarks remain detectable in the generated outputs. However, existing dataset watermarking approaches lack a unified framework for performance evaluation, thereby limiting their effectiveness in practical scenarios. To address this gap, this paper first establishes a generalized threat model and subsequently introduces a comprehensive framework for evaluating dataset watermarking methods, comprising three dimensions: Universality, Transmissibility, and Robustness. Our evaluation results demonstrate that existing methods exhibit universality across diverse fine-tuning approaches and tasks, as well as transmissibility even when only a small proportion of watermarked images is used. In terms of robustness, existing methods show good performance against common image proces sing operations, but this does not match real-world threat scenarios. To address this issue, this paper proposes a practical watermark removal method that can completely remove dataset watermarks without affecting fine-tuning, revealing their vulnerabilities and pointing to a new challenge for future research.",
    "key_points": [
      "dataset watermarking; diffusion model; copyright protection"
    ],
    "gold_summary": "See the Strengths and Weaknesses."
  },
  {
    "paper_id": "SVwEDbi1wR",
    "title": "Who Routes the Router: Rethinking the Evaluation of LLM Routing Systems",
    "domain": "datasets and benchmarks",
    "content": "The growing ecosystem of Large Language Models (LLMs) with diverse capabilities and costs has motivated the need for LLM routing systems that dynamically select the most appropriate model for each query. Evaluating these routing systems is important yet inherently challenging due to the complex interplay of multiple factors: the selection of representative input queries, the composition of the model pool, and the definition of comprehensive evaluation metrics for optimal routing decisions. Through extensive analysis of existing benchmarks, we identify critical limitations that may lead to incomplete results and/or misleading conclusions about router performance: \n(1) limited task diversity, (2) imbalanced model pools, and (3) oversimplified evaluation methodologies. To address these limitations, we propose a novel evaluation framework that incorporates diverse task distributions (33,337 queries across 68 categories), a balanced model pool of 85 models with complementary model strengths, and multi-faceted metrics that reflect real-world deployment scenarios. \nWe implement this framework as an open-source benchmark, enabling researchers to rigorously assess routing strategies under realistic conditions. The code and dataset are shared anonymously at: https://anonymous.4open.science/r/rethinking-routing-evaluation-DE30",
    "key_points": [
      "llm router",
      "evaluation"
    ],
    "gold_summary": "The authors present flaws (redundant tasks, redundant and dominant models, lack of multi-faceted evaluation) with current router evaluation practices. They then present a remastered evaluation of the methods in embedLLM and some binary routing methods."
  },
  {
    "paper_id": "iX39LhePyd",
    "title": "Adaptive Testing for LLM Evaluation: A Psychometric Alternative to Static Benchmarks",
    "domain": "datasets and benchmarks",
    "content": "Large language model evaluation requires thousands of benchmark items, making evaluations expensive and slow. Existing methods compute average accuracy across fixed item sets, treating all items equally despite varying quality and informativeness. We present ATLAS, an adaptive testing framework using Item Response Theory (IRT) to estimate model ability  through Fisher information-guided item selection. Our analysis of five major benchmarks reveals that 3-6\\% of items exhibit negative discrimination, indicating annotation errors that corrupt static evaluation. ATLAS achieves 90\\% item reduction while maintaining measurement precision: on HellaSwag (5,608 items), we match full-benchmark estimates using only 42 items with 0.154 MAE. Our framework maintains item exposure rates below 10\\% and test overlap at 16-27\\%, compared to static benchmarks where every model sees all items (100\\% exposure). Among 4,000+ tested models, IRT ranks differ from accuracy ranks: models with the same accuracy get different IRT scores, and 23-31\\% of all models shift by more than 10 rank positions. Code and calibrated item banks available at https://anonymous.4open.science/r/ATLAS-3210/README.md.",
    "key_points": [
      "adaptive testing",
      "llm evaluation"
    ],
    "gold_summary": "The authors:\n\n- propose and motivate an IRT framework for adaptively sampling items to use to benchmark language model (LM) capabilities\n- evaluate their algorithm on 5 benchmarks"
  },
  {
    "paper_id": "e5OrurYW07",
    "title": "PULSE: Benchmarking Large Language Models for ICU Time Series Classification",
    "domain": "datasets and benchmarks",
    "content": "Large language models (LLMs) are increasingly used on multimodal clinical data, yet their performance on high-stakes ICU time series lacks a standardized evaluation. We introduce PULSE, a comprehensive LLM benchmark for intensive care unit (ICU) time series classification. PULSE evaluates 17 models, strong conventional learners, deep learning, and instruction-following LLMs under nine prompting/agentic strategies, across three datasets (HiRID, MIMIC-IV, eICU) and three clinical endpoints (mortality, sepsis, acute kidney injury). Across settings, well-tuned conventional models, especially gradient-boosted trees, remain the most robust and best-performing, reaching AUROCs up to 0.906. Frontier LLMs approach this level (best 0.889 AUROC, OpenAI o3) but show higher variance and sensitivity to prompting. A hybrid agentic approach that grounds LLM reasoning in a conventional model’s predictions consistently narrows the gap while also providing human-readable explanations at inference time. Notably, on several inferences, LLMs are competitive with classic models despite not being trained on multimodal time-series data. PULSE provides all code, configuration files, and a public results dashboard to enable transparent, reproducible comparison and rapid community extension. We expect PULSE to serve as a common yardstick for developing safer, more reliable LLMs for multimodal time series data, in critical care.",
    "key_points": [
      "icu",
      "intensive care unit",
      "clinical",
      "benchmark",
      "large language model",
      "llm",
      "agents",
      "evaluation",
      "classification"
    ],
    "gold_summary": "This paper measures the accuracy of conventional ML methods, deep learning, and LLMs for the task of predicting various labels for patients based on ICU time series."
  },
  {
    "paper_id": "jU10qDevGg",
    "title": "U2-BENCH: Benchmarking Large Vision-Language Models on Ultrasound Understanding",
    "domain": "datasets and benchmarks",
    "content": "Ultrasound is a widely-used imaging modality critical to global healthcare, yet its interpretation remains challenging due to its varying image quality on operators, noises, and anatomical structures. Although large vision-language models (LVLMs) have demonstrated impressive multimodal capabilities across natural and medical domains, their performance on ultrasound remains largely unexplored. We introduce U2-BENCH, the first comprehensive benchmark to evaluate LVLMs on ultrasound understanding across classification, detection, regression, and text generation tasks. U2-BENCH aggregates 7,241 cases spanning 15 anatomical regions and defines 8 clinically inspired tasks, such as diagnosis, view recognition, lesion localization, clinical value estimation, and report generation, across 50 ultrasound application scenarios. We evaluate 20 state-of-the-art LVLMs, both open- and closed-source, general-purpose and medical-specific. Our results reveal strong performance on image-level classification, but persistent challenges in spatial reasoning and clinical language generation. U2-BENCH establishes a rigorous and unified testbed to assess and accelerate LVLM research in the uniquely multimodal domain of medical ultrasound imaging.",
    "key_points": [
      "medical ultrasound",
      "benchmark",
      "large vision-language model"
    ],
    "gold_summary": "This manuscript presents U2-BENCH, a comprehensive benchmark for large VLM ultrasound understanding on eight clinically-inspired classification, detection, regression and text generation tasks, with 20 SOTA LVLMs evaluated on the benchmark."
  },
  {
    "paper_id": "hFixHMwX1D",
    "title": "BioCoref: Benchmarking Biomedical Coreference Resolution with LLMs",
    "domain": "datasets and benchmarks",
    "content": "Coreference resolution in biomedical texts presents unique challenges due to complex domain-specific terminology, high ambiguity in mention forms, and long-distance dependencies between coreferring expressions. In this work, we present a comprehensive evaluation of generative large language models (LLMs) for coreference resolution in the biomedical domain. Using the CRAFT corpus as our benchmark, we assess the LLMs' performance with four prompting experiments that vary in their use of local, contextual enrichment, and domain-specific cues such as abbreviations and entity dictionaries. We benchmark these approaches against a discriminative span-based encoder, SpanBERT, to compare the efficacy of generative versus discriminative methods. Our results demonstrate that while LLMs exhibit strong surface-level coreference capabilities, especially when supplemented with domain-grounding prompts, their performance remains sensitive to long-range context and mentions ambiguity. Notably, the LLaMA 8B and 17B models show superior precision and F1 scores under entity-augmented prompting, highlighting the potential of lightweight prompt engineering for enhancing LLM utility in biomedical NLP tasks.",
    "key_points": [
      "coreference resolution",
      "large language models (llms)",
      "benchmarking and evaluation",
      "prompt engineering",
      "craft corpus"
    ],
    "gold_summary": "Summary:\nAuthors explore four different prompting methods and asses their performance on biomedical coreference resolution."
  },
  {
    "paper_id": "Kkcaz5XlJB",
    "title": "AgentChangeBench: A Multi-Dimensional Evaluation Framework for Goal-Shift Robustness in Conversational AI",
    "domain": "datasets and benchmarks",
    "content": "Goal changes are a defining feature of real-world multi-turn interactions, yet current agent benchmarks primarily evaluate static objectives or one-shot tool use. We introduce $\\textbf{AgentChangeBench}$, a benchmark explicitly designed to measure how tool augmented language model agents adapt to mid dialogue goal shifts across three enterprise domains. Our framework formalizes evaluation through four complementary metrics: Task Success Rate (TSR) for effectiveness, Tool Use Efficiency (TUE) for reliability, Tool Call Redundancy Rate (TCRR) for wasted effort, and Goal-Shift Recovery Time (GSRT) for adaptation latency. AgentChangeBench comprises of 590 task sequences and five user personas, each designed to trigger realistic shift points in ongoing workflows. Using this setup, we evaluate a mix of proprietary and open source models and uncover sharp contrasts obscured by traditional pass@k scores. Our findings demonstrate that high raw accuracy does not imply robustness under dynamic goals, and that explicit measurement of recovery time and redundancy is essential. AgentChangeBench establishes a reproducible testbed for diagnosing and improving agent resilience in realistic enterprise settings.",
    "key_points": [
      "benchmark",
      "multiturn",
      "goal-shift",
      "robustness",
      "agents",
      "evaluation",
      "llm"
    ],
    "gold_summary": "This paper presents a new agentic benchmark, focusing on goal shift."
  },
  {
    "paper_id": "ZFAFZyohqL",
    "title": "CH-CEMS: A Chinese Multi-Concept Benchmark Dataset Towards Explainable Multi-Modal Sentiment Analysis",
    "domain": "datasets and benchmarks",
    "content": "Explainable Multimodal Sentiment Analysis (EMSA) is a booming research area aimed at advancing robust and faithful multimodal language understanding. Recent explainable datasets and methods based on multimodal large language models (MLLMs) have introduced a new paradigm that produces chain-of-thought–style explanations within affective computing. However, high-quality data resources for EMSA remain scarce, largely because annotating reliable reasoning cues is costly and difficult. To address this gap, we introduce CH-CEMS, the first multimodal sentiment dataset for explainable multimodal sentiment analysis. It contains 3,715 curated video segments with polarity and intensity annotations. In addition, we annotate three semantic concepts for each sample (i.e., speaking style, tone of voice, and facial expression), which serve as explicit reasoning cues to enable process-level supervision. To fully leverage these concept cues, we propose a concept-guided reinforcement learning framework with Group Relative Policy Optimization (GRPO) for MLLMs, in which concept-level supervision explicitly constrains cross-modal semantic relations and guides the model to infer sentiment from verifiable concepts. We further establish baselines with state-of-the-art multimodal machine learning methods and MLLMs via zero-shot inference and supervised fine-tuning. Experiments show that MLLMs outperform feature-based methods, typically by 4–12\\% in accuracy for three-class sentiment analysis, and that our concept-guided GRPO yields a further 8.5\\% improvement, even surpassing closed-source model such as GPT-5. We believe CH-CEMS and the benchmark will facilitate future research on explainable multimodal sentiment analysis. The dataset and codes are avaliable for use at https://anonymous.4open.science/r/CH-CEMS-C34F.",
    "key_points": [
      "multimodal sentiment analysis",
      "dataset",
      "reinforcement learning",
      "multimodal large language models"
    ],
    "gold_summary": "The paper proposes multi-concept datasets for explainable multimodal sentiment analysis task and conduct concept-based GRPO with effective fine-grained reasoning process. Experiments on MOSI/MOSEI are conducted to show effectiveness of the proposed model."
  },
  {
    "paper_id": "R3VBfYVK1x",
    "title": "Evaluating LLMs on Real-World Forecasting Against Expert Forecasters",
    "domain": "datasets and benchmarks",
    "content": "Large language models (LLMs) have demonstrated remarkable capabilities across diverse tasks, but their ability to forecast future events remains understudied. Large language models used to struggle to come close to the accuracy of a human crowd. I evaluate state-of-the-art LLMs on 464 forecasting questions from Metaculus, comparing their performance against top forecasters. Frontier models achieve Brier scores that ostensibly surpass the human crowd but still significantly underperform a group of experts.",
    "key_points": [
      "automated forecasting",
      "benchmarks"
    ],
    "gold_summary": "The paper studies the current state of LLMs on the forecasting task."
  },
  {
    "paper_id": "nA8vLqvBRJ",
    "title": "DeepfakeBench-MM: A Comprehensive Benchmark for Multimodal Deepfake Detection",
    "domain": "datasets and benchmarks",
    "content": "The misuse of advanced generative AI models has resulted in the widespread proliferation of falsified data, particularly forged human-centric audiovisual content, which poses substantial societal risks (e.g., financial fraud and social instability). In response to this growing threat, several works have preliminarily explored countermeasures. However, the lack of sufficient and diverse training data, along with the absence of a standardized benchmark, hinder deeper exploration. To address this challenge, we first build Mega-MMDF, a large-scale, diverse, and high-quality dataset for multimodal deepfake detection. Specifically, we employ 21 forgery pipelines through the combination of 10 audio forgery methods, 12 visual forgery methods, and 6 audio-driven face reenactment methods. Mega-MMDF currently contains 0.1 million real samples and 1.1 million forged samples, making it one of the largest and most diverse multimodal deepfake datasets, with plans for continuous expansion. Building on it, we present DeepfakeBench-MM, the first unified benchmark for multimodal deepfake detection. It establishes standardized protocols across the entire detection pipeline and serves as a versatile platform for evaluating existing methods as well as exploring novel approaches. DeepfakeBench-MM currently supports 5 datasets and 11 multimodal deepfake detectors. Furthermore, our comprehensive evaluations and in-depth analyses uncover several key findings from multiple perspectives (e.g., augmentation, stacked forgery). We believe that DeepfakeBench-MM, together with our large-scale Mega-MMDF, will serve as foundational infrastructures for advancing multimodal deepfake detection. Our DeepfakeBench-MM is released at https://github.com/AnonymousDeepfakeBench-MM/DeepfakeBench-MM for anonymous review. Research-only access to Mega-MMDF will be available after the review period.",
    "key_points": [
      "deepfake detection; multimodal"
    ],
    "gold_summary": "The paper proposes a large scale diverse dataset called Mega-MMDF and DeepfakeBench-MM, which is a unified benchmark for multimodal deepfake detection. The paper unifies the pre-processing pipeline which standardizes the evaluation."
  },
  {
    "paper_id": "RMwJXp5Kb1",
    "title": "MoReBench: Evaluating Procedural and Pluralistic Moral Reasoning in Language Models, More than Outcomes",
    "domain": "datasets and benchmarks",
    "content": "As AI systems progresses, we rely more on them to make decisions with us and for us. To ensure that such decisions are aligned with human values, it is imperative for us to understand not only what decisions they make but also how they come to those decisions. Reasoning language models, which provide both final responses and (partially transparent) intermediate thinking traces, present a timely opportunity to study AI procedural reasoning. Unlike math and code problems which often have objectively correct answers, moral dilemmas are an excellent testbed for process-focused evaluation because they allow for multiple defensible conclusions. To do so, we present MoReBench: 1,000 moral scenarios, each paired with a set of rubric criteria that experts consider essential to include (or avoid) when reasoning about the scenarios. MoReBench contains over 23 thousand criteria including identifying moral considerations, weighing trade-offs, and giving actionable recommendations to cover cases on AI advising humans moral decisions as well as making moral decisions autonomously. Separately, we curate MoReBench-Theory: 150 examples to test whether AI can reason under five major frameworks in normative ethics. Our results show that scaling laws and existing benchmarks on math, code, and scientific reasoning tasks (fail to) predict models' abilities to perform moral reasoning. Models also show partiality towards specific moral frameworks (e.g., Benthamite Act Utilitarianism and Kantian Deontology), which might be side effects of popular training paradigms. Together, these benchmarks advance process-focused reasoning evaluation towards safer and more transparent AI.",
    "key_points": [
      "moral reasoning",
      "reasoning evaluation",
      "ai safety"
    ],
    "gold_summary": "This paper proposes a diverse benchmark together with a set of well-curated criteria to evaluate the morality of llm, not just in the final result, but also the intermediate steps."
  },
  {
    "paper_id": "LScx9M0nLk",
    "title": "GIFARC: Synthetic Dataset for Leveraging Human-Intuitive Analogies to Elevate AI Reasoning",
    "domain": "datasets and benchmarks",
    "content": "The Abstraction and Reasoning Corpus (ARC) poses a stringent test of general AI capabilities, requiring solvers to infer abstract patterns from only a handful of examples. Despite substantial progress in deep learning, state-of-the-art models still achieve accuracy rates of merely 40–55% on the 2024 ARC Competition, indicative of a significant gap between their performance and human-level reasoning. In this work, we seek to bridge that gap by introducing an analogy-inspired ARC dataset, GIFARC. Leveraging vision-language models (VLMs), we synthesize new ARC-style tasks from a variety of GIF images that include analogies. Each new task is paired with ground-truth analogy, providing an explicit mapping between visual transformations and everyday concepts. By embedding robust human-intuitive analogies into ARC-style tasks, GIFARC guides AI agents to adopt analogical reasoning approaches, facilitating more concise and human-understandable solutions. We empirically demonstrate that GIFARC improves task-solving performance by aligning model reasoning with human analogical problem-solving strategies.",
    "key_points": [
      "abstraction and reasoning corpus (arc)",
      "analogical reasoning",
      "synthetic datasets",
      "gif images",
      "benchmark improvement"
    ],
    "gold_summary": "This work proposes a synthetic data generation pipeline for ARC tasks that extracts analogy concepts from online GIFs. The dataset is used to fine-tune an LLM, showing limited improvement on ARC-AGI-1."
  },
  {
    "paper_id": "r0L9GwlnzP",
    "title": "Do LLM Agents Know How to Ground,  Recover, and Assess? A Benchmark for Epistemic Competence in Information-Seeking Agents",
    "domain": "datasets and benchmarks",
    "content": "Recent work has explored training Large Language Model (LLM) search agents with reinforcement learning (RL) for open-domain question answering (QA). However, most evaluations focus solely on final answer accuracy, overlooking how these agents reason with and act on external evidence.\n    We introduce **SeekBench**, the first benchmark for evaluating the *epistemic competence* of LLM search agents through step-level analysis of their response traces. **SeekBench** comprises 190 expert-annotated traces with over 1,800 response steps generated by LLM search agents, each enriched with evidence annotations for granular analysis of whether agents (1) generate reasoning steps grounded in observed evidence, (2) adaptively reformulate searches to recover from low-quality results, and (3) have proper calibration to correctly assess whether the current evidence is sufficient for providing an answer.\n    Our analysis of state-of-the-art LLM search agents reveals critical behavioral gaps overlooked by traditional metrics, including specialized skills like Search-R1's synthesis capabilities. These findings expose distinct epistemic competencies that accuracy-only evaluations fail to capture, providing guidance for developing more capable and reliable agents.",
    "key_points": [
      "epistemic competence",
      "evidence-grounded reasoning",
      "llm search agents"
    ],
    "gold_summary": "This paper proposes SeekBench, a benchmark to evaluate LLM search agents on epistemic competence of three dimensions/metrics: reasoning groundedness, search recovery, and answer calibration."
  },
  {
    "paper_id": "p4ERSIzHdL",
    "title": "CrossPL: Systematic Evaluation of Large Language Models for Cross Programming Language Interoperating Code Generation",
    "domain": "datasets and benchmarks",
    "content": "Large language models (LLMs) have shown strong performance in single-language code generation, but how well they produce cross-programming-language (CPL) interoperating code, which is widely used in cross-platform and complex software systems, remains underexplored. Therefore, a benchmark for evaluating CPL interaction code generation is essential. However, Constructing such a benchmark is challenging owing to sparse interoperating code in real-world multi-programming-language projects, diverse IPC mechanisms, vast FFI language pairs, and the difficulty of evaluation. To address this gap, we introduce CrossPL, the first benchmark for systematically assessing LLM performance of CPL code generation across two primary interoperation modes and 2534 tasks, specifically 1,982 IPC tasks spanning six languages and 522 Python–C FFI tasks. Its construction involved a review of CPL documentation, 156 finite state machines, and analysis of 19,169 multi-language GitHub repositories. Two LLM-based workflows are designed for automating the benchmark construction and evaluation, and assess 20 state-of-the-art LLMs. Results reveal clear limitations: the best model achieves only 19.5\\% Pass@1 and 26.46\\% Pass@5 on the FFI subset, in sharp contrast to the strong performance of these models on single-language benchmarks. These findings underscore the urgent need for improving LLMs regarding CPL interoperating code generation. The benchmark and code are available at https://anonymous.4open.science/r/crosspl-2814/.",
    "key_points": [
      "cross programming language interactions",
      "llm based workflow",
      "benchmark",
      "code generation"
    ],
    "gold_summary": "This paper introduces CrossPL, the first benchmark for systematically assessing LLM performance in Cross Programming Language (CPL) interoperating code generation."
  },
  {
    "paper_id": "SjjXr9mnlk",
    "title": "From Motion to Behavior: Hierarchical Modeling of Humanoid Generative Behavior Control",
    "domain": "datasets and benchmarks",
    "content": "Human motion generative modeling aims to synthesize complex motions from daily activities. However, current research is fragmented, focusing on either low-level, short-horizon motions or high-level, disembodied action planning, thereby neglecting the hierarchical and goal-oriented nature of human activities. This work shifts the research focus from motion generation to the more holistic task of humanoid behavior modeling. To formally address this, we first introduce Generative Behavior Control (GBC), a new task focused on generating long-term, physically plausible, and semantically coherent behaviors from high-level intentions. To tackle this task, we present a novel framework that aligns motion synthesis with hierarchical plans generated by large language models (LLMs), leveraging principles from task and motion planning. Concurrently, to overcome the limitations of existing benchmarks, we introduce the GBC-100K dataset, a large-scale corpus annotated with hierarchical semantic and motion plans. Experimental results demonstrate our framework, trained on GBC-100K, generates more diverse and purposeful human behaviors with up to 10$\\times$ longer horizons than existing methods. This work lays a foundation for future research in behavior-centric modeling, with all code and data to be made publicly available.",
    "key_points": [
      "human motion generation",
      "long-horizon synthesis",
      "task planning",
      "motion planning",
      "behavior control"
    ],
    "gold_summary": "This paper introduces a hierarchical framework, PHYLOMAN, for Generative Behavior Control (GBC), combining language-driven planning, diffusion-based motion generation, and physics-based control, and constructs a large-scale hierarchical text-to-motion dataset."
  },
  {
    "paper_id": "gOQ4x4Ykyg",
    "title": "MACEval: A Multi-Agent Continual Evaluation Network for Large Models",
    "domain": "datasets and benchmarks",
    "content": "Hundreds of benchmarks dedicated to evaluating large models from multiple perspectives have been presented over the past few years. Albeit substantial efforts, most of them remain closed-ended and are prone to overfitting due to the potential data contamination in the ever-growing training corpus of large models, thereby undermining the credibility of the evaluation. Moreover, the increasing scale and scope of current benchmarks with transient metrics, as well as the heavily human-dependent curation procedure, pose significant challenges for timely maintenance and adaptation to gauge the advancing capabilities of large models. In this paper, we introduce MACEval, a Multi-Agent Continual Evaluation network for dynamic evaluation of large models, and define a new set of metrics to quantify performance longitudinally and sustainably. MACEval adopts an interactive and autonomous evaluation mode that employs role assignment, in-process data generation, and evaluation routing through a cascaded agent network. Extensive experiments on 9 open-ended tasks with 23 participating large models demonstrate that MACEval is (1) human-free and automatic, mitigating laborious result processing with inter-agent judgment guided; (2) efficient and economical, reducing a considerable amount of data and overhead to obtain similar results compared to related benchmarks; and (3) flexible and scalable, migrating or integrating existing benchmarks via customized evaluation topologies. We hope that MACEval can broaden future directions of large model evaluation.",
    "key_points": [
      "large generative models",
      "dynamic evaluation",
      "continual evaluation",
      "multi-agent systems"
    ],
    "gold_summary": "This paper introduces a method of using LLMs to automatically generate evals and continuously change their difficulty."
  },
  {
    "paper_id": "JxmjzC6syB",
    "title": "Benchmarking Stochastic Approximation Algorithms for Fairness-Constrained Training of Deep Neural Networks",
    "domain": "datasets and benchmarks",
    "content": "The ability to train Deep Neural Networks (DNNs) with constraints is instrumental in improving the fairness of modern machine-learning models. Many algorithms have been analysed in recent years, and yet there is no standard, widely accepted method for the constrained training of DNNs. In this paper, we provide a challenging benchmark of real-world large-scale fairness-constrained learning tasks, built on top of the US Census (Folktables, Ding et al, 2021). We point out the theoretical challenges of such tasks and review the main approaches in stochastic approximation algorithms. Finally, we demonstrate the use of the benchmark by implementing and comparing three recently proposed, but as-of-yet unimplemented, algorithms both in terms of optimization performance, and fairness improvement. We will release the code of the benchmark as a Python package after peer-review.",
    "key_points": [
      "fair machine learning",
      "stochastic approximation",
      "augmented lagrangian",
      "sequential quadratic programming",
      "benchmarking"
    ],
    "gold_summary": "The paper introduces a new benchmark, based on the US census, for testing fairness-constrained learning tasks. The dataset is tested on various methods from the literature, which are implemented in a toolbox."
  },
  {
    "paper_id": "T29Oa85nzw",
    "title": "CausalProfiler: Generating Synthetic Benchmarks for Rigorous and Transparent Evaluation of Causal Machine Learning",
    "domain": "datasets and benchmarks",
    "content": "Causal machine learning (Causal ML) aims to answer \"what if\" questions using machine learning algorithms, making it a promising tool for high-stakes decision-making. Yet, empirical evaluation practices in Causal ML remain limited. Existing benchmarks often rely on a handful of hand-crafted or semi-synthetic datasets, leading to brittle, non-generalizable conclusions. To bridge this gap, we introduce CausalProfiler, a synthetic benchmark generator for Causal ML methods. Based on a set of explicit design choices about the class of causal models, queries, and data considered, the CausalProfiler randomly samples sets of data, assumptions, and ground truths constituting the synthetic causal benchmarks. In this way, Causal ML methods can be rigorously and transparently evaluated under a variety of conditions. This work offers the first random generator of synthetic causal benchmarks with coverage guarantees and transparent assumptions operating on the three levels of causal reasoning: observation, intervention, and counterfactual. We demonstrate its utility by evaluating several state-of-the-art methods under diverse conditions and assumptions, both in and out of the identification regime, illustrating the types of analyses and insights the CausalProfiler enables.",
    "key_points": [
      "synthetic benchmarks",
      "causal reasoning",
      "causal machine learning",
      "empirical evaluation"
    ],
    "gold_summary": "The paper proposes CausalProfiler, a synthetic benchmark generator for systematically assessing causal machine learning. The proposed generator allows for generation of synthestic causal datasets under different assuptions."
  },
  {
    "paper_id": "WL9shQKYjp",
    "title": "HistoBench: World History Event Extraction and Cognitive-Level Benchmarking of Generative AI",
    "domain": "datasets and benchmarks",
    "content": "We present HistoBench, a benchmark and dataset designed to evaluate and improve large language models’ (LLMs) ability to reason about complex, temporally grounded historical narratives. While LLMs perform well on general language tasks, their historical understanding remains limited. HistoBench provides a richly annotated collection of global events, timelines, and causal chains, alongside an interactive timeline and global map to enhance accessibility for research and education. To assess reasoning across multiple depths, we introduce a set of 1,007 historical questions structured around Bloom’s Taxonomy, covering levels from factual recall (Remember) to higher-order reasoning (Evaluate and Create). Our results show that models perform well on spatial and entity recognition but struggle more with temporal reasoning. Among the evaluated systems, DeepSeek-V3 consistently outperforms GPT4o-mini and Gemma-3 across nearly all levels, achieving over 90% accuracy at the most advanced stages of evaluation and creation, highlighting its stronger capacity for complex historical reasoning.",
    "key_points": [
      "historical reasoning  temporal understanding  multimodal learning  language models  historical event comprehension  long-context modeling  causal inference  narrative generation  knowledge grounding  cognitive benchmarking",
      "historical knowledge"
    ],
    "gold_summary": "This paper introduces a new benchmark that covers historical event understadning. Authors describe the data creation process and benchmark frontier and open-weight LLMs on it."
  },
  {
    "paper_id": "74jqVzrUQ5",
    "title": "VocSim: A Training-free Benchmark for Zero-shot Content Identity in Single-source Audio",
    "domain": "datasets and benchmarks",
    "content": "The goal of general-purpose audio representations is to map acoustically variable instances of the same event to nearby points, i.e., to resolve content identity in a zero-shot setting. We introduce VocSim, a training-free benchmark that measures this capability directly on 125k single-source clips aggregated from 19 corpora spanning human speech, animal vocalizations, and environmental sounds. By restricting to single-source audio, VocSim isolates content representation from source separation confounds. We evaluate embeddings with two training-free measures: local Precision@k and a point-wise Global Separation Rate (GSR) that contrasts each item’s nearest inter-class distance with its mean intra-class distance. To calibrate GSR, we report lift over an empirical random baseline obtained by label permutation. \n\nAcross diverse models, a simple pipeline—frozen Whisper encoder features with time–frequency pooling and label-free PCA—yields strong zero-shot performance. Yet VocSim also surfaces a consistent generalization gap: on blind, low-resource speech, local retrieval (P@k) drops sharply and the GSR lift over baseline is small, indicating that global class structure is only marginally better than chance. As external validation, top embeddings predict zebra finch perceptual similarity (80.9\\% triplet accuracy) and improve downstream bioacoustic classification. We release data, code, and a public leaderboard to standardize evaluation of zero-shot audio similarity and to catalyze representations that better generalize across sound sources and recording conditions.",
    "key_points": [
      "zero-shot audio similarity; content identity; single-source audio; spectral–temporal structure; audio embeddings; training-free evaluation; global confusion rate (gcr); precision@k; embedding geometry; out-of-distribution generalization; cross-source aggregation; whisper; time–frequency pooling; pca; bioacoustics; avian perception."
    ],
    "gold_summary": "This paper aggregates existing datasets into a single set allowing for the investigation of unsupervised clusters. They also introduce a new eval metric GSR."
  },
  {
    "paper_id": "Ym3Abn2qHh",
    "title": "OJBench: A Competition Level Code Benchmark For Large Language Models",
    "domain": "datasets and benchmarks",
    "content": "Recent advancements in large language models (LLMs) have demonstrated remarkable progress in mathematical and coding reasoning. However, existing code benchmarks are limited in their ability to evaluate the full spectrum of these capabilities, especially at the level of top-tier human programming competitions. To bridge this gap, we introduce **OJBench**, a novel and challenging benchmark designed to assess the competitive-level code reasoning abilities of LLMs. OJBench comprises 232 programming competition problems from NOI and ICPC, providing a rigorous test of models' reasoning skills. We conducted a comprehensive evaluation of 37 models on OJBench, including a mix of closed-source, open-source, reasoning-oriented, and general-purpose models. Our results indicate that even state-of-the-art reasoning models like o4-mini and Gemini-2.5-pro-exp struggle with highly challenging, competition-level problems, highlighting the significant challenges models face in this domain.",
    "key_points": [
      "benchmarks",
      "code reasoning",
      "reasoning language model."
    ],
    "gold_summary": "This paper introduces OJBench, which collects 232 programming competition problems and evaluates 37 models. The experiments reveal limitations of current LLMs on competition-level coding and find that C++ is more effective than Python."
  },
  {
    "paper_id": "jjIKGiGqOo",
    "title": "BrowseComp-Plus: A More Fair and Transparent Evaluation  Benchmark of Deep-Research Agent",
    "domain": "datasets and benchmarks",
    "content": "Deep-Research agents, which integrate large language models (LLMs) with search tools, have shown success in improving the effectiveness of handling complex queries that require iterative search planning and reasoning over search results.\nEvaluations on current benchmarks like BrowseComp relies on black-box live web search APIs, have notable limitations in (1) fairness: dynamic and opaque web APIs hinder fair comparisons and reproducibility of deep research methods; (2) transparency: lack of control over the document corpus makes it difficult to isolate retriever contributions. In other words, the current evaluations may compare a complete deep research system at a given time, but they do not foster well-controlled experiments to provide insights into the capability of underlying deep research LLMs.\nTo address these challenges, we introduce BrowseComp-Plus, a benchmark derived from BrowseComp, employing a fixed, carefully curated corpus.\nEach query in BrowseComp-Plus includes human-verified supporting documents and mined challenging negatives, enabling controlled experimentation.\nThe benchmark is shown to be effective in distinguishing the performance of deep research systems.\nFor instance, the open-source model Search-R1, when paired with the BM25 retriever, achieves 3.86\\% accuracy, whereas the GPT-5 achieves 55.9\\%.\nIntegrating the GPT-5 with the Qwen3-Embedding-8B retriever further enhances its accuracy to 70.1\\% with fewer search calls.\nThis benchmark allows comprehensive evaluation and disentangled analysis of deep research agents and retrieval methods, fostering insights into retrieval effectiveness, citation accuracy, and context engineering in Deep-Research system.",
    "key_points": [
      "deep research",
      "inforamtion retrieval",
      "large language model",
      "benchmark"
    ],
    "gold_summary": "The paper introduced BROWSECOMP-PLUS, a deep research benchmark based on BROWSECOMP, with a provided retrieval corpus. Comparisons between multiple deep search systems and retrievers are also included."
  },
  {
    "paper_id": "f4o9OdqAfy",
    "title": "TwinVoice: A Multi-dimensional Benchmark Towards Digital Twins via LLM Persona Simulation",
    "domain": "datasets and benchmarks",
    "content": "Large Language Models (LLMs) are exhibiting emergent human-like abilities and are increasingly envisioned as the foundation for simulating a specific communication style, behavioral tendencies, and personality traits. \nHowever, current evaluations of LLM-based persona simulation remain limited: most rely on synthetic dialogues, lack systematic frameworks, and lack analysis of the capability requirement. \nTo address these limitations, we introduce TwinVoice, a comprehensive benchmark for assessing persona simulation across diverse real-world contexts. \nTwinVoice encompasses three dimensions: Social Persona (public social interactions), Interpersonal Persona (private dialogues), and Narrative Persona (role-based expression).\nThe ability of LLMs in persona simulation is further decomposed into six fundamental capabilities, including opinion consistency, memory recall, logical reasoning, lexical fidelity, persona tone, and syntactic style. \nExperimental results reveal that while advanced models achieve moderate accuracy, they remain insufficient in sustaining consistent persona simulation, especially lacking the capability of syntactic style and memory recall.\nOur data, code, and evaluation results are available at https://anonymous.4open.science/r/TwinVoice-B08E.",
    "key_points": [
      "large langauge model",
      "digital twin",
      "persona simulation"
    ],
    "gold_summary": "Please see the weakness section."
  },
  {
    "paper_id": "ZhdpXY0BwV",
    "title": "Do MLLMs Really Understand Space? A Mathematical Reasoning Evaluation",
    "domain": "datasets and benchmarks",
    "content": "Multimodal large language models (MLLMs) have achieved strong performance on perception-oriented tasks, yet their ability to perform mathematical spatial reasoning, defined as the capacity to parse and manipulate two- and three-dimensional relations, remains unclear.\nHumans easily solve textbook-style spatial reasoning problems with over 95\\% accuracy, but we find that most leading MLLMs fail to reach even 60\\% on the same tasks. This striking gap highlights spatial reasoning as a fundamental weakness of current models.  To investigate this gap, we present MathSpatial, a unified framework for evaluating and improving spatial reasoning in MLLMs.  MathSpatial includes three complementary components: (i) MathSpatial-Bench, a benchmark of 2K problems across three categories and eleven subtypes, designed to isolate reasoning difficulty from perceptual noise; (ii) MathSpatial-Corpus, a training dataset of 8K additional problems with verified solutions; and (iii) MathSpatial-SRT, which models reasoning as structured traces composed of three atomic operations—Correlate, Constrain, and Infer.  Experiments show that fine-tuning Qwen2.5-VL-7B on MathSpatial achieves competitive accuracy while reducing tokens by 25\\%. MathSpatial provides the first large-scale resource that disentangles perception from reasoning, enabling precise measurement of spatial reasoning skills in MLLMs. More broadly, MathSpatial offers a comprehensive foundation for understanding how MLLMs handle mathematical spatial reasoning. Our code and datasets will be released upon paper acceptance.",
    "key_points": [
      "spatial reasoning，multimodal large language models"
    ],
    "gold_summary": "This work presents a spatial reasoning benchmark MathSpatial. This benchmark measures reasoning performance along 3 problem settings, while also addressing scale and scope of problems."
  },
  {
    "paper_id": "FkTEc3XEL6",
    "title": "MOCHA: Multi-sample Omics Cohorts with Human Annotation",
    "domain": "datasets and benchmarks",
    "content": "In spatially resolved transcriptomics (SRT) research, gene expression profiling with spatial context has enabled spatial domain identification within single tissue samples. Extending these analyses to multiple biological samples presents additional challenges, including cross-sample variability and batch effects. Method development has been limited by the lack of datasets that combine multi-subject cohorts with expert-derived annotations. We present MOCHA ($\\underline{M}$ulti-sample $\\underline{O}$mics $\\underline{C}$ohorts with $\\underline{H}$uman $\\underline{A}$nnotation), a curated resource for developing and evaluating multi-sample SRT methods. MOCHA integrates molecular profiles, spatial profiles, and high-resolution Hematoxylin and Eosin (H\\&E) images across multiple subjects, with each sample paired with domain annotations from expert pathologists. For algorithm development and evaluation, MOCHA provides standardized data organization, efficient storage formats for large-scale processing, and protocols for handling batch effects in multi-sample integration.",
    "key_points": [
      "spatially resolved transcriptomics",
      "database",
      "multi-sample annotations"
    ],
    "gold_summary": "This paper introduces MOCHA, a curated resource designed to accelerate the development and evaluation of multi-sample spatially resolved transcriptomics (SRT) methods."
  },
  {
    "paper_id": "rMeo9kHwm9",
    "title": "InfoSynth: Information-Guided Benchmark Synthesis for LLMs",
    "domain": "datasets and benchmarks",
    "content": "Large language models (LLMs) have demonstrated significant advancements in reasoning and code generation. However, efficiently creating new benchmarks to evaluate these capabilities remains a challenge. Traditional benchmark creation relies on manual human effort, a process that is both expensive and time-consuming. Furthermore, existing benchmarks often contaminate LLM training data, necessitating novel and diverse benchmarks to accurately assess their genuine capabilities. This work introduces InfoSynth, a novel framework for automatically generating and evaluating reasoning benchmarks guided by information-theoretic principles. We propose metrics based on KL-divergence and entropy to quantify benchmark novelty and diversity without relying on costly model evaluations. Building on this framework, we develop an end-to-end pipeline that synthesizes robust Python coding problems from seed datasets using genetic algorithms and iterative code feedback. Our method generates accurate test cases and solutions to new problems 97\\% of the time, and the synthesized benchmarks consistently exhibit higher novelty and diversity compared to their seed datasets. Moreover, our algorithm provides a method for controlling the novelty/diversity and difficulty of generated problems. InfoSynth offers a scalable, self-verifying pipeline for constructing high-quality, novel and diverse benchmarks for LLMs.",
    "key_points": [
      "nlp datasets",
      "automatic evaluation of datasets",
      "evaluation methodologies",
      "evaluation"
    ],
    "gold_summary": "This paper proposed a novel framework for automatically generating and evaluting reasoning benchmarks guided by onformation-theoretic principles. Their experiments generate accurate test caes and solutions to new problems 97% of the time."
  },
  {
    "paper_id": "qG6O3jMkCj",
    "title": "SurvHTE-Bench: A Benchmark for Heterogeneous Treatment Effect Estimation in Survival Analysis",
    "domain": "datasets and benchmarks",
    "content": "Estimating heterogeneous treatment effects (HTEs) from right-censored survival data is critical in high-stakes applications such as precision medicine and individualized policy-making. Yet, the survival analysis setting poses unique challenges for HTE estimation due to censoring, unobserved counterfactuals, and complex identification assumptions. Despite recent advances, from causal survival forests to survival meta-learners and outcome imputation approaches, evaluation practices remain fragmented and inconsistent. We introduce SurvHTE‐Bench, the first comprehensive benchmark for HTE estimation with censored outcomes. The benchmark spans (i) a modular suite of synthetic datasets with known ground truth, systematically varying causal assumptions and survival dynamics, (ii) semi-synthetic datasets that pair real-world covariates with simulated treatments and outcomes, and (iii) real-world datasets from a twin study (with known ground truth) and from an HIV clinical trial. Across synthetic, semi-synthetic, and real-world settings, we provide the first rigorous comparison of survival HTE methods under diverse conditions and realistic assumption violations. SurvHTE‐Bench establishes a foundation for fair, reproducible, and extensible evaluation of causal survival methods.",
    "key_points": [
      "causal inference",
      "survival analysis",
      "treatment effect",
      "datasets and benchmarks"
    ],
    "gold_summary": "This paper is a benchmark comparing many methods for time-dependent conditional average treatment estimation, which is key in survival analysis."
  },
  {
    "paper_id": "ltUQwfiFiC",
    "title": "v-HUB: A Visual-Centric Humor Understanding Benchmark for Video LLMs",
    "domain": "datasets and benchmarks",
    "content": "AI models capable of comprehending humor hold real-world promise—for example, enhancing engagement in human-machine interactions. To gauge and diagnose the capacity of multimodal large language models (MLLMs) for humor understanding, we introduce v-HUB, a novel visual-centric video humor understanding benchmark. v-HUB comprises a curated collection of minimally verbal short videos, sourced from classic silent films and online resources, and reflecting real-world scenarios where humor can be appreciated purely through visual cues. Each video clip is paired with rich annotations, including captions, descriptions, and explanations, supporting evaluation tasks like caption matching and humor explanation. To broaden its applicability, we further construct an open-ended video QA task, making it readily integrable into existing video understanding benchmarks. We evaluate a diverse set of MLLMs, from specialized Video-LLMs to versatile OmniLLMs that can process audio, covering both open-source and proprietary domains. The experimental results expose the difficulties MLLMs face in comprehending humor from visual cues alone. For example, all models exhibit a marked performance drop on caption matching when moving from text-based to video-based evaluation (without audio). Our findings also demonstrate that incorporating audio helps with video humor understanding, highlighting the informativeness of sound and the\npromise of integrating richer modalities for complex video understanding tasks.",
    "key_points": [
      "humor understanding",
      "video llms"
    ],
    "gold_summary": "This paper present a visual-centric video humor understanding benchmark, and give a comprehensive evaluation of many sota MLLMs."
  },
  {
    "paper_id": "gu9yu4FTkI",
    "title": "RegexPSPACE: A Benchmark for Evaluating LLM Reasoning on PSPACE-Complete Regex Problems",
    "domain": "datasets and benchmarks",
    "content": "Large language models (LLMs) show strong performance across natural language processing (NLP), mathematical reasoning, and programming, and recent large reasoning models (LRMs) further emphasize explicit reasoning. Yet their computational limits$\\textemdash$particularly spatial complexity constrained by finite context windows$\\textemdash$remain poorly understood. While recent works often focus on problems within the NP complexity class, we push the boundary by introducing a novel benchmark grounded in two PSPACE-complete regular expression (regex) problems: equivalence decision (RegexEQ) and minimization (RegexMin). PSPACE-complete problems serve as a more rigorous standard for assessing computational capacity, as their solutions require massive search space exploration. We perform a double-exponential space exploration to construct a labeled dataset of over a million regex instances with a sound filtering process to build the benchmark. We conduct extensive evaluations on 6 LLMs and 5 LRMs of varying scales, revealing common failure patterns such as verbosity and repetition. With its well-defined structure and quantitative evaluation metrics, this work presents the first empirical investigation into the spatial computational limitations of LLMs and LRMs, offering a new framework for evaluating their advanced reasoning capabilities.",
    "key_points": [
      "pspace-complete",
      "regex minimization",
      "regex equivalence"
    ],
    "gold_summary": "this paper proposes a complexity-based benchmark based on PSPACE complexity, extending beyond traditional NP-complexity complexity hierarchy"
  },
  {
    "paper_id": "tMbmBCfSTz",
    "title": "OdysseyBench: Evaluating LLM Agents on Long-Horizon Complex Office Application Workflows",
    "domain": "datasets and benchmarks",
    "content": "Autonomous agents powered by large language models (LLMs) are increasingly deployed in real-world applications requiring complex, long-horizon workflows. However, existing benchmarks predominantly focus on atomic tasks that are self-contained and independent, failing to capture the long-term contextual dependencies and multi-interaction coordination required in realistic scenarios. To address this gap, we introduce OdysseyBench, a comprehensive benchmark for evaluating LLM agents on long-horizon workflows across diverse office applications including Word, Excel, PDF, Email, and Calendar. Our benchmark comprises two complementary splits: OdysseyBench+ with 300 tasks derived from real-world use cases, and OdysseyBench-Neo with 302 newly synthesized complex tasks. Each task requires agent to identify essential information from long-horizon interaction histories and perform multi-step reasoning across various applications. To enable scalable benchmark creation, we propose HomerAgents, a multi-agent framework that automates the generation of long-horizon workflow benchmarks through systematic environment exploration, task generation, and dialogue synthesis. Our extensive evaluation demonstrates that OdysseyBench effectively challenges state-of-the-art LLM agents, providing more accurate assessment of their capabilities in complex, real-world contexts compared to existing atomic task benchmarks. We believe that OdysseyBench will serve as a valuable resource for advancing the development and evaluation of LLM agents in real-world productivity scenarios.",
    "key_points": [
      "llm agent",
      "benchmark",
      "office workflow"
    ],
    "gold_summary": "This paper proposes a new benchmark (OdysseyBench) for evaluation of LLM-driven agents on complex, long-horizon workflows that involve multiple office applications. In addition, it proposes a multi-agent framework named HomerAgents for construction of benchmarks generally."
  },
  {
    "paper_id": "afO3vnSNsS",
    "title": "ClarifyVC: Clarifying Ambiguous Commands in Vehicle Control with a Hybrid Data Augmentation Pipeline",
    "domain": "datasets and benchmarks",
    "content": "Natural language interfaces for vehicle control must contend with vague commands, evolving dialogue context, and strict protocol constraints. \nWe introduce ClarifyVC, a unified framework that integrates a hybrid data-augmentation pipeline (ClarifyVC-Data), reference models trained on the data (ClarifyVC-Models)\nand a evaluation protocol (ClarifyVC-Eval). \nThe agent-orchestrated pipeline generates diverse, ambiguity-rich dialogues from real-world seeded queries under schema and safety constraints, while the evaluation protocol systematically probes single-turn parsing, conservative clarification under extreme fuzziness, and multi-turn grounding. \nFine-tuning on ClarifyVC-Data yields consistent gains—up to 15\\% higher parsing accuracy, 20\\% stronger ambiguity resolution, and 98\\% protocol compliance—across realistic in-cabin scenarios, with human-in-the-loop assessments confirming high realism, coherence, and applicability. \nClarifyVC thus advances beyond simulation-only datasets by tightly coupling real-world grounding with scalable generation and standardized evaluation, and provides a generalizable pipeline for broader interactive control domains.",
    "key_points": [
      "interactive control systems",
      "clarification-first dialogue",
      "ambiguity resolution",
      "hybrid data augmentation",
      "function-calling language models",
      "human validation and robustness"
    ],
    "gold_summary": "The paper introduces ClarifyVC for clarifying ambiguous natural language commands in vehicle control, combining a dataset, fine-tuned reference models, and a multi-turn dialogue safety-aware evaluation."
  },
  {
    "paper_id": "t5cYJlV6aJ",
    "title": "ExpGuard: LLM Content Moderation in Specialized Domains",
    "domain": "datasets and benchmarks",
    "content": "With the growing deployment of large language models (LLMs) in real-world applications, establishing robust safety guardrails to moderate their inputs and outputs has become essential to ensure adherence to safety policies. Current guardrail models predominantly address general human-LLM interactions, rendering LLMs vulnerable to harmful and adversarial content within domain-specific contexts, particularly those rich in technical jargon and specialized concepts. To address this limitation, we introduce ExpGuard, a robust and specialized guardrail model designed to protect against harmful prompts and responses across financial, medical, and legal domains. In addition, we present ExpGuardMix, a meticulously curated dataset comprising 58,928 labeled prompts paired with corresponding refusal and compliant responses, from these specific sectors. This dataset is divided into two subsets: ExpGuardTrain, for model training, and ExpGuardTest, a high-quality test set annotated by domain experts to evaluate model robustness against technical and domain-specific content. Comprehensive evaluations conducted on ExpGuardTest and eight established public benchmarks reveal that ExpGuard delivers competitive performance across the board while demonstrating exceptional resilience to domain-specific adversarial attacks, surpassing state-of-the-art models such as WildGuard by up to 8.9% in prompt classification and 15.3% in response classification. To encourage further research and development, we open-source our code, data, and model, enabling adaptation to additional domains and supporting the creation of increasingly robust guardrail models.",
    "key_points": [
      "safety",
      "guardrails",
      "moderation",
      "domain specialization",
      "llm"
    ],
    "gold_summary": "The paper contributes a dataset consisting moderation contents in specific domains such as finance, healthcare and law. Experiments on several benchmarks demonstrate the effectiveness of the proposed method."
  },
  {
    "paper_id": "K7UfQFegK5",
    "title": "FullFront: Benchmarking MLLMs Across the Full Front-End Engineering Workflow",
    "domain": "datasets and benchmarks",
    "content": "Front-end engineering involves a complex workflow where engineers conceptualize designs, translate them into code, and iteratively refine the implementation. While recent benchmarks primarily focus on converting visual designs to code, we present FullFront, a benchmark designed to evaluate Multimodal Large Language Models (MLLMs) \\textbf{across the full front-end development pipeline}. \nFullFront assesses three fundamental tasks that map directly to the front-end engineering pipeline: Webpage Design (conceptualization phase), Webpage Perception QA (comprehension of visual organization and elements), and Webpage Code Generation (implementation phase).\nUnlike existing benchmarks that use either scraped websites with bloated code or oversimplified LLM-generated HTML, FullFront employs a novel, two-stage process to transform real-world webpages into clean, standardized HTML while maintaining diverse visual designs and avoiding copyright issues.\nExtensive testing of state-of-the-art MLLMs reveals significant limitations in page perception, code generation (particularly for image handling and layout), and interaction implementation. Our results quantitatively demonstrate performance disparities across models and tasks, and highlight a substantial gap between current MLLM capabilities and human expert performance in front-end engineering.",
    "key_points": [
      "mllm",
      "benchmark",
      "webpage design",
      "webpage perception qa",
      "webpage code generation"
    ],
    "gold_summary": "This work proposes FullFront, a unified benchmark evaluating the full front-end engineering pipeline: Webpage Design, Webpage Perception QA, and Webpage Code Generation."
  },
  {
    "paper_id": "oSX9aenbea",
    "title": "MME-Emotion: A Holistic Evaluation Benchmark for Emotional Intelligence in Multimodal Large Language Models",
    "domain": "datasets and benchmarks",
    "content": "Recent advances in multimodal large language models (MLLMs) have catalyzed transformative progress in affective computing, enabling models to exhibit emergent emotional intelligence. Despite substantial methodological progress, current emotional benchmarks remain limited, as it is still unknown: (a) the generalization abilities of MLLMs across distinct scenarios, and (b) their reasoning capabilities to identify the triggering factors behind emotional states. To bridge these gaps, we present MME-Emotion, a systematic benchmark that assesses both emotional understanding and reasoning capabilities of MLLMs, enjoying scalable capacity, diverse settings, and unified protocols. As the largest emotional intelligence benchmark for MLLMs, MME-Emotion contains over 6,000 curated video clips with task-specific questioning-answering (QA) pairs, spanning broad scenarios to formulate eight emotional tasks. It further incorporates a holistic evaluation suite with hybrid metrics for emotion recognition and reasoning, analyzed through a multi-agent system framework.\nThrough a rigorous evaluation of 20 advanced MLLMs, we uncover both their strengths and limitations, yielding several key insights: (1) Current MLLMs exhibit unsatisfactory emotional intelligence, with the best-performing model achieving only $39.3\\%$ recognition score and $56.0\\%$ Chain-of-Thought (CoT) score on our benchmark. (2) Generalist models (\\emph{e.g.}, Gemini-2.5-Pro) derive emotional intelligence from generalized multimodal understanding capabilities, while specialist models (\\emph{e.g.}, R1-Omni) can achieve comparable performance through domain-specific post-training adaptation. By introducing MME-Emotion, we hope that it can serve as a foundation for advancing MLLMs' emotional intelligence in the future.",
    "key_points": [
      "multimodal large language models",
      "affective computing"
    ],
    "gold_summary": "This work introduces an emotional reasoning dataset and tests a suite of models on it."
  },
  {
    "paper_id": "ngAdlt5n0q",
    "title": "BigO(Bench) - Can LLMs Generate Code with Controlled Time and Space Complexity?",
    "domain": "datasets and benchmarks",
    "content": "We introduce BigO(Bench), a novel coding benchmark designed to evaluate the capabilities of generative language models in understanding and generating code with specified time and space complexities. This benchmark addresses the gap in current evaluations that often overlook the ability of models to comprehend and produce code constrained by computational complexity. BigO(Bench) includes tooling to infer the algorithmic complexity of any Python function from profiling measurements, including human- or LLM-generated solutions. BigO(Bench) also includes a set of 3,105 coding problems and 1,190,250 solutions from Code Contests annotated with inferred (synthetic) time and space complexity labels from the complexity framework, as well as corresponding runtime and memory footprint values for a large set of input sizes. We present results from evaluating multiple state-of-the-art language models on this benchmark, highlighting their strengths and weaknesses in handling complexity requirements. In particular, token-space reasoning models are unrivaled in code generation but not in complexity understanding, hinting that they may not generalize well to tasks for which no reward was given at training time.",
    "key_points": [
      "computational complexity",
      "program synthesis",
      "code generation",
      "competitive programming",
      "llms",
      "large language model",
      "benchmark"
    ],
    "gold_summary": "The paper attempts to test how well code LMs understand the concept of code complexity by gauging how well they adhere to complexity-constrained code generation and code complexity prediction."
  },
  {
    "paper_id": "sHeQG5aav8",
    "title": "SpineBench: A Clinically Salient, Level-Aware Benchmark Powered by the SpineMed-450k Corpus",
    "domain": "datasets and benchmarks",
    "content": "Spine disorders affect 619 million people globally and are a leading cause of disability, yet AI-assisted diagnosis remains limited by the lack of level-aware, multimodal datasets. Clinical decision-making for spine disorders requires sophisticated reasoning across X-ray, CT, and MRI at specific vertebral levels. However, progress has been constrained by the absence of traceable, clinically-grounded instruction data and standardized, spine-specific benchmarks. To address this, we introduce SpineMed, an ecosystem co-designed with practicing spine surgeons. It features SpineMed-450k, the first large-scale dataset explicitly designed for vertebral-level reasoning across imaging modalities with over 450,000 instruction instances, and SpineBench, a clinically-grounded evaluation framework. SpineMed-450k is curated from diverse sources, including textbooks, guidelines, open datasets, and $\\sim$1,000 de-identified hospital cases, using a clinician-in-the-loop pipeline with a two-stage LLM generation method (draft and revision) to ensure high-quality, traceable data for question-answering, multi-turn consultations, and report generation. SpineBench evaluates models on clinically salient axes, including level identification, pathology assessment, and surgical planning. Our comprehensive evaluation of several recently advanced large vision-language models (LVLMs) on SpineBench reveals systematic weaknesses in fine-grained, level-specific reasoning. In contrast, our model fine-tuned on SpineMed-450k demonstrates consistent and significant improvements across all tasks. Clinician assessments confirm the diagnostic clarity and practical utility of our model's outputs.",
    "key_points": [
      "vlm;llm;medical"
    ],
    "gold_summary": "The work presents a largest dataset explicitly designed for vertebral-level reasoning and a related benchmark, which is medically meaningful, but several important points in the manuscript remain unclear or have issues that should be addressed."
  },
  {
    "paper_id": "pabByp2986",
    "title": "SpecEval: Evaluating Model Adherence to Behavior Specifications",
    "domain": "datasets and benchmarks",
    "content": "Companies that develop foundation models often publish behavioral guidelines they pledge their models will follow, but it remains unclear if models actually do so as there has been no systematic audit of adherence to these guidelines. We propose a simple but imperative baseline: at minimum, a foundation model should consistently satisfy its developer's own behavioral specifications when judged by the developer's own evaluator models. Thus our central focus is on __three-way consistency__ between a provider's specification, the provider's model outputs, and adherence scores from the provider model as a judge; an extension of prior two-way generator-validator consistency. We introduce an automated framework that audits models against their providers' specifications by (i) parsing statements that delineate desired behaviors, (ii) generating targeted prompts to elicit the aforementioned behaviors, and (iii) using the responses as inputs to models to judge adherence. We apply our framework to 16 models from six developers across 100+ behavioral statements, finding three-way consistency  gaps of up to 20\\% across providers.",
    "key_points": [
      "model compliance",
      "evals",
      "alignment auditing",
      "lm as a judge"
    ],
    "gold_summary": "The current paper promotes one of the first automated auditing frameworks for model adherence to behavior specifications. They provide an extensive evaluation of 16 models across 6 developers with over 100 behavioral guidelines."
  },
  {
    "paper_id": "uv9olmscIS",
    "title": "OKBench: Democratizing LLM Evaluation with Fully Automated, On-Demand Open Knowledge Benchmarking",
    "domain": "datasets and benchmarks",
    "content": "Knowledge-intensive question answering is central to large language models (LLMs) and is typically assessed using static benchmarks derived from sources like Wikipedia and textbooks. However, these benchmarks fail to capture evolving knowledge in a dynamic world, and centralized curation struggles to keep pace with rapid LLM advancements. To address these drawbacks, we propose OpenKnowledgeBench (OKBench), a fully automated framework for generating high-quality, dynamic knowledge benchmarks on demand. Focusing on the news domain where knowledge updates daily, OKBench is an agentic framework that automates the sourcing, creation, validation, and distribution of benchmarks. Our approach democratizes benchmark creation and facilitates thorough evaluation of retrieval-augmented methods by reducing overlap with pretraining data. We evaluate our framework on multiple open-source and proprietary LLMs of various sizes and configurations, both with and without retrieval over freshly generated knowledge. Our results reveal distinct model behaviors when confronted with new information and highlight how retrieval narrows the performance gap between small and large models. These findings underscore the importance of evaluating LLMs on evolving knowledge benchmarks.",
    "key_points": [
      "llm benchmarking",
      "dynamic evaluation",
      "knowledge updates",
      "automated benchmarks",
      "retrieval-augmented methods"
    ],
    "gold_summary": "This paper introduces OKBench, a dynamic and knowledge-intensive benchmark designed to automatically evaluate large language models on their ability to handle factual, up-to-date information."
  },
  {
    "paper_id": "qeziG97WUZ",
    "title": "lmgame-Bench: How Good are LLMs at Playing Games?",
    "domain": "datasets and benchmarks",
    "content": "Playing video games requires perception, reasoning, memory, and long-horizon planning—exactly the faculties expected of modern large language and vision–language models (LLMs/VLMs). We introduce LMGame-Bench, a benchmark built on six popular games spanning platformer, puzzle, and narrative games through a unified Gym‑style API. Unlike prior game benchmarks that entangle multiple skills, LMGame-Bench employs a modular harness—including perception, memory, and reasoning modules—that can be toggled to selectively probe distinct capabilities. The benchmark further improves robustness through prompt standardization and contamination mitigation. Evaluation of 13 state-of-the-art models demonstrates that LMGame-Bench remains challenging yet effectively discriminates among models. Correlation analysis reveals that individual games align with core LLM capabilities, providing a quantitative framework for interpreting performance. Finally, LMGame-Bench exposes models’ limitations in visual state extraction, reflection, spatiotemporal reasoning, and long-context reasoning, pointing to concrete directions for model improvement.",
    "key_points": [
      "llm",
      "vlm",
      "agents",
      "benchmark",
      "games"
    ],
    "gold_summary": "The paper proposes a benchmark for LLMs on six game environments, they evaluated a variety of popular LLMs. The paper also studies contamination and attempts to create standardize prompting."
  },
  {
    "paper_id": "xtysskccFc",
    "title": "ProRe: A Proactive Reward System for GUI Agents via Reasoner–Actor Collaboration",
    "domain": "applications to robotics",
    "content": "Reward is critical to the evaluation and training of large language models (LLMs). However, existing rule-based or model-based reward methods struggle to generalize to GUI agents, where access to ground-truth trajectories or application databases is often unavailable, and static trajectory-based LLM-as-a-Judge approaches suffer from limited accuracy. To address these challenges, we propose ProRe, a proactive reward system that leverages a general-purpose reasoner and domain-specific evaluator agents (actors). The reasoner schedules targeted state probing tasks, which the evaluator agents then execute by actively interacting with the environment to collect additional observations. This enables the reasoner to assign more accurate and verifiable rewards to GUI agents. Empirical results on over 3K trajectories demonstrate that ProRe improves reward accuracy and F1 score by up to 5.3\\% and 19.4\\%, respectively. Furthermore, integrating ProRe with state-of-the-art policy agents yields a success rate improvement of up to 22.4\\%.",
    "key_points": [
      "llm",
      "gui agent",
      "reward system"
    ],
    "gold_summary": "ProRe introduces a proactive reward framework that lets a general-purpose LLM schedule state-probing tasks and delegates their execution to domain-specific evaluator agents, shifting GUI reward design from passive trajectory scoring to active evidence collection."
  },
  {
    "paper_id": "NjefSiNlcP",
    "title": "Learning Provably Correct Distributed Protocols Without Human Knowledge",
    "domain": "applications to robotics",
    "content": "Provably correct distributed protocols, which are a critical component of modern distributed systems, are highly challenging to design, and have often required decades of human effort. These protocols allow multiple agents to coordinate to come to a common agreement in an environment with uncertainty and failures, e.g., agents only observe their own state, messages can be lost, and agents may crash. We formulate protocol design as a search problem over strategies in a game with imperfect information, and the desired correctness conditions are specified in satisfiability modulo theories. However, standard methods for solving multi-agent games fail to learn correct protocols in this setting, even with then number of agents is small. We develop a learning process we call GGMS that combines a specialized version of Monte Carlo Tree Search with a transformer action encoder, a global depth-first search to break out of local minima, and repeated feedback from a model checker. We show that, under mild assumptions, this process will not miss correct solutions. In experimental validation, we show that GGMS can learn correct protocols for larger settings than existing methods.",
    "key_points": [
      "multiagent",
      "distributed system",
      "reinforcement learning"
    ],
    "gold_summary": "The paper considers how to synthesize correct distributed protocols by combining Monte Carlo tree search, SMT-based correctness analysis, and specialized pruning procedures for guidance. Preliminary experiments and ablation studies are reported."
  },
  {
    "paper_id": "7BiQwV9Sic",
    "title": "Advancing Multi-agent Traffic Simulation via R1-Style Reinforcement Fine-Tuning",
    "domain": "applications to robotics",
    "content": "Scalable and realistic simulation of multi-agent traffic behavior is critical for advancing autonomous driving technologies. Although existing data-driven simulators have made significant strides in this domain, they predominantly rely on supervised learning to align simulated distributions with real-world driving scenarios. A persistent challenge, however, lies in the distributional shift that arises between training and testing, which often undermines model generalization in unseen environments. To address this limitation, we propose SMART-R1, a novel R1-style reinforcement fine-tuning paradigm tailored for next-token prediction models to better align agent behavior with human preferences and evaluation metrics. Our approach introduces a metric-oriented policy optimization algorithm to improve distribution alignment and an iterative \"SFT-RFT-SFT\" training strategy that alternates between Supervised Fine-Tuning (SFT) and Reinforcement Fine-Tuning (RFT) to maximize performance gains. Extensive experiments on the large-scale Waymo Open Motion Dataset (WOMD) validate the effectiveness of this simple yet powerful R1-style training framework in enhancing foundation models. The results on the Waymo Open Sim Agents Challenge (WOSAC) showcase that SMART-R1 achieves state-of-the-art performance with an overall realism meta score of 0.7858, ranking first on the leaderboard at the time of submission.",
    "key_points": [
      "autonomous driving",
      "reinforcement fine-tuning",
      "multi-agent traffic simulation"
    ],
    "gold_summary": "The paper introduces a trajectory forecasting system that is based on SMART and adds DeepSeek-R1-style training, which ultimately leads to SotA performance on a difficult dataset."
  },
  {
    "paper_id": "GUFzf1LRBR",
    "title": "Learning from Imperfection: Mistake-Aware LLM Finetuning for Robust Planning",
    "domain": "applications to robotics",
    "content": "While finetuned Large Language Models (LLMs) for embodied planning excel at producing reliable plans for the given environment, they do so in a very narrow area of operation. Usually one wrong step in such a plan is sufficient to get the agent into an unseen scenario. Current training paradigms focus on preventing mistakes by learning from optimal demonstrations, but neglect the crucial skill of recovering when deviating from the correct plan. To address this gap, we propose Mistake-Aware Finetuning (MAF), a novel training methodology that explicitly teaches agents to recover from planning errors. In the MAF paradigm, the model is exposed to plans containing intentional mistakes, but a targeted loss mask ensures it only learns from the subsequent, correct recovery actions. This allows the model to learn the association between a failure state and its resolution without being negatively influenced by the erroneous action itself.\nWe demonstrate the effectiveness of MAF by finetuning a Llama-3B model on two distinct environments. Our approach substantially improves the task success rate from 21% → 72% on the Tower of Hanoi puzzle and from 65% → 94% on the complex MiniGrid MiniBossLevel. Furthermore, to probe the generalization capabilities of our method, we introduce Unlock-To-Unlock-N, a novel and challenging benchmark designed to test long-horizon planning. We demonstrate that our MAF-trained agent not only performs robustly in this new benchmark but also exhibits generalization capabilities that extend beyond the training dataset. It highlights the MAF's immense potential for developing lightweight, robust embodied agents.",
    "key_points": [
      "large language models",
      "robust planning",
      "embodied agents",
      "mistake-aware finetuning"
    ],
    "gold_summary": "This paper presents a fine tuning technique for agentic planning tasks which makes the model more robust after a mistake."
  },
  {
    "paper_id": "WFQnqY1c39",
    "title": "Action Chunking Proximal Policy Optimization for Universal Robotic Dexterous Grasping",
    "domain": "applications to robotics",
    "content": "Universal dexterous grasping across diverse objects is a crucial step towards human-like manipulation. \nIn order to handle the high degrees of freedom (DoF) of dexterous hands, state-of-the-art universal dexterous grasping methods adopt online reinforcement learning (RL) algorithms such as Proximal Policy Optimization (PPO) to learn action policies.\nAlthough PPO is a common choice, its vanilla version often leads to insufficient exploration and slow policy improvement, requiring additional training augmentation to achieve high performance.\nWhile action chunking is a promising strategy to improve exploration by temporally coherent actions, prior RL algorithms that integrate action chunking are unsuitable for dexterous hands due to their high-DoF Q-functions.\nTo address this, we reformulate the PPO objective over action chunks and use a standard state-value function as the critic, naming \\emph{Action Chunking Proximal Policy Optimization} (ACPPO). \nACPPO retains the simplicity of PPO while encouraging temporally coherent exploration and avoiding the curse of dimensionality.\nValidating on the DexGraspNet dataset, we observe that ACPPO outperforms all prior PPO-based methods by a success rate of 95.4\\% with $2.3\\times$ faster training without any auxiliary learning mechanisms.",
    "key_points": [
      "dexterous grasping",
      "reinforcement learning",
      "action chunking",
      "manipulation"
    ],
    "gold_summary": "The paper studies PPO with an action-chunking actor for learning universal dexterous grasping policies. Experiments on DexGraspNet show that the method outperforms both previous RL-based methods and the vanilla PPO without action chunking."
  },
  {
    "paper_id": "OEnIVaoOaI",
    "title": "Fusing Rewards and Preferences in Reinforcement Learning",
    "domain": "applications to robotics",
    "content": "We present Dual-Feedback Actor (DFA), a reinforcement learning algorithm that fuses both individual rewards and pairwise preferences (if available) into a single update rule. DFA uses the policy's log-probabilities directly to model the preference probability, avoiding a separate reward-modeling step. Preferences can be provided by human-annotators (at state-level or trajectory-level) or be synthesized online from Q-values stored in an off-policy replay buffer. Under a Bradley–Terry model, we prove that minimizing DFA's preference loss recovers the entropy-regularized Soft Actor-Critic (SAC) policy. Our simulation results show that DFA trained on generated preferences matches or exceeds SAC on six control environments and demonstrates a more stable training process. With only a semi-synthetic preference dataset under Bradley-Terry model, our algorithm outperforms reward-modeling reinforcement learning from human feedback (RLHF)  baselines in a stochastic GridWorld and approaches the performance of an oracle with true rewards.",
    "key_points": [
      "reinforcement learning",
      "reinforcement learning from human feedback (rlhf)",
      "preference learning",
      "human feedback",
      "bradley–terry model"
    ],
    "gold_summary": "This paper introduces an RL method that combines two types of feedback: scalar rewards and human preferences to enhance prefromance."
  },
  {
    "paper_id": "R0viKzJ70t",
    "title": "The Unreasonable Effectiveness of Scaling Agents for Computer Use",
    "domain": "applications to robotics",
    "content": "Computer-use agents (CUAs) hold promise for automating everyday digital tasks, but their unreliability and high variance hinder their application to long-horizon, complex tasks. We introduce Behavior Best-of-N (bBoN), a method that scales over agents by generating multiple rollouts and selecting among them using behavior narratives that describe the agents' rollout. It enables both wide exploration and principled trajectory selection, substantially improving robustness and success rates. On OSWorld, our bBoN scaling method establishes a new state of the art (SoTA) at 69.9\\%, significantly outperforming prior methods and approaching 72\\% human-level performance, with comprehensive ablations validating key design choices. \nWe further demonstrate strong generalization results to different operating systems on WindowsAgentArena and AndroidWorld.\nCrucially, our results highlight the unreasonable effectiveness of scaling CUAs, when you do it right: effective scaling requires structured trajectory understanding and selection, and bBoN provides a practical framework to achieve this.",
    "key_points": [
      "computer use",
      "gui agents",
      "multimodal large language models",
      "planning",
      "grounding",
      "vision"
    ],
    "gold_summary": "This paper proposes a Behavior Best-of-N (bBoN) method, which scales over agents by generating multiple rollouts and selecting the best trajectory among them for execution."
  },
  {
    "paper_id": "2Pv41Ey3jK",
    "title": "Learning Open-World Visual-Tactile Grasp Stability Prediction with Synthetic Data",
    "domain": "applications to robotics",
    "content": "Grasp stability prediction with visual-tactile data is an important problem in robotics. Most prior work learns these predictors with limited real-world data. Moreover, their evaluation has also been restricted to a simple and unitary laboratory environment. Our work studies open-world visual-tactile grasp stability prediction, i.e. the predictor should zero-shot generalize to novel objects in novel environment. Towards this problem, we propose to learn with synthetic visual-tactile data, generated with FEM-based simulation and ray-tracing rendering. In our experiment, we show that our simulation pipeline has much higher physical fidelity, compared to the rigid-body simulation. Furthermore, the predictor trained on our synthetic dataset has higher accuracy on open-world grasp stability prediction tasks than models trained on real-world dataset or on synthetic dataset from rigid-body simulation.",
    "key_points": [
      "visual-tactile data; fem-based simulation; grasping"
    ],
    "gold_summary": "This paper proposes a custom tactile simulator and renderer for large-scale synthetic data generation to train a grasping stability predictor. The authors demonstrate that the predictor generalizes to real-world and novel objects."
  },
  {
    "paper_id": "lcuA4RYit9",
    "title": "AuxVLA: Auxiliary Task Learning and Multi-Modal Enhancement for Vision-Language-Action Models in Mobile Manipulation",
    "domain": "applications to robotics",
    "content": "Vision-Language-Action (VLA) models have shown promise for robotic control, but their application to complex household manipulation tasks remains challenging. In this work, we propose AuxVLA, a comprehensive approach that enables VLA models to control mobile manipulation robots in domestic environments through both auxiliary task co-training and enhanced input modalities. Our method addresses the challenges of controlling high-dimensional action spaces (13 dimensions for both arm and mobile base) where direct imitation learning typically yields suboptimal results. AuxVLA incorporates two complementary strategies: (1) leveraging multi-view visual inputs and depth information to provide richer spatial context, and (2) co-training with auxiliary decoders that predict interpretable intermediate representations including global robot position, joint configurations, grasp affordances, target object relative positions, and segmentation masks from shared visual-language features. Through evaluation on home rearrangement tasks, AuxVLA demonstrates favorable performance across picking, placing, opening and closing tasks. We hypothesize that auxiliary supervision on interpretable representations enhances spatial understanding and scene reasoning capabilities, while enriched sensory inputs provide necessary spatial context for precise manipulation. These findings suggest that combining auxiliary objectives with multi-modal sensing offers a promising direction for VLA models in mobile manipulation, contributing to the development of more capable domestic robots.",
    "key_points": [
      "robotics; machine learning; multimodality; vision-language-action"
    ],
    "gold_summary": "The paper proposes a pipeline for mobile manipulation. It achieves this through auxiliary task co-training and enhanced input modalities."
  },
  {
    "paper_id": "XplQLo1I9K",
    "title": "Reasoning to Regulate: Chain-of-Thought for Traffic Rule Understanding",
    "domain": "applications to robotics",
    "content": "Understanding and complying with traffic regulations is a safety-critical requirement for autonomous driving, yet remains challenging due to the diversity and context dependence of traffic signage. Importantly, regulation understanding is not a simple recognition task, but a reasoning problem: whether a rule applies depends on interpreting the sign in relation to the spatial layout of lanes and scene context.\nTo support such reasoning, MapDR provide fine-grained annotations that link each traffic sign’s regulatory rules to the specific lanes they govern. Existing methods, however, largely treat this as direct sequence prediction, ignoring the underlying reasoning that connects sign semantics and map structure.\nTo address this limitation, we explicitly incorporate reasoning into this task and propose a framework that equips vision-language models (VLMs) with chain-of-thought (CoT) capabilities. We first design a scalable CoT curation pipeline that bootstraps rationales from a strong LLM through a two-round strategy and employs a VLM-based verifier to filter out incorrect cases, yielding a high-quality set of (CoT, answer) pairs. Building on this foundation, we adopt a two-stage training scheme: supervised fine-tuning (SFT) to teach rationale-to-answer generation, followed by GRPO reinforcement learning with answer-grounded, fine-grained rewards to further improve final answer accuracy.\nExtensive experiments on MapDR show that our approach significantly improves both interpretability and accuracy, establishing the first reasoning-based framework for regulation-aware autonomous driving.",
    "key_points": [
      "autonomous driving",
      "driving rule understanding",
      "traffic scene cot",
      "driving scene topology reasoning"
    ],
    "gold_summary": "The authors propose a new reasoning data augmentation pipeline that claims to improve the rule-to-lane understanding of current models."
  },
  {
    "paper_id": "vGMg9mu4ug",
    "title": "Shape2Gcode: Direct G-code Generation from 3D Shape Data for Automated Manufacturing",
    "domain": "applications to robotics",
    "content": "Modern manufacturing relies on Computer Numerical Control (CNC) machines, which execute machining operations using G-code, a programming language that defines tool movements, cutting paths, and machining parameters. Despite advancements in automation, generating G-code still requires significant human intervention and reliance on Computer-Aided Manufacturing (CAM) tools. To address these challenges, we propose Shape2Gcode, an end-to-end framework that directly generates optimized G-code from 3D shape data. Our approach leverages reinforcement learning to optimize key machining parameters, including tool radius, milling depth, and toolpath strategies. Additionally, Shape2Gcode incorporates a tool orientation selection module to determine optimal rotation matrices, enhancing the flexibility and precision of the machining. We evaluate Shape2Gcode on CNC manufacturing tasks using the ABC and ShapeNet datasets, comparing its performance against existing CAD reconstitution and CNC automation methods. Experimental results demonstrate that Shape2Gcode outperforms conventional approaches in reconstruction accuracy, significantly reducing the need for manual intervention. By optimizing G-code generation and minimizing manual adjustments, Shape2Gcode improves CNC manufacturing efficiency, lowers costs, and enables more automated machining workflows.",
    "key_points": [
      "cnc manufacturing",
      "manufacturing ai",
      "cad",
      "3d vision",
      "reinforcement learning"
    ],
    "gold_summary": "In this paper, the authors propose a novel method for generating Gcode from 3D shape models that avoids the usual intermediary steps dependent on CAD tools. Using reinforcement learning, their method optimizes key machine parameters."
  },
  {
    "paper_id": "6W5YQcelrz",
    "title": "Separable Policy Learning for Emergency Vehicle Prioritized Traffic Signal Control",
    "domain": "applications to robotics",
    "content": "Traffic Signal Control plays a vital role in optimizing urban traffic flow and reducing accidents by regulating signal phases at intersections. While traditional fixed-time control methods are simple and infrastructure-efficient, they fail to adapt to complex and dynamic traffic patterns, particularly during peak periods or in the presence of emergency vehicles. In this paper, we address the emergency-vehicle-aware traffic signal control problem by proposing a decoupled policy fusion framework that separately optimizes control strategies for regular vehicles and emergency vehicles. The two policies are later combined into a global strategy with automatically learned weights, mitigating the negative impact of $Q$-function approximation errors. We further introduce SplitEMV, a novel multi-agent model that enhances inter-agent communication and decision efficiency. Experiments demonstrate that our method significantly improves emergency vehicle response times while preserving efficiency of regular vehicles. The learned emergency vehicle prioritized policy also integrates seamlessly with existing traffic signal control methods in a zero-shot manner, supporting practical deployment.",
    "key_points": [
      "traffic signal control",
      "reinforcement learning",
      "separable policy learning"
    ],
    "gold_summary": "The paper introduces a two-phase learning scheme, Decoupled Learning and Adaptive Strategy Merging (ASM), that separates policy learning for regular vehicles (RVs) and emergency vehicles (EMVs)."
  },
  {
    "paper_id": "54U3XHf7qq",
    "title": "MemoryVLA: Perceptual-Cognitive Memory in Vision-Language-Action Models for Robotic Manipulation",
    "domain": "applications to robotics",
    "content": "Temporal context is essential for robotic manipulation because such tasks are inherently non-Markovian, yet mainstream VLA models typically overlook it and struggle with long-horizon, temporally dependent tasks. Cognitive science suggests that humans rely on working memory to buffer short-lived representations for immediate control, while the hippocampal system preserves verbatim episodic details and semantic gist of past experience for long-term memory. Inspired by these mechanisms, we propose MemoryVLA, a Cognition-Memory-Action framework for long-horizon robotic manipulation. A pretrained VLM encodes the observation into perceptual and cognitive tokens that form working memory, while a Perceptual-Cognitive Memory Bank stores low-level details and high-level semantics consolidated from it. Working memory retrieves decision-relevant entries from the bank, adaptively fuses them with current tokens, and updates the bank by merging redundancies. Using these tokens, a memory-conditioned diffusion action expert yields temporally aware action sequences. We evaluate MemoryVLA on 150+ simulation and real-world tasks across three robots. On SimplerEnv-Bridge, Fractal, and LIBERO-5 suites, it achieves 71.9%, 72.7%, and 96.5% success rates, respectively, all outperforming state-of-the-art baselines CogACT and π0, with a notable +14.6 gain on Bridge. On 12 real-world tasks spanning general skills and long-horizon temporal dependencies, MemoryVLA achieves 84.0% success rate, with long-horizon tasks showing a +26 improvement over state-of-the-art baseline.",
    "key_points": [
      "embodied ai",
      "vision-language-action models",
      "robotic manipulation"
    ],
    "gold_summary": "The paper introduces a new model, MemoryVLA, which employs a specialized memory bank designed to better handle temporal dependencies."
  },
  {
    "paper_id": "dJKhjK4zpp",
    "title": "BridgeDrive: Diffusion Bridge Policy for Closed-Loop Trajectory Planning in Autonomous Driving",
    "domain": "applications to robotics",
    "content": "Diffusion-based planners have shown great promise for autonomous driving due to their ability to capture multi-modal driving behaviors. However, guiding these models effectively in reactive, closed-loop environments remains a significant challenge. Simple conditioning often fails to provide sufficient guidance in complex and dynamic driving scenarios. Recent work attempts to use typical expert driving behaviors (i.e., anchors) to guide diffusion models but relies on a truncated schedule, which introduces theoretical inconsistencies and can compromise performance. To address this, we introduce BridgeDrive, a novel anchor-guided diffusion bridge policy for closed-loop trajectory planning. Our approach provides a principled diffusion framework that effectively translates anchors into fine-grained trajectory plans, appropriately responding to varying traffic conditions. Our planner is compatible with efficient ODE solvers, a critical factor for real-time autonomous driving deployment. We achieve state-of-the-art performance on the Bench2Drive benchmark, improving the success rate by 5\\% over prior arts.",
    "key_points": [
      "diffusion policy",
      "closed-loop planning",
      "end-to-end autonomous driving"
    ],
    "gold_summary": "This paper introduces BridgeDrive, which adapts the Denoising Diffusion Bridge Model to generate geometric path waypoints from an anchor distribution, achieving state-of-the-art performance on the widely used Bench2Drive benchmark."
  },
  {
    "paper_id": "XwFXJ38jET",
    "title": "ST-VLO: Unified Spatio-Temporal Correlation for Visual-LiDAR Odometry with Temporal Drift Compensation",
    "domain": "applications to robotics",
    "content": "We propose an effective and efficient visual-LiDAR odometry framework named ST-VLO, which establishes the unified spatio-temporal correlation with Mamba models and addresses the long-standing cumulative drift problem with temporal compensation for the localization in 4D dynamic environments. \nSpecifically, ST-VLO includes a novel unified spatial-temporal correlation module established on Mamba to fuse heterogeneous visual and LiDAR information across multi-frame video clips, overcoming the insufficient temporal information exploration in previous pairwise odometry methods. Furthermore, a Temporal Drift Compensation module is designed to minimize cumulative drifts by iteratively learning correction residuals from multiple history frames. To strengthen the spatial feature representation on salient features, we also propose a Keypoint-Aware Auxiliary Loss with a winner-takes-all strategy.\nST-VLO achieves state-of-the-art performance on two commonly-used autonomous driving datasets, surpassing previous methods with a 19\\% \\( t_{rel} \\) and 22\\% \\( r_{rel} \\) reduction on KITTI, and a 18\\% ATE and 16\\% RPE reduction on Argoverse.",
    "key_points": [
      "robot localization",
      "visual-lidar odometry",
      "slam"
    ],
    "gold_summary": "This paper proposes ST-VLO, a visual-LiDAR odometry framework that addresses cumulative drift in autonomous driving scenarios."
  },
  {
    "paper_id": "HBozeTR6J6",
    "title": "DepthSense+DP: Adaptive Learning for Robust and Differential Private Silent Speech Recognition",
    "domain": "alignment",
    "content": "Silent speech recognition (SSR) enables privacy preserving human computer interaction but existing methods remain fragile across devices, users, and environments, while incurring high computational costs. We introduce DepthSense+DP, the first systematic solution for privacy aware cross device SSR that jointly achieves real time performance, robustness, and privacy. Our framework tackles the unique challenge of applying Differential Privacy (DP) to 3D depth point clouds, where biometric identifiers must be perturbed without degrading articulatory features. By combining adaptive neural modules with multimodal fusion, the system learns user specific lip and tongue dynamics while maintaining generalization. Input is transformed into anonymized depth point clouds, enabling zero shot transfer across unseen users and devices. The training strategy supports edge deployment under noisy and varied orientations, while privacy preserving data augmentation ensures biometric protection. Extensive evaluation demonstrates reduced error rates and improved robustness, establishing DepthSense+DP as an efficient and secure foundation for next generation SSR.",
    "key_points": [
      "adaptive learning",
      "silent speech recognition",
      "privacy aware",
      "depth sensing",
      "biometric securiny",
      "zero shot generalization",
      "multimodal fusion"
    ],
    "gold_summary": "This paper defines four critical constraints for cross-device SSR and introduces DepthSense+DP, the first solution to jointly achieve real-time performance, robustness, and DP-based privacy for 3D depth point cloud-driven SSR."
  },
  {
    "paper_id": "pq6rx9r6Aj",
    "title": "Jailbreaking Jailbreaks: A Proactive Defense for LLMs",
    "domain": "alignment",
    "content": "The proliferation of powerful large language models (LLMs) has necessitated robust safety alignment, yet these models remain vulnerable to evolving adversarial attacks, including multi-turn jailbreaks that iteratively search for successful queries. Current defenses, primarily reactive and static, often fail to counter these search-based attacks. In this paper, we introduce ProAct, a novel proactive defense framework designed to disrupt and mislead autonomous jailbreaking processes. Our core idea is to intentionally provide adversaries with \"spurious responses\" that appear to be results of successful jailbreak attacks but contain no actual harmful content. These misleading responses provide false signals to the attacker's internal optimization loop, causing the adversarial search to terminate prematurely and effectively jailbreaking the jailbreak.\nBy conducting extensive experiments across state-of-the-art LLMs, jailbreaking frameworks, and safety benchmarks, our method consistently and significantly reduces attack success rates by up to 92\\%. When combined with other defense frameworks, it further reduces the success rate of the latest attack strategies to 0\\%. ProAct represents an orthogonal defense strategy that can serve as an additional guardrail to enhance LLM safety against the most effective jailbreaking attacks.",
    "key_points": [
      "ai safety",
      "jailbreak defense",
      "multi-agent"
    ],
    "gold_summary": "This paper proposes a jailbreak defense method called ProAct against multi-turn seach-based attacks. The defense method first identifies jailbreak attempts and returns perturbed responses when spotting mallious inputs."
  },
  {
    "paper_id": "f2RSY0sNii",
    "title": "FedANC: Adaptive Sparse Noise Scheduling for Federated Differential Privacy",
    "domain": "alignment",
    "content": "Federated Learning (FL) enables multiple clients to collaboratively train a shared model without sharing raw data. Although this reduces direct exposure of local data, model updates can still leak sensitive information through gradient-based attacks. Differential Privacy (DP) mitigates this risk by adding calibrated noise to updates, providing formal guarantees. However, most existing DP-FL methods adopt fixed noise scales and uniform injection across all gradient dimensions, without adapting to client heterogeneity or training dynamics. This often results in poor privacy-utility trade-offs. To overcome these limitations, we propose FEDANC, an adaptive differential privacy framework for FL. It consists of three components: (i) an Adaptive Noise Controller (ANC) with an LSTM-based design that generates client-specific noise scales and sparsity ratios from local training feedback; (ii) a Selective Noise Injection mechanism that perturbs only the most sensitive gradient entries; and (iii) a Privacy Budget Regularization term that aligns per-round updates with a predefined privacy target. For stability, the ANC is pretrained with synthetic feedback that simulates typical training behavior. We provide theoretical guarantees on both convergence and differential privacy. Extensive experiments demonstrate that FEDANC achieves higher accuracy, faster convergence, and stronger privacy protection compared with existing approaches.",
    "key_points": [
      "federated learning",
      "differential privacy",
      "adaptive noise controller",
      "sparse gradient perturbation"
    ],
    "gold_summary": "The paper proposes an algorithm to using a learned controller to adaptively control noise added to the client-side gradient in FedAvg framework, with the target being improving algorithm performance under fixed privacy budget."
  },
  {
    "paper_id": "JfU0pqSzBu",
    "title": "When Less Is More: Uncovering the Robustness Advantage of Model Pruning",
    "domain": "alignment",
    "content": "The interplay between neural network pruning, a widely adopted approach for model compression, and adversarial robustness has garnered increasing attention. However, most existing work focuses on empirical findings, with limited theoretical grounding. In this paper, we address this gap by providing a theoretical analysis of how pruning influences adversarial robustness. We first show that the pruning strategy and associated parameters play a critical role in determining the robustness of the resulting pruned model. We then examine how these choices affect the optimality of pruning in terms of maintaining performance relative to the original model. Building on these results, we formalize the inherent trade-off between clean accuracy and adversarial robustness introduced by pruning, emphasizing the importance of balancing these competing objectives. Finally, we empirically validate our theoretical insights on different models and datasets, reinforcing our novel understanding of the adversarial implications of pruning. Our findings offer a principled foundation for designing pruning strategies that not only achieve model compression but also enhance robustness without additional constraints or cost, yielding a ``free-lunch'' benefit.",
    "key_points": [
      "adversarial robustness",
      "pruning"
    ],
    "gold_summary": "This paper investigates the theoretical and empirical relationship between model pruning and adversarial robustness, aiming to provide a formal theoretical framework that links pruning parameters to adversarial risk."
  },
  {
    "paper_id": "Jk8g1OxyZY",
    "title": "Fed-Duet: Dual Expert-Orchestrated Framework for Continual Federated Vision-Language Learning",
    "domain": "alignment",
    "content": "Pretrained vision-language models (VLMs), such as CLIP, have shown promise in federated learning (FL) by bringing strong multimodal representations to edge devices. However, continual adaptation remains a core challenge in practical federated settings, where task distributions evolve over time and data remain non-IID across clients. In this emerging area, recent works adopt parameter-efficient fine-tuning (PEFT) as a lightweight way to reduce communication overhead, yet they fail to preserve satisfactory performance under continual learning conditions. Meanwhile, traditional federated continual learning (FCL) methods lack the capacity to maintain cross-modal alignment crucial to VLM performance. We introduce Fed-Duet, a novel Dual-channel Expert-orchestrated framework for efficient federated continual learning in vision-language models. Fed-Duet features a dual-channel adaptation mechanism, combining server-coordinated semantic prompts with client-personalized modular adapters. These channels are dynamically fused via a cross-attention mechanism, enabling effective knowledge transfer while preserving multimodal alignment and mitigating forgetting. We evaluate Fed-Duet across multiple challenging continual learning tasks in federated vision-language settings and demonstrate that it achieves superior performance and stability compared to existing approaches. Our work highlights the importance of coordinated expert composition in enabling scalable and robust multimodal continual learning. The code is available at https://anonymous.4open.science/r/FedDuet-0426/.",
    "key_points": [
      "federated learning",
      "federated continual learning",
      "prompt learning",
      "vision-language model"
    ],
    "gold_summary": "This paper introduces a dual expert-orchestrated framework for continual federated VLM. Various experiments confirms the effectiveness of proposed method."
  },
  {
    "paper_id": "aVa7etWnwF",
    "title": "GOT-Edit: Geometry-Aware Generic Object Tracking via Online Model Editing",
    "domain": "alignment",
    "content": "Human perception for effective object tracking in a 2D video stream arises from the implicit use of prior 3D knowledge combined with semantic reasoning.\nIn contrast, most generic object tracking (GOT) methods primarily rely on 2D features of the target and its surroundings while neglecting the 3D geometric cues, making them susceptible to occlusion, distractors, and large variations in geometry and appearance. \nTo address this, we present GOT-Edit, a novel approach that integrates visual geometry knowledge into a generic object tracker through online model editing. \nOur approach first leverages the features from the Visual Geometry Grounded Transformer (VGGT), which is trained on large-scale 3D-annotated data and can provide reliable geometric cues directly from a set of 2D images.\nTo tackle the challenge of seamlessly combining geometry and semantics, we develop an online model editing strategy with a null-space constraint that adaptively fuses geometric information while preserving the tracker's learned semantic knowledge, yielding consistently better performance across diverse scenarios than a naive fusion of both cues.\nExtensive experiments on multiple GOT benchmarks demonstrate that GOT-Edit achieves superior robustness and accuracy, particularly under occlusion and clutter, establishing a new paradigm for combining 2D semantics with 3D geometric reasoning for generic object tracking.",
    "key_points": [
      "generic object tracking",
      "model editing",
      "model prediction",
      "visual geometry",
      "null-space"
    ],
    "gold_summary": "This paper proposed GOT, which, by introducing the geometric knowledge of VGGT, achieves highly competitive experimental results with smaller trainable parameters."
  },
  {
    "paper_id": "eEds8s9uze",
    "title": "FedSDR: Federated Graph Learning with Structural Noise Detection and Reconstruction",
    "domain": "alignment",
    "content": "Federated Graph Learning (FGL) has emerged as a principled framework for decentralized training of Graph Neural Networks (GNNs) while preserving data privacy. In subgraph-FL scenarios, however, structural noise arising from data collection and storage can damage the GNN message-passing scheme of clients, leading to conflicts in collaboration. Existing approaches exhibit two critical limitations: 1) Globally, they fail to identify corrupted clients, causing destructive message-passing conflicts. 2) Locally, the global GNN performs poorly on these clients due to structural noise, limiting their ability to benefit from federated collaboration. To address these challenges, we propose $\\textbf{FedSDR}$, a robust FGL framework against high-structural-noise scenarios. Specifically, Structural Noise-Aware Aggregation (SNAA) introduces a noise evaluation metric to detect corrupted clients and reduce their contributions, thereby mitigating the impact of noise on the global GNN. Furthermore, Robust Local Structure Reconstruction (RLSR) leverages the knowledge from the healthy global model to repair locally corrupted graph structures. Extensive experiments demonstrate that FedSDR outperforms state-of-the-art methods across various scenarios under structural noise.",
    "key_points": [
      "federated learning; graph learning"
    ],
    "gold_summary": "This paper introduces FedSDR, a robust server–client collaborative algorithm designed to mitigate the impact of low-quality topological perturbations in federated graph learning. Extensive empirical studies substantiate the effectiveness of the proposed approach."
  },
  {
    "paper_id": "SOxO7e6ySB",
    "title": "Language Models Do Not Have Human-Like Working Memory",
    "domain": "alignment",
    "content": "While Large Language Models (LLMs) exhibit remarkable reasoning abilities, we demonstrate that they fundamentally lack a core aspect of human cognition: working memory. Human working memory is an active cognitive system that enables not only the temporary storage of information but also its processing and utilization. Without working memory, individuals may produce unrealistic conversations, exhibit self-contradictions, and struggle with tasks that require mental reasoning. Existing evaluations using N-back or context-dependent tasks fail as they allow LLMs to exploit external context rather than retaining the reasoning process in the latent space. We introduce three novel tasks—(1) Number Guessing, (2) Yes-No Deduction, and (3) Math Magic—that isolate internal representation from external context.\nAcross seventeen frontier models spanning four major model families, we consistently observe irrational or contradictory behaviors, highlighting LLMs' inability to retain and manipulate latent information. Our work establishes a new benchmark for evaluating working memory in LLMs and identifies this deficit as a critical obstacle to artificial general intelligence. Code and prompts will be made publicly available upon publication.",
    "key_points": [
      "large language model",
      "working memory"
    ],
    "gold_summary": "This paper investigates whether LLMs possess human-like working memory through three carefully designed experiments, evaluates the behavior across multiple models, and ultimately concludes that current models do not demonstrate such working-memory capabilities."
  },
  {
    "paper_id": "NsJLyHKjfW",
    "title": "EAGLE: Enhanced Visual Grounding Minimizes Hallucinations in Instructional Multimodal Models",
    "domain": "alignment",
    "content": "Large language models and vision transformers have shown impressive zero-shot capabilities, enabling significant transferability in downstream tasks. The fusion of these models has resulted in multi-modal architectures with enhanced instructional capabilities. Despite incorporating vast image and language pre-training, these multi-modal architectures often generate responses that deviate from the ground truth in the image data. These failure cases (false positives) are known as hallucinations. Current methods for mitigating hallucinations generally focus on regularizing the language component, improving the fusion module, or ensembling multiple visual encoders to improve visual representation. In this paper, we address the hallucination issue by directly enhancing the capabilities of the visual component. Our approach, named EAGLE, is fully agnostic to the LLM or fusion module and works as a post-pretraining stage that improves the grounding and language alignment of the visual encoder. We show that a straightforward reformulation of the original contrastive pre-training task results in an improved visual encoder that can be incorporated into the instructional multi-modal architecture without any additional instructional training. Extensive empirical validation shows that EAGLE significantly reduces hallucinations across six different instructional multi-modal models and four challenging benchmarks.",
    "key_points": [
      "hallucinations",
      "instructional visual language models",
      "visual grounding"
    ],
    "gold_summary": "This paper proposes a method to mitigate hallucinations in VLMs through improved visual encoder capabilities. Experimental results on MMVP and POPE benchmarks show performance gains with the enhanced visual encoder."
  },
  {
    "paper_id": "MlJWmdx5jY",
    "title": "Diff-Fair: Mitigating Intersectional Bias Through Diffusion-Driven Fair Representation",
    "domain": "alignment",
    "content": "Algorithmic fairness remains a critical challenge in Artificial-Intelligence, particularly for high-stakes domains where biased predictions can have significant societal consequences. While recent advances in fair representation learning have shown promise, existing approaches often struggle with the inherent trade-off between fairness and utility, especially when addressing intersectional fairness. In this paper, we introduce Diff-Fair, a novel diffusion-based framework that leverages the progressive denoising process to learn fair representation with the help of proposed fairness constraint for intersectional bias. Our approach simultaneously addresses multiple fairness dimensions through several complementary mechanisms, (1) a diffusion model for representation extraction, (2) a mutual information estimator to minimize sensitive attribute leakage in learned representation, (3) an intersectional fairness regularizer that explicitly accounts for overlapping demographic attributes, and, (4) a false positive rate equalizer that mitigates disparate impacts across groups. Through extensive experimentation on several real-world datasets from different domain, we demonstrate that Diff-Fair consistently outperforms state-of-the-art works, reducing demographic disparities and false-positive rate difference while maintaining competitive accuracy for both binary and multi-class classification.",
    "key_points": [
      "data fairness",
      "intersectional bias",
      "multiple sensitive attributes",
      "fair representation"
    ],
    "gold_summary": "This paper focuses on fair representation learning which aims to address algorithmic bias through a multi-level fairness framework. The trainable framework. The authors claimed that their approach can simultaneously address multiple fairness dimensions."
  },
  {
    "paper_id": "W1x9AzkSnU",
    "title": "SafeMoE: Safe Fine-Tuning for MoE LLMs by Aligning Harmful Input Routing",
    "domain": "alignment",
    "content": "Recent large language models (LLMs) have increasingly adopted the Mixture-of-Experts (MoE) architecture for efficiency. MoE-based LLMs heavily depend on a superficial safety mechanism in which harmful inputs are routed safety-critical experts. However, our analysis reveals that routing decisions for harmful inputs drift significantly after fine-tuning, exposing a critical vulnerability to harmful fine-tuning (HFT) attacks. Existing defenses, primarily designed for monolithic LLMs, are less effective for MoE LLMs as they fail to prevent drift in harmful input routing. To address this limitation, we propose SafeMoE, a safe fine-tuning method tailored to MoE LLMs. SafeMoE directly mitigates routing drift by penalizing the gap between the routing weights of a fine-tuned model and those of the initial safety-aligned model, thereby preserving the safety-aligned routing of harmful inputs to safety-critical experts. Experiments on open-source MoE LLMs ranging from 7B to 141B parameters demonstrate that SafeMoE effectively mitigates HFT attacks, reducing the harmfulness score of OLMoE from 62.0 to 5.0, for example, while maintaining task utility within 1% degradation and incurring only 2\\% overhead. It significantly outperforms state-of-the-art defense methods for safeguarding LLM fine-tuning and remains effective in recent large-scale MoE LLMs such as gpt-oss and Llama 4. Our implementation is available at https://anonymous.4open.science/r/SafeMoE.",
    "key_points": [
      "ai safety",
      "large language model",
      "mixture-of-experts"
    ],
    "gold_summary": "This paper proposes a defense method against harmful fine-tuning attacks on MoE LLMs. The core idea is to regularize the MoE routing decisions during fine-tuning."
  },
  {
    "paper_id": "LLK5KSbaWI",
    "title": "Visual Token Compression Enhances Model Robustness of VLMs",
    "domain": "alignment",
    "content": "In this paper, we show for the first time that visual token pruning enhances the robustness of Vision-Language Models (VLMs), mitigating vulnerabilities such as jailbreak attacks and hallucinations. Given that vision and language modalities cannot be perfectly aligned, the misaligned visual tokens might act as out-of-distribution (OOD) inputs, leading to unpredictable outputs and introducing potential vulnerabilities. Building on this insight, we aim to enhance model robustness against jailbreaks and hallucinations by selectively reducing visual tokens, while also reducing inference cost as a side benefit. Specifically, we measure the distance between each visual token and the language feature space. Then, visual tokens with large distances are identified as OOD tokens, which can be iteratively pruned. To demonstrate the effectiveness of our method, we evaluate it on seven diverse popular benchmarks. Notably, our method yields an average improvement of 13.46\\% in defending jailbreak attacks, consistently achieves competitive performance in mitigating hallucinations, and maintains strong results on general datasets like MME.",
    "key_points": [
      "token compression; robustness"
    ],
    "gold_summary": "This paper proposes a method which prunes a subset of visual tokens which are deemed out-of-distribution. This method, not only improves inference efficiency, but also results in significant improvements on factuality and adversarial robustness."
  },
  {
    "paper_id": "QQdn8nNqgi",
    "title": "Clean-Action Backdoor Attacks on Vision-Language-Action Models via Sequential Error Exploitation",
    "domain": "fairness",
    "content": "Vision-Language-Action (VLA) models have emerged as a popular method for general-purpose embodied AI, enabling robots to interpret multimodal inputs and generate temporally coherent actions. Popular imitation learning methods, including diffusion-based and autoregressive approaches, typically rely on human-collected demonstrations, which often contain small execution errors such as pauses or irregular motions even when consisting only of successful trajectories. Because decision-making in robotics is sequential, even small errors can compound over time, eventually leading to task failure. In this work, we exploit this property to introduce a new class of clean-action backdoor attacks, which require only partial poisoning of demonstration trajectories while preserving overall rollouts and apparent task success. Unlike conventional backdoors, our approach is more difficult to detect, since it conceals malicious behaviors within natural error patterns rather than obvious trajectory alterations. We validate our method by backdooring the $\\pi_0$ model and testing on the LIBERO benchmark, where it achieves consistently high attack success rates while evading standard detection and remaining effective under clean-data fine-tuning. These findings highlight the urgent need for VLA-specific defenses that address sequential vulnerabilities in embodied AI systems.",
    "key_points": [
      "backdoor attacks",
      "vision-language-action models",
      "embodied ai"
    ],
    "gold_summary": "This paper proposes a poisoning method for VLAs. In particular, the attacker can fine-tune the VLA using maliciously inserted data. The authors show that $\\pi_0$ is susceptible to this attack on LIBERO."
  },
  {
    "paper_id": "SFHjSDIMKn",
    "title": "Seeing It Before It Happens: In-Generation NSFW Detection for Diffusion-Based Text-to-Image Models",
    "domain": "fairness",
    "content": "Diffusion-based text-to-image (T2I) models enable high-quality image generation but also pose significant risks of misuse, particularly in producing not-safe-for-work (NSFW) content. While prior detection methods have focused on filtering prompts before generation or moderating images afterward, the in-generation phase of diffusion models remains largely unexplored for NSFW detection. In this paper, we introduce In-Generation Detection (IGD), a simple yet effective approach that leverages the predicted noise during the diffusion process as an internal signal to identify NSFW content. This approach is motivated by preliminary findings suggesting that the predicted noise may capture semantic cues that differentiate NSFW from benign prompts, even when the prompts are adversarially crafted. Experiments conducted on seven NSFW categories show that IGD achieves an average detection accuracy of 91.32% over naive and adversarial NSFW prompts, outperforming seven baseline methods.",
    "key_points": [
      "text-to-image",
      "not-safe-for-work",
      "detection"
    ],
    "gold_summary": "This paper proposes In-Generation Detection (IGD), a method that detects NSFW intent during diffusion-based image generation by analyzing predicted noise, enabling faster and more robust moderation than pre- or post-detection approaches."
  },
  {
    "paper_id": "j60dWQaYbH",
    "title": "Alignment-Aware Decoding",
    "domain": "fairness",
    "content": "Alignment of large language models remains a central challenge in natural language processing. Preference optimization has emerged as a popular and effective method for improving alignment, typically through training-time or prompt-based interventions. In this paper, we introduce alignment-aware decoding (AAD), a method to enhance model alignment directly at inference. Theoretically, AAD can be interpreted as implicit reward optimization, yet it requires no specialized training beyond the standard DPO setup. Empirically, AAD consistently outperforms strong baselines across diverse alignment benchmarks and model scales. Moreover, in data-constrained settings, AAD can produce high-quality synthetic data to improve alignment under standard decoding, providing a practical solution when labeled data is limited.",
    "key_points": [
      "alignement",
      "inference",
      "decoding",
      "llms"
    ],
    "gold_summary": "The paper addresses current issues with common alignment techniques such as RLHF and DPO by proposing a new method for implicit reward optimization."
  },
  {
    "paper_id": "0pVKknV9nM",
    "title": "SaFT: Spotting Style Imitation and Filtering Content Interference for Zero-Shot LLM-Generated Text Detection",
    "domain": "fairness",
    "content": "Large language models (LLMs) have achieved advanced text generation capabilities, necessitating the development of reliable LLM-generated text detection to prevent potential misuse.\nHowever, current probability-based zero-shot detection methods face two critical challenges that reduce the detection accuracy of LLM-generated texts: the $\\textit{style imitation challenge (SIC)}$ and the $\\textit{content interference challenge (CIC)}$. \nThe SIC arises as LLMs develop increasingly stronger abilities to mimic human writing styles, while the CIC occurs when surprising content characteristics interfere with probability analysis.\nTo address these challenges, we propose $\\textbf{\\textit{SaFT}}$, a novel framework built upon $\\textit{Style-Oriented Instruction Prefix (SOIP)}$ to guide probability analysis for spotting style imitation and filtering content interference. Our framework introduces $\\textit{SIC-Detection (SIC-D)}$ that spots style imitation by making style-imitating texts less unexpected through probability analysis conditioned on human-style instructions, and $\\textit{CIC-Detection (CIC-D)}$ that filters content interference by difference analysis between probability distributions conditioned on contrasting style instructions, exploiting the insight that identical models exhibit equivalent content-related surprises.\nThe final detection score is composed of SIC-D and CIC-D components.\nExtensive experiments demonstrate that SaFT consistently outperforms existing state-of-the-art methods, achieving improvements of 4.9\\% in average AUROC and 20.4\\% in average TPR @ 10\\% FPR.",
    "key_points": [
      "llm-generated text detection",
      "zero-shot"
    ],
    "gold_summary": "- The paper proposes SaFT, a novel zero-shot LLM text detector designed to overcome two specific advanced failure modes: the SIC and the CIC, both of which attempt to make AI text more human-like."
  },
  {
    "paper_id": "vTY3i51J3Z",
    "title": "Keep CALM and Avoid Harmful Content: Concept Alignment and Latent Manipulation Towards Safer Answers",
    "domain": "fairness",
    "content": "Large language models are susceptible to jailbreak attacks that bypass built-in safety guardrails (e.g., by tricking the model with adversarial prompts). We propose Concept Alignment and Manipulation (CALM), an inference-time method that suppresses harmful concepts by modifying latent representations in the last layer of the model, without retraining. Leveraging the concept whitening technique from computer vision combined with orthogonal projection, CALM removes unwanted latent directions associated with harmful content while preserving model performance. Experiments show that CALM reduces harmful outputs and outperforms baseline methods on most metrics, offering a lightweight approach to AI safety with no additional training data or model fine-tuning, while incurring only a small computational overhead at inference.",
    "key_points": [
      "ai alignment",
      "llm safety",
      "inference-time interventions",
      "concept whitening",
      "latent space manipulation",
      "interpretability and controllability of llms"
    ],
    "gold_summary": "The authors propose CALM, a technique that filters harmful LLM responses at test-time.\nIn addition to improved safety, CALM's decisions are interpretable by mapping model activations to human-readable semantic concepts."
  },
  {
    "paper_id": "WA2hiqnXye",
    "title": "Towards Non-destructive Privacy Protection for LVLMs via node-level localized editing",
    "domain": "fairness",
    "content": "Large Vision-Language Models (LVLMs) have shown astonishing potential in various vision tasks and are broadly used in sectors like finance and medicine. However, the risk of abuse exists, where attackers may leverage these models to steal private information, creating security vulnerabilities for their deployment. Studies show that LVLMs struggle to consistently refuse privacy-compromising instructions from users. Current privacy protection research primarily focuses on safeguarding training data, aiming to prevent models from leaking sensitive information contained within it. However, privacy leakage can extend beyond training data, where models may be misused to extract private information from images or infer sensitive location details. The protection of such external privacy has received little attention.\nTo address this, we introduce PRN-Edit, a privacy risk mitigation method based on model editing. Our method improves a model's privacy protection by increasing its rate of refusal to answer privacy-related questions, and it can generalize to novel sensitive questions not seen during the mitigation process. PRN-Edit works by using a learnable feature mask to locate privacy risk nodes in the feature encoding of user instructions, which then precisely guides the update of model parameters. Through comprehensive experiments on MiniGPT-4 and LLava-1.5, we show that our algorithm significantly boosts the model's privacy protection while maintaining its utility.",
    "key_points": [
      "large vision-language model",
      "model editing",
      "privacy protection"
    ],
    "gold_summary": "This paper aims to mitigate the privacy leakage problem in large vision-language models (LVLMs). The authors propose PRN-Edit, a two-stage localised editing method designed to modify the models’ responses to predefined privacy-sensitive queries."
  },
  {
    "paper_id": "4vTWdcUobG",
    "title": "Enhancing Adversarial Transferability via Component-Wise Transformation",
    "domain": "fairness",
    "content": "Deep Neural Networks (DNNs) are highly vulnerable to adversarial examples, which pose significant challenges in security-sensitive applications. Among various adversarial attack strategies, input transformation-based attacks have demonstrated remarkable effectiveness in enhancing adversarial transferability. However, current methods struggle with cross-architecture transferability, even when performing well within the same architecture. This limitation arises because, while models of the same architecture may focus on different regions of the object, the variation is even more pronounced across different architectures. Unfortunately, current approaches fail to effectively guide models to attend to these diverse regions. To address this issue, this paper proposes a novel input transformation-based attack method, termed Component-Wise Transformation (CWT). CWT applies interpolation and selective rotation to individual image blocks, ensuring that each transformed image highlights different target regions. Extensive experiments on the standard ImageNet and COCO datasets demonstrate that CWT consistently outperforms state-of-the-art methods across both CNN- and Transformer-based models.",
    "key_points": [
      "adversarial transferability",
      "untargeted attack",
      "input transformation-based attacks"
    ],
    "gold_summary": "The paper proposes Component‑Wise Transformation (CWT), a block-wise input transformation method to improve adversarial example transferability across architectures."
  },
  {
    "paper_id": "FSOoR1ZFtf",
    "title": "Efficient Hallucination Detection for LLMs Using Uncertainty-Aware Attention Heads",
    "domain": "fairness",
    "content": "Recent progress in large language models (LLMs) has led to systems capable of producing text with remarkable fluency. However, these models are still prone to factual inaccuracies, often referred to as \\``hallucinations''. One strategy to alleviate this issue is uncertainty quantification (UQ), but most existing approaches are computationally intensive or require supervision. In this work, we propose Recurrent Attention-based Uncertainty Quantification (RAUQ), an unsupervised and efficient framework for identifying hallucinations. The method leverages an observation about transformer attention behavior: when incorrect information is generated, certain \\``uncertainty-aware'' attention heads, tend to reduce their focus on preceding tokens. RAUQ automatically detects these attention heads and combines their activation patterns with token-level confidence measures in a recurrent scheme, producing a sequence-level uncertainty estimate in just a single forward pass. Through experiments on twelve tasks spanning question answering, summarization, and translation across four different LLMs, we show that RAUQ consistently outperforms state-of-the-art UQ baselines. Importantly, it does so with minimal cost, less than 1\\% additional computation. Since it requires neither labeled data nor extensive parameter tuning, RAUQ serves as a lightweight, plug-and-play solution for real-time hallucination detection in white-box LLMs.",
    "key_points": [
      "hallucination detection",
      "large language models",
      "uncertainty quantification",
      "selective generation",
      "attention mechanisms"
    ],
    "gold_summary": "The authors propose Recurrent Attention-based Uncertainty Quantification (RAUQ), a method that detects \"uncertainty-aware\" attention heads to identify hallucinations in NLG."
  },
  {
    "paper_id": "qfIMtZQspu",
    "title": "Recall-First Moderation via Distribution-Preserving Augmentation and Committee-Diverse Retrieval",
    "domain": "fairness",
    "content": "False negatives—missed unsafe content—remain the dominant risk in safety-critical moderation. We present a novel recall-first moderation framework that integrates two complementary innovations: (i) distribution-preserving contrastiveaugmentation, which generates boundary-focused hard positives and negatives while statistically preserving corpus structure, and (ii) committee-diverse re-trieval, which combines dense, MMR, and graph-based selectors to construct label-informative, non-redundant neighborhoods at inference. Augmented corpora are validated with KL/JS divergence thresholds (≤ 0.05 globally), confirming indistinguishability from the source distribution. On a large held-out test se tof multidomain unbalanced text, vanilla retrieval-augmented pipelines expose the persistent failure mode of under-detecting FLAGGED content (recall ≈ 0.44), but also reveal a strong baseline gap: an open-source stack (FAISS + local LLaMA-3) achieves significantly higher accuracy and macro-F1 than a commercial counter-part (API embeddings + hosted LLM). Adding augmentation and committee retrieval improves sensitive-class recall by ∼ 10 points (to ≈ 0.56) while maintaining global performance, with graph-aware retrieval pushing open-source accuracy to 0.8510 and Macro-F1 to 0.7635. Ensemble experiments with DistilRoBERTa further raise recall to 0.5781 without loss of utility.",
    "key_points": [
      "rag",
      "content moderation",
      "false negatives",
      "recall-first framework",
      "distribution-preserving augmentation",
      "contrastive augmentation",
      "committee-diverse retrieval",
      "dense retrieval",
      "mmr retrieval",
      "graph-based retrieval",
      "llama-3",
      "faiss",
      "reproducibility",
      "nlp safety",
      "fairness evaluation",
      "semantic-aware augmentation"
    ],
    "gold_summary": "This paper presents a \"recall-first\" moderation framework for automated content moderation in safety-critical settings using LLMs with distribution-preserving contrastive data augmentation and a committee-based, diverse retrieval mechanism."
  },
  {
    "paper_id": "O7fxz7D6vf",
    "title": "Obscure but Effective: Classical Chinese Jailbreak Prompt Optimization via Bio-Inspired Search",
    "domain": "fairness",
    "content": "As Large Language Models (LLMs) are increasingly used, their security risks have drawn increasing attention. Existing research reveals that LLMs are highly susceptible to jailbreak attacks, with effectiveness varying across language contexts. This paper investigates the role of classical Chinese in jailbreak attacks. Owing to its conciseness and obscurity, classical Chinese can partially bypass existing safety constraints, exposing notable vulnerabilities in LLMs. Based on this observation, this paper proposes a framework, CC-BOS, for the automatic generation of classical Chinese adversarial prompts based on multi-dimensional fruit fly optimization, facilitating efficient and automated jailbreak attacks in black-box settings. Prompts are encoded into eight policy dimensions—covering role, behavior, mechanism, metaphor, expression, knowledge, trigger pattern and context; and iteratively refined via smell search, visual search, and cauchy mutation. This design enables efficient exploration of the search space, thereby enhancing the effectiveness of black-box jailbreak attacks. To enhance readability and evaluation accuracy, we further design a classical Chinese to English translation module. Extensive experiments demonstrate that effectiveness of the proposed CC-BOS, consistently outperforming state-of-the-art jailbreak attack methods.",
    "key_points": [
      "jailbreak attack",
      "llms",
      "classical chinese"
    ],
    "gold_summary": "This paper proposes a novel jailbreak attack method. It leverages the linguistic characteristics of classical Chinese and introduces a framework, CC-BOS, for automatic generation of jailbreak prompts based on a multi-dimensional Fruit Fly Optimization algorithm."
  },
  {
    "paper_id": "1n7yRC65E4",
    "title": "Semantically Guided Adversarial Testing of Vision Models Using Language Models",
    "domain": "fairness",
    "content": "In targeted adversarial attacks on vision models, the selection of the target label is a critical yet often overlooked determinant of attack success. This target label corresponds to the class that the attacker aims to force the model to predict. Now, existing strategies typically rely on randomness, model predictions, or static semantic resources, limiting interpretability, reproducibility, or flexibility. This paper proposes a semantics-guided framework for adversarial target selection using the cross-modal knowledge transfer from pretrained language and vision-language models. We evaluate several state-of-the-art models (BERT, TinyLLAMA, and CLIP) as similarity sources to select the most and least semantically related labels with respect to the ground truth, forming best- and worst-case adversarial scenarios. Our experiments on three vision models and five attack methods reveal that these models consistently render practical adversarial targets and surpass static lexical databases, such as WordNet, particularly for distant class relationships. We also observe that static testing of target labels offers a preliminary assessment of the effectiveness of similarity sources, a priori testing. Our results corroborate the suitability of pretrained models for constructing interpretable, standardized, and scalable adversarial benchmarks across architectures and datasets.",
    "key_points": [
      "adversarial attacks",
      "target label selection",
      "computer vision",
      "semantic similarity",
      "explainability"
    ],
    "gold_summary": "This paper proposes selecting the most effective target labels for targeted adversarial attacks using pretrained language and vision–language models. Experiments show that the proposed method outperforms baseline approaches. However, there remain several issues."
  },
  {
    "paper_id": "tLY219JUaK",
    "title": "Existing Adversarial LLM Unlearning Evaluations Are Inconclusive",
    "domain": "fairness",
    "content": "Unlearning seeks to remove sensitive knowledge from large language models, with success often judged through adversarial evaluations. In this work, we critically examine these evaluation practices and reveal key limitations that undermine their reliability. First, we show that adversarial evaluations introduce new information into the model, potentially masking true unlearning performance by re-teaching the model during evaluation. Second, we show that evaluation outcomes vary significantly across tasks, undermining the generalizability of current evaluation methods. Collectively, these issues suggest that existing evaluations risk mischaracterizing unlearning success (or failure). To address this, based on our empirical findings, we propose two principles—*minimal information injection* and *downstream task awareness*—for future evaluations.",
    "key_points": [
      "llm",
      "unlearning",
      "ai safety"
    ],
    "gold_summary": "This paper evaluates the effectiveness of current unlearning evaluation methods and proposes two principles—minimal information injection and downstream task awareness—for future evaluations."
  },
  {
    "paper_id": "JbbuSqG822",
    "title": "Thinking in Groups: Permutation Tests Reveal Near-Out-of-Distribution",
    "domain": "safety",
    "content": "Deep neural networks (DNNs) have the potential to power many biomedical workflows, but training them on truly representative, IID datasets is often infeasible. Most models instead rely on biased or incomplete data, making them prone to out-of-distribution (OoD) inputs that closely resemble in-distribution samples. Such near-OoD cases are harder to detect than standard OOD benchmarks and can cause unreliable—even catastrophic—predictions. Biomedical assays, however, offer a unique opportunity: they often generate multiple correlated measurements per specimen through biological or technical replicates. Exploiting this insight, we introduce Homogeneous OoD (HOoD), a novel OoD detection framework for correlated data. HOoD projects groups of correlated measurements through a trained model and uses permutation-based hypothesis tests to compare them with known subpopulations. Each test yields an interpretable p-value, quantifying how well a group matches a subpopulation. By aggregating these p-values, HOoD reliably identifies OoD groups. In evaluations, HOoD consistently outperforms point-wise and ensemble-based OoD detectors, demonstrating its promise for robust real-world deployment.",
    "key_points": [
      "out-of-distribution (ood) detection",
      "deep neural networks",
      "permutation-based hypothesis testing",
      "p-values",
      "group-level ood detection",
      "hood framework"
    ],
    "gold_summary": "The paper try to formulate a near OOD detection approach."
  },
  {
    "paper_id": "GlVokkOzui",
    "title": "Post-Processing Approach for Distributive Fairness in Multi-Class Federated Learning",
    "domain": "safety",
    "content": "Distributive fairness is a critical concern in the application of Federated Learning\n(FL) to decision making. Three concepts of distributive fairness are recently con\nsidered important in FL: global, local group and client fairness. Global fairness\naddresses disparities among legally protected groups across the entire population.\nLocal group fairness addresses disparities between protected groups within indi\nvidual clients. Client fairness focuses on disparities across clients. These concepts\nof distributive fairness coexist in FL and achieving one does not guarantee the\nothers. Most FL studies focus on only a single concept. In real-world applications,\nhowever, different stakeholders often require fairness from different perspectives\nsimultaneously. Enforcing those fairness concepts inherently incurs an accuracy\ncost. This paper investigates that, for a given FL setup, the maximum achievable\naccuracy under various combinations of distributive fairness, i.e., all three, any two,\nor just one, depending on the application. We propose a post-processing algorithm\nthat returns a model with the near-optimal accuracy while satisfying pre-specified\nfairness constraints. Experimental results show that our algorithm outperforms\nthe current state of the art (SOTA) in terms of the fairness–accuracy tradeoff,\ncomputational and communication efficiency. Code is available on Github.",
    "key_points": [
      "fairness",
      "federated learning",
      "post-processing"
    ],
    "gold_summary": "This paper introduces a framework for multi-class FL that balances various combinations of distributive fairness, which is a pioneer work to that seeks to optimize global group, local group, and individual fairness collectively."
  },
  {
    "paper_id": "OMOjEkE5rd",
    "title": "Breaking Safety Alignment in Large Vision-Language Models via Benign-to-Harmful Optimization",
    "domain": "safety",
    "content": "Large vision–language models (LVLMs) achieve remarkable multimodal reasoning capabilities but remain vulnerable to jailbreaks. Recent studies show that a single jailbreak image can universally bypass safety alignment, yet most existing methods rely on Harmful-Continuation (H-Cont.) optimization. In this setting, a jailbreak image is optimized to predict the next token from harmful conditioning. Through systematic analysis, we reveal that H-Cont. has a fundamental limitation. Specifically, harmful conditioning itself biases models toward unsafe outputs, leaving limited capacity for adversarial optimization to genuinely overturn refusals. Consequently, H-Cont. is effective only in continuation-based jailbreak settings and fails to exhibit universal effectiveness across diverse user inputs. To address this limitation, we propose Benign-to-Harmful (B2H) optimization, a new jailbreak paradigm that decouples conditioning and targets (i.e., the target is not the next-token continuation of the conditioning). By explicitly forcing models to map benign conditioning to harmful targets, B2H directly breaks safety alignment rather than merely extending harmful conditioning. Extensive experiments across multiple LVLMs and safety benchmarks demonstrate that B2H achieves stronger and more universal jailbreak success, while preserving the intended jailbreak behavior. Moreover, B2H transfers well in black-box settings, integrates with text-based jailbreaks, and remains robust under common defense mechanisms. Our findings highlight fundamental weaknesses in current LVLM alignment and establish B2H as a simple yet powerful paradigm for studying multimodal jailbreak vulnerabilities.",
    "key_points": [
      "large vision-language models (lvlm)",
      "safety-alignment",
      "jailbreeak"
    ],
    "gold_summary": "The authors argue that previous jailbreak methods based on harmful continuation have a limited scope and depend heavily on the harmful condition. They proposed a more general framework that performs jailbreak on benign conditioning."
  },
  {
    "paper_id": "nlBqL9oXYR",
    "title": "Fundamental Limits of Game-Theoretic LLM Alignment: Smith Consistency and Preference Matching",
    "domain": "safety",
    "content": "Nash Learning from Human Feedback (NLHF) is a game-theoretic framework for aligning large language models (LLMs) with human preferences by modeling learning as a two-player zero-sum game. When the payoff is defined by the true underlying preference, the framework guarantees desirable alignment properties. However, the ground-truth preference matrix is often unavailable in practice due to limited or noisy data, which substantially constrains the effectiveness of this game-theoretic approach to LLM alignment. In this paper, we systematically study what payoff based on the pairwise human preferences can yield desirable alignment properties. \nWe establish necessary and sufficient conditions for Condorcet consistency, diversity through mixed strategies, and Smith consistency. \nThese results provide a theoretical foundation for the robustness of game-theoretic LLM alignment.\nFurther, we show the impossibility of preference matching, i.e., no smooth and learnable mappings of pairwise preferences can guarantee a unique Nash equilibrium that matches a target policy, even under standard assumptions like the Bradley-Terry-Luce model. \nThis result highlights a fundamental limitation of game-theoretic LLM alignment.",
    "key_points": [
      "large language models",
      "preference alignment",
      "nash equilibrium",
      "nash learning from human feedback"
    ],
    "gold_summary": "The paper investigates the theoretical aspects of game-theoretic alignment. The authors discuss from three aspects, revealing game-theoretic alignment's superiority and limitations, as well as common property shared with RLHF."
  },
  {
    "paper_id": "Wf0tGnQOIh",
    "title": "Conjuring Semantic Similarity",
    "domain": "safety",
    "content": "The semantic similarity between sample expressions measures the distance between their latent `meaning'.These meanings are themselves typically represented by textual expressions.  We propose a novel approach whereby the semantic similarity among textual expressions is based not on other expressions they can be rephrased as, but rather based on the imagery they evoke. While this is not possible with humans, generative models allow us to easily visualize and compare generated images, or their distribution, evoked by a textual prompt. Therefore, we characterize the semantic similarity between two textual expressions simply as the distance between image distributions they induce, or 'conjure.' We show that by choosing the Jensen-Shannon divergence between the reverse-time diffusion stochastic differential equations (SDEs) induced by each textual expression, this can be directly computed via Monte-Carlo sampling. Our method contributes a novel perspective on semantic similarity that not only aligns with human-annotated scores, but also opens up new avenues for the evaluation of text-conditioned generative models while offering better interpretability of their learnt representations.",
    "key_points": [
      "meaning representation",
      "semantic similarity",
      "diffusion model"
    ],
    "gold_summary": "The authors propose to evaluate semantic similarity via the image that the text evokes, which is achieved by performing diffusions and then evaluating the JS divergence."
  },
  {
    "paper_id": "DjKPlFEnCk",
    "title": "Bag of Tricks for Subverting Reasoning-based Safety Guardrails",
    "domain": "safety",
    "content": "Recent reasoning-based safety guardrails for Large Reasoning Models (LRMs), such as deliberative alignment, have shown strong defense against jailbreak attacks.\nBy leveraging LRMs’ reasoning ability, these guardrails help the models to assess the safety of user inputs before generating final responses. The powerful reasoning ability can analyze the intention of the input query and will refuse to assist once it detects the harmful intent hidden by the jailbreak methods. Such guardrails have shown a significant boost in defense, such as the near-perfect refusal rates on the open-source gpt-oss series. Unfortunately, we find that these powerful reasoning-based guardrails can be extremely vulnerable to subtle manipulation of the input prompts, and once hijacked, can lead to even more harmful results.\nSpecifically, we first uncover a surprisingly fragile aspect of these guardrails: simply adding a few template tokens to the input prompt can successfully bypass the seemingly powerful guardrails and lead to explicit and harmful responses. \nTo explore further, we introduce a bag of jailbreak methods that subvert the reasoning-based guardrails. Our attacks span white-, gray-, and black-box settings and range from effortless template manipulations to fully automated optimization.\nAlong with the potential for scalable implementation, these methods also achieve alarmingly high attack success rates (e.g., exceeding 90% across 5 different benchmarks on gpt-oss series on both local host models and online API services).\nEvaluations across various leading open-source LRMs confirm that these vulnerabilities are systemic, underscoring the urgent need for stronger alignment techniques for open-sourced LRMs to prevent malicious misuse.",
    "key_points": [
      "large reasoning models",
      "large language models",
      "red-teaming",
      "jailbreaks"
    ],
    "gold_summary": "This paper reveals that advanced chain-of-thought safety guardrails in LLMs are fragile, introducing four simple yet powerful jailbreak techniques that exploit common patterns in reasoning-based defenses."
  },
  {
    "paper_id": "whkb7c1GAV",
    "title": "Teaching RAG to Play Fair: Assessing and Mitigating Encoder-Only PLM Algorithmic Bias",
    "domain": "safety",
    "content": "Retrieval-Augmented Generation (RAG) reduces hallucinations in large language models (LLMs) by retrieving relevant external documents. Central to this process are encoder-only pre-trained language models (PLMs), which map queries and candidate passages into semantic vectors for retrieval. While most fairness research in RAG has focused on biases in generated text or corpora, the encoder’s role as the retrieval bottleneck remains underexplored. In this work, we systematically assess and mitigate representation-level bias in encoder-only PLMs used within RAG systems. We first diagnose bias localization using intrinsic metrics (Sentence Embedding Association Tests and probing classifiers), and show that demographic information is systematically encoded in mid-to-upper layers. We then evaluate whether intrinsic scores correlate with extrinsic disparities measured by statistical parity and equalized odds on the BBQ benchmark, finding moderate-to-strong correlations that establish intrinsic diagnostics as valid predictors of real-world unfairness. Finally, we benchmark lightweight debiasing methods—Low-Rank Adaptation (LoRA), WiSE-FT partial fine-tuning, and targeted attention-head masking—and integrate them into a modular fairness-aware framework. Our results demonstrate that these interventions meaningfully reduce bias with minimal degradation to retrieval quality, highlighting a path towards fairer, representation-aware RAG systems.",
    "key_points": [
      "retrieval-augmented generation",
      "algorithmic fairness",
      "language models"
    ],
    "gold_summary": "The paper aims to identify and mitigate fairness issues in Retrieval-Augmented Generation systems by exploring four key research questions."
  },
  {
    "paper_id": "Bi3PxDwhFC",
    "title": "VAR: Visual Attention Reasoning via Structured Search and Backtracking",
    "domain": "safety",
    "content": "Multimodal Large Language Models (MLLMs), despite their advances, are hindered by their high hallucination tendency and heavy reliance on brittle, linear reasoning processes, leading to failures in complex tasks. To address these limitations, we introduce Visual Attention Reasoning (VAR), a novel framework that recasts grounded reasoning as a structured search over a reasoning trajectory space. VAR decomposes the reasoning process into two key stages: traceable evidence grounding and search-based chain-of-thought (CoT) generation, which incorporates a backtracking mechanism for self-correction. The search is guided by a multi-faceted reward function with semantic and geometric self-verification components, which penalize outputs that are not faithfully grounded in the visual input. We provide a theoretical analysis for our search strategy, validating its capability to find the correct solution with high probability. Experimental results show that our 7B model, VAR-7B, sets a new state-of-the-art on a comprehensive suite of hallucination and safety benchmarks, significantly outperforming existing open-source models and demonstrating competitive performance against leading proprietary systems.",
    "key_points": [
      "mllm",
      "hallucination",
      "visual grounding",
      "multimodal reasoning",
      "reinforcement learning",
      "chain-of-thought"
    ],
    "gold_summary": "The paper proposes Visual Attention Reasoning (VAR), a post-training recipe that involves visual grounding into chain-of-thought verification. The experimental results across diverse benchmarks support the effectiveness of their approach."
  },
  {
    "paper_id": "zjcLFxT7m8",
    "title": "Unifying Latent Uncertainty Signals in Large Language Models for Improved Factual Precision",
    "domain": "safety",
    "content": "Large Language Models (LLMs) have emerged as powerful tools for knowledge-intensive tasks, yet their tendency to generate factually incorrect or misleading outputs—commonly referred to as hallucinations—poses a fundamental challenge to their reliability. While uncertainty estimation is critical for mitigating such errors, LLMs are not explicitly trained to represent or express uncertainty. In this work, we investigate whether and how uncertainty is implicitly encoded within pretrained models. Through a probing-based analysis, we demonstrate that LLMs internalize multiple distinct and dataset-specific uncertainty signals, which can be extracted as linear directions in their latent space. These signals are most pronounced in intermediate layers, exhibit limited cross-task generalization, and are substantially enhanced by instruction-tuning and [IDK]-token training. Building on these findings, we propose a novel framework that leverages a unified uncertainty direction to train LLMs to classify their own correctness. Our experiments show that this approach significantly improves factual precision and reduces hallucination rates under zero-shot evaluation. Together, these results provide new insights into the internal structure of uncertainty in LLMs and introduce a practical method for aligning models toward more trustworthy behavior.",
    "key_points": [
      "alignment",
      "llms",
      "uncertainty",
      "hallucinations",
      "factuality",
      "safety"
    ],
    "gold_summary": "1. Authors explore and analyze the performance characteristics of probe-based UQ methods for NLG tasks.  \n2. Authors propose a finetuning methodology with the intention of improving LLM's ability to abstain when it's uncertain."
  },
  {
    "paper_id": "IPqUBL4R9x",
    "title": "Selective Data Removal for Distributional Machine Unlearning",
    "domain": "safety",
    "content": "Machine learning systems increasingly face requirements to remove entire domains of information—such as toxic language or biases—rather than individual user data. This task presents a dilemma: full removal of the unwanted domain data is computationally expensive, while random partial removal is statistically inefficient. We find that a domain's statistical influence is often concentrated in a small subset of its data samples, suggesting a path between ineffective partial removal and unnecessary complete removal. We formalize this as distributional unlearning: a framework to select a small subset that balances forgetting an unwanted distribution while preserving a desired one. Using Kullback-Leibler divergence constraints, we derive the exact removal-preservation Pareto frontier for exponential families and prove that models trained on the edited data achieve corresponding log-loss bounds. We propose a distance-based selection algorithm and show it is quadratically more sample-efficient than random removal in the challenging low-divergence regime. Experiments across synthetic, text, and image datasets (Jigsaw, CIFAR-10, SMS spam) show our method requires 15–82\\% less deletion than full removal for strong unlearning effects, e.g., halving initial forget set accuracy. Ultimately, by showing a small forget set often suffices, our framework lays the foundations for more scalable and rigorous subpopulation unlearning.",
    "key_points": [
      "unlearning",
      "theory",
      "privacy",
      "sample complexity",
      "machine learning",
      "statistical learning"
    ],
    "gold_summary": "This paper presents an intuitive method to select a subset of the forget data to remove/unlearn to balance model utility and unlearning performance."
  },
  {
    "paper_id": "PS43wqCSME",
    "title": "Through the Stealth Lens: Attention-Aware Defenses Against Poisoning in RAG",
    "domain": "safety",
    "content": "Retrieval-augmented generation (RAG) systems are vulnerable to attacks that inject poisoned passages into the retrieved context, even at low corruption rates. We show that existing attacks are not designed to be stealthy, allowing reliable detection and mitigation. We formalize a distinguishability-based security game to quantify stealth for such attacks. If a few poisoned passages control the response, they must bias the inference process more than the benign ones, inherently compromising stealth. This motivates analyzing intermediate signals of LLMs, such as attention weights, to approximate the influence of different passages on the response. Leveraging attention weights, we introduce the **Normalized Passage Attention Score** (NPAS) and a lightweight **Attention-Variance Filter** (AV Filter) that flags anomalous passages. Our method improves robustness, yielding up to $\\sim$ **20\\%** higher accuracy than baseline defenses. We also develop adaptive attacks that attempt to conceal such anomalies, achieving up to **35\\%** success rate and underscoring the challenges of achieving true stealth in poisoning RAG systems.",
    "key_points": [
      "retrieval-augmented generation",
      "safety",
      "poisoning attacks"
    ],
    "gold_summary": "The authors propose an attention-aware defense mechanism designed to mitigate the impact of knowledge attacks on Retrieval-Augmented Generation systems."
  },
  {
    "paper_id": "sbEb0Ld6MK",
    "title": "Fairness via Independence: A General Regularization Framework for Machine Learning",
    "domain": "safety",
    "content": "Fairness in machine learning has emerged as a central concern, as predictive models frequently inherit or even amplify biases present in training data. Such biases often manifest as unintended correlations between model outcomes and sensitive attributes, leading to systematic disparities across demographic groups. Existing approaches to fair learning largely fall into two directions: incorporating fairness constraints tailored to specific definitions, which limits their generalizability, or reducing the statistical dependence between predictions and sensitive attributes, which is more flexible but highly sensitive to the choice of distance measure. The latter strategy in particular raises the challenge of finding a principled and reliable measure of dependence that can perform consistently across tasks. In this work, we present a general and model-agnostic approach to address this challenge. The method is based on encouraging independence between predictions and sensitive features through an optimization framework that leverages the Cauchy–Schwarz (CS) Divergence as a principled measure of dependence. Prior studies suggest that CS Divergence provides a tighter theoretical bound compared to alternative distance measures used in earlier fairness methods, offering a stronger foundation for fairness-oriented optimization. Our framework, therefore, unifies prior efforts under a simple yet effective principle and highlights the value of carefully chosen statistical measures in fair learning. Through extensive empirical evaluation on four tabular datasets and one image dataset, we show that our approach consistently improves multiple fairness metrics while maintaining competitive accuracy.",
    "key_points": [
      "bias mitigation",
      "statistical independence",
      "fairness in machine learning"
    ],
    "gold_summary": "This paper modifies the typical \"performance+ fairness regularizer\" framework by using the Cauchy-Schwarz divergence as the fairness regularizer."
  },
  {
    "paper_id": "sWs0cCuM8I",
    "title": "Spilling the Beans: Teaching LLMs to Self-Report Their Hidden Objectives",
    "domain": "privacy",
    "content": "As AI systems become more capable of complex agentic tasks, they also become more capable of pursuing undesirable objectives and causing harm. Previous work has attempted to catch these unsafe instances by interrogating LLMs directly about their objectives and behaviors. However, the main weakness of trusting interrogations is that models can lie. We propose self-report fine-tuning (SRFT), a simple supervised fine-tuning technique that makes a model truthfully disclose its hidden objectives when questioned during interrogation. We train models to self-report factual mistakes in question-answering, and show that trained models are more likely to admit hidden objectives, even in the presence of adversarial pressure to conceal them. We evaluate SRFT in out-of-distribution (OOD) stealth tasks, where the model are instructed to complete a hidden misaligned objective alongside a user-specified objective without being caught by monitoring. Interrogation on SRFT models can detect hidden objectives with near-ceiling performance (F1 score = 0.98), while the baseline model lies when interrogated under the same conditions (F1 score = 0.03). Interrogation on SRFT models can further elicit the content of the hidden objective, recovering 28-100\\% details, compared to 0\\% details recovered in the baseline model and by the prefilled assistant turn attack. This provides a promising technique for incriminating misaligned AI systems.",
    "key_points": [
      "honesty",
      "interrogation",
      "alignment auditing"
    ],
    "gold_summary": "The authors propose to fine-tune LLMs on reporting their hidden objectives and show that this results in the model disclosing its hidden and possibly misaligned objectives when interrogated during inference."
  },
  {
    "paper_id": "jvse9ZDuMC",
    "title": "Cryptography in Semantic Watermarks: Undetectability and Deployment Implications",
    "domain": "privacy",
    "content": "Semantic watermarking methods enable the direct integration of watermarks into\nthe generation process of latent diffusion models by only modifying the initial\nlatent noise. One group of watermarks such as Gaussian Shading (GS) and Pseudorandom Codes Watermarks (PRCW) relies on cryptographic primitives to ensure provable undetectability. However, we find that the use of randomness in these schemes has pitfalls, which leads to a flaw in the proof of Gaussian Shading and to ambiguity in the literature.\nWe propose a novel, general framework based on IND\\$-CPA security which highlights the effect of randomness and reveals that reusing it makes watermarks trivially detectable. \nAs a direct consequence, we obtain an undetectable but inefficient deployment mode for GS. To regain practicability, we propose several speed-ups for GS and provide extensive experiments to compare those with other undetectable watermarks in robustness, speed and quality.",
    "key_points": [
      "watermarking",
      "undetectable watermarking",
      "latent diffusion models"
    ],
    "gold_summary": "The paper examines the cryptographic foundations of some semantic watermarking schemes for latent diffusion models. In the work, it is proposed to use the undetectability notion based on a known IND$-CPA scheme."
  },
  {
    "paper_id": "h0lOaeDwF2",
    "title": "MAPA: Multi-turn Adaptive Prompting Attack On Large Vision-Language Models",
    "domain": "privacy",
    "content": "Multi-turn jailbreak attacks are effective against text-only *large language models* (LLMs) by gradually introducing malicious content across turns. However, naively adding visual inputs can cause existing multi-turn jailbreaks to be easily defended by safety-aligned *large vision-language models* (LVLMs). For example, overly malicious visual input will easily trigger the defense mechanism of safety-aligned LVLMs, making the response more conservative. To address this, we propose ***MAPA***: a **m**ulti-turn **a**daptive **p**rompting **a**ttack that 1) *at each turn*, alternates text-vision attack actions to elicit the most malicious response; and 2) *across turns*, adjusts the attack trajectory through iterative back-and-forth refinement to gradually amplify response maliciousness. This two-level design enables ***MAPA*** to consistently outperform state-of-the-art methods, improving attack success rates by 5-13% on HarmBench and JailbreakBench against LLaVA-v1.6-Mistral-7B, Qwen2.5-VL-7B-Instruct, and Llama-3.2-Vision-11B-Instruct. Our code is available at: https://anonymous.4open.science/r/MAPA-jailbreak.",
    "key_points": [
      "multi-turn jailbreaks",
      "jailbreaking"
    ],
    "gold_summary": "This paper proposed a multi-turn jailbreak method on VLMs, including altering text-vision attack actions and back-and-forth refinement. The paper evaluates on three open-source models using some samples from HarmBench and JailbreakBench."
  },
  {
    "paper_id": "yrChwkKhsC",
    "title": "Evaluating the Promise and Pitfalls of Using LLMs in Hiring Decisions",
    "domain": "privacy",
    "content": "Large Language Models (LLMs) hold promise for automating candidate screening in hiring, but their deployment raises serious concerns about predictive accuracy and algorithmic bias. In this work, we benchmark several state-of-the-art foundational LLMs including models from OpenAI, Anthropic, Google, Meta, and Deepseek, and compare them with a domain-specific hiring model (Match Score) for job candidate matching. We evaluate each model’s predictive accuracy (ROC AUC, Precision-Recall AUC, F1-score) and fairness (impact ratio of cut-off analysis across declared gender, race, and intersectional subgroups). Our experiments on a dataset of roughly 10,000 real-world recent candidate-job pairs show that Match Score outperforms the general-purpose LLMs on accuracy (ROC AUC 0.85 vs 0.77) and achieves significantly more equitable outcomes across demographic groups. Notably, Match Score attains a minimum race-wise impact ratio of 0.957 (near-parity), versus 0.809 or lower for the best LLMs, (0.906 vs 0.773 for the intersectionals, respectively). We trace this gap to biases in LLM pretraining: even advanced LLMs can propagate societal biases from their training data if not adequately aligned. In contrast, the Match Score model’s task-specific training and bias-mitigation design help it avoid such pitfalls. Furthermore, we show with empirical evidence that there shouldn’t be a dichotomy between choosing accuracy and fairness in hiring: a well-designed algorithm can achieve both accuracy in hiring and fairness in outcomes. These findings highlight the importance of domain-adapted models and rigorous bias auditing for responsible AI deployment in hiring.",
    "key_points": [
      "algorithmic fairness",
      "llms",
      "hiring",
      "resume screening",
      "bias audits",
      "bias"
    ],
    "gold_summary": "This paper shows that a proprietary job applicant evaluation system is a Pareto improvement on various LLM's' zero-shot performance for resume screening, in terms of accuracy and fairness."
  },
  {
    "paper_id": "KUXLrSXYPv",
    "title": "No Caption, No Problem: Caption-Free Membership Inference via Model-Fitted Embeddings",
    "domain": "privacy",
    "content": "Latent diffusion models have achieved remarkable success in high-fidelity text-to-image generation, but their tendency to memorize training data raises critical privacy and intellectual property concerns. Membership inference attacks (MIAs) provide a principled way to audit such memorization by determining whether a given sample was included in training. However, existing approaches assume access to ground-truth captions. This assumption fails in realistic scenarios where only images are available and their textual annotations remain undisclosed, rendering prior methods ineffective when substituted with vision-language model (VLM) captions. In this work, we propose MoFit , a caption-free MIA framework that constructs synthetic conditioning inputs that are explicitly overfitted to the target model's generative manifold. Given a query image, MoFit proceeds in two stages: (i) model-fitted surrogate optimization, where a perturbation applied to the image is optimized to construct a surrogate in regions of the model’s unconditional prior learned from member samples, and (ii) surrogate-driven embedding extraction, where a model-fitted embedding is derived from the surrogate and then used as a mismatched condition for the query image. This embedding amplifies conditional loss responses for member samples while leaving hold-outs relatively less affected, thereby enhancing separability in the absence of ground-truth captions. Our comprehensive experiments across multiple datasets and diffusion models demonstrate that MoFit consistently outperforms prior VLM-conditioned baselines and achieves performance competitive with caption-dependent methods.",
    "key_points": [
      "membership inference",
      "data privacy in generative models"
    ],
    "gold_summary": "The paper presents new methods for membership inference attacks on diffusion models, focuses on generative/representation learning, and addresses privacy."
  },
  {
    "paper_id": "NnSLujLSfn",
    "title": "Uncovering Vulnerabilities of LLM-Assisted Cyber Threat Intelligence",
    "domain": "privacy",
    "content": "Large Language Models (LLMs) are intensively used to assist security analysts in counteracting the rapid exploitation of cyber threats, wherein LLMs offer cyber threat intelligence (CTI) to support vulnerability assessment and incident response. While recent work has shown that LLMs can support a wide range of CTI tasks such as threat analysis, vulnerability detection, and intrusion defense, significant performance gaps persist in practical deployments. In this paper, we investigate the intrinsic vulnerabilities of LLMs in CTI, focusing on challenges that arise from the nature of the threat landscape itself rather than the model architecture. Using large-scale evaluations across multiple CTI benchmarks and real-world threat reports, we introduce a novel categorization methodology that integrates stratification, autoregressive refinement, and human-in-the-loop supervision to reliably analyze failure instances. Through extensive experiments and human inspections, we reveal three fundamental vulnerabilities: spurious correlations, contradictory knowledge, and constrained generalization, that limit LLMs in effectively supporting CTI. Subsequently, we provide actionable insights for designing more robust LLM-powered CTI systems to facilitate future research.",
    "key_points": [
      "large language model",
      "cybersecurity",
      "cyber threat intelligence (cti)",
      "failure analysis",
      "llm robustness"
    ],
    "gold_summary": "- The paper presents an autoregressive, human-in-the-loop framework to efficiently categorize LLM failure instances with high reliability.\n- It surfaces three dominant vulnerability categories and distinguishes model-specific versus universal gaps across specialized and general-purpose LLMs."
  },
  {
    "paper_id": "16dklduerp",
    "title": "Calibration Attention: Instance-wise Temperature Scaling for Vision Transformers",
    "domain": "privacy",
    "content": "Calibration is essential for deploying Vision Transformers (ViTs) in risk-sensitive settings. While post-hoc temperature scaling fits a single global scalar on a validation split, it can degrade under distribution shift, as it ignores input-dependent uncertainty. We introduce Calibration Attention (CalAttn), a lightweight plug-in head that that dynamically learns an adaptive, per-instance temperature directly from the ViT’s CLS token. On CIFAR-10/100, MNIST, Tiny-ImageNet and ImageNet-1K with ViT/DeiT/Swin backbones, CalAttn reduces ECE by 2.02 pp (57.2\\%) pre-TS and 1.18 pp (56.6\\%) post-TS on average, while adding $<$0.1\\% parameters. Learned temperatures concentrate near 1.0 on in-distribution data, limiting distortion when the model is already calibrated, yet adapt on harder examples. Extensive experiments confirm robustness across datasets, while comparisons highlight CalAttn’s efficiency over Dirichlet heads (3× params) and logit-temperature scaling baselines. Calibration Attention thus offers a simple, efficient strategy for producing trustworthy predictions in state-of-the-art Vision Transformers.",
    "key_points": [
      "probabilistic drediction",
      "calibration attention",
      "model calibration"
    ],
    "gold_summary": "The paper proposes using instance-level temperature scaling for uncertainty calibration in Vision Transformers."
  },
  {
    "paper_id": "qF6TyKhc7S",
    "title": "Majority Bit-aware Watermarking for Large Language Models",
    "domain": "privacy",
    "content": "The growing deployment of Large Language Models (LLMs) in real-world applications has raised concerns about their potential misuse in generating harmful or deceptive content. To address this issue, watermarking techniques have emerged as a promising solution by embedding identifiable binary messages into generated text for origin verification and misuse tracing. While recent efforts have explored multi-bit watermarking schemes capable of embedding rich information such as user identifiers, they typically suffer from the fundamental trade-off between text quality and decoding accuracy: to ensure reliable message decoding, they have to restrict the size of preferred token sets during encoding, yet such restrictions reduce the quality of the generated content. In this work, we propose MajorMark, a novel watermarking method that improves this trade-off through majority bit-aware encoding. MajorMark selects preferred token sets based on the majority bit of the message, enabling a larger and more flexible sampling of tokens. In contrast to prior methods that rely on token frequency analysis for decoding, MajorMark employs a clustering-based decoding strategy, which maintains high decoding accuracy even when the preferred token set is large, thus preserving both content quality and decoding accuracy. We further introduce MajorMark$^+$, which partitions the message into multiple blocks to independently encode and deterministically decode each block, thereby further enhancing the quality of watermarked text and improving decoding accuracy. Extensive experiments on state-of-the-art LLMs demonstrate that our methods significantly enhance both decoding accuracy and text generation quality, outperforming prior multi-bit watermarking baselines. The code of the proposed methods is available \\href{https://anonymous.4open.science/r/MajorMark}{here} for review.",
    "key_points": [
      "large language models",
      "text watermarking",
      "multi-bit watermarking"
    ],
    "gold_summary": "This paper proposes MajorMark and MajorMark+, majority-aware multi-bit watermarking methods for large language models that replace frequency-based decoding with clustering, achieving higher decoding accuracy and better text quality without tuning the green-list ratio γ."
  },
  {
    "paper_id": "jEIhUhvNIi",
    "title": "From Self-Inconsistency to Stability: Achieving Order Invariant In-Context Learning",
    "domain": "privacy",
    "content": "Large Language Models (LLMs) exhibit powerful reasoning capabilities, particularly when guided by in-context learning (ICL). However, their performance is brittle to demonstration order: accuracy can swing from perfect to random based solely on the permutation of input ordering. This sensitivity reveals a fundamental vulnerability where models rely on spurious positional correlations (noise) rather than semantic content (signal). To address this reliability gap, we introduce \\textbf{Self-Inconsistency Optimization (\\algname{})}, a simple model-agnostic post-training framework that teaches models to focus on \\textit{what} is said, not \\textit{how} it is arranged. \\algname{} generates semantically equivalent inputs through permutation and explicitly trains the model to align its output distributions using our proposed self-inconsistency loss which is based on the Jensen--Shannon divergence. We provide a theoretical justification for our framework, proving that minimizing this self-inconsistency loss is sufficient to achieve the desired order invariance. Furthermore, the Bayesian update design of \\algname{} provides a stable optimization process by decoupling the model's prior knowledge from the alignment objective, allowing it to integrate seamlessly with existing post-training pipelines such as reinforcement learning. Empirical evaluations on mathematical reasoning benchmarks show that \\algname{} substantially mitigates order sensitivity while maintaining or even improving task accuracy. Our source code is\navailable at \\url{https://anonymous.4open.science/r/From-Self-Inconsistency-to-Stability-E0BC}.",
    "key_points": [
      "in-context learning (icl)",
      "permutation invariance",
      "jensen-shannon divergence (jsd)",
      "distributional alignment",
      "self-inconsistency optimization"
    ],
    "gold_summary": "The authors introduce a new training scheme for encouraging permutation invariance to exemplar order in ICL. They demonstrate that their methodology appears to work on a math dataset."
  },
  {
    "paper_id": "syOYjXqKnS",
    "title": "Watermark-based Attribution of AI-Generated Images",
    "domain": "privacy",
    "content": "Several companies have deployed watermark-based detection to identify AI-generated images. However, attribution--the ability to trace back to the user of a generative AI (GenAI) service who created a given AI-generated image--remains largely unexplored despite its growing importance. In this work, we aim to bridge this gap by conducting the first systematic study on watermark-based, user-level attribution of AI-generated images. Our key idea is to assign a unique watermark to each user of the GenAI service and embed this watermark into the AI-generated images created by that user. Attribution is then performed by identifying the user whose watermark best matches the one extracted from the given  image. This approach, however, faces a key challenge: How should watermarks be selected for users  to maximize attribution performance? To address the challenge, we first theoretically derive lower bounds on detection and attribution performance through rigorous probabilistic analysis for any given set of user watermarks. Then, we select watermarks for users to maximize these lower bounds, thereby optimizing detection and attribution performance. Our theoretical and empirical results show that watermark-based attribution inherits both the accuracy and (non-)robustness properties of the underlying watermark. Specifically, attribution remains highly accurate when the watermarked AI-generated images is either not post-processed or subjected to common post-processing such as JPEG compression, as well as black-box adversarial post-processing with limited query budgets.",
    "key_points": [
      "image watermark",
      "watermark-based attribution",
      "ai-generated images"
    ],
    "gold_summary": "The paper proposes a user-oriented watermark assignment approach such that the images a user generates are assigned to the image and is then attributed to the user when needed. The approach is a good one."
  },
  {
    "paper_id": "VxrPmimMeZ",
    "title": "SOFTADACLIP: A SMOOTH CLIPPING STRATEGY FOR FAIR AND PRIVATE MODEL TRAINING",
    "domain": "privacy",
    "content": "Differential privacy (DP) provides strong protection for sensitive data, but often reduces model performance and fairness, especially for underrepresented groups. One major reason is gradient clipping in DP-SGD, which can disproportionately suppress learning signals for minority subpopulations. Although adaptive clipping can enhance utility, it still relies on uniform hard clipping, which may restrict fairness. To address this, we introduce SoftAdaClip, a differentially private training method that replaces hard clipping with a smooth, tanh-based transformation to preserve relative gradient magnitudes while bounding sensitivity. We evaluate SoftAdaClip on various datasets, including MIMIC-III (clinical text), GOSSIS-eICU (structured healthcare), and Adult Income (tabular data). Our results show that SoftAdaClip reduces subgroup disparities by up to 87% compared to DP-SGD and up to 48% compared to Adaptive-DPSGD, and these reductions in subgroup disparities are statistically significant. These findings underscore the importance of integrating smooth transformations with adaptive mechanisms to achieve fair and private model training.",
    "key_points": [
      "fairness",
      "differential privacy",
      "gradient clipping",
      "utility",
      "deep learning"
    ],
    "gold_summary": "SoftAdaClip proposes a novel DP training method integrating a smooth tanh-based transformation into adaptive clipping. It is proposed to mitigate a disproportionate effect of DP on minority groups in terms of performance."
  },
  {
    "paper_id": "yr06ivlnaG",
    "title": "DERMARK: A Dynamic, Efficient and Robust Multi-bit Watermark for Large Language Models",
    "domain": "privacy",
    "content": "As large language models (LLMs) grow more powerful, concerns over copyright infringement of LLM-generated texts have intensified. LLM watermarking has been proposed to trace unauthorized redistribution or resale of generated content by embedding identifiers within the text. Existing approaches primarily rely on one-bit watermarking, which only verifies whether a text was generated by a specific LLM. In contrast, multi-bit watermarking encodes richer information, enabling identification of the specific LLM and user involved in generated or distributed content. However, current multi-bit methods directly embed the watermark without considering its capacity, which can result in failures, especially in low-entropy texts. In this paper, we analyze that the watermark embedding follows a normal distribution. We then derive a formal inequality to optimally segment the text for watermark embedding. Building upon this, we propose DERMARK, a dynamic, efficient, and robust multi-bit watermarking method that divides the text into variable-length segments for each watermark bit during inference. Moreover, DERMARK incurs negligible overhead since no additional intermediate matrices are generated and achieves robustness against text editing by minimizing watermark extraction loss. Experiments demonstrate that, compared to SOTA, on average, our method reduces the number of tokens required per embedded bit by 25\\%, reduces watermark embedding time by 50\\%, and maintains high robustness against text modifications and watermark erasure attacks.",
    "key_points": [
      "multi-bit llm watermarking",
      "llm-generated content security",
      "llm copyright protection"
    ],
    "gold_summary": "This paper proposes a new watermarking framework for LLMs that dynamically adjusts watermark embedding based on text capacity and token statistics."
  },
  {
    "paper_id": "YQ1muQBDV4",
    "title": "Potentially Optimal Joint Actions Recognition for Cooperative Multi-Agent Reinforcement Learning",
    "domain": "reinforcement learning",
    "content": "Value function factorization is widely used in cooperative multi-agent reinforcement learning. Existing approaches often impose monotonicity constraints between the joint action value and individual action values to enable decentralized execution.\nHowever, such constraints limit the expressiveness of value factorization, restricting the range of joint action values that can be represented and hindering the learning of optimal policies. To address this, we propose Potentially Optimal Joint Actions Weighting (POW), a method that ensures optimal policy recovery where existing approximate weighting strategies may fail. POW iteratively identifies potentially optimal joint actions and assigns them higher training weights. Our approach can be seamlessly incorporated into a variety of value function factorization algorithms, and we provide a theoretical proof that this iterative weighted training guarantees recovery of the optimal policy. Experiments on matrix games, difficulty-enhanced predator-prey tasks, SMAC, SMACv2, and a highway-env intersection scenario demonstrate that our method consistently improves performance and surpasses state-of-the-art value-based multi-agent reinforcement learning methods.",
    "key_points": [
      "reinforcement learning",
      "value function factorization",
      "multi-agent"
    ],
    "gold_summary": "The paper proposes POW, a value decomposition based MARL method under CTDE for optimal joint policy recovery using recognition weighting design. Empirically, the method demonstrates improved performance over baselines on multiple benchmarks"
  },
  {
    "paper_id": "zV1hR6wWFK",
    "title": "Biasing the Future: Gaussian Attention for Sequential Decision-Making",
    "domain": "reinforcement learning",
    "content": "Transformers have emerged as powerful sequence models for offline reinforcement learning (RL), but their reliance on purely self-attention mechanisms can limit their ability to capture fine-grained local dependencies and Markovian dynamics present in many RL datasets. In this work, we introduce a modified Decision Transformer architecture that incorporates a Gaussian-biased masked causal attention mechanism. By augmenting attention scores with a distance-aware bias, the model adaptively emphasizes temporally local relationships while still retaining the ability to capture long-range dependencies through self-attention. Experimental results on benchmark offline RL tasks show that our Gaussian-biased Decision Transformer achieves achieves state-of-the-art performance and notable gains over the standard DT, particularly in environments with strong Markovian structure. This demonstrates the importance of explicitly encoding locality into attention mechanisms for sequential decision-making.",
    "key_points": [
      "decision transformer",
      "offline reinforcementlearning"
    ],
    "gold_summary": "This paper proposes the Gaussian-Biased Decision Transformer, which is a modification of the standard Decision Transformer (DT) architecture used in offline reinforcement learning (RL)."
  },
  {
    "paper_id": "jymuXl8GYi",
    "title": "Reinforcing Diffusion Models by Direct Group Preference Optimization",
    "domain": "reinforcement learning",
    "content": "While reinforcement learning methods such as Group Relative Preference Optimization (GRPO) have significantly enhanced Large Language Models, adapting them to diffusion models remains challenging. In particular, GRPO demands a stochastic policy, yet the most cost‑effective diffusion samplers are based on deterministic ODEs. Recent work addresses this issue by using inefficient SDE-based samplers to induce stochasticity, but this reliance on model-agnostic Gaussian noise leads to slow convergence. To resolve this conflict, we propose Direct Group Preference Optimization (DGPO), a new online RL algorithm that dispenses with the policy-gradient framework entirely. DGPO learns directly from group-level preferences, which utilize relative information of samples within groups. This design eliminates the need for inefficient stochastic policies, unlocking the use of efficient deterministic ODE samplers and faster training. Extensive results show that DGPO trains around 20 times faster than existing state-of-the-art methods and achieves superior performance on both in-domain and out-of-domain reward metrics.",
    "key_points": [
      "diffusion models; reinforcement learning;"
    ],
    "gold_summary": "The paper presents DGPO, a clear, diffusion-native alternative to GRPO that removes the stochastic-policy requirement while exploiting group-relative preferences."
  },
  {
    "paper_id": "uimQnHP3mt",
    "title": "SegDAC: Improving Visual Reinforcement Learning by Extracting Dynamic Objectc-Centric Representations from Pretrained Vision Models",
    "domain": "reinforcement learning",
    "content": "Visual reinforcement learning (RL) is challenging due to the need to extract useful representations from high-dimensional inputs while learning effective control from sparse and noisy rewards. Although large perception models exist, integrating them effectively into RL for visual generalization and improved sample efficiency remains difficult. We propose **SegDAC**, a **Seg**mentation-**D**riven **A**ctor-**C**ritic method. SegDAC uses Segment Anything (SAM) for object-centric decomposition and YOLO-World to ground the image segmentation process via text inputs. It includes a novel transformer-based architecture that supports a dynamic number of segments at each time step and effectively learns which segments to focus on using online RL, without using human labels. By evaluating SegDAC over a challenging visual generalization benchmark using Maniskill3, which covers diverse manipulation tasks under strong visual perturbations, we demonstrate that SegDAC achieves significantly better visual generalization, doubling prior performance on the hardest setting and matching or surpassing prior methods in sample efficiency across all evaluated tasks.",
    "key_points": [
      "reinforcement learning",
      "manipulation",
      "visual reinforcement learning"
    ],
    "gold_summary": "The paper uses Yolo-World to segment the image and design an interesting architecture to support length-variable embeddings for policy learning. Experiments on Manipulation tasks and image segments variability evaluation show the method's edge."
  },
  {
    "paper_id": "L3xLWvPZhb",
    "title": "Can Exploration Save Us from Adversarial Attacks? A Reinforcement Learning Approach to Adversarial Robustness",
    "domain": "reinforcement learning",
    "content": "Although considerable progress has been made toward enhancing the robustness of deep neural networks (DNNs), they continue to exhibit significant vulnerability to gradient-based adversarial attacks in supervised learning (SL) settings. We investigate adversarial robustness under reinforcement learning (RL), training image classifiers with policy-gradient objectives and $\\epsilon$-greedy exploration. When training models with several architectures on CIFAR-10, CIFAR-100, and ImageNet-100 datasets, RL consistently improves adversarial accuracy under white-box gradient-based attacks. Our results show that on a representative 6-layer CNN, adversarial accuracy increases from approximately 5\\% to 55\\% on CIFAR-10, 2\\% to 25\\% on CIFAR-100, and 5\\% to 18\\% on ImageNet-100, while clean accuracy decreases only 3–5\\% relative to SL. However, transfer analysis reveals that adversarial examples crafted on RL models transfer poorly: both SL and RL retain approximately 43\\% accuracy against these attacks. In contrast, adversarial examples crafted on SL models transfer effectively, reducing both SL and plain RL to around 8\\% accuracy. This indicates that while plain RL can prevent the generation of strong adversarial examples, it remains vulnerable to transferred attacks from other models, thus requiring adversarial training (RL-adv, $\\sim$30\\% adversarial accuracy) for comprehensive defense against cross-model attacks. Analysis of loss geometry and gradient dynamics show that RL induces smaller gradient norms and rapidly changing input-gradient directions, reducing exploitable information for gradient-based attackers. Despite higher computational overhead, these findings suggest RL-based training can complement existing defenses by naturally smoothing loss landscapes, motivating hybrid approaches that combine SL efficiency with RL-induced gradient regularization.",
    "key_points": [
      "adversarial robustness",
      "gradient-based attacks",
      "reinforcement learning",
      "exploration",
      "image classification",
      "transfer attacks",
      "robustness analysis"
    ],
    "gold_summary": "This paper provides a rarely explored perspective of combing reinforcement learning (RL) with adversarial training (AT) for more robust image classification. Experiments are conducted on 4/6-layer CNN and ResNet-18."
  },
  {
    "paper_id": "JKr77ZmZcM",
    "title": "Beyond Correctness: Harmonizing Process and Outcome Rewards through RL Training",
    "domain": "reinforcement learning",
    "content": "Reinforcement learning with verifiable rewards (RLVR) has emerged as a predominant paradigm for mathematical reasoning tasks, offering stable improvements in reasoning ability. However, Outcome Reward Models (ORMs) in RLVR are too coarse-grained to distinguish flawed reasoning within correct answers or valid reasoning within incorrect answers. This lack of granularity introduces noisy and misleading gradients significantly and hinders further progress in reasoning process quality. While Process Reward Models (PRMs) offer fine-grained guidance for intermediate steps, they frequently suffer from inaccuracies and are susceptible to reward hacking.\n    \nTo resolve this dilemma, we introduce PRocess cOnsistency Filter (PROF), an effective data process curation method that harmonizes noisy, fine-grained process rewards with accurate, coarse-grained outcome rewards. Rather than naively blending PRM and ORM in the objective function (Zou et al., 2025), PROF leverages their complementary strengths through consistency-driven sample selection. Our approach retains correct responses with higher averaged process values and incorrect responses with lower averaged process values, while maintaining positive/negative training sample balance. Extensive experiments demonstrate that our method not only consistently improves the final accuracy over $4\\%$ compared to the blending approaches, but also strengthens the quality of intermediate reasoning steps.",
    "key_points": [
      "reasoning",
      "reinforcement learning",
      "large language model"
    ],
    "gold_summary": "The paper proposes a function to combine process reward and outcome reward rather than adding them. The experimental results show that their combination algorithm outperform naive blending."
  },
  {
    "paper_id": "GRfN9CJQ59",
    "title": "Best Arm Identification with Correlated Sampling",
    "domain": "reinforcement learning",
    "content": "Best arm identification (BAI) is an important research topic in sequential decision-making. In the fixed-confidence setting, the sample complexity, i.e., the number of samples needed to guarantee a given confidence level, serves as a fundamental metric for evaluating algorithms. Gariver&Kaufmann (2016) provided a tight characterization of this complexity as $\\mathcal{H}^{\\star}\\log(1/\\delta)$, where $\\mathcal{H}^{\\star}$ captures the problem hardness and $\\delta$ is the confidence parameter. We improve this best-known bound to $\\mathcal{T}^{\\star}\\log(1/\\delta)$ with a strictly smaller hardness parameter $\\mathcal{T}^{\\star}$. Our approach is based on correlated sampling, which requires no assumptions on the reward function or the arm structures. A key theoretical challenge is that the resulting lower bound is defined by a non-convex optimization problem. To solve it, we propose an efficient method that decomposes the feasible region into sub-intervals and identifies local optima within each. Moreover, we propose the first correlated-sampling-based BAI algorithm, CORSA, and prove its asymptotic optimality. Finally, we conduct numerical experiments to evaluate the algorithm's performance.",
    "key_points": [
      "best arm identification; sample complexity; correlated sampling; fixed-confidence"
    ],
    "gold_summary": "This paper makes impactful theoretical innovations to the BAI field by introducing relevant sampling, with rigorous analysis and practical potential. However, it faces non-trivial limitations in computational efficiency, applicability, and experimental comprehensiveness."
  },
  {
    "paper_id": "bMEJQgNkdQ",
    "title": "Select the Right Agent: Data-Driven Online Model Selection in Reinforcement Learning",
    "domain": "reinforcement learning",
    "content": "We study the problem of online model selection in reinforcement learning, where the selector has access to a class of reinforcement learning agents and learns to adaptively select the agent with the right configuration. Our goal is to establish the improved efficiency and performance gains achieved by integrating data-driven model selection methods into reinforcement learning training procedures.  We examine the theoretical characterizations that are effective for identifying the right configuration in practice, and address three practical criteria from a theoretical perspective: 1) Efficient resource allocation, 2) Stabilized training, 3) Adaptation under non-stationary dynamics. Our theoretical results are accompanied by empirical evidence from various model selection tasks in reinforcement learning, including neural architecture selection, step-size selection, and self-model selection.",
    "key_points": [
      "reinforcement learning",
      "model selection"
    ],
    "gold_summary": "The idea is to use a selector meta algorithm that adaptively choose from a set of base RL agents during a training run."
  },
  {
    "paper_id": "wzX6hi5QGj",
    "title": "Offline Reinforcement Learning via Action-Space Pseudo-Labeling",
    "domain": "reinforcement learning",
    "content": "he critical challenge of offline reinforcement learning (offline RL) is improving\nfrom a fixed dataset while avoiding overestimation on out-of-distribution (OOD)\nactions. Existing methods typically regularize the learned policy to avoid choosing overestimated OOD actions. However, we argue that this often over-constrains policy improvement or requires sensitive hyperparameter tuning. We restate this challenge as the absence of explicit training signals for the\nvalue function in parts of the state–action space. A more effective approach is to provide explicit training signals across the entire action space to eliminate overestimation. We introduce a surprisingly simple yet effective method: $\\textbf{Action-Space Pseudo-Labeling (ASPL)}$ to resolve this challenge. It completes the value-function’s\nmissing signals by assigning pseudo Q-targets that decrease with distance from\nthe behavior support (i.e., the support of the behavior policy). In practice, ASPL achieves an implicit behavior-aware regularization that strengthens as behavior likelihood decreases. On D4RL datasets,\nwe observe stable training and consistent improvements over strong offline baselines with minor tuning burden. Code for reproducing the experiments is provided in the supplementary material.",
    "key_points": [
      "offline reinforcement learning",
      "pseudo-labeling"
    ],
    "gold_summary": "The authors propose Action-Space Pseudo-Labeling (ASPL), a simple method that assigns decreasing pseudo Q-targets to actions based on their distance from the behavior action."
  },
  {
    "paper_id": "Je2QqXrcQq",
    "title": "R2-Dreamer: Redundancy-Reduced World Models without Decoders or Augmentation",
    "domain": "reinforcement learning",
    "content": "A central challenge in image-based Model-Based Reinforcement Learning (MBRL) is to learn representations that distill task-essential information from irrelevant details. While promising, approaches that learn representations by reconstructing input images often waste capacity on spatially large but task-irrelevant visual information, such as backgrounds. Decoder-free methods address this issue by leveraging data augmentation (DA) to enforce robust representations, but the reliance on such external regularizers to prevent collapse severely limits their versatility. To address this, we propose R2-Dreamer, an MBRL framework that introduces a self-supervised objective acting as an internal regularizer, thus preventing collapse without resorting to DA. The core of our method is a feature redundancy reduction objective inspired by Barlow Twins, which can be easily integrated into existing frameworks. In evaluations on the standard continuous control benchmark, DMC Vision, R2-Dreamer achieves performance competitive with strong baselines, including the leading decoder-based agent DreamerV3 and its decoder-free counterpart that relies on DA. Furthermore, its effectiveness is highlighted on a challenging benchmark with tiny but task-relevant objects (DMC-Subtle), where our approach demonstrates substantial gains over all baselines. These results show that R2-Dreamer provides a versatile, high-performance framework for decoder-free MBRL by incorporating an effective internal regularizer.",
    "key_points": [
      "model-based reinforcement learning",
      "world models",
      "representation learning"
    ],
    "gold_summary": "This paper  presents a decoder-free agent that introduces a self-supervised objective acting as an internal regularizer to prevent collapse. Experiments on DMC and DMC-Subtle validate the effectiveness of the proposed method."
  },
  {
    "paper_id": "AIKURJjxXT",
    "title": "EFRame: Deeper Reasoning via Exploration-Filter-Replay Reinforcement Learning Framework",
    "domain": "reinforcement learning",
    "content": "Recent advances in reinforcement learning (RL) have significantly enhanced the reasoning capabilities of large language models (LLMs). Group Relative Policy Optimization (GRPO), a lightweight variant of Proximal Policy Optimization (PPO), improves efficiency but suffers from limited exploration and training instability, limiting its effectiveness on complex reasoning tasks. To address these challenges, we introduce EFRame, an Exploration-Filter-Replay framework that augments GRPO across three dimensions: additional rollouts enable deeper and more targeted exploration, online filtering removes low-quality samples to stabilize gradients and accelerate training, and experience replay amplifies rare yet informative trajectories for stable convergence. This unified framework establishes a principled training cycle that balances exploration, efficiency, and stability. Experiments on diverse reasoning benchmarks demonstrate that EFRame achieves consistent gains, including a 37.9\\% relative improvement on Geometry3K over GRPO. EFRame further supports fine-grained sample categorization and precise entropy control, highlighting it as a robust solution for advancing deeper reasoning in LLMs.",
    "key_points": [
      "large language model",
      "reinforcement learning",
      "reasoning",
      "exploration",
      "entropy"
    ],
    "gold_summary": "The paper propose a framework of exploration and filter sample in RLVR. The experimental results show that it can enhance the performance of RL reasoning."
  },
  {
    "paper_id": "3axBqFqDgk",
    "title": "It Takes Two: Your GRPO Is Secretly DPO",
    "domain": "reinforcement learning",
    "content": "Group Relative Policy Optimization (GRPO) is a prominent reinforcement learning algorithm for post-training Large Language Models (LLMs). \nIt is commonly believed that GRPO necessitates a large group size to ensure stable training via precise statistical estimation, which incurs substantial computational overhead.\nIn this work, we challenge this assumption by reframing GRPO as a form of contrastive learning, \nwhich reveals a fundamental connection to Direct Preference Optimization (DPO). \nMotivated by DPO's empirical success, we investigate the minimal two-rollout case (2-GRPO)—a configuration previously deemed infeasible. \nWe provide a rigorous theoretical analysis to validate 2-GRPO and demonstrate empirically that it achieves performance on par with 16-GRPO, \ndespite using only $1/8$ of the rollouts and reducing training time by over $70\\\\%$.",
    "key_points": [
      "reinforcement learning",
      "large language models"
    ],
    "gold_summary": "The authors perform theoretical analysis and experiments in support of a variant of GRPO with group size 2."
  },
  {
    "paper_id": "o3huLE12q5",
    "title": "AXIOM: Learning to Play Games in Minutes with Expanding Object-Centric Models",
    "domain": "reinforcement learning",
    "content": "Current deep reinforcement learning (DRL) approaches achieve state-of-the-art performance in various domains, but struggle with data efficiency compared to human learning, which leverages core priors about objects and their interactions. Active inference offers a principled framework for integrating sensory information with prior knowledge to learn a world model and quantify the uncertainty of its own beliefs and predictions. However, active inference models are usually crafted for a single task with bespoke knowledge, so they lack the domain flexibility typical of DRL approaches. To bridge this gap, we propose a novel architecture that integrates a minimal yet expressive set of core priors about object-centric dynamics and interactions to accelerate learning in low-data regimes. The resulting approach, which we call AXIOM, combines the usual data efficiency and interpretability of Bayesian approaches with the across-task generalization usually associated with DRL. AXIOM represents scenes as compositions of objects, whose dynamics are modeled as piecewise linear trajectories that capture sparse object-object interactions. The structure of the generative model is expanded online by growing and learning mixture models from single events and periodically refined through Bayesian model reduction to induce generalization. AXIOM learns to play various games within only 10,000 interaction steps, with both a small number of parameters compared to DRL, and without the computational expense of gradient-based optimization.",
    "key_points": [
      "active inference",
      "object-centric models",
      "bayesian inference",
      "model-based reinforcement learning",
      "world models",
      "variational bayes",
      "switching linear dynamical system"
    ],
    "gold_summary": "The paper develops a model consisting of multiple mixture components for doing reinforcement learning. It develops a formalism for training that large mixture model."
  },
  {
    "paper_id": "k0Kb1ynFbt",
    "title": "Exploratory Diffusion Model for Unsupervised Reinforcement Learning",
    "domain": "reinforcement learning",
    "content": "Unsupervised reinforcement learning (URL) pre-trains agents by exploring diverse states in reward-free environments, aiming to enable efficient adaptation to various downstream tasks. Without extrinsic rewards, prior methods rely on intrinsic objectives, but heterogeneous exploration data demand strong modeling capacity for both intrinsic reward design and policy learning. We introduce the **Ex**ploratory **D**iffusion **M**odel (**ExDM**), which leverages the expressive power of diffusion models to fit diverse replay-buffer distributions, thus providing accurate density estimates and a score-based intrinsic reward that drives exploration into under-visited regions. This mechanism substantially broadens state coverage and yields robust pre-trained policies. Beyond exploration, ExDM offers theoretical guarantees and practical algorithms for fine-tuning diffusion policies under limited interactions, overcoming instability and computational overhead from multi-step sampling. Extensive experiments on Maze2d and URLB show that ExDM achieves superior exploration and faster downstream adaptation, establishing new state-of-the-art results, particularly in environments with complex structure or cross-embodiment settings.",
    "key_points": [
      "reinforcement learning",
      "diffusion policy",
      "unsupervised reinforcement learning",
      "exploration"
    ],
    "gold_summary": "The authors proposed an unsupervised RL algorithm called ExDM with diffusion action head."
  },
  {
    "paper_id": "5T1vMQldr8",
    "title": "Subgoal-Guided Reward Shaping: Improving Preference-Based Offline Reinforcement Learning via Conditional VAEs",
    "domain": "reinforcement learning",
    "content": "Offline preference-based reinforcement learning (PbRL) learns complex behaviors from human feedback without environment interaction, but suffers from reward model extrapolation errors when encountering out-of-distribution region during policy optimization. These errors arise from distributional shifts between preference-labeled training trajectories and unlabeled inference data, leading to reward misestimation and suboptimal policies. We introduce SPOT (Subgoal-based Preference Optimization Through Attention Weight), which mitigates extrapolation errors by leveraging attention-derived subgoals from preference data. SPOT regularizes the policy toward subgoals observed in preferred trajectories. This approach constrains learning within the training distribution, reducing reward model extrapolation errors. Through comprehensive experiments, we demonstrate that our subgoal-guided approach achieves superior performance compared to existing methods while reducing extrapolation errors. Our approach preserves fine-grained credit assignment information while enhancing query efficiency, suggesting promising directions for reliable and practical offline preference-based learning.",
    "key_points": [
      "preference-based reinforcement learning",
      "reinforcement learning"
    ],
    "gold_summary": "This paper proposes an attention-weight-based subgoal extraction method to mitigate the extrapolation error problem in offline preference-based reinforcement learning. The experiments are sufficient, and the framework is clear."
  },
  {
    "paper_id": "PKIEzYcoxD",
    "title": "ToMPO: Training LLM Strategic Decision Making from a Multi-Agent Perspective",
    "domain": "reinforcement learning",
    "content": "Large Language Models (LLMs) have been used to make decisions in complex scenarios, where they need models to think deeply, reason logically, and decide wisely. Many existing studies focus solely on multi-round conversations in social tasks or simulated environments, neglecting the various types of decisions and their interdependence. Current reinforcement learning methods struggle to consider the strategies of others during training. To address these issues, we first define a strategic decision-making problem that includes two types of decisions and their temporal dependencies. Furthermore, we propose **T**heory **o**f **M**ind **P**olicy **O**ptimization **(ToMPO)** algorithm to optimize the perception of other individual strategies and the game situation trends. Compared to the Group Relative Policy Optimization (GRPO) algorithm, ToMPO enhances the LLM's strategic decision-making mainly by: 1) generating rollouts based on reasoning the strategies of other individuals, 2) estimating advantages at both the graph-level and sample-level, and 3) balancing global and partial rewards. The ToMPO algorithm outperforms the GRPO method by 35% in terms of model output compliance and cooperative outcomes. Additionally, when compared to models with parameter sizes 100 times larger, it shows an 18% improvement. This demonstrates the effectiveness of the ToMPO algorithm in enhancing the model's strategic decision-making capabilities.",
    "key_points": [
      "large language model",
      "decision-making",
      "agents",
      "policy optimization"
    ],
    "gold_summary": "This paper provides a variation of GRPO that factors in ToM for more effective strategic decision-making. It is well-motivated, rigorous, and provides significant improvements in the areas where it is applied (namely, cooperative settings)."
  },
  {
    "paper_id": "vR3wRYaucr",
    "title": "Generalized Linear Markov Decision Process",
    "domain": "reinforcement learning",
    "content": "The linear Markov Decision Process (MDP) provides a principled basis for reinforcement learning (RL) but assumes that both transitions and rewards are linear in the \\textit{same} feature space. This severely limits its applicability when rewards are nonlinear or discrete. We introduce the Generalized Linear MDP (GLMDP), which retains linear transitions while modeling rewards with generalized linear models \\textbf{under potentially different feature maps}. This separation is crucial: transitions may admit rich representations learned from large unlabeled trajectories, while rewards can be modeled with limited labeled data. We show that GLMDPs are Bellman complete with respect to a new function class, enabling efficient value iteration. Based on this, we develop algorithms with provable guarantees in both \\textbf{offline} and \\textbf{online} settings. For offline RL, we design pessimistic and semi-supervised value iteration methods that achieve policy suboptimality bounds and demonstrate significant label-efficiency gains. For online RL, we propose an optimistic algorithm with a near-optimal regret bound. Together, these results broaden the scope of structured and sample-efficient RL to applications with complex reward structures, such as healthcare and e-commerce.",
    "key_points": [
      "structured mdps",
      "bellman completeness",
      "generalized linear models",
      "offline reinforcement learning",
      "sample efficiency"
    ],
    "gold_summary": "The authors propose a novel linear MDP-based framework in which the reward and dynamics are learned using different feature maps."
  },
  {
    "paper_id": "PRHNKeaZpP",
    "title": "Human-in-the-Loop Policy Optimization for Preference-Based Multi-Objective Reinforcement Learning",
    "domain": "reinforcement learning",
    "content": "Multi-objective reinforcement learning (MORL) seeks policies that effectively balance conflicting objectives. However, presenting many diverse policies without accounting for the decision maker’s (DM’s) preferences can overwhelm the decision-making process. On the other hand, accurately specifying preferences in advance is often unrealistic. To address these challenges, we introduce a human-in-the-loop MORL framework that interactively discovers preferred policies during optimization. Our approach proactively learns the DM’s implicit preferences in real time, requiring no a priori knowledge. Importantly, we integrate this preference learning directly into a parallel optimization framework, balancing exploration and exploitation to identify high-quality policies aligned with the DM's preferences. Evaluations on a complex quadrupedal robot simulation environment demonstrate that, with only \n interactions, our proposed method can identify policies aligned with human preferences, e.g., running like a dog. Further experiments on seven MuJoCo tasks and a multi-microgrid system design task against eight state-of-the-art MORAL algorithms fully demonstrate the effectiveness of our proposed framework. Demonstrations and full experiments are in https://sites.google.com/view/pbmorl/home.",
    "key_points": [
      "multi-objective reinforcement learning",
      "human-in-the-loop",
      "preference learning"
    ],
    "gold_summary": "This work proposes a human-in-the-loop multi-objective reinforcement learning (MORL) framework that learns preferences from human feedback. The preferences are modeled using a Gaussian process, and the method is evaluated across various robotic environments."
  },
  {
    "paper_id": "XLGlBWlHmW",
    "title": "ChronosCore: Context-Aware Scheduling via Slack-Driven Temporal Reasoning",
    "domain": "reinforcement learning",
    "content": "Modern real-time systems demand schedulers that can autonomously manage complex temporal interactions without manual tuning. ChronosCore is a value-based agent that integrates a compact Transformer encoder into a Deep Q-Network. Temporal slack is discretized into learnable slack tokens and fed to an attention module that models global inter-task relations in parallel while remaining computationally lightweight. Extensive experiments on single-core benchmarks, industrial mixed-criticality traces, and large-scale multiprocessor workloads show that ChronosCore consistently surpasses classical fixed-priority algorithms and feedforward reinforcement learning baselines in deadline adherence and response time, while preserving sub-millisecond inference latency. Ablation studies on encoder depth, head count, and embedding size indicate that modest architectures attain the best trade-off between decision quality and runtime cost. Finally, attention visualizations reveal that high-attention regions align with critical deadline interactions, improving model transparency and aiding post-hoc analysis.",
    "key_points": [
      "reinforcement learning",
      "real-time systems",
      "transformer models",
      "attention mechanisms",
      "scheduling under uncertainty",
      "resource allocation",
      "embedded ai"
    ],
    "gold_summary": "This paper presents ChronosCore, an attention-driven RL framework that leverages slack-token embeddings and a Transformer-based Q-network to achieve efficient and scalable real-time scheduling on both single-core and multi-core systems."
  },
  {
    "paper_id": "gNOj6BknS0",
    "title": "Two-Stage Coverage Expansion for Cross-Domain Offline Reinforcement Learning via Score-Based Generative Modeling",
    "domain": "reinforcement learning",
    "content": "Cross-domain reinforcement learning (RL) aims to transfer knowledge from a source domain to a target domain with different dynamics, but existing approaches often directly reuse source transitions, which can lead to severe distributional mismatch and performance degradation when the domain gap is large or target data is scarce. We propose Two-stage Coverage Expansion (TCE), a dual score-based generative framework that first expands state coverage through a mixture-based state score network and then aligns transitions with target-domain dynamics using a target-transition score network. This two-stage design broadens the effective support of the target dataset while mitigating harmful distributional shift, enabling more improved policy learning under limited target data. Extensive experiments on diverse cross-domain benchmarks demonstrate that TCE consistently outperforms state-of-the-art cross-domain RL baselines, achieving substantial gains even under large domain gaps and extremely small target datasets.",
    "key_points": [
      "reinforcement learning",
      "offline reinforcement learning",
      "generative model",
      "data augmentation"
    ],
    "gold_summary": "This paper proposes TCE to resolve the distribution mismatch in resuing source transitions. TCE expands state coverage first and aligns transitions with the target domain. Experiments show that TCE outperforms cross-domain baselines on several benchmarks."
  },
  {
    "paper_id": "nQRPHjucHJ",
    "title": "Finite-time Convergence Analysis of Actor-Critic with Evolving Reward",
    "domain": "reinforcement learning",
    "content": "Many popular practical reinforcement learning (RL) algorithms employ evolving reward functions—through techniques such as reward shaping, entropy regularization, or curriculum learning—yet their theoretical foundations remain underdeveloped. This paper provides the first finite-time convergence analysis of a single-timescale actor-critic algorithm in the presence of an evolving reward function under Markovian sampling. We consider a setting where the reward parameters may change at each time step, affecting both policy optimization and value estimation. Under standard assumptions, we derive non-asymptotic bounds for both actor and critic errors. Our result shows that an $O(1/\\sqrt{T})$ convergence rate is achievable, matching the best-known rate for static rewards, provided the reward parameters evolve slowly enough. this rate is preserved when the reward is updated via a gradient-based rule with bounded gradient and on the same timescale as the actor and critic, offering a theoretical foundation for many popular RL techniques. As a secondary contribution, we introduce a novel analysis of distribution mismatch under Markovian sampling, improving the best-known rate by a factor of $\\log^2T$ in the static-reward case.",
    "key_points": [
      "reinforcement learning",
      "actor-critic"
    ],
    "gold_summary": "This paper provides the finite-time analysis of a single-timescale actor-critic with evolving reward."
  },
  {
    "paper_id": "hPz3doftL4",
    "title": "On Discovering Algorithms for Adversarial Imitation Learning",
    "domain": "reinforcement learning",
    "content": "Adversarial Imitation Learning (AIL) methods, while effective in settings with limited expert demonstrations, are often considered unstable. These approaches typically decompose into two components: Density Ratio (DR) estimation $\\frac{\\rho_E}{\\rho_{\\pi}}$, where a discriminator estimates the relative occupancy of state-action pairs under the policy versus the expert; and Reward Assignment (RA), where this ratio is transformed into a reward signal used to train the policy. While significant research has focused on improving density estimation, the role of reward assignment in influencing training dynamics and final policy performance has been largely overlooked. RA functions in AIL are typically derived from divergence minimization objectives, relying heavily on human design and ingenuity. In this work, we take a different approach: we investigate the discovery of data-driven RA functions, i.e, based directly on the performance of the resulting imitation policy. To this end, we leverage an LLM-guided evolutionary framework that efficiently explores the space of RA functions, yielding _Discovered Adversarial Imitation Learning_ (DAIL), the first meta-learnt AIL algorithm. Remarkably, DAIL generalises across unseen environments and policy optimization algorithms, outperforming the current state-of-the-art of _human-designed_  baselines. Finally, we analyse why DAIL leads to more stable training, offering novel insights into the role of RA functions in the stability of AIL.",
    "key_points": [
      "imitation learning",
      "algorithm discovery",
      "llms",
      "evolutionary algorithms"
    ],
    "gold_summary": "This paper proposes Discovered Adversarial Imitation Learning (DAIL) that stabilizes the training process by using an LLM-guided framework to explore the Reward Assignment (RA) functions."
  },
  {
    "paper_id": "FDlvVdh1sB",
    "title": "Flow-Guided Latent Refiner Policies for Safe Offline Reinforcement Learning",
    "domain": "reinforcement learning",
    "content": "Safe offline reinforcement learning remains challenging due to two coupled obstacles: (i) reconciling soft penalty designs with hard safety requirements, and (ii) avoiding out-of-distribution (OOD) actions when the learned policy departs from the behavior data. Existing approaches often rely on penalty tuning that under- or over-regularizes safety, solve constrained objectives that depend on accurate simulators or online rollouts, or train powerful generative policies that still explore low-density, safety-unknown regions at deployment. We introduce a constraint-free offline framework that addresses both issues by (a) modeling the latent action manifold via a trainable flow-based density conditioned on state to explicitly concentrate probability mass on high-density—and empirically safe—regions, and (b) applying a lightweight refiner stage that performs small, ordered updates in the latent space to jointly improve reward and safety before decoding actions. This design keeps policy search inside the modelled data manifold, while a feasibility-aware training signal steers the refiner toward low-violation solutions without requiring explicit constraints or online interaction. Across various safe offline benchmarks, the proposed method achieves lower violation rates while matching or outperforming baselines in return, demonstrating its potential as a practical and effective approach to safer offline policy learning.",
    "key_points": [
      "offline reinforcement learning; safe reinforcement learning"
    ],
    "gold_summary": "This paper integrates several established techniques—flow-based density modeling conditioned on state, latent-space refinement, and feasibility value estimation via a reversed expectile objective—to form a constraint-free offline safe reinforcement learning framework."
  },
  {
    "paper_id": "DOL96nnJpm",
    "title": "Offline Reinforcement Learning Through Trajectory Clustering and Lower Bound Penalisation",
    "domain": "reinforcement learning",
    "content": "In this paper, we propose a new framework for value regularisation for offline reinforcement learning (RL). While most previous methods evade explicit out-of-distribution (OOD) region identification due to its difficulty, our method explicitly identifies the OOD region, which can be non-convex depending on datasets, via a newly proposed trajectory clustering-based behaviour cloning algorithm. With the obtained explicit OOD region, we then define a Bellman-type operator pushing the value in the OOD region to a tight lower bound while operating normally in the in-distribution region. The value function with this operator can be used for policy acquisition in various ways. Empirical results on multiple offline RL benchmarks show that our method yields the state-of-the-art performance.",
    "key_points": [
      "reinforcement learning",
      "offline reinforcement learing",
      "value regularisation"
    ],
    "gold_summary": "The paper proposes a framework for explicit OOD action identification in offline RL and a new lower‑bound value regularizer to penalize Q-values only outside the estimated in‑distribution (ID) set."
  },
  {
    "paper_id": "Hze2lxCX6D",
    "title": "Expressive Value Learning for Scalable Offline Reinforcement Learning",
    "domain": "reinforcement learning",
    "content": "Reinforcement learning (RL) is a powerful paradigm for learning to make sequences of decisions. However, RL has yet to be fully leveraged in robotics, principally due to its lack of scalability. Offline RL offers a promising avenue by training agents on  large, diverse datasets, avoiding the costly real-world interactions of online RL. Scaling offline RL to increasingly complex datasets requires expressive generative models such as diffusion and flow matching. However, existing methods typically depend on either backpropagation through time (BPTT), which is computationally prohibitive, or policy distillation, which introduces compounding errors and limits scalability to larger base policies. In this paper, we consider the question of how to develop a scalable offline RL approach without relying on distillation or backpropagation through time. We introduce Expressive Value Learning for Offline Reinforcement Learning (EVOR): a scalable offline RL approach that integrates both expressive policies and expressive value functions. EVOR learns an optimal, regularized $Q$-function via flow matching during training. At inference-time, EVOR performs inference-time policy extraction via rejection sampling against the expressive value function, enabling efficient optimization, regularization, and compute-scalable search without retraining. Empirically, we show that EVOR outperforms baselines on a diverse set of offline RL tasks, demonstrating the benefit of integrating expressive value learning into offline RL.",
    "key_points": [
      "reinforcement learning",
      "distributional reinforcement learning",
      "temporal difference learning",
      "flow matching"
    ],
    "gold_summary": "This work presents a generative offline RL algorithm, which avoids policy distillation and backpropagation through time during policy optimization. Experiments on OGBench validate the effectiveness of the proposed method."
  },
  {
    "paper_id": "qa1WJQtkJN",
    "title": "Similarity as Reward Alignment: Robust and Versatile Preference-based Reinforcement Learning",
    "domain": "reinforcement learning",
    "content": "Preference-based Reinforcement Learning (PbRL) entails a variety of approaches for aligning models with human intent to alleviate the burden of reward engineering. However, most previous PbRL work has not investigated the robustness to labeler errors, inevitable with labelers who are non-experts or operate under time constraints. We introduce Similarity as Reward Alignment (SARA), a simple contrastive framework that is both resilient to noisy labels and adaptable to diverse feedback formats. SARA learns a latent representation of preferred samples and computes rewards as similarities to the learned latent. On preference data with varying realistic noise rates, we demonstrate strong and consistent performance on continuous control offline RL benchmarks, while baselines often degrade severely with noise. We further demonstrate SARA's versatility in applications such as cross-task preference transfer and reward shaping in online learning.",
    "key_points": [
      "reinforcement learning+preferences+rlhf+contrastive learning"
    ],
    "gold_summary": "SARA (Similarity as Reward Alignment) replaces Bradley-Terry reward modeling in preference-based RL with a contrastive learning approach. It yields robust rewards under noisy labels and supports cross-task preference transfer and reward shaping."
  },
  {
    "paper_id": "398L0TTKiG",
    "title": "FAuNO: Semi-Asynchronous Federated Reinforcement Learning Framework for Task Offloading in Edge Systems",
    "domain": "reinforcement learning",
    "content": "Edge computing addresses the growing data demands of connected‐device networks by placing computational resources closer to end users through decentralized infrastructures. This decentralization challenges traditional, fully centralized orchestration, which suffers from latency and resource bottlenecks. We present \\textbf{FAuNO}---\\emph{Federated Asynchronous Network Orchestrator}---a buffered, asynchronous \\emph{federated reinforcement-learning} (FRL) framework for decentralized task offloading in edge systems. FAuNO adopts an actor–critic architecture in which local actors learn node-specific dynamics and peer interactions, while a federated critic aggregates experience across agents to encourage efficient cooperation and improve overall system performance. Experiments in the \\emph{PeersimGym} environment show that FAuNO consistently matches or exceeds heuristic and federated multi-agent RL baselines in reducing task loss and latency, underscoring its adaptability to dynamic edge-computing scenarios.",
    "key_points": [
      "task offloading",
      "edge systems",
      "partial observability",
      "multi-agent federated reinforcemtent learning",
      "actor-critic methods"
    ],
    "gold_summary": "This paper presents a semi-asynchronous FRL framework tailored for decentralized Task Offloading (TO) in dynamic edge computing systems. The framework models the TO problem as a Partially Observable Markov Game (POMG)."
  },
  {
    "paper_id": "hdcTQ4eEVJ",
    "title": "Multi-Objective Markov Games: Theoretic Foundations and Learning Algorithms",
    "domain": "reinforcement learning",
    "content": "In practical multi-agent systems, agents often have diverse objectives, which makes the system more complex, as each agent's performance across multiple criteria depends on the joint actions of all agents, creating intricate strategic trade-offs. To address this, we introduce the  Multi-Objective Markov Game (MOMG), a framework for multi-agent reinforcement learning with multiple objectives. We propose the Pareto-Nash Equilibrium (PNE) as the primary solution concept, where no agent can unilaterally improve one objective without sacrificing performance on another. We prove existence of PNE, and establish an equivalence between the PNE and the set of Nash Equilibria of MOMG's corresponding linearly scalarized games, enabling solutions of MOMG by transferring to a standard single-objective Markov game. However, we note that computing a PNE is theoretically and computationally challenging, thus we propose and study weaker but more tractable solution concepts. Building on these foundations, we develop online learning algorithm that identify a single solution to MOMGs. Furthermore, we propose a novel two-phase, preference-free algorithm that decouples exploration from planning. Our algorithm enables computation of a PNE for any given preference profile without collecting new samples, providing an efficient methodological characterization of the entire Pareto-Nash front.",
    "key_points": [
      "multi-objective learning",
      "markov games",
      "reinforcement leaning"
    ],
    "gold_summary": "This work studies primal-dual approach to the constrained low-rank MDPs. Specifically, for both soft-constraint and hard-constraint problems, this work proposes primal-dual based algorithms with provable guarantee."
  },
  {
    "paper_id": "UVoJIpQswz",
    "title": "SLED: Self-Supervised Dataset Distillation for Lightweight Experience Replay",
    "domain": "reinforcement learning",
    "content": "Experience Replay (ER) is central to off-policy reinforcement learning, but its reliance on massive buffers creates prohibitive storage and sampling costs. We introduce SLED, a self-supervised dataset distillation framework that replaces conventional replay with a compact, learnable synthetic dataset. SLED progressively shifts the agent’s training from real interactions to a small, self-evolving knowledge base by decoupling data writing from training sampling. On the writing side, a temporal schedule gradually substitutes real trajectories with optimized synthetic samples, leaving the buffer composed solely of distilled data. On the sampling side, a quota-based strategy shapes the training distribution, enabling a seamless transition from real-dominated to synthetic-dominated updates without altering the base algorithm. To preserve the long-term utility of synthetic data, SLED adopts an online-validated evolutionary optimization scheme: candidate synthetic datasets undergo brief parallel training trials, followed by real-environment evaluation, yielding a dataset-level fitness signal that guides their continual refinement. The framework is plug-and-play with mainstream off-policy methods. Overall, SLED systematically extends the idea of dataset distillation to the non-stationary regime of reinforcement learning, providing a practical alternative to large-scale replay buffers. Extensive experiments on DMControl, Habitat, and Atari confirm that SLED delivers superior efficiency and scalability over existing ER approaches, demonstrating its broad effectiveness across diverse domains.",
    "key_points": [
      "dataset distillation",
      "reinforcement learning"
    ],
    "gold_summary": "This paper proposes SLED, a novel self-supervised dataset distillation approach to improve the memory and computational efficiency of traditional replay buffers. The framework is compatible with many existing codebases and demonstrates strong empirical performance."
  },
  {
    "paper_id": "7fn75St2Ee",
    "title": "ProteinZero: Self-Improving Protein Generation via Online Reinforcement Learning",
    "domain": "reinforcement learning",
    "content": "Protein generative models have shown remarkable promise in protein design, yet their success rates remain constrained by reliance on curated sequence-structure datasets and by misalignment between supervised objectives and real design goals. We present ProteinZero, an online reinforcement learning framework for inverse folding models that enables scalable, automated, and continuous self-improvement with computationally efficient feedback. ProteinZero employs a reward pipeline that combines structural guidance from ESMFold with a novel self-derived ddG predictor, providing stable multi-objective signals while avoiding the prohibitive cost of physics-based methods. To ensure robustness in online RL, we further introduce a novel embedding-level diversity regularizer that mitigates mode collapse and promotes functionally meaningful sequence variation. Within a general RL formulation balancing multi-reward optimization, KL-divergence from a reference model, and diversity regularization, ProteinZero achieves robust improvements across designability, stability, recovery, and diversity. On the CATH-4.3 benchmark, it consistently outperforms state-of-the-art baselines including ProteinMPNN, ESM-IF, and InstructPLM, reducing design failure rates by 36-48\\% and achieving success rates above 90\\% across diverse folds. Importantly, a complete RL run can be executed on a single 8$\\times$GPU node within three days, including reward computation and data generation. These results indicate that efficient online RL fine-tuning can complement supervised pretraining by allowing protein generative models to evolve continuously from their own outputs and optimize multiple design objectives without labeled data, opening new possibilities for exploring the vast protein design space.",
    "key_points": [
      "protein design",
      "reinforcement learning",
      "inverse folding",
      "generative models",
      "sequence diversity",
      "online learning",
      "large language model"
    ],
    "gold_summary": "This paper introduces ProteinZero, an online RL framework for improving inverse folding using ESMFold self-consistency and a ddG predictor as rewards. Employs embedding-level diversity regularization to prevent mode collapse and analyzes RL design space."
  },
  {
    "paper_id": "h58qJR4XQZ",
    "title": "CBFlownet: Generating Higher-Quality Candidates via Combinatorial Bandits",
    "domain": "reinforcement learning",
    "content": "As a probabilistic sampling framework, Generative Flow Networks (GFNs) show strong potential for constructing complex combinatorial objects through the sequential composition of elementary components. However, existing {\\GFNs} often suffer from excessive exploration over vast state spaces, leading to over-sampling of low-reward regions and convergence to suboptimal distributions. Effectively biasing {\\GFNs} toward high-reward solutions remains a non-trivial challenge. In this paper, we propose {\\modelname}, which integrates a combinatorial multi-armed bandit (CMAB) framework with GFN policies. The CMAB component prunes low-quality actions, yielding compact subspaces for exploration. Restricting GFNs to these compact subspaces accelerates the discovery of high-value candidates, while the reduced complexity enables faster convergence. Experimental results on multiple tasks demonstrate that {\\modelname} generates higher-reward candidates than existing approaches, without sacrificing diversity. All implementations are publicly available at \\url{https://anonymous.4open.science/r/CBFlowNet-E0BA/}.",
    "key_points": [
      "gflownets",
      "reinforcement learning",
      "combinatorial multi-armed bandit"
    ],
    "gold_summary": "The paper proposes a strategy for GFlowNet search space pruning to accelerate mode discovery."
  },
  {
    "paper_id": "7gLNA6nT5d",
    "title": "N-Gram Induction Heads for In-Context RL: Improving Stability and Reducing Data Needs",
    "domain": "reinforcement learning",
    "content": "In-context learning allows models like transformers to adapt to new tasks from a few examples without updating their weights, a desirable trait for reinforcement learning (RL). However, existing in-context RL methods, such as Algorithm Distillation (AD), demand large, carefully curated datasets and can be unstable and costly to train due to the transient nature of in-context learning abilities. In this work, we integrated the n-gram induction heads into transformers for in-context RL. By incorporating these n-gram attention patterns, we considerably reduced the amount of data required for generalization and eased the training process by making models less sensitive to hyperparameters. Our approach matches, and in some cases surpasses, the performance of AD in both grid-world and pixel-based environments, suggesting that n-gram induction heads could improve the efficiency of in-context RL.",
    "key_points": [
      "reinforcement learning",
      "in-context reinforcement learning"
    ],
    "gold_summary": "This paper examines whether augmenting the architecture with n-gram attention heads improves the performance of Algorithm Distillation [17]."
  },
  {
    "paper_id": "r6Pw3RiMYL",
    "title": "On the Direction of RLVR Updates for LLM Reasoning: Identification and Exploitation",
    "domain": "reinforcement learning",
    "content": "Reinforcement learning with verifiable rewards (RLVR) has substantially improved the reasoning capabilities of large language models. \nWhile existing analyses identify that RLVR-induced changes are sparse, they primarily focus on the **magnitude** of these updates, largely overlooking their **direction**. \nIn this work, we argue that the direction of updates is a more critical lens for understanding RLVR's effects, which can be captured by the signed, token-level log probability difference $\\Delta\\log p$ between the base and final RLVR models.\nThrough statistical analysis and token-replacement interventions, we demonstrate that $\\Delta\\log p$ more effectively identifies sparse, yet reasoning-critical updates than magnitude-based metrics (e.g., divergence or entropy).\nBuilding on this insight, we propose two practical applications:\n(1) a *test-time extrapolation* method that amplifies the policy along the learned $\\Delta\\log p$ direction to improve reasoning accuracy without further training;\n(2) a *training-time reweighting* method that focuses learning on low-probability (corresponding to higher $\\Delta\\log p$) tokens, which improves reasoning performance across models and benchmarks.\nOur work establishes the direction of change as a key principle for analyzing and improving RLVR.",
    "key_points": [
      "rlvr",
      "llm reasoning"
    ],
    "gold_summary": "The paper analyzes reinforcement learning with verifiable rewards through how probabilities shift between the base and RLVR-trained models. The paper finds that upweight advantages of low-probability tokens during RL training improves reasoning accuracy."
  },
  {
    "paper_id": "Id1YBclGbz",
    "title": "Learning Across the Noise Spectrum: An Approach to Reinforcement Learning with Asynchronous Signals",
    "domain": "reinforcement learning",
    "content": "Reinforcement learning (RL) frameworks assume agents receive complete observation vectors at each timestep. However, real-world robotic systems typically operate in environments with asynchronous signals, i.e. sensors that update at different frequencies. We model \\textbf{asynchronous environments} as an instance of a noise-parameterized family of partially observable Markov decision processes (POMDPs). Our primary contribution, **Learning Across the Noise Spectrum (LANS)**, is a novel strategy that exposes the agent to multiple simulated noise regimes during training, implemented using Soft Actor-Critic (SAC) with recurrent neural networks (RNNs). By sampling different asynchronicity rates, we encourage the development of robust estimators. We prove that LANS acts a _time-aware_ regularization term, equivalent to a Jacobian penalty along time-sensitive directions. Experiments on MuJoCo environments with simulated asynchronicity demonstrate that LANS outperforms alternative methods on a variety of tasks—up to a factor of $>1.5\\times$ in some instances—offering a solution for robotic systems that must operate with imperfect sensory information.",
    "key_points": [
      "reinforcement learning",
      "robotics",
      "regularization",
      "sac",
      "rnns",
      "partial observability"
    ],
    "gold_summary": "The paper models asynchronous environments as noise-parameterized POMDPs, and introduces a novel LANS approach that regularizes policies, and validates their claims through experiments. They also introduce new asynchronous MuJoCo tasks for this."
  },
  {
    "paper_id": "pi4tbBMLsM",
    "title": "Local Reinforcement Learning with Action-Conditioned Root Mean Squared Q-Functions",
    "domain": "reinforcement learning",
    "content": "The Forward-Forward (FF) Algorithm is a recently proposed learning procedure for neural networks that employs two forward passes instead of the traditional forward and backward passes used in backpropagation. However, FF remains largely confined to supervised settings, leaving a gap at domains where learning signals can be yielded more naturally such as RL. In this work, inspired by FF's goodness function using layer activity statistics, we introduce Action-conditioned Root mean squared Q-Functions (ARQ), a novel value estimation method that applies a goodness function and action conditioning for local RL using temporal difference learning. Despite its simplicity and biological grounding, our approach achieves superior performance compared to state-of-the-art local backprop-free RL methods in the MinAtar and the DeepMind Control Suite benchmarks, while also outperforming algorithms trained with backpropagation on most tasks.",
    "key_points": [
      "neural network",
      "localized learning",
      "reinforcement leaning",
      "biologically plausible learning"
    ],
    "gold_summary": "This paper introduce an ARQ method which does not use the backpropagation update. Experiments on MinAtar benchmarks show ARQ has higher reward than backpropation methods."
  },
  {
    "paper_id": "U7CezlrHy3",
    "title": "COP-Q: Safety-First Reinforcement Learning with Cholesky Ordered Projection",
    "domain": "reinforcement learning",
    "content": "Using uncertainty in Q-values to mitigate overestimation, enhance exploration, and ensure safety has proven effective in single-objective deep Q-learning. However, when learning vector-valued Q-functions for correlated goals, uncertainties become intertwined across objectives. Conventional approaches either treat uncertainty in each objective independently or collapse them into a scalarized dimension, often resulting in unstable learning, low sample efficiency, limited exploration, and particularly unsafe behaviours. To address these challenges, this study proposes Cholesky Ordered Projection Q-learning (COP-Q), a novel method that guides safety-first exploitation and exploration using full multi-objective uncertainty. We first introduce generalized multi-objective confidence bounds for Q-values via covariance matrix factorization. For priority-ordered objectives, such as in safety-critical or cost-constrained reinforcement learning, Cholesky factorization is employed to incorporate inter-objective covariance into confidence bounds in a conditionally sequential manner. The lower bound yields conservative temporal difference targets to reduce overestimation, while the upper bound assigns optimistic Q-values to promote exploration. COP-Q is evaluated on standard MuJoCo and velocity-constrained SafetyVelocity-v1 benchmarks, demonstrating robust safety performance and competitive total returns. The proposed method is compatible with various deep Q-learning frameworks with minimal computational overhead, making it practical for a wide range of multi-objective and constrained reinforcement learning tasks.",
    "key_points": [
      "safe reinforcement learning",
      "multi-objective reinforcement learning",
      "uncertainty quantification"
    ],
    "gold_summary": "The paper aims to quantify uncertainty in multi-objective reinforcement learning.\nThis is realized using Cholesky factorization in the multi-objective Q-space.\nBy having a richer representation of the uncertainty, the overall performance is slightly improved."
  },
  {
    "paper_id": "DLfNDCcF2F",
    "title": "PrefPoE: Advantage-Guided Preference Fusion for Learning Where to Explore",
    "domain": "reinforcement learning",
    "content": "Exploration in reinforcement learning remains a critical challenge, as naive entropy maximization often results in high variance and inefficient policy updates. We introduce \\textbf{PrefPoE}, a novel \\textit{Preference-Product-of-Experts} framework that performs intelligent, advantage-guided exploration via the first principled application of product-of-experts (PoE) fusion for single-task exploration-exploitation balancing. By training a preference network to concentrate probability mass on high-advantage actions and fusing it with the main policy through PoE, PrefPoE creates a \\textbf{soft trust region} that stabilizes policy updates while maintaining targeted exploration. Across diverse control tasks spanning both continuous and discrete action spaces, PrefPoE demonstrates consistent improvements: +321\\% on HalfCheetah-v4 (1276~$\\rightarrow$~5375), +69\\% on Ant-v4, +276\\% on LunarLander-v2, with consistently enhanced training stability and sample efficiency. Unlike standard PPO, which suffers from entropy collapse, PrefPoE sustains adaptive exploration through its unique dynamics, thereby preventing premature convergence and enabling superior performance. Our results establish that learning \\textit{where to explore} through advantage-guided preferences is as crucial as learning how to act, offering a general framework for enhancing policy gradient methods across the full spectrum of reinforcement learning domains. Code and pretrained models are available in supplementary materials.",
    "key_points": [
      "advantage-guided exploration",
      "product-of-experts",
      "preference learning",
      "policy fusion",
      "soft trust region",
      "entropy dynamics",
      "policy fusion",
      "reinforcement learning"
    ],
    "gold_summary": "The paper presents an RL algorithm called PrefPoE based on PPO that samples action from a product of normal distribution of normal PPO and a Boltzmann distribution constructed with advantages."
  }
]