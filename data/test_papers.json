[
  {
    "paper_id": "bU8tRjuanU",
    "title": "Low-Rank Attention and Contrastive Alignment for Deep Multi-View Clustering",
    "domain": "self-supervised",
    "content": "Recent years have witnessed significant advancements in deep multi-view clustering (MVC). However, prevailing methods exhibit three critical limitations: (1) poor scalability for large-scale datasets, (2) neglect of anchor semantic consistency in feature alignment, and (3) inability to capture high-order feature interactions. To overcome these challenges, we propose a Low-Rank Attention and Contrastive Alignment framework (LRACA). Unlike conventional approaches that align sample-level features in shared subspaces, LRACA employs a category-aware anchor generation module to directly align high-level semantic prototypes (i.e., category centers) across views, explicitly enforcing clustering semantic consistency. Furthermore, we devise a dynamic low-rank attention mechanism to enhance feature discriminability, where entropy regularization constrains attention weight distributions to derive clustering pseudo-labels. Finally, a pseudo-label-guided cluster-level contrastive learning module maximizes cross-view mutual information through a feed-forward optimization paradigm. Extensive experiments on six large-scale multi-view datasets demonstrate that LRACA significantly outperforms state-of-the-art methods.",
    "key_points": [
      "multi-view clustering",
      "low-rank attention",
      "contrastive learning",
      "deep clustering"
    ],
    "gold_summary": "This paper proposes a deep multi-view clustering algorithm equipped with an anchor-based attention mechanism and cluster-based contrastive learning, which achieves good performance, but has many problems, as detailed in the weaknesses section."
  },
  {
    "paper_id": "H4RVXhicSj",
    "title": "Semi-Supervised Contrastive Learning with Orthonormal Prototypes",
    "domain": "self-supervised",
    "content": "Contrastive learning has emerged as a powerful method in deep learning, excelling at learning effective representations through contrasting samples from different distributions. However, dimensional collapse, where embeddings converge into a lower-dimensional space, poses a significant challenge, especially in semi-supervised and self-supervised setups. In this paper, we propose CLOP, a novel semi-supervised loss function designed to prevent dimensional collapse by promoting the formation of orthogonal linear subspaces among class embeddings. Through extensive experiments on real and synthetic datasets, we demonstrate that CLOP improves performance in image classification and object detection tasks while also exhibiting greater stability across different learning rates and batch sizes.",
    "key_points": [
      "contrastive learning",
      "semi-supervised learning"
    ],
    "gold_summary": "This paper proposes Contrastive Learning With Orthonormal Prototypes (CLOP), which forms orthonormal prototypes to prevent dimensional collapse of the embeddings learned by semi-supervised loss functions."
  },
  {
    "paper_id": "hXB2yFoGN2",
    "title": "Tabular Data: Is Deep Learning All You Need?",
    "domain": "self-supervised",
    "content": "Tabular data represent one of the most prevalent data formats in applied machine learning, largely because they accommodate a broad spectrum of real-world problems.  \nExisting literature has studied many of the shortcomings of neural architectures on tabular data and has repeatedly confirmed the scalability and robustness of gradient-boosted decision trees across varied datasets. However, recent deep learning models have not been subjected to a comprehensive evaluation under conditions that allow for a fair comparison with existing classical approaches. This situation motivates an investigation into whether recent deep-learning paradigms outperform classical ML methods on tabular data. \nOur survey fills this gap by benchmarking seventeen state-of-the-art methods, spanning neural networks, classical ML and AutoML techniques. Our empirical results over 68 diverse datasets from a well-established benchmark indicate a paradigm shift, where Deep Learning methods outperform classical approaches.",
    "key_points": [
      "tabula data",
      "tabular survey",
      "tabular foundation models",
      "neural networks",
      "tree-based methods",
      "hyperparameter optimization"
    ],
    "gold_summary": "This paper performs an extensive and thourough comparison of the recent tabural ML approaches. The authors demonstrate that for classification tasks DNN-based methods outperform GBDTs on the benchmark of classification problems."
  },
  {
    "paper_id": "0obDxMfeYu",
    "title": "A Median Perspective on Unlabeled Data for Out-of-Distribution Detection",
    "domain": "self-supervised",
    "content": "Out-of-distribution (OOD) detection plays a crucial role in ensuring the robustness and reliability of machine learning systems deployed in real-world applications. Recent approaches have explored the use of unlabeled data, showing potential for enhancing OOD detection capabilities. However, effectively utilizing unlabeled in-the-wild data remains challenging due to the mixed nature of both in-distribution (InD) and OOD samples. The lack of a distinct set of OOD samples complicates the task of training an optimal OOD classifier. In this work, we introduce Medix, a novel framework designed to identify potential outliers from unlabeled data using the median operation. We use the median because it provides a stable estimate of the central tendency, as an OOD detection mechanism, due to its robustness against noise and outliers. Using these identified outliers, along with labeled InD data, we train a robust OOD classifier. From a theoretical perspective, we derive error bounds that demonstrate Medix achieves a low error rate. Empirical results further substantiate our claims, as Medix outperforms existing methods across the board in open-world settings, confirming the validity of our theoretical insights.",
    "key_points": [
      "out-of-distribution detection",
      "unlabeled data"
    ],
    "gold_summary": "The paper proposes ​​Medix​​, a median-based framework to identify OOD samples from unlabeled wild data and train robust OOD detectors. Theoretical analysis is provided along with the method to demonstrate the benifits of Medix."
  },
  {
    "paper_id": "1K3l3sjwMh",
    "title": "Learn All You Need in One Hypernetwork",
    "domain": "self-supervised",
    "content": "While attention mechanism is considered the cornerstone of Transformers, its layer-specific parameterization presents challenges for efficiency and knowledge reuse. Recent work reformulates multi‑head self-attention as a hypernetwork, suggesting it can be mathematically interpreted as an implicit hypernetwork conditioned on key–query pairs. However, prior work has been limited to small‐scale tasks or theoretical demonstrations, leaving open whether explicit hypernetworks can scale to full language-model pre-training. We first prove the existence of a shared hypernetwork that can approximate the multi-head self-attention with fewer parameters. Building on this insight, we propose HyperBERT, a BERT-style Transformer encoder in which the multi-head self-attention mechanism is replaced by a single-layer MLP dynamically generated by one explicit, shared hypernetwork. In our experiments, a 4-head, 2-layer Transformer decoder serves as the shared hypernetwork to generate a single-layer MLP to replace all query, key, value, and output (QKVO) projection matrices in each layer of a 4-head, 4-layer BERT. Pre-trained on WikiText-103, our 4-layer HyperBERT matches the average GLUE score of a BERT baseline ( $ \\Delta \\le 0.1 $ ) with 6\\% fewer parameters and outperforms other MLP-based attention alternatives. Furthermore, the transplant experiment shows that the hypernetwork's learned weights transfer more effectively to deeper models than conventional attention parameters under a fixed-parameter budget. To the best of our knowledge, this is the first pre-training study that replaces multi-head self-attention with MLPs generated by a shared hypernetwork. Our results suggest that an explicit, shared hypernetwork can serve as a modular, parameter-efficient replacement for multi-head self-attention in BERT-style Transformer encoder models while preserving language modeling capabilities.",
    "key_points": [
      "hypernetworks",
      "attention",
      "transformer"
    ],
    "gold_summary": "The papers proposes to use a single shared hypernetwork for all attention layers. It demonstrates that HyperBERT saves parameters and improves performance in downstream tasks."
  },
  {
    "paper_id": "qz7g2MC32U",
    "title": "Global and Fine-Grained Framework for CLIP with Cross-Modal Mamba in Few-Shot Image Classification",
    "domain": "self-supervised",
    "content": "CLIP is a highly efficient cross-modal text-image embedding model with remarkable generalization ability. However, the encoders in CLIP usually operate independently without dynamic cross-modal interaction, leading to suboptimal performance in few-shot classification. Therefore, we propose a Global and Fine-Grained Framework for CLIP with Cross-Modal Mamba in Few-Shot Image Classification (GF4FC). Specifically, the CLIP with Cross-Modal Mamba module (CLIMA) is conducted to leverage Transformer and Vision-Transformer to interdependently encode text and image. These cross-modal representations then serve as mutual prompts to refine the embedding space, while the proposed Cross-Modal Mamba module ensures efficient time complexity. Moreover, we design a Fine-Grained Capture module (FGC) to enhance CLIMA's image representations using a Vssm module to extract prior fine-grained information. Furthermore, the Local Feature Supplementation (LFS) module is conducted to supplement CLIP's logits with FGC-derived fine-grained representations through a residual structure. Finally, the Adaptive Logits Fusion module is constructed to dynamically fuses logits using learned adaptive weights. Experiments on seven datasets demonstrate that GF4FC achieves superior performance compared with state-of-the-art methods in few-show image classification.",
    "key_points": [
      "clip",
      "multimodality",
      "few-shot learning",
      "mamba"
    ],
    "gold_summary": "See Questions"
  },
  {
    "paper_id": "F2USOqa0La",
    "title": "What We Don't C: Manifold Disentanglement for Structured Discovery",
    "domain": "self-supervised",
    "content": "Accessing information in learned representations is critical for annotation, discovery, and data filtering in disciplines where high-dimensional datasets are common. We introduce What We Don't C, a novel approach based on latent flow matching that disentangles latent subspaces by explicitly removing information included in conditional guidance resulting in meaningful residual representations. This allows factors of variation which have not already been captured in conditioning to become more readily available. We show how guidance in the flow path necessarily represses the information from the guiding, conditioning variables. Our results highlight this approach as a simple yet powerful mechanism for analyzing, controlling, and repurposing latent representations, providing a pathway toward using generative models to explore what we don't capture, consider, or catalog.",
    "key_points": [
      "supervised representation learning",
      "disentanglement",
      "flow matching"
    ],
    "gold_summary": "The paper proposes a new method for disentanglement of the latent spaces of supervised (e.g., with class labels) generative models, using flow matching."
  },
  {
    "paper_id": "b5K7k80gHU",
    "title": "A Unified and Data-Efficient Framework for Out-of-Distribution and Generalization",
    "domain": "self-supervised",
    "content": "Machine learning classification models inevitably encounter two types of out-of-distribution (OOD) data in practical applications, i.e., covariate-shifted data and semantic-shifted data. Current approaches typically address them separately in OOD detection and generalization tasks, resulting in limited capability to handle both types of OOD data simultaneously. This limitation motivates us to tackle both challenges within a unified framework. However, our theoretical investigation uncovers a conflict in jointly addressing these two problems, namely Optimization Conflict (OC). Moreover, collecting OOD data remains a significant challenge, making it difficult to provide models with sufficient OOD samples for effective learning. To this end, we propose a novel method called Tackling OOD Detection and Generalization (TODG), which incorporates a regularization term to mitigate OC and employs a data generation strategy to alleviate the scarcity of OOD data. Extensive experiments demonstrate that TODG outperforms existing methods, showcasing its effectiveness in both OOD detection and generalization tasks.",
    "key_points": [
      "out-of-distribution detection",
      "trustworthy machine learning"
    ],
    "gold_summary": "The paper claims a unified framework (TODG) that simultaneously tackles OOD detection and OOD generalization via a KL-based “feature regularization” term and implicit OOD feature sampling, i.e., Gaussian."
  },
  {
    "paper_id": "QgTA3AvUC5",
    "title": "Cross-View Open-Vocabulary Object Detection in Aerial Imagery",
    "domain": "self-supervised",
    "content": "Traditional object detection models are typically trained on a fixed set of classes, limiting their flexibility and making it costly to incorporate new categories. Open-vocabulary object detection addresses this limitation by enabling models to identify unseen classes without explicit training. Leveraging pretrained models contrastively trained on abundantly available ground-view image-text classification pairs provides a strong foundation for open-vocabulary object detection in aerial imagery. Domain shifts, viewpoint variations, and extreme scale differences make direct knowledge transfer across domains ineffective, requiring specialized adaptation strategies. In this paper, we propose a novel framework for adapting open-vocabulary representations from ground-view images to solve object detection in aerial imagery through structured domain alignment. The method introduces contrastive image-to-image alignment to enhance the similarity between aerial and ground-view embeddings and employs multi-instance vocabulary associations to align aerial images with text embeddings. Extensive experiments on the xView, DOTAv2, VisDrone, DIOR, and HRRSD datasets are used to validate our approach. Our open-vocabulary model achieves improvements of +6.32 mAP on DOTAv2, +4.16 mAP on VisDrone (Images), and +3.46 mAP on HRRSD in the zero-shot setting when compared to finetuned closed-vocabulary dataset-specific model performance, thus paving the way for more flexible and scalable object detection systems in aerial applications.",
    "key_points": [
      "open-vocabulary",
      "aerial",
      "object detection"
    ],
    "gold_summary": "This paper proposes a ContrastiveImage-to-ImageAlignment method to mitigate the gap between ground-view images and aerial-view images, which also prevents the catastrophic forgetting issue of ground-view object detection after fine-tuning the model on aerial images."
  },
  {
    "paper_id": "pJWxT3ZArh",
    "title": "Learning Ordered Representations in Latent Space for Intrinsic Dimension Estimation via Principal Component Autoencoder",
    "domain": "self-supervised",
    "content": "Autoencoders have long been considered a nonlinear extension of Principal Component Analysis (PCA). Prior studies have demonstrated that linear autoencoders (LAEs) can recover the ordered, axis-aligned principal components of PCA by incorporating non-uniform $\\ell_2$ regularization or by adjusting the loss function. However, these approaches become insufficient in the nonlinear setting, as the remaining variance cannot be properly captured independently of the nonlinear mapping. In this work, we propose a novel autoencoder framework that integrates non-uniform variance regularization with an isometric constraint. This design serves as a natural generalization of PCA, enabling the model to preserve key advantages, such as ordered representations and variance retention, while remaining effective for nonlinear dimensionality reduction tasks.",
    "key_points": [
      "pca",
      "autoencoder"
    ],
    "gold_summary": "This paper proposes a generalisation of Principal Component Analysis to the non-linear setting, using an autoencoder. The goal of this is to achieve intrinsic dimensionality estimation."
  },
  {
    "paper_id": "nxzgr96uyV",
    "title": "Deep Hyperbolic Hierarchical Clustering",
    "domain": "self-supervised",
    "content": "Hierarchical clustering is a cornerstone of unsupervised learning, yet it has been a neglected method in modern deep learning. To enable deep hierarchical clustering, the unique geometry of hyperbolic space offers an ideal setting, renowned for its ability to embed tree-like structures with minimal distortion. However, prior attempts have been hampered by significant limitations, including geometric rigidity, a lack of scalability to large datasets, and imprecise formulations of key operations.\nThis paper introduces a novel deep hyperbolic clustering framework that directly addresses these shortcomings through three key advancements. First, we present a generalized and rectified definition of the hyperbolic lowest common ancestor for both the Poincaré Ball and the Lorentz models of arbitrary curvature. Second, to address the critical issue of scalability, we employ a deep encoder that learns clusters in an exceptionally low-dimensional space compared to state of the art Euclidean methods. This makes our approach highly efficient and feasible for large-scale datasets. Finally, we introduce HoroPCA++, an improved and numerically stable dimensionality reduction technique for more faithful and lower distorted visualizations of the resulting hierarchies.",
    "key_points": [
      "hyperbolic geometry",
      "deep clustering",
      "hierarchical clustering",
      "representation learning",
      "unsupervised learning",
      "lowest common ancestor (lca)"
    ],
    "gold_summary": "The paper presents: (1) an autoencoder based on reconstruction loss and hyperbolic lowest common ancestor (LCA) loss, and (2) a hyperbolic dimensional reduction method HoroPCA++."
  },
  {
    "paper_id": "LVXc2Jvjme",
    "title": "Q2D2: A geometry-aware audio codec leveraging two-dimensional quantization",
    "domain": "self-supervised",
    "content": "Recent neural audio codecs have achieved impressive reconstruction quality, typically relying on quantization methods such as Residual Vector Quantization (RVQ), Vector Quantization (VQ) and Finite Scalar Quantization (FSQ). However, these quantization techniques limit the geometric structure of the latent space, make it harder to capture correlations between features leading to inefficiency in representation learning, codebook utilization and token rate. In this paper we introduce Two-Dimensional Quantization (Q2D2), a quantization scheme in which feature pairs are projected onto structured 2D grids—such as hexagonal, rhombic, or rectangular tiling—and quantized to the nearest grid values, yielding an implicit codebook defined by the product of grid levels, with codebook sizes comparable to conventional methods. Despite its simple geometric formulation, Q2D2 improves audio compression efficiency, with low token rates and high codebook utilization while maintaining state-of-the-art (SOTA) reconstruction quality. Specifically, Q2D2 achieves competitive to superior performance in various objective and subjective reconstruction metrics, across extensive experiments in speech domain compared to SOTA models. Comprehensive ablation studies further confirm the effectiveness of our design choices.",
    "key_points": [
      "audio codec",
      "quantization",
      "geometry",
      "2d",
      "two-dimensional"
    ],
    "gold_summary": "This paper proposes a new quantization method for audio codec called Q2D2, and conduct experiments on LibriTTS to show the performance of the proposed method"
  },
  {
    "paper_id": "IZWJhdK2o7",
    "title": "APT: Towards Universal Scene Graph Generation via Plug-in Adaptive Prompt Tuning",
    "domain": "self-supervised",
    "content": "Scene Graph Generation (SGG) is pivotal for structured visual understanding, yet it remains hindered by a fundamental limitation: the reliance on fixed, frozen semantic representations from pre-trained language models. These semantic priors, while beneficial in other domains, are inherently misaligned with the dynamic, context-sensitive nature of visual relationships, leading to biased and suboptimal performance. In this paper, we transcend the traditional one-stage v.s. two-stage architectural debate and identify this representational bottleneck as the core issue. We introduce Adaptive Prompt Tuning (APT), a universal paradigm that converts frozen semantic features into dynamic, context-aware representations through lightweight, learnable prompts. APT acts as a plug-in module that can be seamlessly integrated into existing SGG frameworks. Extensive experiments demonstrate that APT achieves +2.7 improvement in mR@100 on PredCls, +3.6 gain in F@100 and up to +6.0 gain in mR@50 in open-vocabulary novel splits. Notably, it achieves this with less than 0.5M additonal parameters (<1.5\\% overhead) and reduced 7.8\\%-25\\% training time, establishing a new state-of-the-art while offering a unified, efficient, and scalable solution for future SGG research. The source code of APT is available at <https://anonymous.4open.science/r/APT-1D24>.",
    "key_points": [
      "prompt tuning",
      "scene graph generation",
      "open vocabulary"
    ],
    "gold_summary": "The proposed method of using learnable text embeddings for SGG is a good direction. The results on benchmarks confirm the effectiveness of this approach."
  },
  {
    "paper_id": "oj0OhhqAGN",
    "title": "SparseSwaps: Tractable LLM Pruning Mask Refinement at Scale",
    "domain": "self-supervised",
    "content": "The resource requirements of Neural Networks can be significantly reduced through pruning---the removal of seemingly less important parameters. However, with the rise of LLMs, full retraining to recover pruning-induced performance degradation is often prohibitive and classical approaches such as global magnitude pruning are suboptimal on Transformer architectures. State-of-the-art methods hence solve a layer-wise mask selection problem, the problem of finding a pruning mask which minimizes the per-layer pruning error on a small set of calibration data. Exactly solving this problem to optimality using Integer Programming (IP) solvers is computationally infeasible not only due to i) the size of the search space, but also because ii) caching all intermediate values of the matrix multiplication needed to specify the optimization objective is already prohibitive. Existing approaches therefore rely on approximations or heuristics. In this work, we demonstrate that the mask selection problem can be made drastically more tractable at LLM scale. To that end, we leverage three key insights: a) enforcing equal sparsity levels per row decouples the rows without harming performance, b) the dimensionality of the problem can be reduced by leveraging the unitary invariance of the Frobenius norm objective and transforming the calibration data accordingly, and c) computing optimal 1-swaps (exchanging one kept and one pruned weight) can be realized efficiently. These insights enable us to implement a tractable and simple 1-swap algorithm that warm starts from any pruning mask, runs efficiently on GPUs at llm scale, and is essentially hyperparameter-free. We demonstrate that our approach reduces per-layer pruning error by up to 60% over Wanda (Sun et al., 2023) and consistently improves perplexity and zero-shot accuracy across state-of-the-art GPT architectures.",
    "key_points": [
      "pruning",
      "llm",
      "sparsity",
      "wanda",
      "sparsegpt",
      "efficiency"
    ],
    "gold_summary": "The paper proposes a heuristic local optimization algorithm for finding better pruning masks for LLMs.\nAchieves better results than DSnoT."
  },
  {
    "paper_id": "pbXHmLQXVS",
    "title": "An Effective Embedding Approach to Shortest Path Distance Prediction Over Large-Scale Graphs",
    "domain": "self-supervised",
    "content": "In graph data management, computing the shortest path distance between any pair of nodes is a crucial and foundational graph operation with numerous practical applications (e.g.,  travel/route planning, community search).\nTraditional algorithms for solving this problem face significant challenges in time and space complexities, especially when dealing with large-scale graphs. Worse still, existing learning-based approaches often struggle with low accuracy in predicting intricate graph structures.\nTo address these issues, this paper introduces a novel Graph Convolutional Networks (GCN)- and Multi-View Deep Neural Networks (MVDNN)-based Distance Embedding (GM-DE) framework, which enables fast and accurate predictions of the shortest path distances. Specifically, based on our proposed pivot and anchor set selection strategies, \nGM-DE enables the calculation of embeddings for each graph node. \nThen, by feeding such embeddings into our designed GCN and MVDNN models, GM-DE can be well trained to support the mining of accurate global and local positional information for the graph nodes with the help of our constructed predictors. \nIn this way, our GM-DE framework can achieve high accuracy in various complex scenarios, relying solely on basic node attributes as input without the need for scenario-specific data.\nComprehensive experiments confirm the effectiveness and efficiency of GM-DE approach in predicting the shortest path distances on a wide range of real-world graphs.",
    "key_points": [
      "shortest path distance",
      "graph algorithm",
      "representation learning",
      "neural network model"
    ],
    "gold_summary": "This paper presents GM-DE, a framework for shortest-path distance prediction in large-scale graphs. The method combines local and global embeddings via pivot and anchor set selection strategies and introduces three predictors to integrate these representations."
  },
  {
    "paper_id": "bzhCJQz35M",
    "title": "Understanding Weak-to-Strong Generalization: A Spectral Analysis",
    "domain": "self-supervised",
    "content": "Weak-to-Strong (W2S) generalization, where a student model surpasses its weaker teacher using the teacher's labels, is widely studied recently. We theoretically analyze this problem using a kernel ridgeless regression student in a Reproducing Kernel Hilbert Space (RKHS), learning from a teacher with systematic bias and output variance. Our derived asymptotic bias-variance decomposition reveals how teacher errors are processed by the student. This processing is critically mediated by the student's kernel eigenvalues and, crucially, its choice of operational modes and their alignment with the teacher's signal. We then elucidate precise conditions for W2S: outperformance hinges on this selection effectively managing the trade-off between bias and variance. Such strategic mode utilization can lead to a more favorable bias configuration via selectively ignoring the teacher's biased modes, or a reduction of teacher variance through modes with beneficial eigenvalue properties. Our experiments validate these theoretical conditions, demonstrating successful W2S generalization and underscoring the critical impact of kernel selection on navigating the bias-variance trade-off.",
    "key_points": [
      "weak-to-strong generalization",
      "spectral analysis"
    ],
    "gold_summary": "The paper studies generalization performance of kernel regression from a spectral perspective. It derives a spectral bias-variance model risk decomposition and accordingly discusses strategies to minimize the test error. Some experiments are provided."
  },
  {
    "paper_id": "ai3LYEFUGn",
    "title": "Unsupervised learning of disentangled representations via diffusion variational autoencoders",
    "domain": "self-supervised",
    "content": "We present the diffusion variational autoencoder (DiVA), a method for unsupervised representation learning that combines the theoretical frameworks of diffusion models and VAEs. By unifying their respective evidence lower bounds, DiVA formulates a principled objective that learns representations through score-based guidance of the underlying diffusion process. The resulting representations automatically capture meaningful structure in the data: it recovers ground truth generative factors in synthetic datasets, learns factorized, semantic latent dimensions from complex natural images, and encodes video sequences into latent trajectories that are straighter than those of alternative encoders, despite training exclusively on static images. Furthermore, DiVA can extract useful representations from pre-trained diffusion models with minimal additional training. Finally, the explicitly probabilistic formulation provides new ways to identify semantically meaningful axes in the absence of supervised labels. Overall, these results indicate that implicit structural information in diffusion models can be made explicit and interpretable through synergistic combination with a variational autoencoder.",
    "key_points": [
      "unsupervised learning",
      "diffusion models",
      "variational autoencoders",
      "disentangling",
      "elbo"
    ],
    "gold_summary": "The paper presents DiVA, a diffusion variational autoencoder for disentangled representation learning by combining a diffusion model with a VAE. The training loss is formalized under a unified ELBO objective."
  },
  {
    "paper_id": "9eJ4LD3Cco",
    "title": "A Differentiable Alignment Framework for Sequence-to-Sequence Modeling via Optimal Transport",
    "domain": "self-supervised",
    "content": "State-of-the-art end-to-end (E2E) ASR systems, such as the Connectionist Temporal Classification (CTC) and transducer-based models, suffer from peaky behavior and alignment inaccuracies.\nIn this paper, we propose a novel differentiable alignment framework based on one-dimensional optimal transport, enabling the model to learn a single alignment and perform ASR in an E2E manner.\nWe introduce a pseudo-metric, called Sequence Optimal Transport Distance (SOTD), over the sequence space and discuss its theoretical properties.\nBased on the SOTD, we propose Optimal Temporal Transport Classification (OTTC) loss for ASR and contrast its behavior with CTC.\nExperimental results on the TIMIT, AMI, and LibriSpeech datasets show that our method considerably improves alignment performance compared to CTC and the more recently proposed Consistency-Regularized CTC, though with a trade-off in ASR performance.\nWe believe this work opens new avenues for seq2seq alignment research, providing a solid foundation for further exploration and development within the community.",
    "key_points": [
      "optimal transport",
      "sequence to sequence",
      "alignment",
      "speech",
      "asr"
    ],
    "gold_summary": "This paper proposes a differentiable seq2seq alignment via 1D OT (SOTD pseudo-metric + OTTC loss) achieving linear time/space and learning a single path to curb CTC's peaky behavior."
  },
  {
    "paper_id": "slTQdWWQI9",
    "title": "Contrastive Learning with Quantum Projection Heads and Kernels",
    "domain": "self-supervised",
    "content": "Self-supervised contrastive learning is sensitive to architectural choices and to how similarity is defined. Motivated by claims that quantum circuits can induce useful non-classical geometries, we present a systematic empirical analysis of two natural drop-in quantum components for the projection/similarity stage: (i) variational quantum circuits (VQCs) as projection heads and (ii) fixed quantum feature maps whose state fidelities act as similarity measures (``quantum kernels''). Within a controlled SimCLR pipeline on STL-10 (ResNet18 encoder) using mainstream \\emph{analytic} simulators, we report three findings. First, under realistic resource constraints (low qubit count, shallow depth), a tuned classical MLP head consistently matches or outperforms VQC heads. Second, fidelity-based quantum kernels largely mirror cosine similarity without a clear uplift. Third, increasing circuit size rapidly incurs prohibitive latency, exposing scaling bottlenecks that restrict current explorability. These results constitute a useful null baseline for hybrid quantum-classical contrastive learning and point to concrete directions: batching-friendly simulators for higher throughput, lower-variance/better-conditioned feature maps to avoid similarity collapse, and modest, low-latency hardware as a realistic near-term testbed. We release anonymized code and consolidated hyperparameters to facilitate replication and future extensions.",
    "key_points": [
      "contrastive learning",
      "self-supervised learning",
      "quantum meachine learning",
      "variational quantum circuits",
      "quantum kernels",
      "representation learning",
      "infonce loss",
      "quantum fidelity"
    ],
    "gold_summary": "This paper primarily investigates the effectiveness of quantum projection heads and quantum kernels in contrastive learning."
  },
  {
    "paper_id": "huPQfsUpVd",
    "title": "Is a Small Matrix Eigendecomposition Sufficient for Spectral Clustering?",
    "domain": "self-supervised",
    "content": "Spectral clustering has been widely used in clustering tasks due to its effectiveness. However, its key step, eigendecomposition of an $n\\times n$ matrix, is computationally expensive for large-scale datasets. Recent works have proposed methods to reduce this complexity, such as Nystr\\\"om method approximation and landmark-based approaches. These methods aim to maintain good clustering quality while performing eigendecomposition on a smaller matrix. The current minimum matrix size for spectral decomposition in spectral clustering is $k\\times k$ (where $k$ is the number of clusters). However, no existing algorithms can achieve good clustering performance with only a $k\\times k$ matrix eigendecomposition.\n    In this paper, we propose a novel distribution-based spectral clustering. Our method constructs an $n\\times k$ bipartite graph between $n$ data points and $k$ distributions, enabling the eigendecomposition of only a $k\\times k$ matrix and preserving clustering quality at the same time. Extensive experiments performed on synthetic and real-world datasets demonstrate the superiority and effectiveness of the proposed method compared to the state-of-the-art algorithms.",
    "key_points": [
      "spectral clustering",
      "kernel mothods",
      "distributional kernel"
    ],
    "gold_summary": "The authors propose a novel distribution-based spectral clustering method that constructs a bipartite graph, enabling eigendecomposition on a smaller $k\\times k$ matrix while preserving clustering quality, which is validated through extensive experiments."
  },
  {
    "paper_id": "AQo1SEElNb",
    "title": "Selective Rotary Position Embedding",
    "domain": "self-supervised",
    "content": "Position information is essential for language modeling. In softmax transformers, Rotary Position Embeddings (RoPE) encode positions through *fixed-angle* rotations, while in linear transformers, order is handled via input-dependent (selective) gating that decays historical information. Selectivity has generally been shown to improve language related tasks. Inspired by this, we introduce **Selective RoPE**, an *input-dependent* rotary embedding mechanism, that generalizes *RoPE*, and enables rotation in all angels for linear transformers. We show that softmax attention already performs a hidden form of these rotations on query-key pairs, uncovering an implicit positional structure. We further show that in state-space models and gated linear transformers, the real part manages forgetting while the imaginary part encodes positions through rotations. We validate our method by equipping gated linear attention (GLA) with **Selective RoPE**, demonstrating that its input-dependent rotations improve performance in language modeling and on difficult sequence tasks like copying, state tracking, and retrieval.",
    "key_points": [
      "rope",
      "linear transformer",
      "attention",
      "state space models",
      "forget gate"
    ],
    "gold_summary": "The paper introduces Selective Rotary Position Embedding (Selective RoPE), an input-dependent mechanism designed to generalize standard Rotary Position Embeddings (RoPE) by performing rotations at arbitrary, selective frequencies."
  },
  {
    "paper_id": "4YAHuBtzHb",
    "title": "Explore More, Learn Better: Parallel MLLM Embeddings under Mutual Information Minimization",
    "domain": "self-supervised",
    "content": "Embedding models are a cornerstone of modern AI. Driven by Multimodal Large Language Models (MLLMs), they have made great progress in architecture and data curation, while the holistic paradigm is still limited to SSC, {\\em i.e.}, single input, singular embedding, contrastive supervision, which collapses rich, multifaceted inputs into monolithic embeddings and fails to fully exploit MLLM capabilities. In this paper, we tailor one \\textbf{P}arallel \\textbf{D}ecoupling \\textbf{F}ramework (PDF) for multimodal embedding learning, by utilizing the proprietary steerability of MLLMs, {\\em i.e.}, their ability to flexibly generate quite differentiated response under explicit instructions. Concretely, PDF conditions a shared MLLM backbone on distinct, learnable prefixes to roll out multiple parallel paths for one input, then relies on these paths to obtain parallel embeddings. To promote full parallel diversity, we employ Mutual Information Minimization (MIM) as an explicit constraint, coupled with per-path contrastive supervision to maintain semantic alignment. Such dual-objectives force PDF to yield robust semantic coverage and a generalizable embedding space. Ultimately, the remarkable embedding space are accessible at inference via one single forward pass, incurring negligible computational overhead. We instantiate PDF on multiple MLLM backbones and prove its effectiveness on MMEB benchmark. Significant gains are consistently achieved across various resolutions and model sizes, {\\em e.g.}, boosting the VLM2Vec-LLaVA-1.6-LR model by a remarkable +8.9\\% (7B), and the VLM2Vec-Qwen2VL models by +4.2\\% (2B) and +3.1\\% (7B). In terms of efficiency, our 2B model surpasses its baseline by +2.6\\% using only half the computational budget. Code will be available.",
    "key_points": [
      "vlm2vec",
      "mllm",
      "embedding model",
      "mutlti-modal representation"
    ],
    "gold_summary": "The key idea is to replace the standard “single input–single embedding” paradigm with a deep prefix injection mechanism that conditions multiple parallel paths through learnable prefix vectors injected at each transformer layer."
  },
  {
    "paper_id": "VLLcv3B2vE",
    "title": "DeCAL Tokenwise Compression",
    "domain": "self-supervised",
    "content": "This paper introduces DeCAL, a new method for tokenwise compression.  DeCAL uses an encoder-decoder language model pretrained with denoising to learn to produce high-quality, general-purpose compressed representations from the encoder.  DeCAL applies small modifications to the encoder, with the emphasis on maximizing compression quality, even at the expense of compute.  We show that DeCAL at 2x compression can match uncompressed on several downstream tasks, with usually only a minor dropoff in metrics up to 8x compression, among question-answering, summarization, and multi-vector retrieval tasks.  DeCAL offers significant savings where pre-computed dense representations can be utilized, and we believe the approach can be further developed to be more broadly applicable.",
    "key_points": [
      "transformer",
      "representation",
      "compression",
      "encoder-decoder",
      "context",
      "summarization",
      "question-answering",
      "retrieval",
      "nlp"
    ],
    "gold_summary": "Authors propose a compression method based on encode-decoder architecture and showed the evaluation of the method on several benchmark datasets. They have performed ablation on compression ratio and also compared with other methods."
  },
  {
    "paper_id": "323SIitB3Z",
    "title": "WatchLog: From a Glimpse to Decision—Rapid Event Reasoning in Endpoint Detection and Response Logs with Multimodal LLMs",
    "domain": "self-supervised",
    "content": "Endpoint Detection and Response (EDR) systems are essential for detecting malicious activities on endpoint devices, yet existing approaches struggle to efficiently process ultra-long log sequences and provide interpretable reasonings for security analysts. This paper presents \\textbf{WatchLog}, a framework that models raw logs as video-structured representations to enable efficient video-language modeling of endpoint behaviors. Specifically, each event is encoded into a key-value guided image, and the resulting images are temporally arranged into a video-structured sequence. A temporal cross-attention mechanism then performs pixel-wise temporal aggregation, producing compact sequence embeddings that preserve behavioral fidelity while reducing computational cost. We conduct two-stage pre-training followed by supervised fine-tuning to generate behavioral explanations grounded in the semantics of event sequences and final judgments. Experiments on our newly constructed EDR8M-20R dataset demonstrate that WatchLog achieves higher detection accuracy and recall than the state-of-the-art baselines, while also generating reliable reasoning traces and enabling more efficient inference. Furthermore, our real-world application of WatchLog has validated its efficiency, effectiveness, and strong generalization capabilities.",
    "key_points": [
      "endpoint detection and response; interpretable reasonings; cyberattack detection; video-language modeling; log analysis;"
    ],
    "gold_summary": "The paper transfer the tradition EDR problem to a video understanding task, with the help of MLLMs, they achieve more accurate and efficent detection."
  },
  {
    "paper_id": "Z8f0whjttd",
    "title": "Escaping the Homophily Trap: A Threshold-free Graph Outlier Detection Framework via Clustering-guided Edge Reweighting",
    "domain": "semi-supervised",
    "content": "Graph outlier detection is a critical task for identifying rare, deviant patterns in graph-structured data. \nHowever, prevalent methods based on graph convolution are fundamentally challenged by the ''Homophily Trap'': the aggregation of features from neighboring nodes inadvertently contaminates the representations of normal nodes near anomalies, blurring their distinctions. \nTo overcome this limitation, we propose a Clustering-guided Edge Reweighting framework for Graph Outlier Detection (CER-GOD), which jointly optimizes a self-discriminative masking spoiler with an adaptive clustering-based outlier detector. \nThe masking spoiler learns to selectively weaken the influence of heterogeneous neighbors, preserving the discriminative power of node embeddings. \nThis process is guided by the clustering detector, which generates pseudo-labels in an unsupervised manner, thereby eliminating the need for predefined anomaly thresholds. \nTo ensure robust optimization and prevent class collapse—a failure mode exacerbated by the homophily trap—we introduce a diversity loss that stabilizes the clustering process. \nOur end-to-end framework demonstrates superior performance on multiple benchmark datasets, establishing a new state-of-the-art by effectively dismantling the homophily trap.",
    "key_points": [
      "outlier detection",
      "graph neural networks",
      "clustering"
    ],
    "gold_summary": "The authors propose a Clustering-guided Edge Reweighting framework for Graph Outlier Detection (CER-GOD), which jointly optimizes a self-discriminative masking spoiler with an adaptive clustering-based outlier detector. Experiments show their improvement to some extent."
  },
  {
    "paper_id": "XyD1Fw6Q71",
    "title": "Self-Alignment Learning to Improve Myocardial Infarction Detection from Single-Lead ECG",
    "domain": "semi-supervised",
    "content": "Myocardial infarction is a critical manifestation of coronary artery disease, yet detecting it from single-lead electrocardiogram (ECG) remains challenging due to limited spatial information. An intuitive idea is to convert single-lead into multiple-lead ECG for classification by pre-trained models, but generative methods optimized at the signal level in most cases leave a large latent space gap, ultimately degrading diagnostic performance. This naturally raises the question of whether latent space alignment could help. However, most prior ECG alignment methods focus on learning transformation invariance, which mismatches the goal of single-lead detection. To address this issue, we propose SelfMIS, a simple yet effective alignment learning framework to improve myocardial infarction detection from single-lead ECG. Discarding manual data augmentations, SelfMIS employs a self-cutting strategy to pair multiple-lead ECG with their corresponding single-lead segments and directly align them in the latent space. This design shifts the learning objective from pursuing transformation invariance to enriching the single-lead representation, explicitly driving the single-lead ECG encoder to learn a representation capable of inferring global cardiac context from the local signal. Experimentally, SelfMIS achieves superior performance over baseline models across nine myocardial infarction types while maintaining a simpler architecture and lower computational overhead, thereby substantiating the efficacy of direct latent space alignment. Our code and checkpoint will be publicly available after acceptance.",
    "key_points": [
      "ecg",
      "alignment learning",
      "myocardial infarction detection",
      "singl-lead ecg"
    ],
    "gold_summary": "This paper presents an intriguing alignment learning framework for single-lead ECG MI detection, demonstrating promising performance and efficiency, achieving an AUC of 0.83 on *the PTB-XL* dataset and outperforming baseline SSL methods (Table 2)."
  },
  {
    "paper_id": "MNCCZ3ICzi",
    "title": "FedReLa: Imbalanced Federated Learning via Re-Labeling",
    "domain": "semi-supervised",
    "content": "Federated learning has emerged as the foremost approach for decentralized model training with privacy preserving. The global class imbalance and cross-client data heterogeneity naturally coexist, and the mismatch between local and global imbalances exacerbates the performance degradation of the aggregated model. The agnosticism of global minority classes poses significant challenges for data-level methods, especially under extreme conditions with severe class deficiencies across clients. In this paper, we propose FedReLa, a novel data-level approach that tackles the coexistence of data heterogeneity and class imbalance in federated learning. By re-labeling samples with a feature-dependent label re-allocator, FedReLa corrects the biased decision boundaries without requiring knowledge of the global\nclass distribution. This modular, model-agnostic approach can be integrated with algorithmic methods to offer consistent improvements without any extra communication burden. Through extensive experiments, our method significantly improves the accuracy of minority classes and the overall accuracy on step-wise-imbalanced and long-tailed datasets, outperforming the previous state of the art.",
    "key_points": [
      "federated learning",
      "imbalanced learning",
      "long-tailed learning",
      "data heterogeneity"
    ],
    "gold_summary": "This paper proposes FedReLA, aiming to address heterogeneous and long-tailed data distributions by re-labeling majority-class samples as minority ones, thereby expanding the decision boundaries of minority classes. Experimental results demonstrate improvements over existing approaches."
  },
  {
    "paper_id": "sTlL1rwGVb",
    "title": "Semantic Optimal Lossless Vector Quantization",
    "domain": "semi-supervised",
    "content": "Is it possible to derive an optimally compact image representation that preserves semantic information without performance loss for a class of downstream tasks? This paper addresses this fundamental question by providing a formal definition of semantic lossless optimal compression. We introduce a framework called Semantic Optimal Lossless Vector Quantization (SOLO-VQ) as a practical realization to address this concept. Unlike prior works, which often rely on heuristics and evaluate on generic image datasets where optimality is unverifiable, we propose a novel evaluation protocol. We construct a series of synthetic datasets and associated tasks where the information-theoretic rate limits for lossless compression are computable. Within these controlled environments, we empirically demonstrate that SOLO-VQ achieves provably optimal and lossless compression, effectively reaching the theoretical lower bounds. Our work establishes a principled foundation for goal-oriented semantic media data compression and suggests a promising methodology towards achieving this goal for compressive real-world image transmission.",
    "key_points": [
      "lossless semantic compression",
      "vector quantization",
      "representation learning"
    ],
    "gold_summary": "This paper propose a new semantic image compression method based on semantic optimal lossless vector quantization, to preserve semantic information without performance loss for a class of downstream tasks."
  },
  {
    "paper_id": "PSGBG2rBbg",
    "title": "UFL: Uncertainty-Driven Federated Learning",
    "domain": "semi-supervised",
    "content": "Federated Learning (FL), a privacy-preserving distributed machine learning, encounters numerous challenges in practical applications, notably Data Heterogeneity (DH). Current methods primarily address DH, relying on coarse dataset statistics, server aggregation, or local model uncertainty. This paper reveals that FL exhibits a distinct sample-level uncertainty distribution during training, characterized by a pronounced long-tail effect. We further show that this long-tail effect is not solely attributable to DH, but is also an inherent characteristic of the FL framework itself. To this end, we propose Uncertainty-driven Federated Learning (UFL), a framework designed to address the uncertainty challenge at the sample level. UFL employs Monte Carlo (MC) dropout to estimate sample uncertainty and adaptively re-weights the loss function accordingly. Moreover, we design U-Agg, a robust aggregation method using clients' accumulated high-uncertainty sample uncertainty to adjust aggregating weights and improve convergence with theoretical guarantees. Unlike existing approaches that alleviate DH at coarser levels, UFL introduces a sample-centric perspective that directly addresses the uncertainty challenge from its fundamental source, offering an orthogonal yet complementary dimension to traditional techniques. Extensive experiments demonstrate that UFL outperforms SOTA FL methods by mitigating the long-tail effect of sample uncertainty, offering a novel and complementary perspective on sample-level uncertainty to enhance FL efficacy over DH solutions.",
    "key_points": [
      "federated learning",
      "privacy-preserving",
      "uncertainty",
      "monte carlo dropout",
      "data heterogeneity"
    ],
    "gold_summary": "The authors handle data heterogeneity (DH) in federated settings and approximates the sample-level uncertainty via Monte Carlo Dropout (Gal & Ghahramani, 2016). The authors have shown some convergence results."
  },
  {
    "paper_id": "K9j6iggdGX",
    "title": "A$^2$SG: Adaptive and Asymmetric Surrogate Gradients for Training Deep Spiking Neural Network",
    "domain": "semi-supervised",
    "content": "Training deep spiking neural networks (SNNs) remains challenging due to sharp loss landscapes and temporal inconsistency caused by surrogate gradients.\nTo address these challenges, we propose a unified framework: adaptive and asymmetric surrogate gradients ($\\textit{A$^2$SG}$).\nThe adaptive gradients adjust an effective window for spatio-temporal adaptation, reducing spatial gradient variation and maintaining directional consistency of gradients over time.\nThe asymmetric gradients reflect neuronal dynamics by assigning larger gradients to neurons with higher membrane potentials, and we prove that they yield lower variation than symmetric surrogates.\nOur analysis further establishes a direct connection between local gradient variation and the curvature of the loss landscape, providing a principled explanation for how $\\textit{A$^2$SG}$ promotes convergence to flatter minima and improves generalization.\nWe conduct extensive experiments on diverse models, including CNN-based and Transformer-based SNNs, across various tasks such as image classification using both static and neuromorphic datasets, as well as segmentation.\nThe results demonstrate that $\\textit{A$^2$SG}$ consistently improves accuracy and energy efficiency, establishing it as a general and reliable solution for training deep SNNs.",
    "key_points": [
      "deep spiking neural networks",
      "surrogate gradients",
      "adaptive",
      "asymmetric"
    ],
    "gold_summary": "This work proposes an adaptive and asymmetric calculation scheme for surrogate gradients of SNNs, which is based on the theoretical analysis of local gradient variation and the curvature of the loss landscape."
  },
  {
    "paper_id": "5bxmmuRhO6",
    "title": "Supporting Multimodal Intermediate Fusion with Informatic Constraint and Distribution Coherence",
    "domain": "semi-supervised",
    "content": "Based on the prevalent intermediate fusion (IF) and late fusion (LF) frameworks, multimodal representation learning (MML) demonstrates its superiority over unimodal representation learning. To investigate the intrinsic factors underlying the empirical success of MML, research grounded in theoretical justifications from the perspective of generalization error has emerged. However, these provable MML studies derive the theoretical findings based on LF, while theoretical exploration based on IF remains scarce. This naturally gives rise to a question: **Can we design a comprehensive MML approach supported by the sufficient theoretical analysis across fusion types?** To this end, we revisit the IF and LF paradigms from a fine-grained dimensional perspective. The derived theoretical evidence sufficiently establishes the superiority of IF over LF under a specific constraint. Based on a general $K$-Lipschitz continuity assumption, we derive the generalization error upper bound of the IF-based methods, indicating that eliminating the distribution incoherence can improve the generalizability of IF-based MML methods. Building upon these theoretical insights, we establish a novel IF-based MML method, which introduces the informatic constraint and performs distribution cohering. Extensive experimental results on multiple widely adopted datasets verify the effectiveness of the proposed method.",
    "key_points": [
      "multimodal representation learning; generalization error;  informatic constraint; distribution cohering"
    ],
    "gold_summary": "This paper presents a novel framework for multimodal representation learning, with a theoretical analysis centered on intermediate and late fusion mechanisms. The proposed theory further leads to the implementation of the IID method."
  },
  {
    "paper_id": "Wj0qUfH7b3",
    "title": "Refining Heuristic-Based Bitcoin Address Clustering with Graph Neural Networks",
    "domain": "semi-supervised",
    "content": "Bitcoin’s pseudonymous nature makes it challenging to analyze user-level activity, since a single user may control multiple identifiers (addresses). Existing heuristic-based methods attempt to identify addresses belonging to the same user, but they often produce flat cluster assignments with limited modularity and are prone to errors such as merging different users together. In this work, we propose a method for refining heuristic-obtain clusters by grounding our clustering on contrastive embeddings yielded by graph neural networks . Our contribution is threefold: (i) we release a publicly available dataset of Bitcoin transaction graphs containing a substantial number of clusters; (ii) we propose a methodology for learning address embeddings consistent with heuristics, and back it up with solid theoretical foundations and empirical results; (iii) through hierarchical clustering, we allow a finer analysis of heuristic clusters and provide a quantitative criterion for flagging suspicious merges.",
    "key_points": [
      "graph neural networks",
      "representation learning",
      "clustering",
      "hierarchical clustering",
      "bitcoin"
    ],
    "gold_summary": "The paper proposes to use graph neural networks with slightly modified loss function to compute embeddings in Bitcoin graphs to address clustering."
  },
  {
    "paper_id": "TkerLrovDn",
    "title": "Stretch Transformation for Tabular Data",
    "domain": "semi-supervised",
    "content": "Tabular data presents unique challenges for deep learning due to its heterogeneous nature, where features exhibit diverse distributions, scales, and statistical properties. Although recent advances have achieved strong performance on tabular benchmarks, feature transformation, a critical preprocessing step, remains largely unsupervised despite the availability of target information during training. We introduce the stretch transformation framework, which formulates feature preprocessing as an optimization problem to make the target function smoother and thus more learnable. Our framework has two variants: (1) unsupervised stretch, which uniformly redistributes feature density via minimax optimization, and (2) supervised stretch, which is the first method to systematically leverage target information for numeric features by minimizing the target function's Dirichlet energy in the transformed space. Our theoretical analysis reveals fundamental connections to existing methods, as unsupervised stretch explains why empirical CDF transformation can improve learning despite being label-agnostic, and supervised stretch generalizes target encoding with principled regularization for numeric features. Comprehensive experiments on 38 datasets from the TALENT benchmark demonstrate that supervised stretch consistently outperforms all baselines. These results show that explicitly optimizing for target function smoothness is a powerful and underexplored strategy for tabular deep learning.",
    "key_points": [
      "tabular machine learning",
      "preprocessing"
    ],
    "gold_summary": "The paper presents Stretch Transformation, a new framework for numerical feature preprocessing in tabular deep learning."
  },
  {
    "paper_id": "WbVTxfv1Mp",
    "title": "Rectified Decoupled Dataset Distillation: A Closer Look for Fair and Comprehensive Evaluation",
    "domain": "semi-supervised",
    "content": "Dataset distillation aims to generate compact synthetic datasets that enable models trained on them to achieve performance comparable to those trained on full real datasets, while substantially reducing storage and computational costs. Early bi-level optimization methods (e.g., MTT) have shown promising results on small-scale datasets, but their scalability is limited by high computational overhead.\nTo address this limitation, recent decoupled dataset distillation methods (e.g., SRe$^2$L) separate the teacher model pre-training from the synthetic data generation process. These methods also introduce random data augmentation and epoch-wise soft labels during the post-evaluation phase to improve performance and generalization. However, existing decoupled distillation methods suffer from inconsistent post-evaluation protocols, which hinders progress in the field. In this work, we propose **R**ectified **D**ecoupled **D**ataset **D**istillation (RD$^3$), and systematically investigate how different post-evaluation settings affect test accuracy. We further examine whether the reported performance differences across existing methods reflect true methodological advances or stem from discrepancies in evaluation procedures. Our analysis reveals that much of the performance variation can be attributed to inconsistent evaluation rather than differences in the intrinsic quality of the synthetic data. In addition, we identify general strategies that improve the effectiveness of distilled datasets across settings. By establishing a standardized benchmark and rigorous evaluation protocol, RD$^3$ provides a foundation for fair and reproducible comparisons in future dataset distillation research.",
    "key_points": [
      "decoupled dataset distillation"
    ],
    "gold_summary": "This paper introduces a unified and systematic evaluation framework for dataset distillation to compare decoupled distillation methods."
  },
  {
    "paper_id": "qF9WJxvHX8",
    "title": "Guiding Mixture-of-Experts with Temporal Multimodal Interactions",
    "domain": "semi-supervised",
    "content": "Mixture-of-Experts (MoE) architectures have become pivotal for large-scale multimodal models. However, their routing mechanisms typically overlook the informative, time-varying interaction dynamics between modalities. This limitation hinders expert specialization, as the model cannot explicitly leverage intrinsic modality relationships for effective reasoning. To address this, we propose a novel framework that guides MoE routing using quantified temporal interaction. A multimodal interaction-aware router learns to dispatch tokens to experts based on the nature of their interactions. This dynamic routing encourages experts to acquire generalizable interaction-processing skills rather than merely learning task-specific features. Our framework builds on a new formulation of temporal multimodal interaction dynamics, which are used to guide expert routing. We first demonstrate that these temporal multimodal interactions reveal meaningful patterns across applications, and then show how they can be leveraged to improve both the design and performance of MoE-based models. Comprehensive experiments on challenging multimodal benchmarks validate our approach, demonstrating both enhanced performance and improved interpretability.",
    "key_points": [
      "multimodal interaction",
      "mixture-of-experts",
      "transformer"
    ],
    "gold_summary": "This paper presents TIME-MoE, a Temporal Interaction-guided Mixture-of-Experts framework that leverages information-theoretic decomposition (RUS) to guide expert routing."
  },
  {
    "paper_id": "wLcTAJ7DF9",
    "title": "Multi-ReduNet: Interpretable Class-Wise Decomposition of ReduNet",
    "domain": "semi-supervised",
    "content": "ReduNet has emerged as a promising white-box neural architecture grounded in the principle of maximal coding rate reduction, offering interpretability in deep feature learning. However, its practical applicability is hindered by computational complexity and limited ability to exploit class-specific structures, especially in undersampled regimes. In this work, we propose Multi-ReduNet and its variant Multi-ReduNet-LastNorm, which decompose the global learning objective into class-wise subproblems. These extensions preserve the theoretical foundation of ReduNet while improving training efficiency by reducing matrix inversion costs and enhancing feature separability. We provide a concise theoretical justification for the class-wise decomposition and show through experiments on diverse datasets that our models retain interpretability while achieving superior efficiency and discriminative power under limited supervision. Our findings suggest that class-wise extensions of ReduNet broaden its applicability, bridging the gap between interpretability and practical scalability in deep learning.",
    "key_points": [
      "interpretable machine learning",
      "white-box neural networks",
      "redunet",
      "multi-redunet"
    ],
    "gold_summary": "This paper improves the objective of ReduNet under the assumption of “undersampled regimes” and proposes two extensions, Multi-ReduNet and Multi-ReduNetLastNorm, for computational efficiency and representation separability"
  },
  {
    "paper_id": "27fc8hXB5N",
    "title": "Geometric Compression in Grokking: The Three-Stage Modular Dynamics of Transformers",
    "domain": "semi-supervised",
    "content": "A central mystery in deep learning is how generalizable algorithms emerge from the complex dynamics of training. The phenomenon of grokking serves as a canonical example of this puzzle. While mechanistic reverse engineering has successfully identified the final algorithms networks discover, the dynamic process of their formation remains largely uncharacterized. Progress in understanding these dynamics is hindered by complexity metrics that are either monolithic or presuppose non-universal architectural properties like piecewise linearity. We approach this challenge from a geometric perspective, introducing the Geometric Coherence Score (GCS), which quantifies how consistently networks transform local geometric structures across inputs, revealing the hidden geometric evolution of algorithmic learning. Applying GCS to Transformer grokking on modular arithmetic, we discover a universal three-stage construct-then-compress dynamic with precise modular division of labor: (I) Early Geometric Convergence attention achieves high geometric coherence through simple memorization patterns; (II) Geometric Restructuring attention actively decreases coherence by constructing complex structured representations necessary for generalization; (III) System wide Consolidation all computational flows coordinately increase coherence, stabilizing the generalizable algorithm. We substantiate this discovery through multiple lines of evidence: the dynamic persists across various activation functions (ReLU, GeLU, SiLU); it distinguishes successful grokking from overfitting (where geometric restructuring fails); and GCS dynamics directly correspond to the evolution of attention patterns from uniform simplicity to algorithmic sophistication. Our work reframes grokking as sophisticated modular geometric reorganization, providing the first direct geometric evidence for construct then compress mechanisms in neural networks and offering a principled diagnostic tool for interpreting emergent algorithms.",
    "key_points": [
      "grokking",
      "geometric deep learning",
      "transformers"
    ],
    "gold_summary": "This work offers a mechanistic perspective on grokking and introduces a principled geometric framework to analyze the dynamic interplay of complexities that drive learning in neural networks."
  },
  {
    "paper_id": "y6piOp5MSO",
    "title": "GeoPE:A Unified Geometric Positional  Embedding for Structured Tensors",
    "domain": "semi-supervised",
    "content": "Rotary Positional Embedding (RoPE) excels at encoding relative positions in 1D sequences, but its generalization to higher-dimensional structured data like images and videos remains a challenge. Existing approaches often treat spatial axes independently or combine them heuristically, failing to capture their geometric coupling in a symmetric and consistent manner. To address this, we introduce Geometric Positional Embedding (GeoPE), a framework that extends rotations to 3D Euclidean space using quaternions. To overcome the non-commutativity of quaternion multiplication and ensure symmetry, GeoPE constructs a unified rotational operator by computing the geometric mean of rotations within the corresponding Lie algebra. We also propose a linear variant that preserves the strict relative positional encoding of 1D RoPE, offering superior extrapolation. Extensive experiments on image classification, object detection, and 3D semantic segmentation demonstrate that GeoPE consistently outperforms standard baselines and existing 2D RoPE variants, while retaining the strong extrapolation properties of its 1D predecessor.",
    "key_points": [
      "positional embedding",
      "vision transformer",
      "rope"
    ],
    "gold_summary": "This paper builds on rotary positional embedding, extending rotations to 3D Euclidean space using quaternions. The authors developed a method to avoid the quaternion multiplication non-commutativity, and test the method in various benchmarks."
  },
  {
    "paper_id": "n1rsWhJf8B",
    "title": "Enhancing Cross-Lingual Embedding Alignment with Additive Keywords for International Trade Product Classification",
    "domain": "semi-supervised",
    "content": "Cross-lingual embedding alignment plays an important role in enabling effective multilingual classification tasks. Although multilingual pretrained language models and fine-tuning techniques are increasingly adopted, current approaches inadequately address specialised domains, where domain-specific terminology and mixed-language content present unique challenges that hinder classification accuracy. This work considers the problem of automatically classifying text-based descriptions of international trade transactions with respect to an international standard Harmonized System (HS) code taxonomy. We propose a novel method that incorporates mixed-language keyword embeddings to improve cross-lingual alignment, focusing on bilingual models, and subsequently leverages this alignment for downstream classification tasks, with particular applicability to low-resource domains. Using a supervised learning framework implemented through neural network architectures, the model is trained on pairs of product descriptions and their corresponding extracted keywords. Experimental results on benchmark bilingual datasets demonstrate significant and consistent improvements in classification performance over baseline models, including in low-resource target language scenarios. The findings demonstrate the effectiveness of incorporating additive keywords as a strategy for cross-lingual embedding alignment, thereby enhancing representation quality and improving classification accuracy.",
    "key_points": [
      "bilingual classification",
      "cross-lingual embedding alignment",
      "low-resource languages",
      "international trade classification",
      "harmonized system codes"
    ],
    "gold_summary": "This paper studies on using mixed-language keywords to enhance cross-lingual embedding alignment for a challenging, real-world task: bilingual HS code classification. The proposed method demonstrates consistent improvements over baselines."
  },
  {
    "paper_id": "LRqfcdqLY8",
    "title": "Quantum-Classical Knowledge Distillation via Quantum Soft Labels",
    "domain": "semi-supervised",
    "content": "Quantum machine learning offers a path to leverage near-term quantum devices for tasks that remain challenging for classical models. We introduce a quantum–classical hybrid knowledge distillation framework in which variational quantum circuits, equipped with angle and Quantum Fourier Transform-inspired encodings, serve as teachers that generate expressive soft-label distributions. These signals are distilled into lightweight classical students via a hybrid loss that blends hard and soft supervision. On MNIST and CIFAR-10, students distilled from quantum teachers achieve stronger robustness to Gaussian noise and rotations than classical baselines, while retaining high clean accuracy and calibration. Crucially, this shows that even capacity-limited NISQ models can provide valuable supervisory signals, suggesting a practical route toward quantum-enhanced learning without requiring quantum inference at deployment.",
    "key_points": [
      "quantum machine learning",
      "knowledge distillation",
      "variational quantum circuits",
      "quantum soft labels",
      "hybrid models",
      "qft-inspired encoding."
    ],
    "gold_summary": "This paper proposes a hybrid knowledge distillation (KD) framework that leverages variational quantum circuits as teachers to supervise lightweight student models through quantum-generated soft labels."
  },
  {
    "paper_id": "DtkIH5TKe6",
    "title": "Let OOD Feature Exploring Vast Predefined Classifiers",
    "domain": "semi-supervised",
    "content": "Real-world out-of-distribution (OOD) data exhibit broad, continually evolving distributions, rendering reliance solely on in-distribution (ID) data insufficient for robust detection. Consequently, methods leveraging auxiliary Outlier Exposure (OE) data have emerged, substantially enhancing generalization by jointly fine-tuning models on ID and large-scale OE data. However, many existing approaches primarily enforce orthogonality between ID and OE features while pushing OE predictions toward near-uniform, low-confidence scores, thus overlooking the controllability of representation geometry. We propose Vast Predefined Classifiers (VPC), which instantiates a pre-specified Orthogonal Equiangular Feature Space (OEFS) to explicitly separate ID and OOD representations while capturing the rich variability of OOD features. We employ evidential priors to align ID features with their class-specific Equiangular Basic Vectors (EBVs), thereby preserving ID performance. In parallel, a new VEBV loss encourages OE features to explore the subspace spanned by Vast EBVs (VEBVs), enabling a rich characterization of diverse OOD patterns. This dual optimization, coupled with the prescribed geometric representation space, guarantees optimal orthogonality between ID and OOD representations. Furthermore, we introduce the VPC Score, a discriminative metric based on the L2 activation intensity of features over the predefined classifiers. Extensive experiments across Far- and Near-OOD detection settings, as well as two-stage and one-stage training paradigms, demonstrate state-of-the-art performance, validating the effectiveness of deploying Vast Predefined Classifiers for distinguishing OOD features.",
    "key_points": [
      "out of distribution",
      "representation learning",
      "neural collapse",
      "evidential deep learning"
    ],
    "gold_summary": "The paper proposes Vast Predefined Classifiers for OE-based OOD detection by combining Neural Collapse and Evidential Deep Learning. extensive experiments demonstrate the effectiveness of Vast Predefined Classifiers."
  },
  {
    "paper_id": "T0k5OO2Keb",
    "title": "NeuMatC: A General Neural Framework For Fast \tParametric Matrix Operation",
    "domain": "semi-supervised",
    "content": "Matrix operations (e.g., inversion and singular value decomposition (SVD)) are fundamental in science and engineering. In many emerging real-world applications (such as wireless communication and signal processing), these operations must be performed repeatedly over matrices with parameters varying continuously.  However, conventional methods tackle each matrix operation independently, underexploring the inherent low-rankness  and continuity along the parameter dimension, resulting in significantly redundant computation.  To address this challenge, we propose \\textbf{\\textit{Neural Matrix Computation Framework} (NeuMatC)}, which elegantly tackles general parametric matrix operation tasks by leveraging  the underlying low-rankness and continuity along the parameter dimension. Specifically, NeuMatC unsupervisedly learns a low-rank and continuous mapping from parameters to their corresponding matrix operation results. Once trained, NeuMatC enables efficient computations at arbitrary parameters using only a few basic operations (e.g., matrix multiplications and nonlinear activations), significantly reducing redundant computations. Experimental results on both synthetic and real-world datasets demonstrate the promising performance of NeuMatC, exemplified by over $3\\times$ speedup in parametric inversion and $10\\times$ speedup in parametric SVD compared to the widely used NumPy baseline in wireless communication, while maintaining acceptable accuracy.",
    "key_points": [
      "low-rank representation;continuous representation;parameterized matrix computation;tensor factorization;machine learning"
    ],
    "gold_summary": "The authors train a MLP with a tensor head to solve matrix problems that are related in a 1 dimensional parameter space\nby minimizing a data fidelity and structure consistency loss."
  },
  {
    "paper_id": "Iq6o8A8NVA",
    "title": "Manifold-Matching Autoencoders",
    "domain": "semi-supervised",
    "content": "We propose Manifold-Matching Autoencoders (MMAEs), a simple yet effective framework that aligns autoencoder latent spaces with precomputed geometric references. This is accomplished by using distance-based regularization to match latent and reference distance matrices, enabling the same architecture to achieve different data representations by simply changing the reference embedding. We demonstrate that MMAEs achieve scalable topological control in high-dimensional settings where existing methods become computationally intractable. One key finding is that aligning with PCA yields unexpected benefits: MMAEs achieve SOTA preservation of the original data structure, comparable to sophisticated topological autoencoders, while maintaining significantly better reconstruction quality and more efficient computation. When combining with VAEs, the present regularization has the effect of concentrating variance in fewer dimensions. This balance between structure preservation, variance concentration, and reconstruction fidelity enables superior generative capabilities, including clearer interpolations and more effective discovery of semantically meaningful latent directions for attribute manipulation.",
    "key_points": [
      "manifold learning",
      "autoencoders",
      "topology preservation",
      "dimensionality reduction",
      "representation learning",
      "geometric regularization",
      "unsupervised learning"
    ],
    "gold_summary": "The paper introduces a Manifold-Matching Autoencoders (MMAEs), a framework that aligns autoencoder latent spaces with precomputed geometric references. This is accomplished by using distance-based regularization to match latent and reference distance matrices."
  },
  {
    "paper_id": "4XQVBihXUD",
    "title": "Unsupervised Parallel MRI Reconstruction via Projected Conditional Flow Matching",
    "domain": "semi-supervised",
    "content": "Reconstructing high-quality images from substantially undersampled k-space data for accelerated MRI presents a challenging ill-posed inverse problem. Supervised deep learning has transformed the field by using large amounts of fully sampled ground-truth MR images, either to directly reconstruct undersampled data into fully sampled images with neural networks, or to learn the prior distribution of fully sampled images through generative models. However, in practical scenarios, acquiring ground-truth fully sampled MRI images is not viable due to the inherently slow nature of its data acquisition process. Despite advances in self-supervised/unsupervised MRI reconstruction, the performance remains inadequate at high acceleration rates. To address these gaps, we introduce the Projected Conditional Flow Matching (PCFM) and its unsupervised transformation, which is designed to learn the prior distribution of fully sampled parallel MRI by solely utilizing the undersampled k-space measurements. To reconstruct the image, we establish a novel relationship between the marginal vector field in the measurement space, which generates the associated probability flow in terms of the continuity equation, and the optimal solution to PCFM. This connection results in a cyclic dual-space sampling algorithm for unsupervised reconstruction. Our method was evaluated against contemporary state-of-the-art supervised, self-supervised, and unsupervised baseline techniques on parallel MRI using publicly available datasets fastMRI and CMRxRecon. Experimental results show that our technique significantly surpasses existing self-supervised and unsupervised baselines, while also yielding better performance than most supervised methods. Our code will be available at \\url{https://github.com/anonymous}.",
    "key_points": [
      "unsupervised learning",
      "mri reconstruction",
      "flow matching",
      "generative models"
    ],
    "gold_summary": "The paper provides a projected CFM for parallel MRI reconstruction. The paper largely follows the single-coil derivation of Luo et al, ICML, 2025 with some modifications for multi-coil operators. The results show good performance."
  },
  {
    "paper_id": "zMAIP3FZ6g",
    "title": "Sculpting Latent Spaces With MMD: Disentanglement With Programmable Priors",
    "domain": "semi-supervised",
    "content": "Learning disentangled representations, where distinct factors of variation are captured by independent latent variables, is a central goal in machine learning. The dominant approach has been the Variational Autoencoder (VAE) framework, which uses a Kullback-Leibler (KL) divergence penalty to encourage the latent space to match a factorized Gaussian prior. In this work, however, we provide direct evidence that this KL-based regularizer is an unreliable mechanism, consistently failing to enforce the target distribution on the aggregate posterior. We validate this and quantify the resulting entanglement using our novel, unsupervised Latent Predictability Score (LPS). To address this failure, we introduce the Programmable Prior Framework, a method built on the Maximum Mean Discrepancy (MMD). Our framework allows practitioners to explicitly sculpt the latent space, achieving state-of-the-art mutual independence on complex datasets like CIFAR-10 and Tiny ImageNet without the common reconstruction trade-off. Furthermore, we demonstrate how this programmability can be used to engineer sophisticated priors that improve alignment with semantically meaningful features. Ultimately, our work provides a foundational tool for representation engineering, opening new avenues for model identifiability and causal reasoning.",
    "key_points": [
      "disentanglement",
      "non-linear independent component analysis (nica)",
      "maximum mean discrepancy (mmd)",
      "autoencoder",
      "representation learning"
    ],
    "gold_summary": "This manuscript presents a method to improve learning of disentangled latent space. The key component is using MMD instead of KL for regularization. The paper also proposes a metric LPS, latent predictability score."
  },
  {
    "paper_id": "CFP6SS9B6y",
    "title": "FISHER: A Foundation Model for Multi-Modal Industrial Signal Comprehensive Representation",
    "domain": "semi-supervised",
    "content": "Industrial signal analysis has emerged as a critical problem for the industry. Due to severe heterogeneity within industrial signals, which we summarize as the M5 problem, previous works could only deal with small sub-problems by training specialized models, which lacks robustness and incurs huge burdens during development and deployment. However, we argue that the M5 problem can be dealt by scaling up, where dealing with the multi-sampling-rate is the first step. In this paper, we propose FISHER, a Foundation model for multi-modal Industrial Signal compreHEnsiveRepresentation. To support arbitrary sampling rates, FISHER considers the increment of sampling rate as the concatenation of sub-band information. Specifically, FISHER takes the STFT sub-band as the modeling unit and adopts a teacher-student SSL framework for pre-training. To evaluate the model performance, we also develop the RMIS benchmark, which consists of 19 datasets across four modalities. FISHER is compared with 15 SOTA speech/audio/music encoders, demonstrating versatile and outstanding capabilities with a general performance gain of at least 3.23\\%. Meanwhile, FISHER possesses much more efficient scaling curves, where even FISHER-tiny with 5.5M parameters outperforms huge baseline encoders up to 2B. We further reveal that the key to success is adaptively utilizing the full signal bandwidth regardless of the sampling rate. Both FISHER and RMIS will be open-sourced.",
    "key_points": [
      "self-supervised learning",
      "foundation model",
      "anomaly detection",
      "fault diagnosis"
    ],
    "gold_summary": "The paper presents a foundation model for multi-modal signal representations including sound, vibration, voltage, current, temperature, and etc."
  },
  {
    "paper_id": "bvvBOwDQ0c",
    "title": "A Revisit of Total Correlation in Disentangled Variational Auto-Encoder with Partial Disentanglement",
    "domain": "semi-supervised",
    "content": "A fully disentangled variational auto-encoder (VAE) aims to identify disentangled latent components from observations. However, enforcing full independence between all latent components may be too strict for certain datasets. In some cases, multiple factors may be entangled together in a non-separable manner, or a single independent semantic meaning could be represented by multiple latent components within a higher-dimensional manifold. To address such scenarios with greater flexibility, we develop the Partially Disentangled VAE (PDisVAE), which generalizes the total correlation (TC) term in fully disentangled VAEs to a partial correlation (PC) term. This framework can handle group-wise independence and can naturally reduce to either the standard VAE or the fully disentangled VAE. Validation through three synthetic experiments demonstrates the correctness and practicality of PDisVAE. When applied to real-world datasets, PDisVAE discovers valuable information that is difficult to uncover with fully disentangled VAEs, implying its versatility and effectiveness.",
    "key_points": [
      "disentangled variational auto-encoder",
      "partial disentanglement",
      "group-wise independence"
    ],
    "gold_summary": "PDisVAE replaces the TC penalty with a PC term to enforce group-wise independence while allowing within-group entanglement."
  },
  {
    "paper_id": "IuZoTgsUws",
    "title": "AgentFold: Long-Horizon Web Agents with Proactive Context Folding",
    "domain": "applications to computer vision",
    "content": "LLM-based web agents show immense promise for information seeking, yet their effectiveness on long-horizon tasks is hindered by a fundamental trade-off in context management. Prevailing ReAct-based agents suffer from context saturation as they accumulate noisy, raw histories, while methods that fixedly summarize the full history at each step risk the irreversible loss of critical details. Addressing these, we introduce AgentFold, a novel agent paradigm inspired by the human cognitive process of retrospective consolidation. AgentFold treats its context as a dynamic cognitive workspace to be actively sculpted, rather than a passive log to be filled. At each step, it learns to execute a folding operation, which manages its historical trajectory at multiple scales: it can perform granular condensations to preserve vital, fine-grained details, or deep consolidations to abstract away entire multi-step sub-tasks. The results on prominent benchmarks are striking: our AgentFold-30B-A3B agent achieves 36.2% on BrowseComp and 47.3% on BrowseComp-ZH. Notably, this performance not only surpasses or matches open-source models of a dramatically larger scale, such as the GLM-4.5-355B-A32B and the DeepSeek-V3.1-671B-A37B, but also surpasses leading proprietary agents like OpenAI's o4-mini. Model will be open-sourced.",
    "key_points": [
      "web agent",
      "context management",
      "ai agent"
    ],
    "gold_summary": "This paper addresses the important long-history handling issue among agents, by proposing AgentFold, which consolidates the latest interactions into fine- and coarse-grained memory. Experiments across different benchmarks demonstrate its empirical advantages among open-source LMs."
  },
  {
    "paper_id": "Ha075JDMZR",
    "title": "MotionGPT3: Human Motion as a Second Modality",
    "domain": "applications to computer vision",
    "content": "With the rapid progress of large language models (LLMs), multimodal frameworks that unify understanding and generation have become promising, yet they face increasing complexity as the number of modalities and tasks grows. We observe that motion quantization introduces approximation errors that cap motion quality, and that unifying discrete text and continuous motion within a single-stream backbone amplifies cross-modal interference. Motivated by recent multi-branch Transformer designs that separate signals from different modalities, we propose MotionGPT3, a bimodal motion–language model for both understanding and generation. MotionGPT3 encodes raw motion into a continuous latent space using a variational autoencoder (VAE), thereby avoiding quantization-induced artifacts, while leveraging the semantic prior of pretrained language models. A dual-stream Transformer with shared attention preserves modality-specific routes while enabling controlled, bidirectional information flow, which reduces interference, stabilizing optimization, and empirically accelerates convergence without degrading fidelity. For multimodal joint training, a generate-then-align three-stage schedule further improves stability and limits cross-task interference. Experiments show that MotionGPT3  achieves 2× faster convergence in training loss and up to 4× faster convergence in validation, while maintaining state-of-the-art performance on standard motion understanding and motion generation benchmarks.",
    "key_points": [
      "3d motion",
      "text-driven motion generation",
      "text-to-motion",
      "human motion synthesis",
      "motion caption"
    ],
    "gold_summary": "This paper propose MotionGPT3, a bimodal motion-language framework to unify the motion understanding and generation. It introduces two different modality branches to endow the model with motion-to-text and text-to-motion abilities."
  },
  {
    "paper_id": "whu2doKCti",
    "title": "Binary Neural Network for Hyperspectral pansharpening",
    "domain": "applications to computer vision",
    "content": "Hyperspectral pan-sharpening aims to generate high-resolution hyperspectral (HRHS) images by fusing low-resolution hyperspectral (LRHS) data with high-resolution panchromatic (PAN) images, enabling applications in mapping, surveillance, and environmental monitoring. While deep learning methods achieve strong performance, their heavy computational and memory demands limit deployment on resource-constrained satellite platforms. To address this, we explore binary neural networks (BNNs) for hyperspectral pan-sharpening. Conventional binarization, however, introduces gradient instability and severe information loss, compromising spectral–spatial fidelity. We propose the Adaptive Tan Identity Straight-Through Estimator (ATISTE), a soft binarization strategy that decouples forward approximation from gradient propagation and employs adaptive scaling to preserve consistency with full-precision features. Building on ATISTE, we design HS-BiNet, a lightweight binary CNN with residual connections and multi-scale fusion to effectively capture spectral–spatial dependencies, while avoiding computationally intensive operations such as unfolding inference and non-local self-attention, thereby ensuring suitability for real-time deployment on edge and satellite platforms. Extensive experiments show that HS-BiNet consistently outperforms binary baselines and remains competitive with, and in some cases surpasses, full-precision models, offering a practical solution for high-fidelity HRHS reconstruction.",
    "key_points": [
      "deep learning",
      "hyperspectral pansharpening",
      "image fusion"
    ],
    "gold_summary": "This paper applies exploration of binary neural networks for hyperspectral pan-sharpening and introduces a lightweight architecture driven by the proposed Adaptive Tan Identity Straight-Through Estimator (ATISTE)."
  },
  {
    "paper_id": "imb1oWYpa8",
    "title": "When Uncertainty, Coverage, and Representation Matter in Active Learning Frameworks",
    "domain": "applications to computer vision",
    "content": "Active learning (AL) aims to reduce annotation costs by querying informative and representative samples for labeling. Despite significant progress, many AL methods remain heuristic and lack a unified theoretical foundation. We present the first systematic and theory-guided framework that connects the core principles of AL (uncertainty, representation, and coverage) to a decomposition of generalization error into empirical risk, distributional discrepancy, model complexity, and confidence. This mapping not only explains why different AL strategies excel under varying annotation budgets but also provides a blueprint for designing future methods, positioning our work as a foundation for principled AL development. Our analysis unifies prior empirical observations into a generalization-theoretic foundation, complemented by extensive experiments on CIFAR and ImageNet subsets with self-supervised embeddings and pretrained encoders. Results show that representation is critical in early rounds to address cold-start issues; coverage promotes diversity in mid-budget regimes; and uncertainty becomes most effective once decision boundaries are partially learned. We also observe that while per-sample reductions in model complexity are modest, their cumulative effect across acquisition rounds is substantial. We further assess runtime behavior, highlighting trade-offs between theoretical alignment and scalability.  Rather than proposing a new method, our contribution is a unifying and generalizable framework that explains strategies and guides principled AL design, bridging theory and practice.",
    "key_points": [
      "active learning",
      "deep learning",
      "generalization error",
      "self-supervised learning",
      "cold-start problem",
      "uncertainty",
      "scalability"
    ],
    "gold_summary": "The paper proposes a PAC learning-based theoretical framework for analyzing which active learning strategy is most effective in different sample size regimes."
  },
  {
    "paper_id": "aPnLQ6WfQQ",
    "title": "Towards Robust and Realistic Human Pose Estimation via WiFi Signals",
    "domain": "applications to computer vision",
    "content": "Robust WiFi-based human pose estimation (HPE) is a challenging task that bridges discrete and subtle WiFi signals to human skeletons. We revisit this problem and reveal two critical yet overlooked issues: 1) cross-domain gap, i.e., due to significant discrepancies in pose distributions between source and target domains; and 2) structural fidelity gap, i.e., predicted skeletal poses manifest distorted topology, usually with misplaced joints and disproportionate bone lengths. This paper fills these gaps by reformulating the task into a novel two-phase framework dubbed $\\textit{\\textbf{DT-Pose}}$: $\\underline{\\textit{\\textbf{D}}}$omain-consistent representation learning and $\\underline{\\textit{\\textbf{T}}}$opology-constrained $\\underline{\\textit{\\textbf{Pose}}}$ decoding. Concretely, we first propose a temporal consistency contrastive learning strategy with uniformity regularization, integrated into a self-supervised masked pretraining paradigm. This design facilitates robust learning of domain-consistent and motion-discriminative WiFi representations while mitigating potential mode collapse caused by signal sparsity. Beyond this, we introduce an effective hybrid decoding architecture that incorporates explicit skeletal topology constraints. By compensating for the inherent absence of spatial priors in WiFi semantic vectors, the decoder enables structured modeling of both adjacent and overarching joint relationships, producing more realistic pose predictions. Extensive experiments conducted on various benchmark datasets highlight the superior performance of our method in tackling these fundamental challenges in 2D/3D WiFi-based HPE tasks. The code is available in the supplementary materials.",
    "key_points": [
      "wifi-based hpe"
    ],
    "gold_summary": "This paper presents DT-Pose, a two-stage framework for WiFi-based human pose estimation that addresses cross-domain generalization and structural fidelity issues. It combines self-supervised domain-consistent representation learning with topology-constrained pose decoding using GCN and Transformer modules."
  },
  {
    "paper_id": "ilir6A52vh",
    "title": "Planning at Inference: MCTS Test-Time Scaling for Long Video Generation",
    "domain": "applications to computer vision",
    "content": "Generating long videos with consistent content and visual quality remains a ma-\njor challenge, as existing one-shot and chunked methods often suffer from se-\nmantic drift and compounding artifacts. We explore Test-Time Scaling (TTS)\nas a framework for long video generation, formulating the task as a sequential\ndecision-making problem. Our approach uses Monte Carlo Tree Search (MCTS)\nto evaluate multiple continuations with look-ahead rollouts and backpropagated\nrewards, and we introduce a Multi-Tree MCTS variant that improves exploration\nin continuous generation spaces. The method is modular and can be applied to ex-\nisting backbones without retraining. Experiments on Cosmos-Predict2 and other\nmodels show consistent improvements in object permanence, temporal coherence,\nand text-video alignment over Best-of-N, Greedy, and Beam search. Furthermore,\nour method produces high-quality videos exceeding 20 seconds, surpassing the\noutput of leading models like Sora and Kling by 18% and 47% respectively, all\nwhile maintaining comparable visual fidelity. Although the results are limited\nby the quality of current generators and verifiers, our study highlights both the\npromise of search-based TTS and the limitations of today’s video generation and\nevaluation models.",
    "key_points": [
      "video generation",
      "long video generation",
      "test time scaling",
      "monte carlo tree search"
    ],
    "gold_summary": "The author introduces a Multi-Tree MCTS variant that improves exploration in continuous generation spaces."
  },
  {
    "paper_id": "Q8KIhPV9sU",
    "title": "Spatial-Frequency Synergy for Remote Sensing Image Super-Resolution with Holistic Feature Enhancement",
    "domain": "applications to computer vision",
    "content": "High-resolution (HR) remote sensing images are essential for various applications of Earth observation, but hardware limitations often give rise to degraded and low-resolution (LR) acquisitions. Super-resolution (SR) has currently emerged as a popular manner to ease this issue. However, most existing SR methods fail to effectively exploit the synergism between frequency and spatial information, while also suffering from inadequate feature enhancement. In this work, we present a novel model for remote sensing image SR, termed as Spatial-Frequency Synergy Network (SFSN). Firstly, it holistically boosts hierarchical features from both the channel and spatial dimensions, through Adaptive Channel Shifting (AdaCS) and Multi-Scale Large Kernel Attention (MS-LKA), respectively. Meanwhile, a Dual-Domain Interaction Attention (DDIA) is devised to explicitly model the mutual effect between spatial and frequency domains, enabling synergic feature refinement and HR detail recovery. It also delivers a versatile solution for bridging the spatial-frequency domain gap in remote sensing SR tasks. Extensive experiments on benchmark datasets have demonstrated the superiority of our SFSN over advanced SR models quantitatively and qualitatively, while maintaining considerably low overhead.",
    "key_points": [
      "super-resolution",
      "remote sensing",
      "holistic feature enhancement",
      "dual-domain feature interaction"
    ],
    "gold_summary": "This paper proposes a lightweight model for remote-sensing image super-resolution, SFSN (Spatial–Frequency Synergy Network), which integrates spatial–frequency dual-domain interaction and full-dimensional feature enhancement (HFFE + DDIA), and achieves competitive performance."
  },
  {
    "paper_id": "0tzvmjMcXC",
    "title": "SophiaVL-R1: Reinforcing MLLMs Reasoning with Thinking Reward",
    "domain": "applications to computer vision",
    "content": "Recent advances have shown success in eliciting strong reasoning abilities in multimodal large language models (MLLMs) through rule-based reinforcement learning (RL) with outcome rewards. However, this paradigm typically lacks supervision over the thinking process leading to the final outcome. As a result, the model may learn sub-optimal reasoning strategies, which can hinder its generalization ability. In light of this, we propose SophiaVL-R1, as an attempt to add reward signals for the thinking process in this paradigm. To achieve this, we first train a thinking reward model that evaluates the quality of the entire thinking process. Given that the thinking reward may be unreliable for certain samples due to reward hacking, we propose the Trust-GRPO method, which assigns a trustworthiness weight to the thinking reward during training. This weight is computed based on the thinking reward comparison of responses leading to correct answers versus incorrect answers, helping to mitigate the impact of potentially unreliable thinking rewards. Moreover, we design an annealing training strategy that gradually reduces the thinking reward over time, allowing the model to rely more on the accurate rule-based outcome reward in later training stages. Experiments show that our SophiaVL-R1 surpasses a series of reasoning MLLMs on various benchmarks (\\textit{e.g.}, MathVisita, MMMU), demonstrating strong reasoning and generalization capabilities. Notably, our SophiaVL-R1-7B even outperforms LLaVA-OneVision-72B on most benchmarks, despite the latter having 10 $\\times$ more parameters. All code, models, and datasets will be made publicly available.",
    "key_points": [
      "multimodal large language models",
      "reinforcement learning",
      "reasoning"
    ],
    "gold_summary": "The paper proposes SophiaVL-R1 which rewards the thinking processes of multimodal large language models and performs RLVR on top of this."
  },
  {
    "paper_id": "SZvhmFntRA",
    "title": "Pixel to Gaussian: Ultra-Fast Continuous Super-Resolution with 2D Gaussian Modeling",
    "domain": "applications to computer vision",
    "content": "Arbitrary-scale super-resolution (ASSR) aims to reconstruct high-resolution (HR) images from low-resolution (LR) inputs with arbitrary upsampling factors using a single model, addressing the limitations of traditional SR methods constrained to fixed-scale factors (\\textit{e.g.}, $\\times$ 2). Recent advances leveraging implicit neural representation (INR) have achieved great progress by modeling coordinate-to-pixel mappings. However, the efficiency of these methods may suffer from repeated upsampling and decoding, while their reconstruction fidelity and quality are constrained by the intrinsic representational limitations of coordinate-based functions. To address these challenges, we propose a novel ContinuousSR framework with a Pixel-to-Gaussian paradigm, which explicitly reconstructs 2D continuous HR signals from LR images using Gaussian Splatting. This approach eliminates the need for time-consuming upsampling and decoding, enabling extremely fast ASSR. Once the Gaussian field is built in a single pass, ContinuousSR can perform arbitrary-scale rendering in just 1ms per scale. Our method introduces several key innovations. Through statistical analysis, we uncover the Deep Gaussian Prior (DGP) and propose DGP-Driven Covariance Weighting, which dynamically optimizes covariance via adaptive weighting. Additionally, we present Adaptive Position Drifting, which refines the positional distribution of the Gaussian space based on image content, further enhancing reconstruction quality. Extensive experiments on seven benchmarks demonstrate that our ContinuousSR delivers significant improvements in SR quality across all scales, with an impressive 19.5× speedup when continuously upsampling an image across forty scales.",
    "key_points": [
      "continuous super-resolution; 2dgs; fast model"
    ],
    "gold_summary": "This paper introduces a 2D Gaussian splatting based arbitrary-scale SR model. With the help of Deep Gaussian Prior and Adaptive Position Drifting, the proposed ContinuousSR achieves excellent performance and ultra-fast inference speed."
  },
  {
    "paper_id": "hu2aOpy11D",
    "title": "Generalist Scanner Meets Specialist Locator: A Synergistic Coarse-to-Fine Framework for Robust GUI Grounding",
    "domain": "applications to computer vision",
    "content": "Grounding natural language queries in graphical user interfaces (GUIs) presents a challenging task that requires models to comprehend diverse UI elements across various applications and systems, while also accurately predicting the spatial coordinates for the intended operation. To tackle this problem, we propose GMS: Generalist Scanner Meets Specialist Locator, a synergistic coarse-to-fine framework that effectively improves GUI grounding performance. GMS leverages the complementary strengths of general vision-language models (VLMs) and small, task-specific GUI grounding models by assigning them distinct roles within the framework. Specifically, the general VLM acts as a \"Scanner\" to identify potential regions of interest, while the fine-tuned grounding model serves as a \"Locator\" that outputs precise coordinates within these regions. This design is inspired by how humans perform GUI grounding, where the eyes scan the interface and the brain focuses on interpretation and localization. Our whole framework consists of five stages and incorporates hierarchical search with cross-modal communication to achieve promising prediction results. Experimental results on the ScreenSpot-Pro dataset show that while the \"Scanner\" and \"Locator\" models achieve only $2.0\\%$ and $3.7\\%$ accuracy respectively when used independently, their integration within \\textit{GMS} framework yields an overall accuracy of $35.7\\%$, representing a $10 \\times$ improvement. Additionally, GMS significantly outperforms other strong baselines under various settings, demonstrating its robustness and potential for general-purpose GUI grounding.",
    "key_points": [
      "synergistic",
      "gui grounding"
    ],
    "gold_summary": "This paper introduces GMS, a training-free multi-agent framework that emulates human-like grounding by assigning complementary roles to generalist and specialist models, achieving substantial gains without additional fine-tuning. Extensive experiments demonstrate its effectiveness."
  },
  {
    "paper_id": "xFsv2A9rkK",
    "title": "ID-PreFeR: ID-Preserving Face Restoration with Mixed Data Quality",
    "domain": "applications to computer vision",
    "content": "This paper introduces ID-PreFeR, a robust ID-preserving face restoration method that addresses the ill-posed face restoration problem by introducing personalized information. Existing methods often suffer from computationally expensive training and storage requirements while being sensitive to the quality of reference images. We present a lightweight personalized injector to enable efficient personalization without the burden of regularization data. Besides, we propose an ID-quality disentanglement training strategy to ensure robust identity learning, even when some of the reference images are of low-quality. An ID-preserving sampling strategy is further proposed to enhance the identity fidelity during inference. Experiments on both synthetic and a newly collected real-world mobile phone dataset validate the effectiveness and practicality of the proposed method.",
    "key_points": [
      "face restoration",
      "diffusion",
      "image enhancement"
    ],
    "gold_summary": "The authors propose ID-PreFeR, a framework for personalized face restoration that improves robustness by introducing three components: a personalized injector, an ID-quality disentanglement strategy, and an ID-preserving sampling strategy."
  },
  {
    "paper_id": "BPzRMRT567",
    "title": "SG-Tailor: Inter-Object Commonsense Relationship Reasoning for Scene Graph Manipulation",
    "domain": "applications to computer vision",
    "content": "Scene graphs capture complex relationships among objects and serve as powerful priors for 3D scene understanding tasks, yet their manipulation, such as adding nodes or modifying edges, remains underexplored and highly challenging. Even a single edge change can propagate conflicts across the graph due to intricate interdependencies, making the task computationally difficult. We propose $\\textbf{SG-Tailor}$, an autoregressive model for structure-aware scene graph editing that generates commonsense edges for newly added nodes and resolves conflicts arising from edge modifications to ensure globally coherent graphs. For node addition, SG-Tailor queries the target node, forms candidate pairs with existing nodes, and predicts the appropriate relationships, while for edge modification it introduces a $\\textbf{Cut-and-Stitch}$ strategy that repairs conflicts and adjusts the graph holistically. Extensive experiments demonstrate that SG-Tailor substantially outperforms prior approaches and can be seamlessly integrated as a plug-and-play module for downstream tasks such as scene generation and robotic manipulation.",
    "key_points": [
      "scene graph manipulation",
      "autoregressive modeling",
      "spatial reasoning"
    ],
    "gold_summary": "This work addresses the conflict issues that arise during the graph manipulation steps of generated scene graphs for downstream tasks."
  },
  {
    "paper_id": "dmzlAUkulz",
    "title": "AUHead: Realistic Emotional Talking Head Generation via Action Units Control",
    "domain": "applications to computer vision",
    "content": "Realistic talking-head video generation is critical for virtual avatars, film production, and interactive systems. Current methods struggle with nuanced emotional expressions due to the lack of fine-grained emotion control. To address this issue, we introduce a novel two-stage method (AUHead) to disentangle fine-grained emotion control, i.e. , Action Units (AUs), from audio and achieve controllable generation. In the first stage, we explore the AU generation abilities of large audio-language models (ALMs), by spatial-temporal AU tokenization and an \"emotion-then-AU\" chain-of-thought mechanism. It aims to disentangle AUs from raw speech, effectively capturing subtle emotional cues. In the second stage, we propose an AU-driven controllable diffusion model that synthesizes realistic talking-head videos conditioned on AU sequences. Specifically, we first map the AU sequences into the structured 2D facial representation to enhance spatial fidelity, and then model the AU-vision interaction within cross-attention modules. To achieve flexible AU-quality trade-off control, we introduce an AU disentanglement guidance strategy during inference, further refining the emotional expressiveness and identity consistency of the generated videos. Results on benchmark datasets demonstrate that our approach achieves competitive performance in emotional realism, accurate lip synchronization, and visual coherence, significantly surpassing existing techniques.\nOur implementation is available at https://anonymous.4open.science/r/AUHead-3761.",
    "key_points": [
      "talking head generation",
      "diffusion model"
    ],
    "gold_summary": "The paper proposes AUHead, a two-stage talking head generation method that leverages ALM and  facial action units to control the speaker's emotion."
  },
  {
    "paper_id": "uO2WfDYfeK",
    "title": "ChartMaster: Advancing Chart-to-Code Generation with Real-World Charts and Chart Similarity Reinforcement Learning",
    "domain": "applications to computer vision",
    "content": "The chart-to-code generation task requires MLLMs to convert chart images into executable code. This task faces two main challenges: limited data diversity and the difficulty of maintaining visual consistency between generated charts and the original ones. Existing datasets mainly rely on synthetic seed data to prompt GPT models for code generation, resulting in homogeneous samples that limit model generalization to real-world chart styles. To address this, we propose **ReChartPrompt**, leveraging real-world, human-designed charts extracted from arXiv papers as prompts. By harnessing the rich content and diverse visual styles of arXiv charts, we construct ReChartPrompt-240K, a large-scale and highly diverse dataset that better reflects realistic chart variations.\nFor the second challenge, although SFT improves code understanding by optimizing next-token prediction, it does not provide direct supervision on visual features. As a result, it often fails to guarantee that the generated charts visually match the original ones. To address this, we propose **ChartSimRL**, a GRPO-based reinforcement learning algorithm guided by a novel chart similarity reward. This reward consists of two components: *attribute similarity*, which measures the overlap of chart attributes like layout and color between the generated and original charts, and *visual similarity*, which evaluates overall visual features, including texture, using convolutional neural networks. Unlike traditional text-based rewards, our reward accounts for the multimodal nature of the chart-to-code generation task, significantly enhancing the model's ability to accurately reproduce charts.\nIntegrating ReChartPrompt and ChartSimRL, we develop the **ChartMaster** model, achieving SOTA results among 7B-parameter models and rivaling GPT-4o on various chart-to-code benchmarks.\nWe will release all code, datasets, and models to facilitate further research.",
    "key_points": [
      "chart-to-code generation; reinforcement learning"
    ],
    "gold_summary": "Introduced “ReChartPrompt-240K”, a new real-world chart-to-code dataset with higher variability.\nIntroduced ChartSimRL, a GRPO-based RL algorithm to ensure the code-generated images align with the visual and the semantic attributes of the input image."
  },
  {
    "paper_id": "lk86ohBGnp",
    "title": "Text2Lip: Progressive Lip-Synced Talking Face Generation from Text via Viseme-Guided Rendering",
    "domain": "applications to computer vision",
    "content": "Generating semantically coherent and visually accurate talking faces requires bridging the gap between linguistic meaning and facial articulation. Although audio-driven methods remain prevalent, their reliance on high-quality paired audio visual data and the inherent ambiguity in mapping acoustics to lip motion pose significant challenges in terms of scalability and robustness. To address these issues, we propose Text2Lip, a viseme-centric framework that constructs an interpretable phonetic-visual bridge by embedding textual input into structured viseme sequences. These mid-level units serve as a linguistically grounded prior for lip motion prediction. Furthermore, we design a progressive viseme-audio replacement strategy based on curriculum learning, enabling the model to gradually transition from real audio to pseudo-audio reconstructed from enhanced viseme features. This allows for robust generation in both audio-present and audio-free scenarios. Finally, a landmark-guided renderer synthesizes photorealistic facial videos with accurate lip synchronization. Extensive evaluations show that Text2Lip outperforms existing approaches in semantic fidelity, visual realism, and modality robustness, establishing a new paradigm for controllable and flexible talking face generation.",
    "key_points": [
      "lip video generation",
      "lip reading"
    ],
    "gold_summary": "This paper tackles text-driven lip-synced facial animation. They propose a method which uses a viseme-based intermediate representation, a progressive viseme-audio replacement strategy, and a landmark-guided renderer to generate realistic, synchronized talking faces directly from text."
  },
  {
    "paper_id": "tz5GRv9Vzu",
    "title": "Durian: Dual Reference Image-Guided Portrait Animation with Attribute Transfer",
    "domain": "applications to computer vision",
    "content": "We present Durian, the first method for generating portrait animation videos with cross-identity attribute transfer from one or more reference images to a target portrait. Training such models typically requires attribute pairs of the same individual, which are rarely available at scale. To address this challenge, we propose a self-reconstruction formulation that leverages ordinary portrait videos to learn attribute transfer without explicit paired data. Two frames from the same video act as a pseudo pair: one serves as an attribute reference and the other as an identity reference. To enable this self-reconstruction training, we introduce a Dual ReferenceNet that processes the two references separately and then fuses their features via spatial attention within a diffusion model. To make sure each reference functions as a specialized stream for either identity or attribute information, we apply complementary masking to the reference images.\nTogether, these two components guide the model to reconstruct the original video, naturally learning cross-identity attribute transfer.\nTo bridge the gap between self-reconstruction training and cross-identity inference, we introduce a mask expansion strategy and augmentation schemes, enabling robust transfer of attributes with varying spatial extent and misalignment. Durian achieves state-of-the-art performance on portrait animation with attribute transfer. Moreover, its dual reference design uniquely supports multi-attribute composition and smooth attribute interpolation within a single generation pass, enabling highly flexible and controllable synthesis.",
    "key_points": [
      "attribute transfer",
      "portrait animation"
    ],
    "gold_summary": "This paper presents Durian, which generates portrait animation videos with cross-identity attribute transfer from one or more reference images to a target portrait"
  },
  {
    "paper_id": "wED9O48qmH",
    "title": "KernelFusion: Zero-Shot Blind Super-Resolution via Patch Diffusion",
    "domain": "applications to computer vision",
    "content": "Traditional super-resolution (SR) methods assume an \"ideal'' downscaling SR-kernel (e.g., bicubic downscaling) between the high-resolution (HR) image and the low-resolution (LR) image. Such methods fail once the LR images are generated differently. Current blind-SR methods aim to remove this assumption, but are still fundamentally restricted to rather simplistic downscaling SR-kernels (e.g., anisotropic Gaussian kernels), and fail on more complex (out of distribution) downscaling degradations. However, using the correct SR-kernel is often more important than using a sophisticated SR algorithm. In \"KernelFusion'' we introduce a zero-shot diffusion-based method that uses an unrestricted kernel. Our method recovers the unique image-specific SR-kernel directly from the LR input image, while simultaneously recovering its corresponding HR image.  KernelFusion exploits the principle that the correct SR-kernel is the one that  maximizes patch similarity across different scales of the LR image.  We first train an image-specific patch-based diffusion model on the single LR input image, capturing its unique internal patch statistics. We then reconstruct a larger HR image with the same learned patch distribution, while simultaneously recovering the correct downscaling  SR-kernel that maintains this cross-scale relation between the HR and LR images. Empirical results demonstrate that KernelFusion handles complex downscaling degradations where existing Blind-SR methods fail, achieving robust kernel recovery and superior SR quality. By breaking free from predefined kernel assumptions and training distributions, KernelFusion establishes a new paradigm of zero-shot Blind-SR that can handle unrestricted, image-specific kernels previously thought impossible.",
    "key_points": [
      "kernel estimation",
      "super resolution"
    ],
    "gold_summary": "This paper lacks sufficient motivation and fair evaluations. The proposed method tends to resolve complex kernel, however, the simulations are carried on unfair settings. The complex kernels are not real in application."
  },
  {
    "paper_id": "WFgtMF6vk6",
    "title": "TFMAudio: High-Fidelity Long-Form Text-to-Audio via Mamba-based Flow Matching",
    "domain": "applications to computer vision",
    "content": "Recent advancements in audio generation have been dominated by transformer-based diffusion models, which face challenges in extrapolating positional encodings and exhibit quadratic complexity in self-attention, limiting their consistency and efficiency for long-form generation.\nTo address these limitations, we propose TFMAudio, a novel latent audio generation model that integrates the strengths of Flow Matching and a custom-designed TFMamba backbone.\nTFMamba employs a dual-scan mechanism: TimeMamba captures long-range causal dependencies with linear complexity, while FrequencyMamba models spectral correlations such as harmonic structures. To enhance stability, we further introduce Energy-Aware Guidance (EAG), which mitigates state drift by adaptively regularizing classifier-free guidance. Experiments demonstrate that TFMAudio achieves state-of-the-art performance on text-to-audio benchmarks and exhibits robust extrapolation to ultra-long sequences. Remarkably, our model generates 30-minute high-fidelity audio while preserving temporal consistency and semantic alignment, significantly advancing the scalability and usability of text-to-audio models.\n  Demo:https://huggingface.co/spaces/tfmaudio/TFMAudio",
    "key_points": [
      "text-to-audio",
      "flow-matching",
      "mamba",
      "ssm",
      "diffusion"
    ],
    "gold_summary": "The paper proposes TFMAudio, a latent text-to-audio generator that replaces Transformer backbones with a Time–Frequency Mamba (TFMamba) block trained with flow matching, plus an Energy-Aware Adaptive Guidance (EAG) scheme to stabilize long generations."
  },
  {
    "paper_id": "KQPoMbxInu",
    "title": "Point-Focused Attention Meets Context-Scan State Space: Robust Biological Visual Perception for Point Cloud Representation",
    "domain": "applications to computer vision",
    "content": "Synergistically capturing intricate local structures and global contextual dependencies has become a critical challenge in point cloud representation learning. To address this, we introduce PointLearner, a point cloud representation learning network that closely aligns with biological vision which employs an active, foveation-inspired processing strategy, thus enabling local geometric modeling and long-range dependency interactions simultaneously. Specifically, we first design a point-focused attention, which simulates foveal vision at the visual focus through a competitive normalized attention mechanism between local neighbors and spatially downsampled features. The spatially downsampled features are extracted by a pooling method based on learnable inducing points, which can flexibly adapt to the non-uniform distribution of point clouds as the number of inducing points is controlled and they interact directly with point clouds. Second, we propose a context-scan state space that mimics eye's saccade inference, which infers the overall semantic structure and spatial content in the scene through  a scan path guided by the Hilbert curve for the bidirectional S6. With this focus-then-context biomimetic modules, PointLearner demonstrates remarkable robustness and achieves state-of-the-art performance across multiple point cloud tasks.",
    "key_points": [
      "point cloud learning",
      "attention mechanism",
      "state space model",
      "biomimetic vision"
    ],
    "gold_summary": "This paper proposes PointLearner, a point cloud representation learning network that closely aligns with biological vision by employing an active, foveation-inspired processing strategy, thus enabling simultaneous local geometric modeling and long-range dependency interactions."
  },
  {
    "paper_id": "WWnCWCzQcS",
    "title": "UI-S1: Advancing GUI Automation via Semi-online Reinforcement Learning",
    "domain": "applications to computer vision",
    "content": "Graphical User Interface (GUI) agents have demonstrated remarkable progress in automating complex user interface interactions through reinforcement learning (RL). However, current approaches face a fundamental dilemma: offline RL enables stable training on pre-collected trajectories, but struggles with multi-step task execution for lack of trajectory-level reward signals; online RL captures these signals through environment interaction, but suffers from sparse rewards and prohibitive deployment costs. To address it, we present $\\textbf{Semi-online Reinforcement Learning}$, a novel paradigm that simulates online RL on offline trajectories. During each rollout process, we preserve the original model output within the multi-turn dialogue, where a Patch Module adaptively recovers the divergence between rollout and expert trajectories. To capture long-term training signals, Semi-online RL introduces discounted future returns into the reward computation and optimizes the policy with weighted step-level and episode-level advantages. We further introduce Semi-Online Performance ($\\textbf{SOP}$), a metric that aligns better with true online performance, serving as a practical and effective proxy for real-world evaluation. Experiments show that ours $\\textbf{UI-S1-7B}$ achieves SOTA performance among 7B models across four dynamic benchmarks, with significant gains over the base model (e.g., +12.0\\% on AndroidWorld, +23.8\\% on AITW), demonstrating significant progress in bridging the gap between offline training efficiency and online multi-turn reasoning.",
    "key_points": [
      "gui agent",
      "reinforcement learning",
      "large language model"
    ],
    "gold_summary": "The manuscript deals with reinforcement learning for GUI development. An approach called semi-online RL is introduced."
  },
  {
    "paper_id": "TUbfsCpciR",
    "title": "MoMamba: A Lightweight Music Oriented Mamba-Based Model for Music Information Retrieval Tasks",
    "domain": "applications to computer vision",
    "content": "Music Information Retrieval (MIR) tasks on raw audio have traditionally been tackled using convolutional neural networks (CNNs) and transformer-based models. While CNNs effectively capture local structures and transformers leverage attention for long-range dependencies, both architectures come with computational and scalability challenges. In this study, we introduce a novel extension of Mamba tailored to music. Our resulting method, MoMamba (Music Oriented Mamba), is a lightweight Mamba-based music classification model. We evaluate MoMamba's performance across several benchmark MIR tasks. Our results show that MoMamba consistently outperforms a number of baselines, including an existing Mamba-based method, on all of the benchmark datasets we considered. Importantly, all models were trained from scratch without any pretraining, making the performance gains especially notable since they cannot be attributed to transfer learning. Additionally, our model's performance rivals existing benchmarks from models pretrained on much larger datasets. Our work highlights the advantages of MoMamba in music analysis and retrieval such as accuracy and inference time, encouraging further research into its capabilities within the MIR domain.",
    "key_points": [
      "mir",
      "mamba",
      "state space models",
      "music",
      "genre classification",
      "global key classification",
      "emotion regression",
      "instrument classification",
      "pitch classification"
    ],
    "gold_summary": "This paper propose a Mamba-based model for music information retrieval tasks. The proposed method is evaluated on a set of typical MIR tasks, following similar research."
  },
  {
    "paper_id": "NAN0I3pNWk",
    "title": "DXFeat: Depth-Aware Features for Robust Image Matching",
    "domain": "applications to computer vision",
    "content": "This study introduces DXFeat, a novel architecture that integrates depth infor-mation as an auxiliary branch for keypoint detection, leveraging depth cues to enhance localization accuracy, which improves localization accuracy with an average 3.1% gain while preserving inference efficiency. DXFeat refines feature extraction during training while maintaining computational efficiency. The model incorporates a modified reliability loss and learnable weighting mechanisms, balancing accuracy and robustness. By optimizing network channels while preserving high-resolution inputs, DXFeat supports both sparse and semi-dense matching, making it well-suited for visual  localization and augmented reality. A depth-assisted refinement module further enhances feature representation using coarse local descriptors. Notably, the depth auxiliary branch is only needed during training, ensuring streamlined deployment. Comprehensive evaluations on MegaDepth, ScanNet, and HPatches confirm that the combination of loss-level optimization and depth-auxiliary refinement yields consistent AUC improvements, establishing DXFeat as a strong and efficient framework for real-world image matching tasks.",
    "key_points": [
      "image matching",
      "keypoint detection",
      "sparse matching",
      "semi-dense matching",
      "depth-auxiliary"
    ],
    "gold_summary": "The paper adds a depth-assisted regularization loss to XFeat, which helps in relative pose and homography estimation. The idea is quite straightforward, but more experiments would be needed to really prove its effectiveness."
  },
  {
    "paper_id": "zvdDRZJlea",
    "title": "AgentAda: Skill-Adaptive Data Analytics for Tailored Insight Discovery",
    "domain": "applications to computer vision",
    "content": "We introduce AgentAda, the first LLM-powered analytics agent that can learn and use new analytics skills to extract more specialized insights. Unlike existing methods that require users to manually decide which data analytics method to apply, AgentAda automatically identifies the skill needed from a library of analytical skills to perform the analysis. This also allows AgentAda to use skills that existing LLMs cannot perform out of the box. The library covers a range of methods, including clustering, predictive modeling, and NLP techniques like BERT, which allow AgentAda to handle complex analytics tasks based on what the user needs. AgentAda's dataset-to-insight extraction strategy consists of three key steps: a (I) question generator to generate queries relevant to user's goal and persona, a (II) hybrid Retrieval-Augmented Generation (RAG)-based skill matcher to choose the best data analytics skill from the skill library, and a (III) code generator that produces executable code based on the retrieved skill's documentation to extract key patterns. We also introduce KaggleBench, a benchmark of curated notebooks across diverse domains, to evaluate AgentAda’s performance. We conducted a human evaluation demonstrating that AgentAda provides more insightful analytics than existing tools, with 48.78% of evaluators preferring its analyses, compared to 27.67% for the unskilled agent. We also propose a novel LLM-as-a-judge approach that we show is aligned with human evaluation as a way to automate insights' quality evaluation at larger scale.",
    "key_points": [
      "large language models",
      "automated data analysis",
      "insight extraction",
      "question generation",
      "skill matching",
      "retrieval-augmented generation",
      "code generation",
      "information visualization"
    ],
    "gold_summary": "This paper introduces AgentAda, an agentic data analysis framework, as well as a data analysis benchmark (KaggleBench) and an LLM-as-a-judge scoring mechanism (SCORER)."
  },
  {
    "paper_id": "p0XNfv3cEe",
    "title": "Multi-Level CLIP Transfer for Open-Vocabulary Object Detection",
    "domain": "applications to computer vision",
    "content": "Open-vocabulary object detection (OVOD) aims to detect novel objects beyond the training categories. Recent approaches extend conventional detectors to OV detectors by combining their detector scores with zero-shot classification scores of pre-trained vision-language models such as CLIP, which is capable of identifying various visual concepts via language descriptions. However, such a simple score-level combination struggles to balance the localization and classification of novel objects: CLIP encodes global semantics for accurate classification but exhibits limited sensitivity to localization precision when scoring proposals, whereas the detector provides robust localization yet tends to misclassify novel objects as background. Instead of a trade-off, our goal is to leverage the complementary strengths of CLIP and the detector. To this end, we propose the Multi-level CLIP Transfer (MCT-Det) strategy, which effectively transfers context, alignment, and generalization knowledge from CLIP to the detector at three distinct levels. Specifically, for each region proposal: 1) At the feature-level, we refine region features by dynamically integrating CLIP’s global context via cross-attention to improve localization. 2) At the embedding-level, we integrate the region representations of CLIP and the detector into a unified embedding to couple image-text alignment with localization-awareness for reliable recognition. 3) At the score-level, we follow previous methods to exploit CLIP's zero-shot classification ability via the scores combination strategy. Building upon F-ViT, our MCT-Det achieves comprehensive improvements and outperforms state-of-the-art methods, with 52.9 AP50novel on OV-COCO and 39.8 mAPr on OV-LVIS using ViT-L/14.",
    "key_points": [
      "open-vocabulary object detection"
    ],
    "gold_summary": "This paper proposes a multi-level (feature level, embedding level, score level) knowledge transfer framework, which leverages CLIP to improve the localization and classification ability of the detector for novel classes."
  },
  {
    "paper_id": "PdreKtvy8J",
    "title": "WebPlanner: Task Planning with Autonomous Experience Exploration and Utilization for Real World Multimodal Web Agents",
    "domain": "applications to computer vision",
    "content": "Multimodal web agents can assist humans in operating unfamiliar websites and handling repetitive GUI tasks, where effective task planning is essential for decomposing complex tasks into executable actions. While small open‑source multimodal large language models (MLLMs) offer a cost‑efficient alternative to commercial models, they suffer from weak planning ability and limited generalization especially in cross‑website scenarios. To address this, we propose the task decomposition hierarchical analysis framework (TDHAF) to systematically study compositional generalization across three task granularities: low, middle and high levels. And two generalization types: in‑domain and out‑of‑domain. Our analysis reveals that mastering low‑level atomic skills does not guarantee high‑level planning competence, while high‑level task training yields stronger OOD generalization. Motivated by these findings, we introduce the planning experience exploration and utilization (PEEU) method, which enables agents to autonomously set goals, explore unfamiliar environments, and synthesize well‑aligned high‑level task trajectories from extracted experiences. In real‑world multimodal online web navigation, where agents train on one website and are evaluated on 12 unseen websites, PEEU consistently outperforms baselines across model scales (3B, 7B) and training paradigms (SFT, GRPO), reaching 14.9% accuracy, compared to 7.2% and 10.1% for the atomic and basic methods on the GRPO 7B model. These results demonstrate that constructing high‑level tasks and leveraging experiences is crucial for OOD planning abilities of small MLLMs.",
    "key_points": [
      "agent",
      "task planning"
    ],
    "gold_summary": "The paper introduces a multi-level evaluation framework to study in-domain and out-of-domain generalization, and presents Planning Experience Exploration and Utilization (PEEU), an automatic method for collecting and leveraging planning knowledge from real web interactions."
  },
  {
    "paper_id": "yI79EvEm8G",
    "title": "Adversarial Shallow Watermarking",
    "domain": "applications to computer vision",
    "content": "Recent advances in digital watermarking make use of deep neural networks for message embedding and extraction. They typically follow the \"encoder-noise layer-decoder''-based architecture. By deliberately establishing a differentiable noise layer to simulate the distortion of the watermarked signal, they jointly train the deep encoder and decoder to fit the noise layer to guarantee robustness. As a result, they are usually weak against unknown distortions that are not used in their training pipeline. In this paper, we propose a novel watermarking framework to resist unknown distortions, namely Adversarial Shallow Watermarking (ASW). ASW utilizes only a shallow decoder that is randomly parameterized and designed to be insensitive to distortions for watermarking extraction. During the watermark embedding, ASW freezes the shallow decoder and adversarially optimizes a host image until its updated version (i.e., the watermarked image) stably triggers the shallow decoder to output the watermark message. During the watermark extraction, it accurately recovers the message from the watermarked image by leveraging the insensitive nature of the shallow decoder against arbitrary distortions. Our ASW is training-free, encoder-free, and noise layer-free. Experiments indicate that the watermarked images created by ASW have strong robustness against various unknown distortions. Compared to the existing \"encoder-noise layer-decoder'' approaches, ASW achieves comparable results on known distortions and better robustness on unknown distortions. Code is available in the supplementary material.",
    "key_points": [
      "digital watermarking",
      "adverisarial perturbation"
    ],
    "gold_summary": "This paper introduces ​​Adversarial Shallow Watermarking (ASW)​​, a novel framework designed to address the limitation of existing Learning-based Deep Watermarking (LDW) methods, which exhibit poor robustness against ​​unknown distortions​​ not encountered during training."
  },
  {
    "paper_id": "jaYdn7RbRO",
    "title": "PhysToolBench: Benchmarking Physical Tool Understanding for MLLMs",
    "domain": "applications to computer vision",
    "content": "The ability to use, understand, and create tools is a hallmark of human intelligence, enabling sophisticated interaction with the physical world. For any general-purpose intelligent agent to achieve true versatility, it must also master these fundamental skills. While modern Multimodal Large Language Models (MLLMs) leverage their extensive common knowledge for high-level planning in embodied AI and in downstream Vision-Language-Action (VLA) models, the extent of their true understanding of physical tools remains unquantified. To bridge this gap, we present PhysToolBench, the first benchmark dedicated to evaluating the comprehension of physical tools by MLLMs.\nOur benchmark is structured as a Visual Question Answering (VQA) dataset comprising over 1,000 image-text pairs. It assesses capabilities across three distinct difficulty levels: 1) Tool Recognition: Requiring the recognition of a tool's primary function. 2) Tool Understanding: Testing the ability to grasp the underlying principles of a tool's operation. 3) Tool Creation: Challenging the model to fashion a new tool from surrounding objects when conventional options are unavailable. Our comprehensive evaluation of 32 MLLMs—spanning proprietary, open-source, specialized embodied, and backbones in VLAs—reveals a significant deficiency in the tool understanding. Furthermore, we provide an in-depth analysis and propose preliminary solutions. Code and dataset are publicly available at https://github.com/PhysToolBench/PhysToolBench.",
    "key_points": [
      "benchmark",
      "physical tool",
      "robotic",
      "multimodal large language model"
    ],
    "gold_summary": "The paper proposes a benchmark to evaluate the ability of VLMs and VLAs to understand physical tools."
  },
  {
    "paper_id": "SgSfmOuK6Z",
    "title": "HG-Mamba: Heuristic-Guided State Space Model for Laparoscopic Image Desmoking",
    "domain": "applications to computer vision",
    "content": "Developing smoke removal algorithms for laparoscopic surgery is crucial for enhancing surgical visibility and supporting accurate intraoperative decision-making. Recently, Mamba, a representative state space model (SSM), has shown strong potential in visual tasks by balancing global receptive fields with efficiency. However, its reliance on sequential state transitions limits spatial correlation modeling, and its feed-forward layers lack mechanisms to model frequency features—both of which hinder effective removal of complex surgical smoke. To overcome these limitations, we propose Heuristic-Guided Mamba (HG-Mamba), which extends Mamba by integrating spatial and frequency domain improvements.  HG-Mamba comprises two key components: a Heuristic-Guided State Space Model (HG-SSM), which performs input-guided dynamic sampling and flexible state fusion to enable adaptive spatial context modeling; and a Frequency Refine Feed-Forward Network (FR-FFN), which conducts multi-band frequency decomposition and adaptive weighting to enhance frequency-domain representations. By jointly leveraging spatial adaptability and frequency-aware refinement, HG-Mamba serves as an effective backbone for surgical smoke removal. Extensive experiments demonstrate that HG-Mamba outperforms state-of-the-art methods on both synthetic and real-world smoke/smokeless datasets. The code will be publicly released.",
    "key_points": [
      "laparoscopic surgery",
      "surgical smoke removal",
      "state space model",
      "deep learning"
    ],
    "gold_summary": "This method describes a mamba-based method for Laparoscopic Image Desmoking.They proposed to use deformable vmamba block and frequency-refine FFN. The proposed method shows positive results on synthethic and real datasets."
  },
  {
    "paper_id": "lh3Aa1u7kU",
    "title": "Stacked from One: Multi-Scale Self-Injection for Context Window Extension",
    "domain": "applications to computer vision",
    "content": "The limited context window of contemporary large language models (LLMs) hinders broader application. In this work, we present SharedLLM, a novel approach grounded in the design philosophy of multi-grained context compression and query-aware information retrieval. SharedLLM is composed of two short-context LLMs: a lower moel (compressor) and an upper model (decoder). The lower model compresses context information, while the upper model processes compressed, context information from the lower model and performs context-aware modeling. Information transfer between the compressor and decoder occurs only at the lowest layers to reduce redundant computation. Based on this architecture, we introduce a specialized tree-style data structure to efficiently encode, store and retrieve multi-grained contextual information from text chunks. This entire process, wherein the sender and receiver are derived from the same LLM layer, is referred to as self-injection. In our evaluation on long-context modeling and understanding tasks, SharedLLM achieves superior or comparable results to several strong baselines, striking an effective balance between efficiency and performance. Meanwhile, with the aforementioned design choices, SharedLLM can greatly reduce memory consumption, and demonstrates substantial speed-ups over other advanced baselines. The core code of our implementation along with training and evaluation is available in appendix and supplementary.",
    "key_points": [
      "long-context modeling; continual pretraining; extrapolation"
    ],
    "gold_summary": "This paper proposes a two-LLM architecture for long-context inference. One LLM compresses the context, and the other LLM operates based on compressed context, achieving 2x speedup without hurting accuracy."
  },
  {
    "paper_id": "3vmDyYC9Tn",
    "title": "Visual Prompt-Agnostic Evolution",
    "domain": "applications to computer vision",
    "content": "Visual Prompt Tuning (VPT) enables effective adaptation of a frozen Vision Transformer (ViT) to downstream tasks by inserting a small number of learnable prompt tokens into the token sequence at each layer. However, we observe that existing VPT variants often suffer from unstable training dynamics, characterized by gradient oscillations. A closer layer-wise analysis reveals that shallow-layer prompts tend to stagnate early, while deeper-layer prompts exhibit high-variance oscillations, leading to a cross-layer mismatch. These issues contribute to slower convergence and degraded final performance. To address these challenges, we propose the Prompt-Agnostic Evolution (PAE) framework, which can strengthen vision prompt tuning by explicitly modeling the dynamics of learnable prompts. patterns that the backbone inherently exploits for recognition. To ensure coherent evolution across layers, we further employ a shared Koopman operator, which imposes a global linear transformation rather than uncoordinated, layer-specific updates. Finally, inspired by Lyapunov stability theory, we introduce a regularizer that constrains error amplification during evolution, leading to improved training robustness. Extensive experiments demonstrate that using PAE with VPT variants not only accelerates convergence with an average 1.48× speedup but also yields 1–3% classification accuracy gains on two image classification benchmarks, including FGVC and VTAB-1k. Beyond performance, PAE remains prompt-agnostic and lightweight, and it integrates seamlessly with diverse VPT variants without backbone modification or inference-time changes, and thus provides a practical and scalable solution for advancing prompt tuning.",
    "key_points": [
      "computer vision",
      "visual prompt tuning"
    ],
    "gold_summary": "Visual prompt tuning enables parameter-efficient fine-tuning. However, existing VPT variants often suffer from unstable training. To address this challenge, the authors propose the Prompt-Agnostic Evolution (PAE) by explicitly modeling the dynamics of learnable prompts."
  },
  {
    "paper_id": "0qFN7Ugt4k",
    "title": "Multi-Source Knowledge-Fusion for Source-Free Domain Adaptation in Object Detection",
    "domain": "applications to computer vision",
    "content": "Source-free domain adaptation (SFDA) enables adaptation to a target domain without access to source data or labeled target samples, making it particularly valuable in privacy-sensitive applications such as military operations and healthcare. To leverage complementary and transferable knowledge from multiple source domains, multi-source-free domain adaptation (MSFDA) extends SFDA by collectively adapting pre-trained models from multiple sources. However, a key challenge in MSFDA is the significant distribution shift among multiple source and target domains, which often leads to suboptimal performance, especially in complex tasks like object detection. To address this, we propose a novel multi-source knowledge-fusion framework that effectively aggregates knowledge from multiple sources and mitigates distribution discrepancies. We first conduct text-driven feature augmentation that narrows the semantic gap by transforming unlabeled target images into source-stylized images using only textual descriptions of each source domain, such that the pre-trained source models are directly applicable. Each domain expert is then updated with its respective stylized target images, while the aggregator undergoes both local and global updates to ensure stable adaptation. To further improve pseudo-label quality, peer network-based confidence selection is performed to filter out noisy labels. Our method achieves state-of-the-art performance on multiple real-world datasets, demonstrating its effectiveness in multi-source free domain adaptation.",
    "key_points": [
      "multi-source learning",
      "domain adaptation"
    ],
    "gold_summary": "A method for multi-source-free domain adaptation, including a style translation module and a noisy label filtering module.\nThe performance achieves state-of-the-art."
  },
  {
    "paper_id": "Uhqmmpx4Rx",
    "title": "ORFLEX: Orthogonal Reparameterization with Flexibility for Multimodal Large Language Model Fine-Tuning",
    "domain": "applications to computer vision",
    "content": "Parameter-Efficient Fine-Tuning (PEFT) has emerged as a key strategy for adapting pretrained large models with minimal trainable parameters. While most methods were developed for LLMs and later extended to multimodal domains, their direct application to multimodal large language models (MLLMs) often overlooks modality-specific discrepancies. In particular, although visual tokens are aligned with language tokens in feature space, differences persist during forward propagation, which existing LoRA-based approaches fail to address.In this work, we propose ORFLEX, a reparameterized PEFT method tailored for MLLMs. First, we observe that the LoRA column spaces associated with visual and text tokens tend to be strongly orthogonal when the parameters are decoupled. Further, we leverage this property by introducing modality-specific reparameterization branches and designing a QR-inspired decomposition of the LoRA matrix into a frozen orthogonal basis $\\hat{Q}$ and a lightweight learnable matrix $\\hat{R}$. In addition, we incorporate learnable Householder transformations to adaptively rotate $\\hat{Q}$ while preserving orthogonality, enhancing expressiveness.Extensive experiments demonstrate that our approach consistently outperforms strong baselines on both general and domain-specific multimodal benchmarks, underscoring the effectiveness of modality-aware reparameterization to advance PEFT for MLLMs.",
    "key_points": [
      "mllm",
      "peft",
      "low rank adaptation"
    ],
    "gold_summary": "The paper proposes a modality-decoupled orthogonal reparameterization of LoRA that preserves inter-modality column-space orthogonality via frozen orthonormal bases, learnable coefficients, and Householder rotations, enabling robust MLLM fine-tuning at near-LoRA cost."
  },
  {
    "paper_id": "mNya9d1DA2",
    "title": "DIVA: Discrete Diffusion Vision-Language-Action Models for Parallelized Action Generation",
    "domain": "applications to computer vision",
    "content": "Vision-Language-Action (VLA) models have shown promising results in robot control, yet prevailing auto-regressive frameworks suffer from inherent limitations, such as error accumulation and temporal rigidity in action generation. To address this, we introduce a DIscrete diffusion Vision-language-Action model (DIVA), a discrete diffusion-based VLA framework that reformulates action generation as an iterative denoising process over discrete latent representations. The innovation of DIVA lies in the unified discrete diffusion architecture that systematically integrates three core designs: first, a learnable discrete action tokenization process bridges continuous action with the structural multimodal space. Second, A latent-driven policy learning strategy is proposed to align the representative space of the vision-language backbone and the policy head through a joint optimization. Third, a selective group unmasking strategy is introduced during the discrete diffusion decoding to preserve spatiotemporal coherence. Extensive evaluation demonstrates that DIVA achieves state-of-the-art performance in both simulated and real-world environments, validating its advantages in generating coherent, precise, and generalizable robot behaviors. Our work establishes a robust and scalable paradigm for future embodied decision-making systems.",
    "key_points": [
      "embodied artificial intelligence"
    ],
    "gold_summary": "This paper proposes DIVA, which use discrete diffusion to generate actions. It contains three designs, including a discrete action tokenization, a policy learning, and a selective group unmasking strategy."
  },
  {
    "paper_id": "MyKspTvxBl",
    "title": "GaussianTrim3R: Controllable 3D Gaussians Pruning for Feedforward models",
    "domain": "applications to computer vision",
    "content": "Feed-forward methods offer a promising paradigm for novel-view synthesis, eliminating computationally expensive per-scene optimization. However, current feed-forward approaches typically predict a fixed number of pixel-aligned Gaussian primitives, leading to significant redundancy. Naively pruning these Gaussians creates severe visual artifacts, necessitating fine-tuning that compromises the feed-forward nature. We introduce GaussianTrim3R, a novel framework for controllable and feed-forward 3D Gaussian representation method which gradually prunes 3D Gaussians and simultaneously adjusts the attributes of remaining Gaussians maintaining rendering quality, thus eliminating the need for finetuning 3D Gaussians post pruning. To achieve this, we construct SuperClusters by partitioning the 3D scene based on spatial and color attributes. By leveraging Discrete Wavelet Transform, we assign and rank texture complexity to these SuperClusters, enabling selective, texture-aware pruning. Doing so enables our method to directly predict attribute-adjusted Gaussians, thereby preserving scene integrity. Unlike existing methods, GaussianTrim3R offers an efficient, real-time solution with extensive experiments demonstrating superior trade-offs between quality and efficiency across diverse real world RealEstate10K, ACID and DTU datasets.",
    "key_points": [
      "gaussians",
      "feed-forward"
    ],
    "gold_summary": "This paper proposes GaussianTrim3R, a feed-forward framework for pruning 3D Gaussian Splatting (3DGS) representations under a limited Gaussian budget. The authors argue that current feed-forward models predict a fixed number of Gaussians, leading to redundancy."
  },
  {
    "paper_id": "9vMXKNSqI2",
    "title": "Towards Principled Task Grouping for Multi-Task Learning",
    "domain": "applications to computer vision",
    "content": "Multi-task learning (MTL) aims to leverage shared information among tasks to improve learning efficiency and accuracy. However, MTL often struggles to effectively manage positive and negative transfer between tasks, which can hinder performance improvements. Task grouping addresses this challenge by organizing tasks into meaningful clusters, maximizing beneficial transfer while minimizing detrimental interactions. \nThis paper introduces a principled approach to task grouping in MTL, advancing beyond existing methods by addressing key theoretical and practical limitations. Unlike prior studies, our method offers a theoretically grounded approach that does not depend on restrictive assumptions for constructing transfer gains. We also present a flexible mathematical programming formulation that accommodates a wide range of resource constraints, thereby enhancing its versatility.\nExperimental results across diverse domains, including computer vision datasets, combinatorial optimization benchmarks, and time series tasks, demonstrate the superiority of our method over extensive baselines, thereby validating its effectiveness and general applicability in MTL without sacrificing efficiency.",
    "key_points": [
      "multi-task learning",
      "task grouping"
    ],
    "gold_summary": "This paper studies task grouping by organizing tasks into coherent clusters. It provides theoretical guarantees for task affinity measures and formulates task grouping as a mathematical programming problem."
  },
  {
    "paper_id": "FSL1J2gmJV",
    "title": "MergePRAG: Orthogonal Merging of Passage-experts for Multi-hop Parametric RAG",
    "domain": "applications to computer vision",
    "content": "Large language models (LLMs) can be enhanced with external knowledge through two dominant approaches: (1) $\\textbf{retrieval-augmented generation (RAG)}$, which supplements LLMs with in-context retrieved passages, and (2) $\\textbf{parametric knowledge adaptation (PKA)}$, which directly updates model parameters with new domain knowledge. Recently, parametric RAG (PRAG) has emerged as a promising framework, extending RAG by translating retrieved passages into parameter updates, thereby mitigating inefficiency and noise sensitivity inherent to RAG. However, existing PRAG methods remain limited to single-pass retrieval, falling short of the $\\textbf{multi-hop RAG}$ setting that requires iterative retrieval and reasoning. We propose $\\textbf{MergePRAG}$($\\textit{Orthogonal Merging of Passage-experts for Multi-hop PRAG}$), a novel framework that sequentially integrates retrieved passages into LLM parameters through a continual merging mechanism, which is advanced by two key proposals: (1) $\\textbf{orthogonal merging}$ using the Gram–Schmidt process to minimize conflicts between experts, and (2) $\\textbf{critical-layer parameterization}$ to efficiently encode in-context passages. Experiments on multi-hop open-domain QA and reasoning-aware knowledge editing show that MergePRAG consistently outperforms both standard and state-of-the-art RAGs as well as existing parametric adaptation methods, achieving superior effectiveness and efficiency. \n\nAll datasets and code will be released at https://anonymous.4open.science/r/MhQA_hypernetwork-B31F.",
    "key_points": [
      "multi-hop reasoning",
      "knowledge enhancement",
      "retrieval-augmented generation",
      "hypernetwork-based expert generation"
    ],
    "gold_summary": "The paper proposes extending Parametric RAG (PRAG) to handle multi-hop question answering by decomposing questions into atomic sub-questions and recursively merging a hypernetwork with retrieved passages."
  },
  {
    "paper_id": "a4fSF5pGJq",
    "title": "AToken: A Unified Tokenizer for Vision",
    "domain": "applications to computer vision",
    "content": "We present AToken, the first unified visual tokenizer that achieves both high-fidelity reconstruction and semantic understanding across images, videos, and 3D assets. Unlike existing tokenizers that specialize in either reconstruction or understanding for single modalities, AToken encodes these diverse visual inputs in a shared 4D latent space, optimizing without separate model designs. Specifically, we introduce a pure transformer architecture with 4D rotary position embeddings to process visual inputs of arbitrary resolutions and temporal durations. To ensure stable training, we introduce an adversarial-free training objective that combines perceptual and Gram matrix losses, achieving state-of-the-art reconstruction quality. By employing a progressive training curriculum, AToken gradually expands from single images, videos, and 3D, and supports both continuous and discrete latent tokens. AToken achieves 0.21 rFID with 82.2% ImageNet accuracy for images, 3.01 rFVD with 32.6% MSRVTT retrieval for videos, and 28.19 PSNR with 90.9% classification accuracy for 3D. \nIn downstream applications, AToken enables both visual generation tasks (e.g., image generation with continuous and discrete tokens, text-to-video generation, image-to-3D synthesis) and understanding tasks (e.g., multimodal LLMs), achieving 1.44/2.23 gFID on ImageNet for continuous/discrete tokens, and 48.7% on MMMU and 64.5% on VideoMME. These results shed light on the next-generation multimodal AI systems built upon the unified visual tokenization.",
    "key_points": [
      "tokenizer",
      "omni model"
    ],
    "gold_summary": "This paper proposes AToken, a unified tokenizer that bridges visual generation and visual understanding. Experiments demonstrate that AToken achieves superior performance on ImageNet image reconstruction, ImageNet zero-shot image classification, multimodal understanding and generation tasks."
  },
  {
    "paper_id": "fZi8HxJbMO",
    "title": "InfVSR: Breaking Length Limits of Generic Video Super-Resolution",
    "domain": "applications to computer vision",
    "content": "Real-world videos often extend over thousands of frames, posing unique demands far beyond current short benchmarks. Existing video super-resolution (VSR) approaches, however, face two persistent challenges when processing long sequences: (1) Efficiency due to the heavy cost of multi-step denoising for full-length sequences; and (2) Scalability hindered by temporal decomposition that causes artifacts and discontinuities. To break these limits, we propose InfVSR, which novelly reformulate VSR as an autoregressive-one-step-diffusion paradigm. This enables streaming inference while fully leveraging pre-trained video diffusion priors. First, we adapt the pre-trained DiT into a causal structure, maintaining  both local and global coherence via rolling KV-cache and joint visual guidance. Second, we distill diffusion process into a single step efficiently, with patch-wise pixel supervision and cross-chunk distribution matching. Together, these designs enable efficient and scalable VSR for unbounded-length videos. To fill the gap in long-form video evaluation, we build a new benchmark tailored for extended sequences, and further introduce semantic-level metrics to comprehensively assess temporal consistency. Our method pushes the frontier of long-form VSR, achieves state-of-the-art quality with enhanced semantic consistency, and delivers up to 58x speed-up over existing methods such as MGLD-VSR. Code will be released soon.",
    "key_points": [
      "video super-resolution",
      "one-step diffusion",
      "auto-regression"
    ],
    "gold_summary": "The authors propose a new VSR framework, InfVSR, to handle long videos efficiently. InfVSR uses an autoregressive-one-step-diffusion (AR-OSD) paradigm for temporal modeling."
  },
  {
    "paper_id": "Bzmb5LeCKx",
    "title": "Part-level Semantic-guided Contrastive Learning for Fine-grained Visual Classification",
    "domain": "applications to computer vision",
    "content": "Fine-Grained Visual Classification (FGVC) aims to distinguish visually similar subcategories within a broad category, and poses significant challenges due to subtle inter-class differences, large intra-class variations, and data scarcity. Existing methods often struggle to effectively capture both part-level detail and spatial relational features, particularly across rigid and non-rigid object categories. To address these issues, we propose Part-level Semantic-guided Contrastive Learning (PSCL), a novel framework that integrates three key components. (1) The Part Localization Module (PLM) leverages clearCLIP to enable text-controllable region selection, achieving decoupled and semantically guided spatial feature extraction. (2) The Multi-scale Multi-part Branch Progressive Reasoning (MMBPR) module captures discriminative features across multiple parts and scales, while reducing inter-branch redundancy. (3) The Visual-Language Contrastive Learning based on Multi-grained Text Features (VLCL-MG) module introduces intermediate-granularity category concepts to improve feature alignment and inter-class separability. Extensive experiments on five publicly available FGVC datasets demonstrate the superior performance and generalization ability of PSCL, validating the effectiveness of its modular design and the synergy between vision and language. Code is available at: https://anonymous.4open.science/r/PSCL-3E1F.",
    "key_points": [
      "fine-grained classification",
      "attention",
      "location",
      "scale",
      "vision-language learning",
      "contrastive learning"
    ],
    "gold_summary": "This paper proposed Part-level Semantic-guided Contrastive Learning to capture both part-level detail and spatial relational features for FGVC task.\nAuthors combine vision–language alignment, part reasoning, and progressive confidence modeling into an unified framework."
  },
  {
    "paper_id": "NWK6hrnZ7Z",
    "title": "Stability-Aware Post-Training Cascade of Experts for Compute-Efficient Inference",
    "domain": "applications to computer vision",
    "content": "State-of-the-art models achieve high accuracy at the cost of substantial inference compute, hindering deployment on edge devices and under strict latency budgets.\nTo address this, we present a stability-aware post-training cascade-of-experts that operates over a heterogeneous pool of pre-trained models, balancing accuracy, inference cost, and decision stability.\nSpecifically, we address three questions:\nWhich base models to select—from a heterogeneous pool we retain $\\epsilon$-competitive candidates by $\\epsilon$-Pareto screening the accuracy–compute trade-off, forming the cascade’s candidate set;\nHow to optimize thresholds—we learn stage-wise accept/defer thresholds via a recursive threshold-grid search with optimal tail-set reuse, minimizing expected inference cost subject to a user-set accuracy tolerance;\nWhat final cascade and execution order to deploy—we choose them by jointly considering expected inference cost and cross-validated decision stability.\nIn experiments across text, vision, and audio, when the reference single model shows no substantial validation–test discrepancy, the framework delivers large compute reductions at a bounded accuracy drop.",
    "key_points": [
      "post-training cascade of experts",
      "compute-efficient inference",
      "threshold optimization",
      "tail-set reuse",
      "decision stability",
      "epsilon-pareto selection"
    ],
    "gold_summary": "This paper studies the problem of automatic cascade generation and proposes a novel threshold selection mechanism."
  },
  {
    "paper_id": "0h5ohpUGY4",
    "title": "Understanding Dataset Distillation via Spectral Filtering",
    "domain": "applications to computer vision",
    "content": "Dataset distillation (DD) has emerged as a promising approach to compress datasets and speed up model training. However, the underlying connections among various DD methods remain largely unexplored. In this paper, we introduce UniDD, a spectral filtering framework that unifies diverse DD objectives. UniDD interprets each DD objective as a specific filter function applied to the eigenvalues of the feature-feature correlation (FFC) matrix to extract certain frequency information of the feature-label correlation (FLC) matrix. In this way, UniDD reveals that the essence of DD fundamentally lies in matching frequency-specific features. Moreover, we characterize the roles of different filters. For example, low-pass filters, \\eg, DM and DC, capture blurred patches, while high-pass filters, \\eg, MTT and FrePo, prefer to synthesize fine-grained textures and have better diversity. However, existing methods can only learn the sole frequency information as they rely on fixed filter functions throughout distillation. To address this limitation, we further propose Curriculum Frequency Matching (CFM), which gradually adjusts the filter parameter to cover both low- and high-frequency information of the FFC and FLC matrices. Extensive experiments on small-scale datasets, such as CIFAR-10/100, and large-scale ImageNet-1K, demonstrate the superior performance of CFM over existing baselines and validate the practicality of UniDD.",
    "key_points": [
      "dataset distillation",
      "spectral filtering"
    ],
    "gold_summary": "The paper proposed the combination technique, which produce both blurring (low-pass filter) and fine-grained (high-pass filter) image for dataset distillation. Experiments across various benchmarks demonstrate its superior performance over existing baselines."
  },
  {
    "paper_id": "XDIqAGxSrE",
    "title": "Influence Guided Sampling for Domain Adaptation of Text Retrievers",
    "domain": "applications to computer vision",
    "content": "General-purpose open-domain dense retrieval systems must usually be trained with a large, eclectic mix of corpora and search tasks. How should these diverse corpora and tasks be sampled for training? Conventional approaches are to sample them uniformly, or proportional to their instance population sizes, or depend on human-level expert supervision. It is well known that the training data sampling strategy can greatly impact model performance. However, how to find the optimal strategy has not been adequately studied in the context of embedding models. We propose Inf-DDS, a novel reinforcement learning–driven sampling framework that adaptively reweighs training datasets guided by influence‑based reward signals and is much more lightweight w.r.t. to GPU consumption. Our technique iteratively refines the sampling policy, prioritizing sampling from datasets that maximize the model performance on a target development set. We evaluate the efficacy of our sampling strategy on a wide range of text retrieval tasks, demonstrating strong improvements in retrieval performance and better adaptation compared to existing gradient-based sampling methods, while also being *1.5×–4×* cheaper than them in terms of GPU compute needed. Our sampling strategy achieves a **5.03** absolute *NDCG@10* improvement while training a multilingual *bge-m3-dense* model and an absolute *NDCG@10* improvement of **0.94** while training *sentence-transformers/all-MiniLM-L6-v2*, even when starting from an expert assigned weights on a large pool of training datasets.",
    "key_points": [
      "retrieval",
      "domain adaptation",
      "dataset sampling"
    ],
    "gold_summary": "This paper proposes Inf-DDS, a dynamic data sampling method for domain-adaptive text retriever training."
  },
  {
    "paper_id": "Z6VfjNfkhw",
    "title": "CTA-Flux: Integrating Chinese Cultural Semantics into High-Quality English Text-to-Image Communities",
    "domain": "applications to computer vision",
    "content": "We proposed the Chinese Text Adapter-Flux (CTA-Flux). An adaptation method fits the Chinese text inputs to Flux, a powerful text-to-image (TTI) generative model initially trained on the English corpus. Despite the notable image generation ability conditioned on English text inputs, Flux performs poorly when processing non-English prompts, particularly due to linguistic and cultural biases inherent in predominantly English-centric training datasets. Existing approaches, such as translating non-English prompts into English or finetuning models for bilingual mappings, inadequately address culturally specific semantics, compromising image authenticity and quality. To address this issue, we introduce a novel method to bridge Chinese semantic understanding with compatibility in English-centric TTI model communities. Existing approaches relying on ControlNet-like architectures typically require a massive parameter scale and lack direct control over Chinese semantics. In comparison, CTA-flux leverages MultiModal Diffusion Transformer (MMDiT) to control the Flux backbone directly, significantly reducing the number of parameters while enhancing the model's understanding of Chinese semantics. This integration significantly improves the generation quality and cultural authenticity without extensive retraining of the entire model, thus maintaining compatibility with existing text-to-image plugins such as LoRA, IP-Adapter, and ControlNet. Empirical evaluations demonstrate that CTA-flux supports Chinese and English prompts and achieves superior image generation quality, visual realism, and faithful depiction of Chinese semantics.",
    "key_points": [
      "diffusion model",
      "text-to-image generation"
    ],
    "gold_summary": "This paper proposes CTA-Flux, which adapts an English-only text-to-image model to support both Chinese and English."
  },
  {
    "paper_id": "pXYwksqDyE",
    "title": "HyperClick: Advancing Reliable GUI Grounding via Uncertainty Calibration",
    "domain": "applications to computer vision",
    "content": "Autonomous Graphical User Interface (GUI) agents rely on accurate GUI grounding, which maps language instructions to on-screen coordinates, to execute user commands. However, current models, whether trained via supervised fine-tuning (SFT) or reinforcement fine-tuning (RFT), lack self-awareness of their capability boundaries, leading to overconfidence and unreliable predictions. We first systematically evaluate probabilistic and verbalized confidence in general and GUI-specific models, revealing a misalignment between confidence and actual accuracy, which is particularly critical in dynamic GUI automation tasks, where single errors can cause task failure. To address this, we propose HyperClick, a novel framework that enhances reliable GUI grounding through uncertainty calibration. HyperClick introduces a dual reward mechanism, combining a binary reward for correct actions with a truncated Gaussian–based spatial confidence modeling, calibrated using the Brier score. This approach jointly optimizes grounding accuracy and confidence reliability, fostering introspective self-criticism. Extensive experiments on seven challenge benchmarks show that HyperClick achieves state-of-the-art performance while providing well-calibrated confidence. By enabling explicit confidence calibration and introspective self-criticism, HyperClick reduces overconfidence and supports more reliable GUI automation.",
    "key_points": [
      "gui agent; uncertainty calibration; self-evolution;"
    ],
    "gold_summary": "The paper introduces HyperClick, a framework to address the poor confidence calibration of GUI grounding models. The authors identify that existing models are often overconfident, producing unreliable predictions that are detrimental in GUI tasks."
  },
  {
    "paper_id": "JFWMuY8OLL",
    "title": "Deepfake Detection through Color-Based Spatial-Temporal Feature Mapping with Biometric Information",
    "domain": "applications to computer vision",
    "content": "The detection of deepfakes continues to grapple with challenges arising from the rapid evolution of generative models and the intricate characteristics of real-world data. Current detection frameworks frequently exhibit overfitting to particular artifacts, which constrains their effectiveness against novel manipulation techniques. While many models demonstrate high accuracy on standardized benchmark datasets, their performance often deteriorates when confronted with authentic deepfake instances. This study investigated the integration of biometric data, explicitly addressing the limitations of deepfake generation in mirroring the subtle biometric variations present in human faces. By segmenting facial regions into mesh representations, we analyzed the correlation between RGB features and biometric signals, particularly focusing on heart rate data. This approach enabled the development of Color-Based Spatial-Temporal (CST) feature maps, which provide a more nuanced depiction of the interactions between visual attributes and biometric inputs. The goal of this study was to propose a novel feature map and evaluate its performance. We assessed the effectiveness of these biosignal feature maps in conjunction with established detection models on the FaceForensics++ and Celeb-DF datasets. The incorporation of these feature maps resulted in remarkable outcomes, achieving nearly 99\\% accuracy (ACC) and an area under the curve (AUC) nearing 1. Importantly, cross-validation demonstrated significant improvements in both ACC and AUC with the addition of these feature maps. Transitioning to a transfer learning framework, while retaining the biosignal feature maps, yielded further enhancements in performance metrics. These findings underscore the considerable value of integrating biometric information to bolster deepfake detection capabilities, often surpassing the results of prior research while remaining anchored in fundamental learning principles. The model exhibited consistent performance across diverse cross-testing scenarios, highlighting its robustness and adaptability.",
    "key_points": [
      "deepfake detection; color spatial temporal feature map"
    ],
    "gold_summary": "The paper introduces a deepfake detection approach that integrates biometric information such as heart rate signals extracted from facial color variations, into a new feature representation called CST feature map."
  },
  {
    "paper_id": "yTXuGTwBVC",
    "title": "Adaptive Projected Guidance for Controllable Instruction-Guided Image Editing",
    "domain": "applications to computer vision",
    "content": "Instruction-guided diffusion models have demonstrated strong capabilities in generating targeted image edits based on diverse textual prompts. A fundamental challenge in this setting is achieving the right balance between adhering to textual instructions and preserving the original content of the input image. InstructPix2Pix (IP2P) addresses this by applying separate classifier-free guidance (CFG) terms to the text and image conditions, each scaled independently. However, this limited parametrization restricts user control, as increasing one guidance scale often causes the corresponding condition to dominate the output, resulting in imbalanced edits. Independently, Adaptive Projected Guidance (APG) was recently introduced to mitigate inherit limitations of CFG at high guidance scales in text- and class-conditioned diffusion models, reframing CFG as a gradient ascent process with decomposed guidance directions and improved signal control. In this work, we present IP2P-APG, a plug-and-play extension of IP2P that repurposes APG to improve the balance between instruction adherence and content preservation in image editing tasks. IP2P-APG significantly expands the controllable parameter space, allowing users to have more precise control over the editing process. Moreover, by enabling the use of higher guidance scales without introducing artifacts or compromising fidelity to the original content, IP2P-APG achieves a more effective trade-off between textual alignment and content preservation. Extensive experiments across multiple generative backbones and datasets demonstrate that our method consistently produces more realistic and instruction-faithful edits, without additional training and with negligible computational overhead. Code will be released after the review process.",
    "key_points": [
      "instruction-guided image editing",
      "diffusion models"
    ],
    "gold_summary": "The paper applies Adaptive Projected Guidance (APG) to intruction-guided diffusion model (IP2P) as a plug-and-play framework. The model-agnostic framework shows improvement across benchmarks."
  },
  {
    "paper_id": "3wZ6IIwPJq",
    "title": "Prompt-Robust Vision-Language Models via Meta-Finetuning",
    "domain": "applications to computer vision",
    "content": "Vision-language models (VLMs) have demonstrated remarkable generalization across diverse tasks by leveraging large-scale image-text pretraining. However, their performance is notoriously unstable under variations in natural language prompts, posing a considerable challenge for reliable real-world deployment. To address this prompt sensitivity, we propose Promise, a meta-learning framework for prompt-Robust vision-language models via meta-finetuning, which explicitly learns to generalize across diverse prompt formulations. Our method operates in a dual-loop meta-finetuning setting: the inner loop adapts token embeddings based on a set of varied prompts, while the outer loop optimizes for generalization on unseen prompt variants. To further improve robustness, we introduce an adaptive prompt weighting mechanism that dynamically emphasizes more generalizable prompts and a token-specific learning rate module that fine-tunes individual prompt tokens based on contextual importance. We further establish that Promise’s weighted and preconditioned inner update provably (i) yields a one-step decrease of the outer empirical risk together with a contraction of across-prompt sensitivity, and (ii) tightens a data-dependent generalization bound evaluated at the post-inner initialization. Across 15 benchmarks spanning base-to-novel generalization, cross-dataset transfer, and domain shift, our approach consistently reduces prompt sensitivity and improves performance stability over existing prompt learning methods.",
    "key_points": [
      "vision-language models",
      "prompt learning",
      "meta-learning"
    ],
    "gold_summary": "This paper introduces PROMISE, a meta-learning framework designed for prompt-robust vision-language models through meta-finetuning. It achieves performance improvements via dual-loop fine-tuning and provides comprehensive experiments in both in-domain and cross-domain settings."
  },
  {
    "paper_id": "jmQKr47S77",
    "title": "MLLM-Pruner: Efficient Activation-aware Pruning for Multimodal LLMs",
    "domain": "applications to computer vision",
    "content": "Multimodal large language models (MLLMs) have demonstrated impressive performance across a wide range of vision-language tasks. However, the increasing scale of these models leads to significant challenges in deployment costs. Post-training pruning emerges as an effective compression technique to address these challenges. \nRecent pruning studies on large language models (LLMs) has shown that activation-aware pruning strategies that combine weight magnitude with the $\\ell_2$-norm of input activations can achieve superior performance. Nevertheless, directly applying these approaches to MLLMs often leads to substantial performance degradation. This is because the $\\ell_2$-norm assumes all activations contribute equally, while in MLLMs, visual and textual tokens exhibit divergent activation patterns. Moreover, textual-only calibration datasets used in LLM pruning are inadequate for capturing modality-specific dependencies, which further limits their ability to evaluate the importance of weight. In this paper, we propose MLLM-Pruner, a novel activation-aware pruning framework specifically tailored for MLLMs.    To address these issues, MLLM-Pruner introduces two key innovations: (1) we construct a representative multimodal calibration dataset comprising general-domain text, Instruction Tuning, and Visual Instruction Tuning data to comprehensively preserve language generation, instruction-following, and visual reasoning abilities for MLLMs. (2), we design a modality-sensitive importance estimation metric that leverages the Singular Value Decomposition (SVD) of attention distributions to reweight the input activations, effectively captures the activation contribution across modalities, and reduces the pruning error.\n Our MLLM-Pruner does not rely on an expensive iterative reconstruction and re-training process. Extensive experiments on LLaVA-based MLLMs across various benchmarks demonstrate that MLLM-Pruner consistently outperforms state-of-the-art pruning methods while maintaining efficient compression. Our code, model weights, and multimodal calibration dataset will be made publicly available upon publication.",
    "key_points": [
      "post-training pruning",
      "activation-aware pruning",
      "mllm"
    ],
    "gold_summary": "The proposed method, MLLM-Pruner, presents two main contributions: a hybrid calibration dataset and a modality-sensitive pruning metric."
  },
  {
    "paper_id": "Z8Hu7CJfZy",
    "title": "Time Conditioned Foreseeing: Temporal Generative Pretraining for EHR foundation models",
    "domain": "applications to computer vision",
    "content": "Electronic Health Records (EHRs) possess unique characteristics that differ significantly from natural language. However, existing models have overlooked these properties and largely relied on Natural Language Processing (NLP) approaches, resulting in suboptimal performance. To address these limitations, we propose a pretraining method designed to effectively capture the distinctive features of EHRs. First, EHRs contain both clinically critical and less informative numerical ranges. To reflect this, we introduce a Pathology-Focused Binning strategy that emphasizes values with clinical significance. Second, both absolute timestamps and relative time intervals are important in EHRs. To incorporate these temporal aspects, we propose a Dual-Calendar Rotary Positional Embedding (RoPE) that jointly encodes complementary temporal signals. Third, many medical applications require modeling long-term patient interactions. Accordingly, we extend conventional next-token prediction with a Time-Conditioned Foreseeing (TCF) objective, enabling the model to forecast long-range clinical events across multiple temporal horizons. Our approach establishes the first genuine temporal generative EHR model, advancing long-range clinical forecasting. It outperforms existing EHR foundation models on seven diverse downstream tasks and enables realistic and temporally consistent EHR generation. All code and models will be made publicly available in the final version of the manuscript.",
    "key_points": [
      "electronic health record",
      "temporal modeling",
      "generative pre-training",
      "irregularly sampled timestamps"
    ],
    "gold_summary": "This paper improves EHR foundation models by better featurizing time and numeric values and incorporating time into the pertraining objective."
  },
  {
    "paper_id": "Uh8NGna3VE",
    "title": "Background Matters: Robust 3D Human Pose Estimation via Controllable Video Generation",
    "domain": "applications to computer vision",
    "content": "Deep learning models for 3D human pose estimation (HPE) often fail to generalize across domains with varying environments, camera setups, or data distributions. We address this challenge with a controllable video synthesis framework that systematically varies poses, scenes, and viewpoints to generate diverse human motion sequences. \nUnlike conventional methods that only augment skeletal data, our approach produces RGB video sequences, from which 2D poses can be extracted for both training and inference. This integration of video modality helps bridge the gap between idealized 2D pose inputs and real-world detection noise. We explore different combinations of ideal and real-world 2D inputs during training and evaluation, showing that while ideal conditions yield the best theoretical accuracy, using real-world detections leads to significantly stronger robustness and generalization.\nExperiments across multiple benchmarks, including corrupted 2D inputs, demonstrate that models trained with our synthetic videos consistently outperform baselines. These results highlight the importance of scene diversity in 3D HPE and establish controllable video generation as an effective strategy for domain-generalized pose estimation.",
    "key_points": [
      "3d human pose estimation",
      "domain generalization",
      "video generation"
    ],
    "gold_summary": "While the paper is well written and experimentally detailed, it lacks sufficient novelty and fails to demonstrate competitive performance compared to existing methods. The absence of comparisons with strong baselines further weakens the technical contribution."
  },
  {
    "paper_id": "1ludR5XHnB",
    "title": "DisIR: Disentangled Learning of Controllable All-in-One Image Restoration under Composite Degradations",
    "domain": "applications to computer vision",
    "content": "Composite degradation scenarios, in which multiple types of degradation are mixed together, have attracted increasing interest in the development of restoration models. Although prior knowledge of degradation types exists, the challenge of precise image restoration persists, particularly when multiple degradations are intricately mixed, and selectively handling individual degradations poses considerable difficulty. To tackle this challenge, we propose DisIR, a novel disentangled framework that learns controllable representations for composite image restoration through four distinct training objectives. First, we introduce an identity embedding as a prompt, along with an identity loss that guides the model to reproduce the input without modification. Second, we design a ratio control mechanism where the identity embedding can be linearly combined with degradation-specific embeddings at controllable ratios, enabling fine-grained restoration intensity control through a dedicated ratio control loss. Third, to disentangle multiple degradations, we incorporate an intermediate loss that supervises intermediate outputs, each aimed at selectively removing only one type of degradation among multiple composite degradations. Fourth, a permutation-invariant loss is applied to enforce consistent restoration results, regardless of the order in which multiple degradations are removed. By focusing on the training pipeline, our method acts as a versatile enhancement that can be integrated into controllable architectures without requiring their structural redesign. Experimental results demonstrate that our DisIR achieves state-of-the-art performance on composite degradation benchmarks while enabling flexible and selective removal of multiple degradations, either sequentially or in a single step, through a fused embedding with user-controlled intensity ratios.",
    "key_points": [
      "image restoration",
      "all-in-one"
    ],
    "gold_summary": "The paper introduces DisIR, a new training framework that turns an existing all-in-one restoration network into a controllable system for composite degradations."
  },
  {
    "paper_id": "Q3t0QBVFSG",
    "title": "Not Just a Flash in Time: Interpreting Long Event Streams through Language",
    "domain": "applications to computer vision",
    "content": "Event cameras operate asynchronously with microsecond-level temporal precision and generate sparse event streams, enabling low-latency visual perception under high dynamic range conditions. However, current multimodal large language models (MLLMs) remain suboptimal when handling such data: they either fail to effectively interpret event streams or are limited to very short temporal sequences. To address this problem, we propose a unified approach for long event-stream–text understanding. This method employs an adaptive compression mechanism that significantly reduces input volume while preserving key motion and structural cues, thereby supporting long-term cross-modal reasoning. The training pipeline adopts a two-stage optimization process: the model is first guided to develop representational capacity for streaming data, followed by cross-modal alignment to enhance semantic consistency between event and textual modalities. To handle the substantial temporal information inherent in long event streams, the model uses text-guided cross-modal queries to select salient features and combines hierarchical clustering with similarity scoring to extract representative event segments. During training, a large-scale event–text aligned dataset is curated and constructed, facilitating more effective embedding of event features within the semantic space of language models. In addition, we establish a comprehensive benchmark covering a diverse set of tasks including reasoning, captioning, classification, temporal localization, and moment retrieval. Experimental results demonstrate that the proposed approach outperforms existing state-of-the-art MLLMs in both descriptive accuracy and semantic understanding on long-duration event streams. All datasets, code, and models will be released publicly.",
    "key_points": [
      "event",
      "multimodal learning",
      "long sequence",
      "language and vision"
    ],
    "gold_summary": "The authors introduce LET-US, a framework designed for understanding long event streams, which achieves the comprehension of event streams with up to 10⁹ timestamps, and construct EVQA-1M and EVQA-Bench for training and evaluation."
  },
  {
    "paper_id": "MCnbUQsSmo",
    "title": "CLQ: Cross-Layer Guided Orthogonal-based Quantization for Diffusion Transformers",
    "domain": "applications to computer vision",
    "content": "Visual generation quality has been greatly promoted with the rapid advances in diffusion transformers (DiTs), which is attributed to the scaling of model size and complexity. However, these attributions also hinder the practical deployment of DiTs on edge devices, limiting their development and application. Serve as an efficient model compression technique, model post-training quantization (PTQ) can reduce the memory consumption and speed up the inference, with inevitable performance degradation. To alleviate the degradation, we propose CLQ, a cross-layer guided orthogonal-based quantization method for DiTs. To be specific, CLQ consists of three key designs. First, we observe that the calibration data used by most of the PTQ methods can not honestly represent the distribution of the activations.  Therefore, we propose cross-block calibration (CBC) to obtain accurate calibration data, with which the quantization can be better guided. Second, we propose orthogonal-based smoothing (OBS), which quantifies the outlier score of each channel and leverages block Hadamard matrix to smooth the outliers with negligible overhead. Third, we propose cross-layer parameter searching (CLPS) to search. We evaluate CLQ with both image generation and video generation models and successfully compress the model into W4A4 with negligible degradation in visual quality and metrics. CLQ achieves 3.98x memory saving and 3.95x speedup with real-world deployment testing. Our code will be released soon.",
    "key_points": [
      "quantization",
      "diffusion transformer"
    ],
    "gold_summary": "This paper proposes a cross-layer guided orthogonal-based quantization method for DiTs. The approach focuses on optimizing calibration data, rotation matrices, and cross-layer parameter search to improve W4A4 quantization performance."
  },
  {
    "paper_id": "wIYWEYLztY",
    "title": "Prior-based 4D Human-Scene Reconstruction from Monocular Videos",
    "domain": "applications to computer vision",
    "content": "Accurately capturing dynamic humans as they interact with their 3D environment from a single camera is a pivotal goal for applications spanning from assistive robotics to AR. However, current monocular approaches fall short, as they are typically restricted to reconstructing either the person or the static background in isolation. Methods that capture both often rely on cumbersome multi-view setups, limiting their real-world applicability. To this end, we propose a novel framework that reconstructs the complete 4D human-scene representation from monocular video. We formulate the task as an ill-posed inverse problem and introduce a robust regularization strategy that leverages two complementary priors: a static 3D Gaussian Splatting representation of the scene, and an animatable, SMPL-based 3D Gaussian avatar of the human. Our method jointly optimizes the camera pose, human motion, and the parameters of both priors to faithfully reconstruct time-varying geometry, appearance, and physically plausible human-scene interactions. We validate our approach on a self-collected dataset featuring synchronized human acting videos, human and scene scan videos. Our results demonstrate state-of-the-art performance, achieving average 23 dB PSNR on challenging novel views and surpassing existing monocular baselines.",
    "key_points": [
      "gaussian splatting",
      "4d human-scene reconstruction",
      "avatar reconstruction",
      "novel-view synthesis"
    ],
    "gold_summary": "This paper proposes a 4D human-scene reconstruction method that integrates a 3DGS scene prior and a SMPL-based Gaussian avatar prior, and jointly optimizes these priors, achieving realistic rendering results"
  },
  {
    "paper_id": "YQ5wH5C69t",
    "title": "Dimple: Discrete Diffusion Multimodal Large Language Model with Parallel Decoding",
    "domain": "applications to computer vision",
    "content": "In this work, we present Dimple and Dimple+, two Discrete Diffusion Multimodal Large Language Models (dMLLMs). Dimple is initialized from a discrete diffusion Large Language Model (dLLM) without multimodal understanding ability, and learns such ability through a hybrid training paradigm that first applies autoregressive training and then switches to discrete diffusion training. Dimple+ is initialized from an autoregressive Multimodal Large Language Models, and acquires parallel decoding capability through pure discrete diffusion training. Both models achieve performance comparable to their autoregressive baselines, and Dimple+ establishes new state-of-the-art results among dMLLMs. To enhance inference efficiency, we propose Confident Decoding, which dynamically adjusts the number of tokens generated per iteration. Experiments show that it accelerates decoding by 2×–6× with only minor performance degradation. We also demonstrate that the Prefilling technique, previously used in autoregressive models, can be effectively applied to dMLLMs with bidirectional attention, achieving nearly lossless speedups of 1.7×–7×. Finally, we introduce the Structure Prior method, enabling fine-grained control over response format and reasoning structure, which is difficult to realize in autoregressive models.",
    "key_points": [
      "diffusion large multimodal model"
    ],
    "gold_summary": "This paper explore the discrete diffusion for MLLMs, and present two diffusion MLLMs, termed Dimple and Dimple+. Besides, the authors also explore the parallel decoding to accelerate the inference of MLLMs."
  },
  {
    "paper_id": "a8oVqmtQDW",
    "title": "DynamicTree: Interactive Real Tree Animation via Sparse Voxel Spectrum",
    "domain": "applications to computer vision",
    "content": "Generating dynamic and interactive 3D objects, such as trees, has wide applications in virtual reality, games, and world simulation. \nNevertheless, existing methods still face various challenges in generating realistic 4D motion for complex real trees. In this paper, we propose DynamicTree, the first framework that can generate long-term, interactive animation of 3D Gaussian Splatting trees. Unlike prior optimization-based methods, our approach generates dynamics in a fast feed-forward manner. The key success of our approach is the use of a compact sparse voxel spectrum to represent the tree movement. Given a 3D tree from Gaussian Splatting reconstruction, our pipeline first generates mesh motion using the sparse voxel spectrum and then binds Gaussians to deform the mesh. Additionally, the proposed sparse voxel spectrum can also serve as a basis for fast modal analysis under external forces, allowing real-time interactive responses. To train our model, we also introduce 4DTree, the first large-scale synthetic 4D tree dataset containing 8,786 animated tree meshes with semantic labels and 100-frame motion sequences. Extensive experiments demonstrate that our method achieves realistic and responsive tree animations, significantly outperforming existing approaches in both visual quality and computational efficiency.",
    "key_points": [
      "gaussian splatting",
      "tree animation",
      "motion generation",
      "interactive simulation"
    ],
    "gold_summary": "This paper introduces DynamicTree, a novel framework that generates realistic long-term animations and enables real-time interactions for 3D Gaussian Splatting trees through an efficient sparse voxel spectrum representation."
  },
  {
    "paper_id": "IsIYBWFBii",
    "title": "MV-Diffus3R: Refining Multi-View Diffusions for Geometric Coherence 3D Reconstruction",
    "domain": "applications to computer vision",
    "content": "Recent breakthrough text-to-image models like GPT have achieved unprecedented photorealistic quality that rivals professional photography, yet our experimental analysis reveals critical geometric inconsistencies when leveraging these powerful models for multi-view generation. These inconsistencies manifest as specific rotational errors-such as facial expressions changing between views (open mouth becoming closed) or object details disappearing during rotation (remote control buttons missing in side views)-alongside systematic texture loss that fundamentally compromises downstream 3D reconstruction quality. While existing methods attempt to address multi-view consistency through end-to-end generation with geometric constraints, they face an inherent trade-off between visual fidelity and geometric coherence, often producing over-smoothed results that sacrifice the exceptional detail quality achievable by models like GPT. To harness the full potential of these powerful 2D foundation models while resolving their geometric limitations, we introduce a novel two-stage pipeline that strategically decouples view generation from geometric refinement. Our core contribution is MV-Diffus3R, a specialized plug-and-play refinement module that takes high-quality but geometrically inconsistent multi-view images from GPT and produces geometrically coherent outputs suitable for high-quality 3D reconstruction. MV-Diffus3R employs Plucker ray embeddings for precise geometric conditioning and a dual-pathway attention mechanism that simultaneously preserves fine visual details while enforcing cross-view geometric correspondence. Through comprehensive evaluation on GPT-generated multi-view sets, we demonstrate superior geometric fidelity compared to existing text-to-3D and multi-view generation methods, achieving 33% FID improvements while maintaining the exceptional visual quality that makes GPT outputs distinctive. Our approach provides an effective solution for bridging powerful but geometrically inconsistent 2D generators with the stringent geometric requirements of 3D content creation.",
    "key_points": [
      "3d consistency",
      "diffusion",
      "reconstruction"
    ],
    "gold_summary": "This paper proposes a post processing method to process some GPT generated multi-view images to better and geometry aligned images. The network structure is based on instructp2p."
  },
  {
    "paper_id": "kLzpTy4mVl",
    "title": "Dynamic Semantic Routing for Multimodal Sentiment Analysis",
    "domain": "applications to computer vision",
    "content": "Multimodal sentiment analysis (MSA) aims to understand human emotions by integrating heterogeneous signals such as language, vision, and acoustic modalities. However, multimodal data often suffer from internal semantic entanglement, ambiguous cues, and inconsistent modality contributions, which limit the effectiveness of unified representations. To address these challenges, we propose a Dynamic Semantic Routing Framework (DSRF) for the MSA task. Specifically, we present a hierarchical semantic factorization module, which disentangles each modality into four functionally independent representations: primary emotion, contextual cue, ambiguity, and noise, enabling fine-grained semantic modeling. Moreover, we introduce a semantic dynamic routing interaction mechanism, which dynamically routes and aggregates the semantic factors through a capsule-inspired interaction process to reconstruct modality representations with high-order compositionality. Finally, we design an uncertainty-aware semantic fusion strategy that estimates the reliability of each semantic factor and adaptively integrates them across modalities for robust sentiment prediction under modality inconsistency. Extensive experiments on four benchmark datasets demonstrate that our framework achieves state-of-the-art performance.",
    "key_points": [
      "multimodal sentiment analysis",
      "representation learning",
      "semantic factorization"
    ],
    "gold_summary": "The paper proposes a Dynamic Semantic Routing Framework (DSRF) for the MSA task.Framework incorporates three dedicated modules to tackle the semantic complexity, reconstruction, and inconsistency issues in multimodal emotion modeling."
  },
  {
    "paper_id": "Z1hBkIebqc",
    "title": "INFER: Implicit Neural Features for Exposing Realism",
    "domain": "applications to computer vision",
    "content": "Deepfakes pose a significant threat to the authenticity of digital media, with current detection methods often falling short in generalizing to unseen manipulations. INFER is the first deepfake detection framework that leverages Implicit Neural Representations (INRs), marking a new direction in representation learning for forensic analysis. We combine high-level semantic priors from Contrastive Language–Image Pre-training (CLIP) with spatially detailed, frequency-sensitive features from INR-derived heatmaps. While CLIP captures global context grounded in natural image statistics, INR heatmaps expose subtle structural inconsistencies often overlooked by conventional detectors. Crucially, their fusion transforms the feature space in a way that enhances class separability—effectively re-encoding both spatial artifacts and semantic inconsistencies into a more discriminative representation. This complementary integration leads to more robust detection, especially under challenging distribution shifts and unseen forgery types. Extensive experiments on standard deepfake benchmarks demonstrate that our method outperforms existing approaches by a clear margin, highlighting its strong generalization, robustness, and practical utility.",
    "key_points": [
      "implicit neural representations",
      "deep fake detection",
      "classification"
    ],
    "gold_summary": "The authors propose to use a CLIP encoder together with feature maps of an implicit neural network for the detection of GAN-generated images."
  },
  {
    "paper_id": "vRSTsFsl0k",
    "title": "The Role of Active Learning in Modern Deep Learning",
    "domain": "applications to computer vision",
    "content": "Even though Active Learning (AL) is widely studied, it is rarely applied in contexts outside its\nown scientific literature. \nWe posit that the reason for this is AL's high computational cost coupled with the comparatively small lifts \nit is typically able to generate in scenarios with few labeled points.\nIn this work we study the practical setup of exhausting a fixed budget to label points from a large unlabeled\npool and designing a training pipeline to train the strongest possible model on this small labeled set. \nWe compare the impact of different methods to combat this low data scenario, namely data augmentation (DA), \nsemi-supervised learning (SSL) as options for the training pipeline and AL as selection strategy for the labeled points.\nWe find that AL is by far the least efficient method of solving the low data problem, generating a lift of only 1-4% \nover random sampling, while DA and SSL methods can generate up to 60% lift in combination with random sampling.\nHowever, when AL is combined with strong DA and SSL techniques, it surprisingly is still able to provide improvements.\nBased on these results, we frame AL not as a method to combat missing labels, but as the final building block to \nsqueeze the last bits of performance out of data after appropriate DA and SSL methods as been applied.",
    "key_points": [
      "deep learning",
      "semi-supervised learning",
      "active learning",
      "data augmentation"
    ],
    "gold_summary": "This paper investigates the combination of Active Learning with Data Augmentation and Semi-Supervise Learning in classification tasks (CIFAR10, CIFAR100 and Small LSUN)."
  },
  {
    "paper_id": "NuYcnDYQuQ",
    "title": "Evil in the Pairing Assumption: Multimodal Attribution via Adaptive Information Bottleneck",
    "domain": "applications to computer vision",
    "content": "Multimodal attribution methods such as M2IB aim to interpret vision-language models without requiring task-specific labels, but they often rely on the assumption of accurate semantic alignment between image-text pairs. This assumption does not hold in open-world settings, where noisy or mismatched inputs are common. Under such conditions, existing attribution methods tend to overfit and generate forced explanations, compromising the reliability and trustworthiness of interpretability results. To address this issue, we observe that a well-balanced trade-off between the compression and prediction terms in the information bottleneck objective can mitigate overfitting. Based on this insight, we propose an attribution framework that leverages an adaptive information bottleneck optimization objective. Our method dynamically adjusts the bottleneck constraints without assuming reliable cross-modal alignment. Extensive experiments on large-scale image-text datasets demonstrate that our approach consistently outperforms existing attribution methods in both quantitative metrics and qualitative interpretability, providing more robust and trustworthy explanations while relaxing the requirement for aligned image-text pairs.",
    "key_points": [
      "interpretability",
      "information bottleneck",
      "multi-modal learning"
    ],
    "gold_summary": "This paper identifies the implicit reliance on the pairing assumption of existing multimodal attribution methods. It extends Multimodal Information Bottleneck (M2IB) by dynamically controlling the tradeoff between compression and fitting."
  },
  {
    "paper_id": "OqqgbtAe2T",
    "title": "Efficient Visual Grounding via Alignment Priors and Scale Adaptability",
    "domain": "applications to computer vision",
    "content": "Visual Grounding links textual descriptions to the corresponding image regions, and its complexity increases with target semantic complexity. Existing methods encounter performance bottlenecks due to semantic alignment bias and scale-induced perception mismatch. In this paper, we propose ASVG, an efficient framework that exploits alignment priors from the cross-modal encoder to build target-aware queries and enhances scale adaptability through progressive cross-scale reasoning. First, we design an alignment prior-guided query generator, which embeds text-conditioned visual heatmaps into object queries to enhance their semantic discriminability. Second, we develop a progressive cross-scale decoder that builds a multi-resolution pyramid solely from single-scale features, enabling progressive cross-scale reasoning while avoiding redundant feature-pyramid fusion. In addition, we introduce a lightweight token branch and Soft Cross-head Distillation (SCD), which enforces feature consistency and adaptively reweights losses, reducing inference cost while maintaining high performance. Our method achieves significant performance gains across six VG and GREC datasets, particularly under complex or ambiguous target semantics.",
    "key_points": [
      "visual grounding",
      "cross-modal alignment priors",
      "target-aware query generation",
      "scale adaptability"
    ],
    "gold_summary": "See Questions."
  },
  {
    "paper_id": "TsdlOjcQNu",
    "title": "UALM: Unified Audio Language Model for Understanding, Generation and Reasoning",
    "domain": "applications to computer vision",
    "content": "Recent advances in the audio language modeling (ALM) domain tackle audio understanding and text-to-audio generation as separate tasks. Very few studies attempt to unify these tasks -- an essential step toward advanced multimodal reasoning. This paper introduces Unified Audio Language Model (UALM), which aims to unify audio understanding, text-to-audio generation, and multimodal reasoning in a single model. To achieve this goal, we first present UALM-Gen, a text-to-audio language model that directly predicts audio tokens and is comparable to state-of-the-art diffusion-based models. We then demonstrate, using proper data blending, training recipes, and inference techniques, that our single UALM model matches the quality of state-of-the-art specialized models in audio understanding, text-to-audio generation, and text reasoning.  Furthermore, we present UALM-R1, a multimodal reasoning model that utilizes both text and audio in the intermediate thinking steps to facilitate complex generation tasks. To our knowledge, this is the first demonstration in audio research of cross-modal generative reasoning, with its effectiveness confirmed by subjective evaluations.",
    "key_points": [
      "audio language model",
      "audio understanding",
      "audio generation"
    ],
    "gold_summary": "This paper presents UALM, a unified audio-language model designed for understanding, generation, and reasoning. The authors further introduce UALM-R1, which demonstrates enhanced reasoning capabilities. Overall, the paper is clearly written and easy to follow."
  },
  {
    "paper_id": "TVZUs605BB",
    "title": "Efficient Quad Bayer Demosaicing with Look-Up Tables",
    "domain": "applications to computer vision",
    "content": "This paper presents a novel look-up table-based demosaicing method for quad Bayer pattern. Recent deep learning approaches, though effective, are computationally expensive and unsuitable for efficient implementation. We first introduces a residual LUT to reduce memory and computational complexity. The method employs a two-stage demosaicing process: the first stage performs primary demosaicing, while the second stage enhances high-frequency components. Each stage consists of a number of residual LUTs and they are stacked both in serial and parallel to effectively enlarge the receptive field size. In experiments, our method achieves stable performance and improved image quality with efficiency. In addition, the size and the computational complexity of our method enable efficient hardware implementation.",
    "key_points": [
      "quad bayer",
      "demosaicing",
      "real-time",
      "efficient",
      "isp"
    ],
    "gold_summary": "The paper introduces a two-stage residual Look-Up Table (LUT)-based framework for quad Bayer demosaicing. It aims for a hardware-efficient, low-latency solution suitable for resource-constrained devices like smartphone ISPs, featuring a compact model size of 73kB."
  },
  {
    "paper_id": "RxsImkHOYj",
    "title": "DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation",
    "domain": "applications to computer vision",
    "content": "Contact languages like English exhibit rich regional variations in the form of dialects, which are often used by dialect speakers interacting with generative models. However, can multimodal generative models effectively produce content given dialectal textual input? In this work, we study this question by constructing a new large-scale benchmark spanning six common English dialects. We work with dialect speakers to collect and verify over 4200 unique prompts and evaluate on 17 image and video generative models. Our automatic and human evaluation results show that current state-of-the-art multimodal generative models exhibit 32.26% to 48.17% performance degradation when a single dialect word is used in the prompt. Common mitigation methods such as fine-tuning and prompt rewriting can only improve dialect performance by small margins (< 7%), while potentially incurring significant performance degradation in Standard American English (SAE). To this end, we design a general encoder-based mitigation strategy for multimodal generative models. Our method teaches the model to recognize new dialect features while preserving SAE performance. Experiments on models such as Stable Diffusion 1.5 show that our method is able to simultaneously raise performance on five dialects to be on par with SAE (+34.4%), while incurring near zero cost to SAE performance.",
    "key_points": [
      "multimodality",
      "dialect",
      "text-to-image",
      "text-to-video",
      "robustness"
    ],
    "gold_summary": "The authors introduce DialectGen, a benchmark for evaluating dialect robustness in multimodal generation across six english dialects."
  },
  {
    "paper_id": "41JeFWdVFa",
    "title": "LDP: A Lightweight Denoising Plugin Enhancing Generalization in Single-Image Super-Resolution",
    "domain": "applications to computer vision",
    "content": "Current single-image super-resolution (SISR) models struggle to generalize to real-world degradations. To address this challenge, we propose LDP, an innovative lightweight denoising autoencoder~(DAE) plug-in. It improves the generalization ability of SR models via low-resolution (LR) images prediction-based cyclic regularization. LDP models the SISR degradation process within the DAE framework. It leverages a property of diffusion models, where after noise is added, high-resolution (HR) images and LR features become aligned, so that denoising noisy HR features is equivalent to denoising noisy LR features. During the corruption process, noise is added independently to each HR patch. During the denoising process, a convolutional denoiser uses learned filters to approximate blur kernels. \nIn addition, LR degradation is used to distinguish different LR from the same HR. LDP can be applied to SR models in two modes: as a training loss to improve reconstruction quality, or as an inference post-processing step to correct artifacts. Extensive experiments demonstrate that LDP substantially improves the generalization of existing SR models to unseen degradations.",
    "key_points": [
      "low-level vision",
      "single image super-resolution",
      "degradation model"
    ],
    "gold_summary": "This paper proposed a general HR to LR lightweight network, which can regularize the training and act as an auxiliary task for test-time adaptation."
  },
  {
    "paper_id": "MFuM9KAEYc",
    "title": "What Matters for Bioacoustic Encoding",
    "domain": "applications to computer vision",
    "content": "Bioacoustics, the study of sounds produced by living organisms, plays a vital role in conservation, biodiversity monitoring, and behavioral studies. Many tasks in this field, such as species, individual, and behavior classification and detection, are well-suited to machine learning. However, they often suffer from limited annotated data, highlighting the need for a general-purpose bioacoustic encoder capable of extracting useful representations for diverse downstream tasks. Such encoders have been proposed before, but are often limited in scope due to a focus on a narrow range of species (typically birds), and a reliance on a single model architecture or training paradigm. Moreover, they are usually evaluated on a small set of tasks and datasets. In this work, we present a large-scale empirical study that covers aspects of bioacoustics that are relevant to research but have previously been scarcely considered: training data diversity and scale, model architectures and training recipes, and the breadth of evaluation tasks and datasets. We obtain encoders that are state-of-the-art on the existing and newly proposed benchmarks.\nWe also identify *what matters* for training these encoders, such that this work can be extended when more data are available or better architectures are proposed. Specifically, across 26 datasets with tasks including species classification, detection, individual ID, and vocal repertoire discovery, we find that self-supervised pre-training followed by supervised post-training on a mixed bioacoustics + general-audio corpus yields the strongest in- and out-of-distribution performance. We show the importance of data diversity in both stages. To support ongoing research and application, we will release the model checkpoints.",
    "key_points": [
      "bioacoustics",
      "evaluation",
      "benchmarks",
      "audio",
      "sound",
      "classification",
      "detection",
      "clustering"
    ],
    "gold_summary": "The paper is an empirical study of bioacoustic encoder. The paper explores several benchmarks and training configurations."
  },
  {
    "paper_id": "1cypyDBSAl",
    "title": "Emotion-o1: Adaptive Long Reasoning for Emotion Understanding in LLMs",
    "domain": "applications to computer vision",
    "content": "Long chain-of-thought (CoT) reasoning has shown great promise in enhancing the emotion understanding performance of large language models (LLMs). However, current fixed-length CoT methods struggle to balance reasoning depth and efficiency. Simple tasks (e.g., sentiment classification) are over-reasoned, while complex tasks (e.g., sarcasm understanding) lack depth. To fill this gap, we present Emotion-o1, an adaptive CoT framework that dynamically adjusts reasoning length based on task complexity. Emotion-o1 is trained by distilling adaptive CoT patterns from a large reasoning model (LRM), followed by supervised fine-tuning and reinforcement learning with a four-part reward targeting accuracy, brevity, structure, and redundancy. Experimental results on four emotion tasks highlight: (1) Emotion-o1 demonstrates significant improvements over its backbone, with F1 score increases of 11\\%↑(Sentiment), 14\\%↑(Emotion), 18\\%↑(Humor), and 27\\%↑(Sarcasm). (2) In sentiment and emotion tasks, our 8B model demonstrates superior performance against SoTA LLMs, outperforming Grok‑3 by 2.1\\% in sentiment and within 1\\% of OpenAI‑o1 in emotion. (3) The framework maintains accuracy while reducing reasoning length by 83\\% compared to OpenAI-o1, demonstrating effective precision-efficiency optimization. From a lower-cost perspective, the framework also empowers SLMs to achieve reasoning capabilities comparable to larger ones.",
    "key_points": [
      "large language model",
      "affective computing",
      "long chain-of-thought",
      "adaptive length"
    ],
    "gold_summary": "This paper proposes Emotion-o1, a training framework involving distillation and RL that trains an 8B LLM to vary its chain-of-thought length by task difficulty for emotion understanding tasks."
  },
  {
    "paper_id": "9HeKCYl1zl",
    "title": "Auto-Regressive Surface Cutting",
    "domain": "applications to computer vision",
    "content": "Surface cutting is a fundamental task in computer graphics, with applications in UV parameterization, texture mapping, and mesh decomposition. However, existing methods often produce technically valid but overly fragmented atlases that lack semantic coherence. We introduce SeamGPT, an auto-regressive model that generates cutting seams by mimicking professional workflows. Our key technical innovation lies in formulating surface cutting as a next token prediction task: sample point clouds on mesh vertices and edges, encode them as shape conditions, and employ a GPT-style transformer to sequentially predict seam segments with quantized 3D coordinates. Our approach achieves exceptional performance on UV unwrapping benchmarks containing both manifold and non-manifold meshes, including artist-created, and 3D-scanned models. In addition, it enhances existing 3D segmentation tools by providing clean boundaries for part decomposition.",
    "key_points": [
      "surface cutting",
      "mesh uv unfolding",
      "3d part segmentation",
      "auto-regressive generative model"
    ],
    "gold_summary": "The paper formulates surface cutting as a next token prediction task, and designs a novel auto-regressive architecture that predicts seam coordinate sequences from a given mesh."
  },
  {
    "paper_id": "SlqE2mfITO",
    "title": "LightMotion: A Light and Tuning-free Method for Simulating Camera Motion in Video Generation",
    "domain": "applications to computer vision",
    "content": "Existing camera-controlled video generation methods face computational bottlenecks, either due to significant fine-tuning overhead or heavy inference processes. In this paper, we proposes LightMotion, a light and tuning-free method for simulating camera motion in video generation. Operating in the latent space, it eliminates additional fine-tuning, inpainting, and depth estimation, making it more streamlined than existing methods. The endeavors of this paper comprise: (i) The latent space permutation operation simulates three basic camera motions: panning, zooming, and rotation, whose combinations cover almost all real-world movements. (ii) The latent space resampling strategy combines background-aware sampling with cross-frame alignment, accurately filling new perspectives while maintaining coherence across frames. (iii) Our analysis reveals that the tuning-free permutation and resampling will cause an SNR shift in latent space, leading to poor-quality generation. To address this, we propose the latent space correction scheme, which mitigates the shift and consequently improves video quality. Extensive experiments validate the superiority of LightMotion over other baselines.",
    "key_points": [
      "tuning-free",
      "lightweight",
      "video generation",
      "camera simulation"
    ],
    "gold_summary": "This paper proposes a camera control algorithm for video generation models to enable controllable camera motion during generation."
  },
  {
    "paper_id": "eNmANCkefl",
    "title": "Declarative Audio Editing with Audio Language Model",
    "domain": "applications to computer vision",
    "content": "Audio editing plays a central role in VR/AR immersion, virtual conferencing, sound design, and other interactive media. \nHowever, recent generative audio editing models depend on template-like instruction formats and are restricted to mono-channel audio.\nThese models fail to deal with declarative audio editing, where the user declares what the desired outcome should be, while leaving the details of editing operations to the system.\nWe introduce SmartDJ, a novel framework for stereo audio editing that combines the reasoning capability of audio language models with the generative power of latent diffusion. \nGiven a high-level instruction, SmartDJ decomposes it into a sequence of atomic edit operations, such as adding, removing, or spatially relocating events.\nThese operations are then executed by a diffusion model trained to manipulate stereo audio. \nTo support this, we design a data synthesis pipeline that produces paired examples of high-level instructions, atomic edit operations, and audios before and after each edit operation. \nExperiments demonstrate that SmartDJ achieves superior perceptual quality, spatial realism, and semantic alignment compared to prior audio editing methods. \nDemos are provided in the supplementary file. Code and data will be released upon acceptance.",
    "key_points": [
      "audio editing",
      "latent diffusion model",
      "audio language model"
    ],
    "gold_summary": "This paper introduces SmartDJ, a novel framework for stereo audio editing that combines the reasoning capability of audio language models with the generative power of latent diffusion."
  },
  {
    "paper_id": "8HZzPtMcZo",
    "title": "Visual Sparse Steering (VS2): Unsupervised Adaptation for Image Classification via Sparsity-Guided Steering Vectors",
    "domain": "applications to computer vision",
    "content": "Steering vision foundation models at test time, without retraining or access to large labeled datasets, is a desirable yet challenging goal, particularly in dynamic or resource-constrained settings. We present Visual Sparse Steering (VS2), a lightweight, label-free test-time method that constructs a steering vector from sparse features extracted by a Sparse Autoencoder (SAE) trained on the model’s internal activations. On CIFAR-100, CUB-200, and Tiny-ImageNet, VS2 improves the top-1 accuracy of the CLIP zero-shot baseline by 4.12\\%, 1.08\\%, and 1.84\\%, respectively. Since not all features learned by the SAE are equally important for classification, we introduce VS2++, a retrieval-augmented variant that selectively amplifies relevant sparse features using pseudo-labeled neighbors retrieved from an external unlabeled corpus at inference time. With oracle positive and negative sets (upper bound), VS2++ achieves absolute top-1 gains over the CLIP zero-shot baseline of up to 21.44\\% on CIFAR-100, 7.08\\% on CUB-200, and 20.47\\% on Tiny-ImageNet, highlighting the potential of steering vectors when relevant feature selection is accurate. VS2 and VS2++ also improve per-class accuracy by up to 25\\% and 38\\%, respectively, indicating that sparse steering disproportionately benefits visually or semantically similar classes. Finally, VS2 includes a built-in reliability diagnostic based on SAE reconstruction loss, which is absent in common steering vectors, signaling when steering may underperform and safely triggering a fallback to the baseline.",
    "key_points": [
      "sparse autoencoders",
      "steering vectors",
      "unsupervised adaptation",
      "image classification"
    ],
    "gold_summary": "The paper presents an unsupervised steering technique (VS2) to adapt vision models. The authors mainly test the approach on 3 common benchmarks using the CLIP ViTs backbones."
  },
  {
    "paper_id": "jimY7NF6aJ",
    "title": "MUSEG: Reinforcing Video Temporal Understanding via Timestamp-Aware Multi-Segment Grounding",
    "domain": "applications to computer vision",
    "content": "Video temporal understanding is crucial for multimodal large language models (MLLMs) to reason over events in videos. Despite recent advances in general video understanding, current MLLMs still struggle with fine-grained temporal reasoning. While reinforcement learning (RL) has been explored to address this issue recently, existing RL approaches remain limited in performance on time-sensitive tasks. In this work, we propose **MUSEG**, a novel RL-based method that enhances temporal understanding by introducing timestamp-aware multi-segment grounding. MUSEG enables MLLMs to align queries with multiple relevant video segments, promoting more comprehensive temporal reasoning. To facilitate effective learning, we design a customized RL training recipe with phased rewards that progressively guides the model toward temporally grounded reasoning. Extensive experiments on temporal grounding and time-sensitive video question answering (QA) tasks demonstrate that \\methodname significantly outperforms existing methods and generalizes well across diverse temporal understanding scenarios.",
    "key_points": [
      "video temporal understanding",
      "temporal video grounding",
      "reinforcement learning"
    ],
    "gold_summary": "The paper design rewards for temporal reasoning to do RL, and experiment on 2 models: Qwen2.5VL 7B and 3B, which beats the baselines. The rewards they design are segment matching rewards and timestamp reward."
  },
  {
    "paper_id": "Ommc0WBraJ",
    "title": "Long-Tailed Distribution-Aware Router For Mixture-of-Experts in Large Vision-Language Model",
    "domain": "applications to computer vision",
    "content": "The mixture-of-experts (MoE) architecture, which replaces dense architectures with sparse ones, has garnered attention in large vision-language models (LVLMs) for achieving comparable performance with fewer activated parameters. Existing MoE architectures for LVLMs primarily focus on token-to-expert routing (TER), encouraging different experts to specialize in processing specific tokens. However, these architectures typically rely on the load balancing mechanism, neglecting the inherent distributional differences between vision and language modalities. To address this, we propose the Long-Tailed Distribution-aware Router (LTDR) for vision-language TER, which tackles two key challenges: (1) Modality-specific distribution-aware routing. We observe that language TER follows a relatively uniform distribution, whereas vision TER exhibits a long-tailed distribution. This modality discrepancy necessitates specific routing strategies for each modality. (2) Vision-specific expert activation. Recognizing the importance of high-information vision tail tokens, we introduce an oversampling-like strategy by increasing the number of activated experts to sufficiently learn vision tail token representations. Experiments on extensive vision-language and vision benchmarks validate the effectiveness of our approach.",
    "key_points": [
      "long-tailed distribution",
      "vision-language model",
      "mixture-of-experts",
      "modality-specific routing"
    ],
    "gold_summary": "This paper proposes LTDR, which (1) eliminates load balancing for vision tokens and (2) assigns more experts to tail vision tokens. Experimental results demonstrate consistent performance improvements on both vision and vision-language tasks."
  },
  {
    "paper_id": "LElJH6EYBq",
    "title": "AudioMoG: Guiding Audio Generation with Mixture-of-Guidance",
    "domain": "applications to computer vision",
    "content": "Guidance methods have demonstrated significant improvements in cross-modal audio generation, including text-to-audio (T2A) and video-to-audio (V2A) generation. The popularly adopted method, classifier-free guidance (CFG), steers generation by emphasizing condition alignment, enhancing fidelity but often at the cost of diversity. Recently, autoguidance (AG) has been explored for audio generation, encouraging the sampling to faithfully reconstruct the target distribution and showing increased diversity. Despite these advances, they usually rely on a single guiding principle, \\textit{e.g.}, condition alignment in CFG or score accuracy in AG, leaving the full potential of guidance for audio generation untapped. In this work, we explore enriching the composition of the guidance method and present a mixture-of-guidance framework, AudioMoG. Within the design space, AudioMoG can exploit the complementary advantages of distinctive guiding principles by fulfilling their~\\textit{cumulative benefits}. With a reduced form, AudioMoG can consider parallel complements or recover a single guiding principle, without sacrificing generality. We experimentally show that, given the same inference speed, AudioMoG approach consistently outperforms single guidance in T2A generation across sampling steps, concurrently showing advantages in V2A, text-to-music, and image generation. These results highlight a “free lunch” in current cross-modal audio generation systems: higher quality can be achieved through mixed guiding principles at the sampling stage without sacrificing inference efficiency. Demo samples are available at: \\url{audiomog.github.io}.",
    "key_points": [
      "diffusion models",
      "text-to-audio generation",
      "video-to-audio generation",
      "classifier-free guidance",
      "mixture-of-guidance"
    ],
    "gold_summary": "This work explores enriching the composition of the guidance method and presents a mixture-of-guidance framework, AudioMoG."
  },
  {
    "paper_id": "PBz9CMIOtn",
    "title": "Rethinking the Spatiotemporal Distribution for High-Fidelity Parallel ANN-to-SNN Conversion",
    "domain": "applications to computer vision",
    "content": "Spiking Neural Networks (SNNs) have attracted increasing attention for their low power consumption and constant-time inference on neuromorphic hardware. Among existing approaches, ANN-to-SNN conversion is one of the most effective ways to obtain deep SNNs with accuracy comparable to traditional ANNs, and recent work has even extended it to \\emph{parallel} conversion, where the full spike train is emitted in a single pass. Despite this promise, we find that ANN-to-SNN parallel conversion suffers from severe performance degradation at ultra-low timesteps ($T \\leq 4$), limiting its practical use.\nIn this work, we analyze the source of this performance gap and demonstrate that it originates from assumptions in the standard quantization–clip–floor–shift (QCFS) formulation, which, under the one-shot firing rule, introduces a step-dependent bias. To overcome this, we propose a \\emph{distribution-aware parallel calibration} that corrects spatiotemporal mismatches while leaving the backbone and firing rule unchanged. Our method consists of two stages: (1) \\textbf{spatial recalibration}, which adapts normalization layers to spike-domain statistics, and (2) \\textbf{temporal correction}, which learns a per-channel, time-collapsed aggregated membrane potential bias to offset timestep-dependent errors.  \nOn ImageNet-1k, our approach boosts ResNet-18 top-1 accuracy from $\\mathbf{25.20\\%\\!\\to\\!62.28\\%}$ at $T=4$ and ResNet-34 from $\\mathbf{50.67\\%\\!\\to\\!68.23\\%}$ at $T=8$. These results demonstrate that revisiting—and correcting—standard QCFS premises in the \\emph{parallel setting} is essential for accurate, low-latency SNNs without retraining the backbone.",
    "key_points": [
      "spiking neural networks",
      "snn",
      "ann-to-snn conversion",
      "parallel conversion"
    ],
    "gold_summary": "This work proposes a two-stage distribution-aware calibration method for ANN-SNN Parallel Conversion, which further enhances the performance of SNN parallel inference under the condition of ultra-low time latency."
  },
  {
    "paper_id": "NX6oMuoLxu",
    "title": "Layer-Wise Analysis in Exploring the Normalization Strategies in Mamba",
    "domain": "applications to computer vision",
    "content": "The Mamba architecture achieves linear time and memory complexity in long-sequence modeling and vision tasks through a dynamic, input-conditioned state transition mechanism and hardware-efficient scan operations. However, as network depth increases, the state space model (SSM) component tends to amplify activation magnitudes during the forward pass, often leading to gradient explosion. This highlights the urgent need for a systematic normalization design to balance training stability and convergence speed. To address this, we analyze training stability by tracking (i) the spectral norm of the output projection weights and (ii) the largest eigenvalue of the joint input-output covariance matrix, demonstrating the effectiveness of Norm2 (post-SSM) in suppressing activation and gradient scale inflation. From an optimization efficiency perspective, we use K-FAC to pproximate the Fisher Information Matrix and show that Norm1 (pre-SSM) significantly reduces the condition number of per-layer gradients, thereby accelerating convergence. Furthermore, we propose a composite normalization strategy (BN→SSM→LN), combining BatchNorm at the input and LayerNorm at the output of SSM. We evaluate this strategy across a broad range of benchmarks. Experimental results demonstrate that the composite scheme consistently outperforms single or no normalization in both convergence speed and final accuracy. We hope this work provides both theoretical insights and empirical guidance for normalization in designing SSM-based models.",
    "key_points": [
      "mamba",
      "normalization",
      "stability",
      "optimization",
      "scale invariance",
      "condition number"
    ],
    "gold_summary": "This paper focuses on addressing the training instability and optimization inefficiency of the Mamba architecture. Authors propose the BN->LN. Next, they use optimization metrics to prof its effectiveness."
  },
  {
    "paper_id": "O3CuUy5XAX",
    "title": "One-Timestep is Enough: Achieving High-performance ANN-to-SNN Conversion via Scale-and-Fire Neurons",
    "domain": "applications to computer vision",
    "content": "Spiking Neural Networks (SNNs) are gaining attention as energy-efficient alternatives to Artificial Neural Networks (ANNs), especially in resource-constrained settings. While ANN-to-SNN conversion (ANN2SNN) achieves high accuracy without end-to-end SNN training, existing methods rely on large time steps, leading to high inference latency and computational cost. In this paper, we propose a theoretical and practical framework for single-timestep ANN2SNN. We establish the Temporal-to-Spatial Equivalence Theory, proving that multi-timestep integrate-and-fire (IF) neurons can be equivalently replaced by single-timestep multi-threshold neurons (MTN).\nBased on this theory, we introduce the Scale-and-Fire Neuron (SFN), which enables effective single-timestep ($T=1$) spiking through adaptive scaling and firing. Furthermore, we develop the SFN-based Spiking Transformer (SFormer), a specialized instantiation of SFN within Transformer architectures, where spike patterns are aligned with attention distributions to mitigate the computational, energy, and hardware overhead of the multi-threshold design.\nExtensive experiments on image classification, object detection, and instance segmentation demonstrate that our method achieves state-of-the-art performance under single-timestep inference. Notably, we achieve 88.8\\% top-1 accuracy on ImageNet-1K at $T=1$, surpassing existing conversion methods.",
    "key_points": [
      "spiking neural network",
      "ann-snn conversion",
      "one-timestep conversion",
      "multi-threshold neurons",
      "scale-and-fire neurons"
    ],
    "gold_summary": "This paper proposes SFN, which enables converted SNNs to achieve good performance within 1 time step."
  },
  {
    "paper_id": "WPJnLvQrP3",
    "title": "Prompt and Parameter Co-Optimization for Large Language Models",
    "domain": "applications to computer vision",
    "content": "Prompt optimization and fine-tuning are two major approaches to improve the performance of Large Language Models (LLMs).\nThey enhance the capabilities of LLMs from complementary perspectives: the former through explicit natural language, and the latter through implicit parameter updates. \nHowever, prior work has typically studied them in isolation, leaving their synergistic potential largely underexplored. To bridge this gap, in this paper, we introduce MetaTuner, a novel framework that jointly integrates prompt optimization and fine-tuning for LLM training.\nSpecifically, we introduce two neural networks to generate prompts and parameters, respectively, while allowing them to share a common bottom encoding layer to enable knowledge sharing.\nBy the guidance of the final supervised signals, our framework is optimized to discover the optimal combinations between the prompts and parameters.\nGiven that prompt learning involves discrete optimization while fine-tuning operates in a continuous parameter space, we design a supervised regularization loss to train our framework effectively.\nExtensive experiments across diverse benchmarks show that our method consistently outperforms the baselines.  To benefit the research community, we have released our project at https://anonymous.4open.science/r/metatuner.",
    "key_points": [
      "prompt-parameter co-optimization",
      "shared-private parameterization",
      "supervised regularization"
    ],
    "gold_summary": "The paper proposes a joint framework for LLM prompt optimization and parameter training. Clear gains are demonstrated over prompt optimization and fine-tuning."
  },
  {
    "paper_id": "QQLWwzhROL",
    "title": "CubistMerge: Spatial-Preserving Token Merging For Diverse ViT Backbones",
    "domain": "applications to computer vision",
    "content": "Many modern ViT backbones have adopted spatial architectural designs, such as window attention in Swin, decomposed relative positional embeddings in SAM, and RoPE in DINOv3. While token reduction has been a successful research direction for reducing computational costs of ViT, the vast majority of existing methods fail to preserve the structured spatial layouts these architectures fundamentally depend on, rendering them incompatible with such spatial architectures.\n\nIn this paper, we introduce a simple yet effective token merging method that maintains spatial layouts, enabling seamless compatibility with spatial architectures. We show how to reconcile two seemingly conflicting requirements: exploiting the uneven information distribution across the spatial layout while preserving spatial structure of merged tokens. Our approach employs (1) a 2D token reduction strategy that ensures structured 2D layouts in the resulting tokens, (2) a spatial-aware merging algorithm to selectively merge redundant tokens while preserving relative spatial relationships of the tokens, and (3) a novel max-magnitude-element token representation that preserves salient features.\n\nOur method demonstrates strong performance both off-the-shelf and with fine-tuning, achieving state-of-the-art results on spatial and non-spatial architectures across various vision tasks. Specifically, we achieve 1.25× speedup on SAM-H with only 0.7 mIOU drop evaluated on COCO off-the-shelf, and 1.15× speedup on DeiT-B without accuracy drop evaluated on ImageNet within just one epoch of fine-tuning.",
    "key_points": [
      "token merging",
      "token reduction",
      "vision transformer",
      "off-the-shelf"
    ],
    "gold_summary": "The paper introduces a token merging method designed to preserve the 2D spatial structure of Vision Transformer (ViT) tokens during pruning."
  },
  {
    "paper_id": "G3dW21Geb6",
    "title": "CosyCPT: Coreness-Aware Synthetic Continued Pretraining",
    "domain": "applications to computer vision",
    "content": "Synthetic continued pretraining adapts LLMs to specific domains by fine-tuning them on synthetic data that augments real domain data. However, existing methods are often data-inefficient (requiring massive synthetic corpora to enumerate all relational facts) and fail to account for the relative importance of different entity relationships. In this paper, we propose coreness-aware synthetic continued pretraining (CosyCPT), a systematic pipeline that addresses both limitations. Our method (1) constructs a graph representation of entity relations in a document, (2) quantifies relation importance via coreness scores derived from the graph, and (3) leverages these scores to guide synthetic data sampling and augmentation for continued pretraining. We investigate four definitions of entity coreness and four formulations of relation coreness, verifying that multiple variants of coreness-aware sampling can outperform random sampling of augmented data for synthetic continued pretraining. We offer a mathematical analysis, proving that (1) given a learning budget, maximizing the expected accuracy on a query set about relational knowledge in a document collection is an NP-complete problem, (2) coreness-aware sampling is the optimal solution when each query examines one entity pair, and (3) coreness-aware sampling has a better upper bound for expected accuray than random sampling.",
    "key_points": [
      "synthetic continued pretraining",
      "knowledge acquisition",
      "large language models",
      "graph mining",
      "sampling",
      "data augmentation"
    ],
    "gold_summary": "This paper proposes a systematic pipeline, \"COSYCPT: Coreness-Aware Synthetic Continued Pretraining\". COSYCPT is a systematic graph-theoretic framework designed to prioritize the most structurally important knowledge within a document collection for synthetic data generation."
  },
  {
    "paper_id": "LOLhTA51tr",
    "title": "PPLLaVA: Varied Video Sequence Understanding With Prompt Guidance",
    "domain": "applications to computer vision",
    "content": "The past year has witnessed the significant advancement of video-based large language models. However, the challenge of developing a unified model for both short and long video understanding remains unresolved. Most existing video LLMs cannot handle hour-long videos, while methods custom for long videos tend to be ineffective for shorter videos and images. In this paper, we identify the key issue as the redundant content in videos. To address this, we propose a novel pooling strategy that simultaneously achieves token compression and instruction-aware visual feature aggregation. Our model is termed Prompt-guided Pooling LLaVA, or PPLLaVA for short. Specifically, PPLLaVA consists of three core components: the CLIP-based visual-prompt alignment that extracts visual information relevant to the user's instructions, the prompt-guided pooling that compresses the visual sequence to arbitrary scales using convolution-style pooling, and the clip context extension designed for lengthy prompt common in visual dialogue. Extensive experiments have validated the performance of our model. With superior throughput, PPLLaVA achieves better results on image benchmarks as a video LLM, while achieving state-of-the-art performance across various video benchmarks, excelling in tasks ranging from caption generation to multiple-choice questions, and handling video lengths from seconds to hours.",
    "key_points": [
      "video llm",
      "prompt-guided pooling",
      "ppllava"
    ],
    "gold_summary": "This paper proposes PPLLaVA, a video LLM that introduces a prompt-guided pooling strategy for adaptive token compression, aiming to achieve unified and state-of-the-art performance on both short and long video understanding benchmarks."
  },
  {
    "paper_id": "sQkeWe3p6R",
    "title": "NO DARK DATA REQUIRED: BRIDGING THE GAP BETWEEN NORMAL AND LOW-LIGHT DETECTION VIA RETINEX DECOMPOSITION",
    "domain": "applications to computer vision",
    "content": "Conventional low-light object detection approaches typically involve distinct image enhancement modules before the detection process. This can lead to compromised performance due to misaligned objectives and reduced robustness in challenging visual contexts. Many existing methodologies either do not optimize both tasks jointly or overlook significant latent features that are essential for accurate detection. To address this issue, a novel end-to-end framework was proposed that was exclusively trained on normal-light images, eliminating the need for low-light data during the training phase. This approach drew inspiration from the Retinex theory, which separated images into reflectance (representing scene structure) and illumination (indicating lighting conditions). The proposed framework approximates this decomposition within the feature space. The architecture utilises deep multi-scale feature aggregation along with a reflectance-guided fusion pathway, enabling the adaptive integration of illumination-aware representations through element-wise modulation. Despite being trained on normal-light images, the framework demonstrates effective generalisation to low-light and visibility compromised environments. Comprehensive experiments conducted on both synthetic datasets (Pascal VOC) and real-world benchmarks (ExDark, RTTS) indicate that this method achieves enhanced detection accuracy and robustness, particularly in adverse lighting conditions, and outperforms current state-of-the-art techniques.",
    "key_points": [
      "low-light images",
      "adversarial visibility condition",
      "retinex theory",
      "image processing."
    ],
    "gold_summary": "This manuscript attempts to introduce Retinex theory into the YOLO framework, but in reality, it is merely a patchwork of pre-existing concepts and methods."
  },
  {
    "paper_id": "c21yqwf02V",
    "title": "DispViT: Direct Stereo Disparity Regression with a Single-Stream Vision Transformer",
    "domain": "applications to computer vision",
    "content": "Deep stereo disparity estimation has long been dominated by a \\textbf{matching-centric paradigm}, built on constructing cost volumes and iteratively refining local correspondences.\nDespite its success, this paradigm exhibits an intrinsic vulnerability: visual ambiguities from occlusion or non-Lambertian surfaces invevitably induce errorneous matches that refinement cannot recover.\nThis paper introduces \\textbf{DispViT}, a new architecture that establishes a \\textbf{regression-centric paradigm}. \nInstead of explicit matching, DispViT directly regresses disparity from tokenized binocular representations using a single-stream Vision Transformer.\nThis is enabled by a set of lightweight yet critical designs, such as a probability-based disparity parameterization for stable training and an asymmetrically initialized stereo tokenizer for effective view distinction.\nTo better align the two views during stereo tokenization, we introduce a novel shift-embedding mechanism that encodes different disparity shifts into channel groups, preserving geometric cues even under large view displacements.\nA lightweight refinement module then sharpens the regressed disparity map for fine-grained accuracy.\nBy prioritizing holistic regression over explicit matching, DispViT streamlines the stereo pipeline while improving robustness and efficiency.\nExperiments on standard benchmarks show that our approach achieves state-of-the-art accuracy, with strong resilience to matching ambiguities and wide disparity ranges.\nCode will be released.",
    "key_points": [
      "stereo disparity estimation",
      "vision transformer",
      "positional encoding"
    ],
    "gold_summary": "The manuscript proposed the DispViT, a new architecture that directly regresses disparity from tokenized binocular representations using a single-stream Vision Transformer. The architecture achieves state-of-the-art accuracy on standard benchmarks."
  },
  {
    "paper_id": "A2FvWrV4o4",
    "title": "Knowledge-enhanced MCTS for LLM-based Medical Diagnosis Reasoning",
    "domain": "applications to computer vision",
    "content": "Medical diagnosis is a high-stakes, knowledge-intensive task that requires precise reasoning over complex patient information. While Large Language Models (LLMs) have shown promise across a range of medical applications, their ability to perform accurate and interpretable diagnostic reasoning remains limited. Existing LLM-based approaches often rely on shallow, single-step inferences and lack mechanisms to systematically evaluate multiple diagnostic hypotheses. To address these challenges, we propose Med-MCTS, a knowledge-enhanced diagnostic reasoning framework that integrates Monte Carlo Tree Search (MCTS) with external medical knowledge. Med-MCTS formulates diagnosis as a sequential decision-making process and introduces domain-specific state and action representations that align with clinical reasoning practices. During MCTS tree expansion, the model traverses structured medical knowledge graphs to enrich reasoning trajectories with relevant contextual information. To select high-quality paths, Med-MCTS employs a multi-dimensional scoring mechanism that evaluates self-consistency, factual accuracy, and diversity of reasoning. Experiments on multiple benchmark datasets demonstrate that Med-MCTS significantly improves diagnostic accuracy, enabling open-source LLMs to outperform domain-specific medical models and approach the performance of advanced proprietary systems such as GPT-4o.",
    "key_points": [
      "large language models",
      "medical diagnosis",
      "knowledge-enhanced reasoning"
    ],
    "gold_summary": "This paper proposed Med-MCTS, a knowledge-enhanced diagnostic reasoning framework that integrates MCTS with external medical knowledge."
  },
  {
    "paper_id": "w70fv82Vft",
    "title": "SLAKE: Softmax-Approximated Training-Free Linear Attention with KV-Cache Eviction for Long-Sequence LLMs",
    "domain": "applications to computer vision",
    "content": "Recent advances in transformer-based large language models (LLMs) have enabled inference over contexts as long as 128K tokens. However, the quadratic computational and memory costs of full self-attention remain a fundamental bottleneck at such scales. Prior efforts to mitigate this challenge largely fall into two camps: (i) structural approximations (e.g., linear attention) that reduce asymptotic complexity but typically require costly retraining, and (ii) KV-cache optimizations (e.g., eviction or merging) that are training-free yet inevitably discard information. We introduce Softmax-Approximated Training-Free Linear Attention with KV-Cache Eviction (SLAKE), a novel framework that unifies the complementary advantages of these two paradigms. At its core, SLAKE employs Partially Taylor-Approximated Attention (PTAA), which leverages a first-order Taylor expansion to selectively linearize the Softmax attention kernel. This design enables tokens deemed low-importance via eviction scoring to be processed efficiently with linear attention, while preserving exact Softmax computation for high-salience tokens. To further improve cache efficiency, we propose Value-Aware Budget Scoring (VABS), a new allocation strategy that incorporates value contributions and overcomes key limitations of previous eviction heuristics. Extensive experiments on LLaMA-3 8B demonstrate that SLAKE delivers up to 10$\\times$ inference speedup and 30.8\\% peak-memory reduction on 128K-token sequences, while keeping accuracy loss below 4\\%. To our knowledge, SLAKE is the first training-free approach to jointly integrate linear attention with KV-cache eviction, establishing a new state of the art among long-context, training-free methods.",
    "key_points": [
      "large language models",
      "linear attention",
      "kv cache compression",
      "self attention approximation"
    ],
    "gold_summary": "This paper proposes SLAKE, a training-free framework combining linear attention and KV cache attention for efficient long context inference."
  },
  {
    "paper_id": "nlJX6Hwyl0",
    "title": "Code2Video: A Code-centric Paradigm for Educational Video Generation",
    "domain": "applications to computer vision",
    "content": "While recent generative models advance pixel-space video synthesis, they remain limited in producing professional educational videos, which demand disciplinary knowledge, precise visual structures, and coherent transitions, limiting their applicability in educational scenarios. Intuitively, such requirements are better addressed through the manipulation of a renderable environment, which can be explicitly controlled via logical commands (*e.g.*, code). In this work, we propose **Code2Video**, a code-centric agent framework for generating educational videos via executable Python code. The framework comprises three collaborative agents: *(i) Planner*, which structures lecture content into temporally coherent flows and prepares corresponding visual assets; *(ii) Coder*, which converts structured instructions into executable Python codes while incorporating scope-guided auto-fix to enhance efficiency; and *(iii) Critic*, which leverages vision-language models (VLM) with visual anchor prompts to refine spatial layout and ensure clarity. To support systematic evaluation, we build **MMMC**, a benchmark of professionally produced, discipline-specific educational videos. We evaluate MMMC across diverse dimensions, including VLM-as-a-Judge aesthetic scores, code efficiency, and particularly, **TeachQuiz**, a novel end-to-end metric that quantifies how well a VLM, after unlearning, can recover knowledge by watching the generated videos. Our results demonstrate the potential of Code2Video as a scalable, interpretable, and controllable approach, achieving 40% improvement over direct code generation and producing videos comparable to human-crafted tutorials.",
    "key_points": [
      "video generation",
      "multi-agent",
      "coding",
      "video synthesis"
    ],
    "gold_summary": "This paper proposes a code-centric agent framework for generating educational videos via executable Python code."
  },
  {
    "paper_id": "0YV1iyqz16",
    "title": "ECMNet: Lightweight Semantic Segmentation  with Efficient CNN-Mamba Network",
    "domain": "applications to computer vision",
    "content": "In the past decade, Convolutional Neural Networks (CNNs) and Transformers have achieved wide application in semantic segmentation tasks. Although CNNs with Transformer models greatly improve performance, the global context modeling remains inadequate. Recently, Mamba achieved great potential in vision tasks, showing its advantages in modeling long-range dependency. In this paper, we propose a lightweight Efficient CNN-Mamba Network for semantic segmentation, dubbed as ECMNet.  ECMNet combines CNN with Mamba skillfully in a capsule-based framework to address their complementary weaknesses. Specifically, We design a Enhanced Dual-Attention Block (EDAB) for lightweight bottleneck. In order to improve the representations ability of feature, We devise a Multi-Scale Attention Unit (MSAU) to integrate multi-scale feature aggregation, spatial aggregation and channel aggregation. Moreover, a Mamba enhanced Feature Fusion Module (FFM) merges diverse level feature, significantly enhancing segmented accuracy. Extensive experiments on two representative datasets demonstrate that the proposed model excels in accuracy and efficiency balance, achieving 70.6% mIoU on Cityscapes and 73.6% mIoU on CamVid test datasets, with 0.87M parameters and 8.27G FLOPs on a single RTX 3090 GPU platform.",
    "key_points": [
      "semantic segmentation",
      "lightweight",
      "convolutional neural network",
      "mamba"
    ],
    "gold_summary": "This paper proposes a lightweight semantic segmentation model called ECMNet that combines CNN and Mamba, achieving a favorable balance between parameter efficiency and accuracy on the Cityscapes and CamVid datasets."
  },
  {
    "paper_id": "nHEMumYcwt",
    "title": "Video Language Models are Human-Aligned Evaluators for Text to Motion Generation",
    "domain": "applications to computer vision",
    "content": "Recently, text-to-motion (T2M) has become a basic setting for human motion generation. This work studies the evaluation of alignment between text and generated motion, to credit the reliable use of T2M models. We consider solving the T2M evaluation task by making use of a video language model (VLM). Our basic idea is: render the generated human motion into a skinned video, and then use a VLM for evaluation. To address information loss problem when 3D motion is rendered into 2D video, we develop a method, which ensures reliable evaluation score by analyzing VLM entropy. Our evaluation method, named VeMo, frees T2M evaluation from reliance on motion data while seamlessly leveraging the semantic understanding and reasoning capabilities of advanced VLMs trained on Internet-scale data. To systematically compare the empirical usefulness of different evaluation methods, we manually annotate a meta-evaluation benchmark that includes coarse-grained alignment labels and fine-grained reasons. Extensive experiments and case studies demonstrate the effectiveness of VeMo.",
    "key_points": [
      "text-driven human motion generation"
    ],
    "gold_summary": "The paper considers solving the T2M evaluation task by making use of a video language model, and provides a meta-evaluation dataset."
  },
  {
    "paper_id": "Ef5O9gNNLE",
    "title": "ToolTree: Efficient LLM Tool Planning via Dual-Feedback Monte Carlo Tree Search and Bidirectional Pruning",
    "domain": "applications to computer vision",
    "content": "Large Language Model (LLM) agents are increasingly applied to complex, multi-step tasks that require interaction with diverse external tools across various domains. However, current LLM agent tool planning methods typically rely on greedy, reactive tool selection strategies that lack foresight and fail to account for inter-tool dependencies.\nIn this paper, we present ToolTree, a novel Monte-Carlo tree search-inspired planning paradigm for tool planning. ToolTree explores possible tool usage trajectories using a dual-stage LLM evaluation and bidirectional pruning mechanism that enables the agent to make informed, adaptive decisions over extended tool-use sequences while pruning less promising branches before and after the tool execution. Empirical evaluations across both open-set and closed-set tool planning tasks on 4 benchmarks demonstrate that ToolTree consistently improves performance while keeping the highest efficiency, achieving an average gain of around 10\\% compared to the state-of-the-art planning paradigm.",
    "key_points": [
      "tool planning",
      "monte-carlo tree search",
      "agent tool use"
    ],
    "gold_summary": "This paper proposes ToolTree, a planning-time framework that casts multi‑tool orchestration for LLM agents as an MCTS-style search augmented with dual LLM feedback."
  },
  {
    "paper_id": "3YtTzpEHZR",
    "title": "LoBE-GS: Load-Balanced and Efficient 3D Gaussian Splatting for Large-Scale Scene Reconstruction",
    "domain": "applications to computer vision",
    "content": "3D Gaussian Splatting (3DGS) has established itself as an efficient representation for real-time, high-fidelity 3D scene reconstruction. However, scaling 3DGS to large and unbounded scenes such as city blocks remains difficult. Existing divide-and-conquer methods alleviate memory pressure by partitioning the scene into blocks, but introduce new bottlenecks: (i) partitions suffer from severe load imbalance since uniform or heuristic splits do not reflect actual computational demands, and (ii) coarse-to-fine pipelines fail to exploit the coarse stage efficiently, often reloading the entire model and incurring high overhead. In this work, we introduce LoBE-GS, a novel Load-Balanced and Efficient 3D Gaussian Splatting framework, that re-engineers the large-scale 3DGS pipeline. LoBE-GS introduces a depth-aware partitioning method that reduces preprocessing from hours to minutes, an optimization-based strategy that balances visible Gaussians—a strong proxy for computational load—across blocks, and two lightweight techniques, visibility cropping and selective densification, to further reduce training cost.\nEvaluations on large-scale urban and outdoor datasets show that LoBE-GS consistently achieves up to $2\\times$ faster end-to-end training time than state-of-the-art baselines, while maintaining reconstruction quality and enabling scalability to scenes infeasible with vanilla 3DGS.",
    "key_points": [
      "neural rendering",
      "novel view synthesis",
      "large-scale scene",
      "3d gaussian splatting"
    ],
    "gold_summary": "This paper proposes LoBE-GS, a load-balanced and efficient pipeline for large-scale 3D Gaussian Splatting (3DGS)."
  },
  {
    "paper_id": "PfIAcdbce2",
    "title": "AdvEvo-MARL: Shaping Internalized Safety through Adversarial Co-Evolution in Multi-Agent Reinforcement Learning",
    "domain": "applications to computer vision",
    "content": "LLM-based multi-agent systems excel at planning, tool use, and role coordination, but their openness and interaction complexity also expose them to jailbreak, prompt-injection, and adversarial collaboration. Existing defenses fall into two lines: (i) self-verification that asks each agent to pre-filter unsafe instructions before execution, and (ii) external guard modules that police behaviors. The former often underperforms because a standalone agent lacks sufficient capacity to detect cross-agent unsafe chains and delegation-induced risks; the latter increases system overhead and creates a single-point-of-failure—once compromised, system-wide safety collapses, and adding more guards worsens cost and complexity. To solve these challenges, we propose AdvEvo-MARL, a co-evolutionary multi-agent reinforcement learning framework that internalizes safety into task agents. Rather than relying on external guards, AdvEvo-MARL jointly optimizes attackers (which synthesize evolving jailbreak prompts) and defenders (task agents trained to both accomplish their duties and resist attacks) in adversarial learning environments. To stabilize learning and foster cooperation, we introduce a public baseline for advantage estimation: agents within the same functional group share a group-level mean-return baseline, enabling lower-variance updates and stronger intra-group coordination. Across representative attack scenarios, AdvEvo-MARL consistently keeps attack-success rate (ASR) below 20\\%, whereas baselines reach up to 38.33\\%, while preserving—and sometimes improving—task accuracy (up to +3.67\\% on reasoning tasks). These results show that safety and utility can be jointly improved without relying on extra guard agents or added system overhead.",
    "key_points": [
      "multi-agent system",
      "safety",
      "reinforcement learning",
      "multimodal large language models"
    ],
    "gold_summary": "This paper proposes a multi-agent reinforcement learning framework for training LLMs to be robust against adversarial attacks. The attackers learn to synthesize jailbreak prompts."
  },
  {
    "paper_id": "Nk3iEsYJtd",
    "title": "Policy-Based Sentence Simplification: Replacing Parallel Corpora with LLM-as-a-Judge",
    "domain": "applications to computer vision",
    "content": "Sentence simplification aims to modify a sentence to make it easier to read and understand while preserving the meaning. Different applications require distinct simplification policies, such as replacing only complex words at the lexical level or rewriting the entire sentence while trading off details for simplicity. However, achieving such policy-driven control remains an open challenge. In this work, we introduce a simple yet powerful approach that leverages Large Language Model-as-a-Judge (LLM-as-a-Judge) to automatically construct policy-aligned training data, completely removing the need for costly human annotation or parallel corpora. Our method enables building simplification systems that adapt to diverse simplification policies. Remarkably, even small-scale open-source LLMs such as Phi-3-mini-3.8B surpass GPT-4o on lexical-oriented simplification, while achieving comparable performance on overall rewriting, as verified by both automatic metrics and human evaluations. The consistent improvements across model families and sizes demonstrate the robustness of our approach",
    "key_points": [
      "sentence simplification",
      "llm-as-a-judge"
    ],
    "gold_summary": "The paper focus on training small LLMs doing sentence simplification. The method involves sampling simplification outputs from different models and then use LLM as judge to construct preference pairs, and then apply preference learning algorithm."
  },
  {
    "paper_id": "YV5Zgv8pdg",
    "title": "Vivid-VR: Distilling Concepts from Text-to-Video Diffusion Transformer for Photorealistic Video Restoration",
    "domain": "applications to computer vision",
    "content": "We present Vivid-VR, a DiT-based generative video restoration method built upon an advanced T2V foundation model, where ControlNet is leveraged to control the generation process, ensuring content consistency. However, conventional fine-tuning of such controllable pipelines frequently suffers from distribution drift due to limitations in imperfect multimodal alignment, resulting in compromised texture realism and temporal coherence. To tackle this challenge, we propose a concept distillation training strategy that utilizes the pretrained T2V model to synthesize training samples with embedded textual concepts, thereby distilling its conceptual understanding to preserve texture and temporal quality. To enhance generation controllability, we redesign the control architecture with two key components: 1) a control feature projector that filters degradation artifacts from input video latents to minimize their propagation through the generation pipeline, and 2) a new ControlNet connector employing a dual-branch design. This connector synergistically combines MLP-based feature mapping with cross-attention mechanism for dynamic control feature retrieval, enabling both content preservation and adaptive control signal modulation. Extensive experiments show that Vivid-VR performs favorably against existing approaches on both synthetic and real-world benchmarks, as well as AIGC videos, achieving impressive texture realism, visual vividness, and temporal consistency.",
    "key_points": [
      "video restoration",
      "diffusion transformer",
      "text-to-video",
      "controlnet",
      "concept distillation"
    ],
    "gold_summary": "This paper proposes a video restoration method. The core contributions include training with mixed real/synthesized data (termed “concept distillation”) and two architectural modifications."
  },
  {
    "paper_id": "onkWWltsSa",
    "title": "Open Set Face Forgery Detection via Dual-Level Evidence Collection",
    "domain": "applications to computer vision",
    "content": "The proliferation of face forgeries has increasingly undermined confidence in the authenticity of online content. Given the rapid development of face forgery generation algorithms, new fake categories are likely to keep appearing, posing a major challenge to existing face forgery detection methods. Despite recent advances in face forgery detection, existing methods are typically limited to binary Real-vs-Fake classification or the identification of known fake categories, and are incapable of detecting the emergence of novel types of forgeries.\nIn this work, we study the Open Set Face Forgery Detection (OSFFD) problem, which demands that the detection model recognize novel fake categories. We reformulate the OSFFD problem and address it through uncertainty estimation, enhancing its applicability to real-world scenarios. Specifically, we propose the Dual-Level Evidential face forgery Detection (DLED) approach, which collects and fuses category-specific evidence on the spatial and frequency levels to estimate prediction uncertainty. Extensive evaluations conducted across diverse experimental settings demonstrate that the proposed DLED method achieves state-of-the-art performance, outperforming various baseline models by an average of $20\\%$ in detecting forgeries from novel fake categories. Moreover, on the traditional Real-versus-Fake face forgery detection task, our DLED method concurrently exhibits competitive performance.",
    "key_points": [
      "face forgery detection",
      "uncertainty estimation"
    ],
    "gold_summary": "This paper reformulated the OSFFD problem and address it through uncertainty estimation, enhancing its applicability to real-world scenarios. Experiments show that the proposed model achieves state-of-the-art performance."
  },
  {
    "paper_id": "W2UHin1T0R",
    "title": "Learning to Describe Urban Change: Graph-Guided Detection and spatio-Temporal State Space Model with Uncertainty Estimation",
    "domain": "applications to computer vision",
    "content": "Automated change detection (CD) and captioning from satellite imagery plays a crucial role in urban development monitoring, infrastructure assessment, and land-use analysis. However, existing change captioning systems lack uncertainty quantification, making it challenging to assess prediction reliability when analysing critical infrastructure changes, building construction, or environmental modifications where inaccurate interpretations could impact urban planning decisions or infrastructure management. We address this limitation through a comprehensive pipeline combining SemanticGraphCD module for enhanced change detection with a State Space Model(SSM)-based captioning module for scalable description generation. SemanticGraphCD integrates graph neural networks with task-agnostic semantic learning, employing an adaptive processing mechanism that dynamically switches between GNN-based feature propagation and convolutional operations. This architecture learns semantic representations through bi-temporal consistency constraints, better discriminating meaningful infrastructure and land-use changes from temporal variations in very high-resolution imagery. The State Space Model based captioning module contains a Spatial Difference-aware SSM (SD-SSM) which improves upon previous CNN and Transformer-based models in receptive field. Moreover a Temporal Traversing SSM (TT-SSM) is used which scans bi-temporal features in a temporal cross-wise manner enhancing the model's temporal understanding and information interaction. This SSM is guided by SemanticGraphCD's change masks using a convolutional focusing module which aggregates change information from the masks with the bitemporal images. This guides the model in representing the changes between the bi-temporal images within the state space model hidden states, enabling linear computational scaling while maintaining competitive performance. Instead of treating all caption tokens equally in the context of change detection, we introduce Semantic-Weighted Sentence Entropy (SWSE) for principled uncertainty quantification. SWSE emphasizes domain-relevant vocabulary over function words, providing interpretable confidence measures that correlate with caption quality. Experimental results demonstrate that our approach achieves improvement in captioning performance compared to existing state space models, while SWSE provides reliable uncertainty estimates for informed decision-making in urban monitoring applications.",
    "key_points": [
      "change detection",
      "change captioning",
      "state space model",
      "uncertainity estimation",
      "urban development monitoring",
      "deep learning"
    ],
    "gold_summary": "The manuscript aims to present a comprehensive pipeline for automated change captioning from remote sensing imagery. The pipeline integrates SemanticGraphCD, state space models, Semantic Weighted Sentence Entropy."
  },
  {
    "paper_id": "fNC3aaGeIa",
    "title": "Simplicity is Key: An Unsupervised Pretraining Approach for Sparse Radio Channels",
    "domain": "applications to computer vision",
    "content": "We introduce Sparse pretrained Radio Transformer (SpaRTran), an unsupervised representation learning approach based on the concept of compressed sensing for wireless channels. SpaRTran learns embeddings that focus on the physical properties of radio propagation to allow for an efficient fine-tuning on radio-based downstream tasks.\nSpaRTran uses a sparse gated autoencoder that induces a simplicity bias to the learned representations, resembling the sparse nature of radio propagation. For signal reconstruction, it learns a dictionary that holds atomic features, which increases flexibility across signal waveforms and spatio-temporal signal patterns. \nCompared to the state of the art, SpaRTran cuts positioning error by up to 28% and increases top-1 codebook selection accuracy for beamforming by 26%pts. By pretraining models solely on individual channel measurements, it is system-agnostic and more versatile, allowing fine-tuning for diverse radio tasks and substantially reducing labeling costs.",
    "key_points": [
      "unsupervised learning",
      "feature extraction",
      "compressive sensing",
      "location awareness",
      "machine learning",
      "iclr",
      "wireless networks",
      "5g mobile communication",
      "generative pre-trainer"
    ],
    "gold_summary": "The manuscript proposes a transformer based approach for sparse presentation of radio channels."
  },
  {
    "paper_id": "xi9xhoKybM",
    "title": "Med-K2N: Flexible K-to-N Modality Translation for Medical Image Synthesis",
    "domain": "applications to computer vision",
    "content": "Cross-modal medical image synthesis research focuses on reconstructing missing imaging modalities from available ones to support clinical diagnosis. Driven by clinical necessities for flexible modality reconstruction, we explore K→N medical generation, where three critical challenges emerge: (1)How can we model the heterogeneous contributions of different modalities to various target tasks? (2) How can we ensure fusion quality control to prevent degradation from noisy information? (3)How can we maintain modality identity consistency in multi-output generation? Driven by these clinical necessities, and drawing inspiration from SAM2's sequential frame paradigm and clinicians' progressive workflow of incrementally adding and selectively integrating multi-modal information, we treat multi-modal medical data as sequential frames with quality-driven selection mechanisms. Our key idea is to \"learn\" adaptive weights for each modality-task pair and \"memorize\" beneficial fusion patterns through progressive enhancement. To achieve this, we design three collaborative modules: PreweightNet for global contribution assessment, ThresholdNet for adaptive filtering, and EffiWeightNet for effective weight computation. Meanwhile, to maintain modality identity consistency, we propose the Causal Modality Identity Module (CMIM) that establishes causal constraints between generated images and target modality descriptions using vision-language modeling. Extensive experimental results demonstrate that our proposed Med-K2N outperforms state-of-the-art methods by significant margins on multiple benchmarks. Source code is available at https://anonymous.4open.science/r/Med-K2N-74E7/.",
    "key_points": [
      "medical image synthesis；multi-modal learning；clinical ai； quality-aware learning；progressive fusion"
    ],
    "gold_summary": "This paper proposes Med-K2N, a quality-aware progressive fusion framework for medical image synthesis."
  },
  {
    "paper_id": "szTtIL0IFx",
    "title": "Tracking Any Point In Multi-View Videos",
    "domain": "applications to computer vision",
    "content": "Accurate point tracking across video frames is a core challenge in computer vision, but existing single-view approaches often fail in dynamic real-world settings due to the limited geometric information in monocular video. While multi-view inputs provide complementary geometric cues, most current correspondence methods assume rigid scenes, calibrated cameras, or other priors that are rarely available in casual captures. In this work, we introduce the task of multi-view point tracking, which seeks to robustly track query points across multiple, uncalibrated videos of dynamic scenes. We present MV-TAP, a framework that leverages cross-view attention to aggregate spatio-temporal information across views, enabling more complete and reliable trajectory estimation. To support this new task, we construct a large-scale synthetic dataset tailored for multi-view tracking. Extensive experiments demonstrate that MV-TAP outperforms single-view tracking methods on challenging benchmarks, establishing an effective baseline for advancing multi-view point tracking research.",
    "key_points": [
      "video tracking",
      "low-level vision"
    ],
    "gold_summary": "The authors propose a novel multi-view point tracking framework (MV-TAP) that leverages cross-frame information to enhance tracking quality. The framework introduces view-support and view-attention mechanisms to better aggregate information across views."
  },
  {
    "paper_id": "XO5SxIbXQ8",
    "title": "Automotive Object Detection under Adversarial Attacks: A Robust Two-Stage Training Framework",
    "domain": "applications to computer vision",
    "content": "Deep learning-based object detectors are widely used in autonomous driving, but remain vulnerable to adversarial attacks. In this paper, we propose a lightweight and modular two-stage training framework that enhances adversarial robustness by integrating a binary adversarial classifier into the backbone of a Faster Region-Based Convolutional Neural Network (Faster R-CNN). The classifier is trained in two phases: (1) freezing the detector while learning to distinguish adversarial inputs, and (2) joint fine-tuning to refine performance. Our method achieves over 90\\% accuracy in detecting adversarial examples and generalizes well across white-box attack types and strengths, including the Fast Gradient Sign Method (FGSM), Basic Iterative Method (BIM), and Projected Gradient Descent (PGD). The model demonstrated strong zero-shot transferability and achieved further gains after fine-tuning on the target datasets. We evaluated the approach on the Berkeley DeepDrive 100K (BDD100K) dataset and further demonstrated strong cross-dataset robustness on KITTI and nuScenes: the model transfers effectively in a zero-shot setting and achieves AUROC above 0.98 under BIM and PGD attacks after fine-tuning. The proposed defense improves adversarial perturbation detection with minimal impact on object detection accuracy, making it suitable for real-world deployment in automotive systems.",
    "key_points": [
      "adversarial robustness",
      "object detection",
      "faster r-cnn",
      "adversarial examples",
      "automotive perception",
      "binary classifier",
      "two-phase training",
      "fgsm",
      "pgd",
      "bim",
      "adversarial detection",
      "deep learning",
      "model robustness",
      "adversarial defense",
      "transfer learning"
    ],
    "gold_summary": "This paper proposes a two-stage training framework to enhance adversarial robustness in automotive object detection. The method integrates a lightweight binary classifier into the Faster R-CNN backbone to detect adversarial inputs"
  },
  {
    "paper_id": "B7r8ZkBk4F",
    "title": "Two-Way Garment Transfer: Unified Diffusion Framework for Dressing and Undressing Synthesis",
    "domain": "applications to computer vision",
    "content": "While recent advances in virtual try-on (VTON) have achieved realistic garment transfer to human subjects, its inverse task, virtual try-off (VTOFF), which aims to reconstruct canonical garment templates from dressed humans, remains critically underexplored and lacks systematic investigation. Existing works predominantly treat them as isolated tasks: VTON focuses on garment dressing while VTOFF addresses garment extraction, thereby neglecting their complementary symmetry. To bridge this fundamental gap, we propose the Two-Way Garment Transfer Model (TWGTM), to the best of our knowledge, the first unified framework for joint clothing-centric image synthesis that simultaneously resolves both mask-guided VTON and mask-free VTOFF through bidirectional feature disentanglement. Specifically, our framework employs dual-conditioned guidance from both latent and pixel spaces of reference images to seamlessly bridge the dual tasks. On the other hand, to resolve the inherent mask dependency asymmetry between mask-guided VTON and mask-free  VTOFF, we devise a phased training paradigm that progressively bridges this modality gap. Extensive qualitative and  quantitative experiments conducted across the DressCode and VITON-HD datasets validate the efficacy and competitive edge of our proposed approach.",
    "key_points": [
      "diffusion models",
      "image generation",
      "virtual try-on",
      "virtual try-off"
    ],
    "gold_summary": "This paper proposes a unified framework for TryOn and TryOff, implementing both TryOn and TryOff through dual-conditional control. It achieves excellent performance on both TryOn and TryOff tasks."
  },
  {
    "paper_id": "YgOY1QTEZj",
    "title": "Language-Guided 4D Gaussian Splatting for Real-Time Dynamic Scene Rendering",
    "domain": "applications to computer vision",
    "content": "Dynamic rendering methods often prioritize photometric fidelity while lacking explicit semantic representations, which constrains their ability to perform semantically guided rendering. To this end, we introduce Language-Guided 4D Gaussian Splatting (L4DGS), a lightweight framework for real-time dynamic scene rendering that integrates natural language into semantically structured 4D Gaussian representations. Central to L4DGS is a Sparse Multi-Scale Attention (SMSA) mechanism that enables fine-grained, language-driven control by emphasizing semantically relevant regions across space and time. To enforce semantic fidelity and spatial coherence, we propose a static regularization that aligns language-guided features with rendered outputs and ensures consistent depth. To further ensure temporal consistency, A dynamic regularization penalizes abnormal variations in semantics and depth over consecutive unit time intervals. L4DGS achieves a 16.1% improvement in PSNR, reduces perceptual error by 58.8%, and increases rendering speed by over 50\\%. Experimental results demonstrate the superiority of our approach in both visual quality and computational efficiency.",
    "key_points": [
      "novel view synthesis",
      "dynamic scene",
      "gaussian splatting"
    ],
    "gold_summary": "This paper introduces a language-guided regularization loss to enhance semantic consistency and rendering quality in 4D Gaussian Splatting (4DGS)."
  },
  {
    "paper_id": "vr6bwTvhH7",
    "title": "A Dataset and Benchmark for 3D Part Recognition from 2D Images",
    "domain": "applications to computer vision",
    "content": "While 3D semantic part understanding underpins numerous downstream applications, 3D part detection from images remains underexplored due to limited annotated datasets. To address this, we introduce DST-Part3D, a 3D semantic part dataset with $3,300$ fine-grained 3D part annotations across $475$ shapes from $50$ object categories, paired with $125,000$ realistic synthetic images. DST-Part3D enables training and evaluation of 3D part detection from images, 2D part segmentation via projection, and benchmarking of 3D correspondence quality through transferred part labels. Using this dataset, we develop Part321, an algorithm that recognizes 3D parts in images using only one annotated mesh per category. Part321 establishes mesh-to-mesh and mesh-to-image correspondences to propagate part pseudo-labels across instances, allowing effective 3D part detector training with minimal supervision. Experiments demonstrate that Part321 outperforms previous methods on 3D and 2D part detection tasks. In addition, we use DST-Part3D to analyze the mesh-to-mesh correspondence obtained by different methods leveraging transferred 3d part labels, highlighting the key challenge in 3D part correspondence, which provides insight into future work.",
    "key_points": [
      "3d vision",
      "3d from single image",
      "3d part recognition"
    ],
    "gold_summary": "This paper introduces a novel dataset comprising 475 3D shapes paired with part annotation and corresponding 2D images, and proposes a one-shot part segmentation method applicable to both 2D and 3D inputs."
  },
  {
    "paper_id": "QtlEWXJq2K",
    "title": "Cube Kernel: Enabling Local Gradient Flow Across Channels in CNNs for Robust and Efficient Building Segmentation",
    "domain": "applications to computer vision",
    "content": "Understanding inter-band and cross-channel relationships is fundamental to human color perception and object recognition. However, conventional CNN-based image processing fails to propagate local gradients across channels during backpropagation, limiting cross-channel interactions until the summation stage. To address this limitation, we develop Cube Kernel, a plug-and-play convolutional operator that enforces local cross-channel gradient coupling by mapping channels onto a finer spatial lattice through group-based re-construction. To further enhance flexibility in feature grouping, we introduce a learnable router that adaptively reorders channels and emphasizes task-relevant representations. This is combined with a spatial attention mechanism, which effectively suppresses redundant responses introduced during reconstruction. Across multiple CNN-based and Transformer-based backbones, Cube Kernel delivers consistent improvements on the WBD, WHU, and Inria datasets. ConvNeXt-U-Cube achieves an F1 score of 90.42% and an mIoU of 82.63% on Inria, surpassing recent state-of-the-art methods with reductions of 9.2% and 20.8% in parameters and GFLOPs, respectively. Ablations isolate the effect of re-construction, the router, and attention, and analysis shows stronger inter-channel decorrelation. Owing to its lightweight design, compatibility with diverse architectures, and ability to be stacked across layers, Cube Kernel is highly implantable and can serve as a strong default operator for structured channel mixing in dense prediction. All code will be made publicly available.",
    "key_points": [
      "cube kernel",
      "channel-wise convolution",
      "inter-channel gradient flow",
      "convolutional neural networks",
      "building rooftop extraction",
      "semantic segmentation",
      "remote sensing"
    ],
    "gold_summary": "The paper develops a convolutional operator called Cube Kernel that enforces local cross-channel gradient coupling by mapping channels onto a finer spatial lattice."
  },
  {
    "paper_id": "OmRdnZA9rn",
    "title": "SimpliHuMoN: Simplifying Human Motion Prediction",
    "domain": "applications to computer vision",
    "content": "Human motion prediction combines the tasks of trajectory forecasting, human pose prediction, and possibly also multi-person modeling. \nFor each of the three tasks, specialized, sophisticated models have been developed due to the complexity and uncertainty of human motion. While compelling for each task, combining these models for holistic human motion prediction is non-trivial. Conversely, holistic human motion prediction methods, which have been introduced recently, have struggled to compete on established benchmarks for individual tasks. To address this dichotomy, we study a simple yet effective model for human motion prediction based on a transformer architecture. The model employs a stack of self-attention modules to effectively capture both spatial dependencies within a pose and temporal relationships across a motion sequence. This simple, streamlined, end-to-end model is sufficiently versatile to handle pose-only, trajectory-only, and combined prediction tasks without task-specific modifications. We demonstrate that our approach achieves state-of-the-art results across all tasks through extensive experiments on a wide range of benchmark datasets, including Human3.6M, AMASS, ETH-UCY, and 3DPW. Our results challenge the prevailing notion that architectural complexity is a prerequisite for achieving accuracy and generality in human motion prediction. Code will be released.",
    "key_points": [
      "human motion prediction",
      "generalist model",
      "pose prediction",
      "trajectory prediction"
    ],
    "gold_summary": "This paper proposes a Transformer-based approach for human motion prediction. It combines two kinds of tasks, including pose prediction and trajectory prediction."
  },
  {
    "paper_id": "WLSt5tIOSA",
    "title": "Fine-tuning VLMs Without Forgetting Is Easier Than You Think",
    "domain": "applications to computer vision",
    "content": "*This paper does not propose a new method; rather, we find that simple adjustments of the fine-tuning recipes of vision language models (VLM) are sufficient to mitigate catastrophic forgetting.* Using visual question answering tasks, we design a 2×2 experimental framework to assess model performance across in-distribution and out-of-distribution image and text inputs. Our results show that appropriate regularization, such as constraining the number of trainable parameters or adopting a low learning rate, effectively prevents forgetting when dealing with out-of-distribution images. However, we uncover a distinct form of forgetting in settings with in-distribution images and out-of-distribution text. We attribute this forgetting as task-specific overfitting and address this issue by introducing a data-hybrid training strategy that combines datasets and tasks. Finally, we demonstrate that this approach naturally extends to continual learning, outperforming existing methods without the need for complex auxiliary mechanisms. In general, our findings challenge the prevailing assumptions by highlighting the inherent robustness of VLMs and providing practical guidelines for adapting them while preserving their general-purpose capabilities.",
    "key_points": [
      "vlm finetuning",
      "catastrophic forgetting",
      "continual learning"
    ],
    "gold_summary": "The paper provides experimental results to support that with appropriate regularization (low learning rate, constraining trainable params), VLMs prevent forgetting. Extensions to continual learning are shown, and practical guidelines."
  },
  {
    "paper_id": "7JT8yIPELM",
    "title": "MemGUI-Bench: Benchmarking Memory of Mobile GUI Agents in Dynamic Environments",
    "domain": "applications to computer vision",
    "content": "Current mobile GUI agent benchmarks systematically fail to assess memory capabilities, with only 5.2-11.8\\% memory-related tasks and no cross-episode learning evaluation. We introduce \\textbf{MemGUI-Bench}, the first comprehensive benchmark designed to assess both short-term and long-term memory in mobile GUI agents. Our contributions include: (1) a systematic memory taxonomy with analysis of 11 prominent agents; (2) 128 tasks across 26 applications where 89.8\\% challenge memory through cross-temporal and cross-spatial information retention; (3) \\textbf{MemGUI-Eval}, an automated evaluation pipeline with novel \"Progressive Scrutiny\" and 8 hierarchical metrics for memory fidelity and learning effectiveness; and (4) comprehensive assessment revealing significant memory deficits across all evaluated agents. Our experiments expose 4-10× performance gaps between memory-intensive and standard tasks, demonstrate the potential of explicit long-term memory mechanisms, and identify 7 distinct failure modes through systematic analysis. MemGUI-Bench establishes crucial empirical baselines for developing more capable and human-like GUI agents. Code and results: \\url{https://anonymous.4open.science/r/MemGUI-Bench-Anonymous}.",
    "key_points": [
      "agent",
      "mllm",
      "memory",
      "nlp"
    ],
    "gold_summary": "This paper proposed a benchmark to evaluate short- and long-term memory usage among mobile GUI agents. This paper aggregates tasks from varied applications and compares 11 agent frameworks, revealing their relative performance."
  },
  {
    "paper_id": "nErnNhJx2o",
    "title": "REORIENTING THE FROZEN SPACE: TRAINING-FREE TEST-TIME ADAPTATION BY GEOMETRIC TRANSFORMATION",
    "domain": "applications to computer vision",
    "content": "With the widespread application of Vision-Language Models (VLMs) in downstream tasks, test-time adaptation methods based on VLMs, particularly the training-free paradigm, have been gaining increasing attention due to their advantages in handling distribution shifts during testing. Yet, existing training-free methods remain constrained by the fixed geometry of pretrained feature spaces, which limits class separability. We propose SOBA, a training-free TTA method that edits decision geometry by re-expressing class prototypes in a test-induced orthogonal basis. SOBA maintains a lightweight dynamic queue of high-confidence test samples, derives an orthogonal basis via singular value decomposition, and aligns prototypes to the most discriminative directions of the test distribution. This simple adjustment enlarges inter-class margins, sharpens decision boundaries, and improves the recognition of semantically similar categories—without modifying features, prompts, or model parameters. Extensive experiments on multiple benchmarks demonstrate that SOBA achieves state-of-the-art accuracy and superior efficiency compared to both training-free and backprop-based TTA methods.",
    "key_points": [
      "training-free test-time adaptation",
      "vision-language model",
      "clip"
    ],
    "gold_summary": "The paper proposes to use orthogonal basis transformation on the embeddings in visual-language models (VLMs), such as CLIP, for better out-of-distribution (OOD) detection."
  },
  {
    "paper_id": "AzbqTZAfvW",
    "title": "iLRM: An Iterative Large 3D Reconstruction Model",
    "domain": "applications to computer vision",
    "content": "Feed-forward 3D modeling has emerged as a promising approach for rapid and high-quality 3D reconstruction.\nIn particular, directly generating explicit 3D representations, such as 3D Gaussian splatting, has attracted significant attention due to its fast and high-quality rendering, as well as numerous applications.\nHowever, many state-of-the-art methods, primarily based on transformer architectures, suffer from severe scalability issues because they rely on full attention across image tokens from multiple input views, resulting in prohibitive computational costs as the number of views or image resolution increases.\nToward a scalable and efficient feed-forward 3D reconstruction, we introduce an iterative Large 3D Reconstruction Model (*iLRM*) that generates 3D Gaussian representations through an iterative refinement mechanism, guided by three core principles: (1) decoupling the scene representation from input-view images to enable *compact 3D representations*; (2) decomposing fully-attentional multi-view interactions into a *two-stage attention* scheme to reduce computational costs; and (3) injecting *high-resolution information at every layer* to achieve high-fidelity reconstruction. Experimental results on widely used datasets, such as RE10K and DL3DV, demonstrate that iLRM outperforms existing methods in both reconstruction quality and speed.",
    "key_points": [
      "feed-forward 3d reconstruction",
      "3d gaussian splatting",
      "multi-view geometry"
    ],
    "gold_summary": "The paper introduces iLRM, an iterative 3D reconstruction model that overcomes the severe scalability issues of previous feed-forward methods by decoupling the scene representation from the input images."
  },
  {
    "paper_id": "gorR3RUgwy",
    "title": "When Glass Disappears at Night: A Novel NIR-RGB Multi-modal Solution",
    "domain": "applications to computer vision",
    "content": "Glass surface detection (GSD) has recently been attracting research interests. However, existing GSD methods focus on modeling glass surface properties for daytime scenes, and can easily fail in nighttime scenes due to significant lighting discrepancies. We observe that, due to the spectral differences between Near-Infrared (NIR) light sources and common LED lights, NIR and RGB cameras capture complementary visual patterns (e.g., light reflections, shadows, and edges) of glass surfaces, and cross-comparing their lighting and reflectance information can provide reliable cues for GSD at nighttime. Inspired by this observation, we propose a novel approach for nighttime GSD based on the multi-modal NIR and RGB image pairs. We first construct a nighttime GSD dataset, which contains 6,192 RGB-NIR image pairs captured in diverse real-world nighttime scenes, with corresponding carefully-annotated glass surface masks. We then propose a novel network for the nighttime GSD task with two novel modules: (1) a RGB-NIR Guidance Enhancement (RNGE) module for extracting and enriching the NIR reflectance features with the guidance of RGB reflectance features, and (2) a RGB-NIR Fusion and Localization (RNFL) module for fusing RGB and NIR reflectance features into glass features conditioned on the multi-modal illumination discrepancy-aware features. Extensive experiments demonstrate that our method outperforms state-of-the-art methods in nighttime scenes while generalizing well to daytime scenes. We will release our dataset and codes.",
    "key_points": [
      "glass surface detection",
      "multi-modal image",
      "deep learning"
    ],
    "gold_summary": "This submission introduces a method for glass detection at night by proposing an approach for nighttime glass surface detection."
  },
  {
    "paper_id": "wUkAwglpzD",
    "title": "Fine-grained Contrastive Learning for ECG-Report Alignment with Waveform Enhancement",
    "domain": "applications to computer vision",
    "content": "Electrocardiograms (ECGs) are essential for diagnosing cardiovascular diseases. However, existing ECG-Report contrastive learning methods focus on whole-ECG and report alignment, missing the link between local ECG features and individual report tags.\nIn this paper, we propose FG-CLEP (Fine-Grained Contrastive Language ECG Pre-training), which achieves fine-grained alignment between specific ECG segments and each tag in the report via tag-specific ECG representations. Furthermore, we found that nearly 55\\% of ECG reports in the MIMIC-ECG training dataset lack detailed waveform features, which hinders fine-grained alignment. To address this, we introduce a coarse-to-fine training process that leverages large language models (LLMs) to recover these missing waveform features and validate the LLM outputs using a coarse model. Additionally, fine-grained alignment at the tag level, rather than at the report level, exacerbates the false negative problem, as different reports may share common tags. To mitigate this, we introduce a semantic similarity matrix to guide the model in identifying and correcting false negatives. \nExperiments on six datasets demonstrate that FG-CLEP significantly improves fine-grained alignment, outperforming state-of-the-art methods in both zero-shot prediction and linear probing. Meanwhile, the fine-grained reports we generate also enhance the performance of other methods.",
    "key_points": [
      "ecg",
      "fine-grained alignment",
      "multimodal contrastive learning"
    ],
    "gold_summary": "This paper presents FG-CLEP, a fine-grained ECG–report alignment model that links ECG patches with report tags."
  },
  {
    "paper_id": "EPN5MU4liR",
    "title": "A^2TG: Adaptive Anisotropic Textured Gaussians for Efficient 3D Scene Representation",
    "domain": "applications to computer vision",
    "content": "Gaussian Splatting has emerged as a powerful representation for high-quality, real-time 3D scene rendering. While recent works extend Gaussians with learnable textures to enrich visual appearance, existing approaches allocate a fixed square texture per primitive, leading to inefficient memory usage and limited adaptability to scene variability. In this paper, we introduce adaptive anisotropic textured Gaussians (A$^2$TG), a novel representation that generalizes textured Gaussians by equipping each primitive with an anisotropic texture. Our method employs a gradient-guided adaptive rule to jointly determine texture resolution and aspect ratio, enabling non-uniform, detail-aware allocation that aligns with the anisotropic nature of Gaussian splats. This design significantly improves texture efficiency, reducing memory consumption while enhancing image quality. Experiments on multiple benchmark datasets demonstrate that A$^2$TG consistently outperforms fixed-texture Gaussian Splatting methods, achieving comparable rendering fidelity with substantially lower memory requirements.",
    "key_points": [
      "computer vision;novel view synthesis:neural rendering;3d gaussian splatting"
    ],
    "gold_summary": "The paper proposes Adaptive Anisotropic Textured Gaussians (A2TG), which equips each Gaussian primitive with an anisotropic, gradient-adaptive texture, improving memory efficiency and visual fidelity over fixed-square textures in real-time 3D scene rendering."
  },
  {
    "paper_id": "ehbcigJ6wH",
    "title": "MRS-YOLO : A YOLO model for signal detection in multi-resolution spectrograms",
    "domain": "applications to computer vision",
    "content": "Many real-world signals contain structures spanning multiple time–frequency (TF) scales, where short transients and long-duration patterns coexist. Standard spectrograms, based on the short-time Fourier transform, are constrained by the Heisenberg uncertainty principle, consequently, fixed-resolution detectors often miss critical information.  We propose MRS-YOLO, a multi-resolution extension of YOLO that processes spectrograms at complementary scales through parallel branches and fuses them with an attention block.  On a challenging dataset of heterogeneous radio-frequency signals with spectral congestion, low SNR, and stealthy emissions, MRS-YOLO achieves higher recall in low-SNR regimes and stronger classification accuracy than single-resolution baselines, demonstrating the value of explicit multi-scale representation learning in TF analysis. Code available at https://github.com/ICLRanonymous2026/MRS_YOLO_ICLR26.",
    "key_points": [
      "multi-resolution learning",
      "spectrogram object detection",
      "yolo",
      "time–frequency (tf) analysis",
      "attention mechanisms"
    ],
    "gold_summary": "This paper proposes MRS-Yolo, a Yolo-based model for signal detection in multi-resolution spectrograms. The idea of using multi-resolution analysis is well-motivated in digital signal processing, though similar approaches have been explored in previous works."
  },
  {
    "paper_id": "PTzByqd0aJ",
    "title": "CoEmoGen: Towards Semantically-Coherent and Scalable Emotional Image Content Generation",
    "domain": "applications to computer vision",
    "content": "Emotional Image Content Generation (EICG) aims to generate semantically clear and emotionally faithful images based on given emotion categories, with broad application prospects. While recent text-to-image diffusion models excel at generating concrete concepts, they struggle with the complexity of abstract emotions. There have also emerged methods specifically designed for EICG, but they excessively rely on word-level attribute labels for guidance, which suffer from semantic incoherence, ambiguity, and limited scalability. To address these challenges, we propose CoEmoGen, a novel pipeline notable for its semantic coherence and high scalability. Specifically, leveraging multimodal large language models (MLLMs), we construct high-quality captions focused on emotion-triggering content for context-rich semantic guidance. Furthermore, inspired by psychological insights, we design a Hierarchical Low-Rank Adaptation (HiLoRA) module to cohesively model both polarity-shared low-level features and emotion-specific high-level semantics. Extensive experiments demonstrate CoEmoGen’s superiority in emotional faithfulness and semantic coherence from quantitative, qualitative, and user study perspectives. To intuitively showcase scalability, we curate EmoArt, a large-scale dataset of emotionally evocative artistic images, providing endless inspiration for emotion-driven artistic creation. The dataset and code will be available on GitHub.",
    "key_points": [
      "emotional image content generation",
      "semantically-coherent sentence-level guidance",
      "hierarchical lora"
    ],
    "gold_summary": "The paper introduces CoEmoGen, a diffusion-based approach to generate emotion-conditioned images by utilizing hierarchical LORAs."
  },
  {
    "paper_id": "orEZifISvf",
    "title": "Learning to Enhance Low-Light Images with Reliable Attention and Reinforced Distribution Alignment",
    "domain": "applications to computer vision",
    "content": "Low-light image enhancement (LLIE) methods have recently adopted the HVI color space, which alleviates the entanglement between luminance and color and improves color fidelity through chrominance polarization and intensity compression. However, existing approaches may suffer from error accumulation during the interaction between luminance and chrominance components, and the lack of fine-grained modeling of color distribution can lead to unsatisfactory enhancement results. To address these challenges, we propose a novel low-light image enhancement framework, Learning to Enhance Low-Light Images with Reliable Attention and Reinforced Distribution Alignment. Specifically, we introduce two key modules: the Reliable Cross Attention (RCA) module, which aggregates luminance and chrominance features with reliable queries, and the Reinforced Distribution Alignment (RDA) module, which robustly fits the color distribution in a more fine-grained manner. These designs significantly improve the quality of enhanced images under low-light conditions. Extensive experiments on multiple benchmark datasets demonstrate that our method achieves state-of-the-art performance compared with existing approaches.",
    "key_points": [
      "attention mechanism",
      "gaussian mixture model",
      "low-light image enhancement"
    ],
    "gold_summary": "This manuscript proposes a novel low-light image enhancement framework by introducing a reliable cross-attention and reinforced distribution alignment. Comprehensive experiments and ablation analyses across ten benchmark datasets consistently validate the superiority of the proposed method."
  },
  {
    "paper_id": "70n4clRSTj",
    "title": "Time Blindness: Why Video-Language Models Can’t See What Humans Can?",
    "domain": "datasets and benchmarks",
    "content": "Recent advances in vision–language models (VLMs) have made impressive strides in understanding spatio-temporal relationships in videos. However, when spatial information is obscured, these models struggle to capture purely temporal patterns. We introduce $\\textbf{SpookyBench}$, a benchmark where information is encoded solely in temporal sequences of noise-like frames, mirroring natural phenomena from biological signaling to covert communication. Interestingly, while humans can recognize shapes, text, and patterns in these sequences with over 98\\% accuracy, state-of-the-art VLMs achieve 0\\% accuracy. This performance gap highlights a critical limitation: an over-reliance on frame-level spatial features and an inability to extract meaning from temporal cues. Overcoming this limitation will require novel architectures or training paradigms that decouple spatial dependencies from temporal processing. Our systematic analysis shows that this issue persists across model scales and architectures. We release SpookyBench to catalyze research in temporal pattern recognition and bridge the gap between human and machine video understanding. Dataset is available at this anonymous link: https://tinyurl.com/spooky-bench",
    "key_points": [
      "vision language models",
      "temporal understanding",
      "benchmark construction",
      "low snr dataset"
    ],
    "gold_summary": "The paper introduces SpookyBench, a benchmark to test whether video-language models can understand information encoded in temporal patterns rather than spatial features. Humans easily perceive these patterns, but all reported models fail completely."
  },
  {
    "paper_id": "uDgDuVMpfW",
    "title": "MultiHal: MultiLingual Dataset for Knowledge-Graph Grounded Evaluation of LLM Hallucinations",
    "domain": "datasets and benchmarks",
    "content": "Large Language Models (LLMs) have inherent limitations of faithfulness and factuality, commonly referred to as hallucinations. Several benchmarks have been developed that provide a test bed for factuality evaluation within the context of English-centric datasets, while relying on supplementary informative context like web links or text passages but ignoring the available structured factual resources. To this end, Knowledge Graphs (KGs) have been identified as a useful aid for hallucination mitigation, as they provide a structured way to represent the facts about entities and their relations with minimal linguistic overhead. We bridge the lack of KG paths and multilinguality for factual language modeling within the existing hallucination evaluation benchmarks and propose a KG-based multilingual, multihop benchmark called **MultiHal** framed for generative text evaluation. As part of our data collection pipeline, we mined 140k KG-paths from open-domain KGs, from which we pruned noisy KG-paths, curating a high-quality subset of 25.9k. Our baseline evaluation shows an absolute scale improvement by approximately 0.12 to 0.36 points for the semantic similarity score, 0.16 to 0.36 for NLI entailment and 0.29 to 0.42 for hallucination detection in KG-RAG over vanilla QA across multiple languages and multiple models, demonstrating the potential of KG integration. We anticipate MultiHal will foster future research towards several graph-based hallucination mitigation and fact-checking tasks.",
    "key_points": [
      "factuality",
      "llms",
      "knowledge graphs",
      "hallucinations"
    ],
    "gold_summary": "This paper introduces MultiHal, a multilingual, knowledge-graph (KG)-grounded benchmark for evaluating LLM hallucinations, addressing critical gaps in existing English-centric."
  },
  {
    "paper_id": "mDXSvmz4np",
    "title": "TRACE: Coarse-to-Fine Automated Evaluation of Mobile Agents with Safety Considerations in Realistic Environments",
    "domain": "datasets and benchmarks",
    "content": "The online evaluation of mobile agents is becoming increasingly important for both accurately assessing agent capabilities and providing reward signals for online reinforcement learning. Evaluating mobile agents on complex multi-step tasks remains challenging, as existing work suffers from limitations in reliability and generality, while overlooking issues of environmental realism and operational safety. This paper introduces TRACE (TRajectory-based Automated Coarse-to-fine Evaluation), a fully automated vision language model (VLM)-based method designed to evaluate arbitrary mobile agents across diverse environments. TRACE evaluates agent trajectories in a two-stage manner, first through step-wise assessment and then through overall judgment, which significantly reduces evaluation difficulty and enhances reliability. Potentially risky or harmful operations are also detected simultaneously during the step-wise assessment. Furthermore, we construct TRACEBench, a scalable benchmark consisting of 187 tasks from 35 commonly used mobile applications, to better reflect the actual performance of agents in realistic online environments. Task design explicitly considers operational safety, and evaluation metrics cover three key dimensions: task completion, safety, and resource consumption. Experiments show that TRACE achieves an F1 score of 0.836 with the open-sourced Qwen2.5-VL-72B-Instruct, indicating high precision as well as better usability and cost-effectiveness. Extensive evaluation of 8 representative mobile agents on TRACEBench reveals that current mobile agents still have substantial room for improvement, particularly in terms of task completion and operational safety.",
    "key_points": [
      "mobile agents",
      "benchmark",
      "vision language models"
    ],
    "gold_summary": "The paper proposes TRACE, a coarse-to-fine method for judging mobile agent trajectories, along with a new benchmark for mobile agents, TRACEBench. The paper evaluates and analyzes several existing models on TRACEBench."
  },
  {
    "paper_id": "f43lpq1Q8i",
    "title": "When Validity Isn't Enough: Reliability Gaps in Molecular Generation and KRAS Case Study",
    "domain": "datasets and benchmarks",
    "content": "Molecule generation remains a core challenge in computational chemistry. Practical use of generative models is complicated by strict chemical, structural, and biological constraints: candidate compounds must satisfy physicochemical bounds, avoid reactive or toxic substructures, be synthesizable, and plausibly bind a target. We are the first to perform such comprehensive analysis of modern molecule generators via the Five-Stage Filtering Pipeline, a target-agnostic, practice-oriented benchmark for evaluating de novo generators using the following stages:  (i) physicochemical descriptors; (ii) structural alerts; (iii) synthesis feasibility; (iv) docking and binding affinity estimation; and (v) blind medicinal chemist review. We compare 18 generators across three families (unconditional, ligand-based, and protein-based), and to make it practically relevant, apply the pipeline to KRAS G12D switch-II pocket for conditional design case study. Less than 1% of molecules pass all stages, exposing a gap between high scores on standard generative metrics and practical medicinal chemistry usage. We release our benchmark, and code to enable reproducible evaluation and to focus future model development on practically useful chemical space.",
    "key_points": [
      "molecule generation",
      "generative models",
      "kras",
      "benchmark"
    ],
    "gold_summary": "This paper presents a 5 stage pipeline for evaluating molecular generators."
  },
  {
    "paper_id": "tQJYKwc3n4",
    "title": "RoboCasa365: A Large-Scale Simulation Framework for Training and Benchmarking Generalist Robots",
    "domain": "datasets and benchmarks",
    "content": "Recent advances in robot learning have accelerated progress toward generalist robots that can operate across diverse tasks and environments. Yet despite this momentum, it remains difficult to gauge how close we are to this goal, as the field lacks a reproducible, large-scale benchmark for systematic evaluation. To address this gap, we present RoboCasa365, a comprehensive robot simulation benchmark for everyday tasks. Built on the RoboCasa platform, RoboCasa365 introduces 365 everyday tasks across 2,500 diverse kitchen environments, and over 2,000 hours of robot interaction data, making it one of the most diverse and large-scale resources for studying generalist policies. We design the benchmark to support evaluation across key settings, including multi-task learning, robot foundation model training, and lifelong learning. We present extensive experiments with state-of-the-art methods and analyze how task diversity, dataset scale, and environment variation shape generalization. Our results provide new insights into what factors most strongly affect the performance of generalist robots and help inform strategies for future progress in the field.",
    "key_points": [
      "robot datasets and benchmarking",
      "vision-language-action models",
      "robot simulation"
    ],
    "gold_summary": "The authors presented RoboCasa365, a large-scale simulation framework for benchmarking generalist robot policies, and offer large pre-training and post-training datasets as well. It provides 2500 kitchen environments with 2000 hours of simulated robot data."
  },
  {
    "paper_id": "28uCSxzPT6",
    "title": "Towards Large Reasoning Models for Agriculture",
    "domain": "datasets and benchmarks",
    "content": "Agricultural decision-making involves complex, context-specific reasoning, where choices about crops, practices, and interventions depend heavily on geographic, climatic, and economic conditions. Traditional large language models (LLMs) often fall short in navigating this nuanced problem due to limited reasoning capacity. We hypothesize that recent advances in large reasoning models (LRMs) can better handle such structured, domain-specific inference. To investigate this, we introduce AgReason, the first expert-curated open-ended science benchmark with 100 questions for agricultural reasoning. Evaluations across eighteen open-source and proprietary models reveal that LRMs outperform conventional ones, though notable challenges persist, with the strongest Gemini–based baseline achieving 36% accuracy. We also present AgThoughts, a large-scale dataset of 44.6K question-answer pairs generated with human oversight and equipped with synthetically generated reasoning traces. Using AgThoughts, we develop AgThinker, a suite of small reasoning models that can be run on consumer-grade GPUs, and show that our dataset can be effective in unlocking agricultural reasoning abilities in LLMs.",
    "key_points": [
      "large language models (llms)",
      "dataset",
      "agriculture benchmark"
    ],
    "gold_summary": "The paper introduces an open-ended reasoning benchmark and a suite of reasoning models for the domain of agriculture."
  },
  {
    "paper_id": "kCnokG3SfU",
    "title": "FedAgentBench: Towards Automating Real-world Federated Medical Image Analysis with Server–Client LLM Agents",
    "domain": "datasets and benchmarks",
    "content": "Federated learning (FL) allows collaborative model training across healthcare sites without sharing sensitive patient data. However, real-world FL deployment is often hindered by complex operational challenges that demand substantial human efforts in cross-client coordination and data engineering. This includes: (a) selecting appropriate clients (hospitals), (b) coordinating between the central server and clients, (c) client-level data pre-processing, (d) harmonizing non-standardized data and labels across clients, and (e) selecting FL algorithms based on user instructions and cross-client data characteristics. However, the existing FL works overlook these practical orchestration challenges. These operational bottlenecks motivate the need for autonomous, agent-driven FL systems, where intelligent agents at each hospital client and the central server agent collaboratively manage FL setup and model training with minimal human intervention. To this end, we first introduce: (i) an agent-driven FL framework that captures key phases of real-world FL workflows from client selection to training completion, and (ii) a benchmark dubbed FedAgentBench that evaluates the ability of LLM agents to autonomously coordinate healthcare FL. Our framework incorporates 40 FL algorithms, each tailored to address diverse task-specific requirements and cross-client characteristics. Furthermore, we introduce a diverse set of complex tasks across 201 carefully curated datasets, simulating 6 modality-specific real-world healthcare environments, viz., Dermatoscopy, Ultrasound, Fundus, Histopathology, MRI, and X-Ray. We assess the agentic performance of 14 open-source and 10 proprietary LLMs spanning small, medium, and large model scales. While some agent cores such as GPT-4.1 and DeepSeek V3 can automate various stages of the FL pipeline, our results reveal that more complex, interdependent tasks based on implicit goals remain challenging for even the strongest models.",
    "key_points": [
      "medical image analysis",
      "dermatoscopy",
      "ultrasound",
      "fundus",
      "histopathology",
      "mri",
      "x-ray",
      "federated learning"
    ],
    "gold_summary": "This paper presents FedAgentBench, the first systematic benchmark applying the LLM Agent framework to FL operation automation, particularly in medical image analysis, representing a meaningful step toward agent-driven FL automation."
  },
  {
    "paper_id": "NskQgtSdll",
    "title": "PepBenchmark: A Standardized Benchmark for Peptide Machine Learning",
    "domain": "datasets and benchmarks",
    "content": "Peptide therapeutics are widely regarded as the “third generation” of drugs, yet progress in peptide Machine Learning (ML) are hindered by the absence of standardized benchmarks. Here we present \\textbf{PepBenchmark}, which standardizes datasets, preprocessing, and evaluation protocols for peptide drug discovery. PepBenchmark comprises three components: (1) \\textbf{PepBenchData}, a well-curated collection comprising 29 canonical-peptide and 6 non-canonical-peptide datasets across 7 groups, systematically covering key aspects of peptide drug development—representing, to the best of our knowledge, the most comprehensive AI-ready dataset resource to date; (2) \\textbf{PepBenchPipeline}, a standardized preprocessing pipeline that ensures consistent cleaning, representation conversion, and dataset splitting, addressing the quality issues that often arise from ad-hoc pipelines; and (3) \\textbf{PepBenchLeaderboard}, a unified evaluation protocol and leaderboard with strong baselines across 4 major methodological families: fingerprint-based, GNN-based, PLM-based, and SMILES-based models. Together, PepBenchmark provides the first standardized and comparable foundation for peptide drug discovery, facilitating methodological advances and translation into real-world applications. Code is included in the supplementary material and will be made publicly available.",
    "key_points": [
      "peptide machine learning",
      "benchmark",
      "protein language models"
    ],
    "gold_summary": "This paper introduces PepBenchmark, a standardized benchmark for peptide machine learning that unifies diverse datasets(PepBenchData), standardized preprocessing(PepBenchPipeline), and unified evaluation protocols(PepBenchLeaderboard) across diverse peptide-related tasks."
  },
  {
    "paper_id": "zGxAx4WFHO",
    "title": "AutoQG: An Automated Framework for Evidence-Traceable Question Generation via Ontology-Guided Knowledge Graph Construction",
    "domain": "datasets and benchmarks",
    "content": "Large Language Models (LLMs) present unprecedented opportunities for generating scientific questions. However, existing approaches face two key limitations: heavy reliance on costly human annotations and the production of brittle, unverifiable outputs. To address these challenges, we propose AutoQG, a fully automated multi-agent framework for evidence-grounded scientific QA generation. AutoQG comprises three complementary agents: (i) KG Extraction Agent, which performs ontology-guided knowledge graph construction with section-aware prompts for precise information retrieval; (ii) KG Evaluation Agent, a multi-dimensional evaluation module with iterative refinement to ensure accuracy and consistency; and (iii) QA Generation Agent, which produces schema-constrained QA pairs grounded in reasoning paths and explicit textual evidence. Applied to over 4,000 scientific papers, AutoQG constructs 243k triples and introduces AutoQG-20k, a benchmark containing more than 20,000 QA pairs. Each pair is explicitly linked to its reasoning chains and supporting evidence, ensuring transparency and verifiability. We further release AutoQG-7k, a challenging subset designed with hard questions that strong LLMs struggle to answer. Extensive experiments demonstrate that AutoQG consistently outperforms strong baselines in both human evaluation and LLM-as-a-Judge assessments. By transforming LLM output into a controlled and auditable pipeline, AutoQG advances evidence-based AI for the understanding of reliable scientific knowledge. Source code will be released upon publication.",
    "key_points": [
      "knowledge graph construction",
      "question generation",
      "multi-agent systems"
    ],
    "gold_summary": "The authors proposed AutoQG, a fully automated multi-agent framework for evidence-grounded scientific QA generation."
  },
  {
    "paper_id": "jSM71b1JsV",
    "title": "Battery Fault: A Comprehensive Dataset and Benchmark for Battery Fault Diagnosis",
    "domain": "datasets and benchmarks",
    "content": "With the accelerated popularization of electric vehicles (EV), battery safety issues have become an important research focus. Data-driven battery fault diagnosis algorithms, built on real-world operational data, are critical methods for reducing safety risks. However, existing battery datasets have limitations such as insufficient scale, coarse-grained labels, and lack of coverage of real-world operating conditions, which seriously restrict the development of data-driven fault diagnosis algorithms. To address these issues, this paper introduces a large-scale benchmark dataset named \\textbf{CH-BatteryGen}, which is, to the best of our knowledge, the first EV battery system fault diagnosis dataset based on real-world operating conditions. This dataset integrates real on-board operation data with mechanism-constrained generative modeling technology, balancing authenticity and scalability. It covers two mainstream battery chemistries, namely nickel-cobalt-manganese (NCM) lithium batteries and lithium iron phosphate (LFP) batteries, and involves charging, discharging, and operation data of 1000 electric vehicles. It provides four fault labels (normal, self-discharge, high-resistance, low-capacity) and three severity level annotations, supporting two benchmark tasks: fault classification and fault grading. Through systematic validation using traditional machine learning methods (random forest (RF), support vector machine (SVM)) and deep learning models (long short-term memory (LSTM), convolutional neural network (CNN)), the results show that the CNN model performs best in the fault classification task, achieving an F1-score of 0.9280 in the LFP discharging scenario; in the fault grading task, the F1-score reaches 0.8813. The CH-BatteryGen dataset has been open-sourced, aiming to provide a standardized evaluation platform for battery fault diagnosis algorithms, promote research development in this field, and contribute to the transformation of sustainable transportation systems.",
    "key_points": [
      "lithium-ion batteries",
      "fault diagnosis",
      "benchmark dataset",
      "generative modeling",
      "time series analysis"
    ],
    "gold_summary": "This paper introduces a new dataset for classifying the failure mode and severity for lithium-ion batteries."
  },
  {
    "paper_id": "hcuEdq6eKD",
    "title": "GDPval: Evaluating AI Model Performance on Real-World Economically Valuable Tasks",
    "domain": "datasets and benchmarks",
    "content": "We introduce GDPval, an evaluation assessing AI model capabilities on real-world economically valuable tasks. GDPval covers the majority of U.S. Bureau of Labor Statistics Work Activities for 44 occupations across the top 9 sectors contributing to U.S. GDP (Gross Domestic Product). Tasks are constructed from the representative work of industry professionals with an average of 14 years of experience. We find that frontier model performance on GDPval has been improving roughly linearly over time, and that the current best frontier models are approaching industry experts in deliverable quality. We analyze the potential for frontier models, when paired with human oversight, to perform GDPval tasks cheaper and faster than unaided expert workflows. We also demonstrate that increased reasoning effort, increased task context, and increased scaffolding improves model performance on GDPval. Finally, we open-source a gold subset of 220 tasks and provide a public automated grading service to facilitate future research in understanding real-world model capabilities.",
    "key_points": [
      "benchmark",
      "real-world tasks",
      "rl environments",
      "model evaluation",
      "reinforcement learning",
      "ai impacts",
      "dataset",
      "evals",
      "benchmarks",
      "multi-modal",
      "computer use",
      "agents",
      "long-horizon tasks",
      "ai",
      "artificial intelligence",
      "ml",
      "machine learning",
      "deep learning",
      "llms",
      "language models"
    ],
    "gold_summary": "This paper introduces GDPval, a new benchmark to evaluate the performance of large AI models on real-world economically valuable tasks."
  },
  {
    "paper_id": "309pxoSvWr",
    "title": "GQA-Q2Q: A Large-scale Dataset for Resolving Entity Ambiguity in Visual Question-Answering via Clarifying Subquestion",
    "domain": "datasets and benchmarks",
    "content": "Vision-Language Models (VLMs) have achieved remarkable results on various visual question-answering (VQA) benchmarks. However, their performance is significantly impacted by ambiguous questions in which the target entity in the image is not clearly identified. To address and evaluate this issue, it is essential to create a dedicated benchmark dataset that aligns ambiguous questions with a clarifying subquestion. However, constructing a large, high-quality benchmark dataset is costly, particularly when it relies on expert annotations. To efficiently construct such a dataset at scale, this paper presents a hybrid human-machine pipeline. This pipeline begins by generating a small initial set of subquestions using rule-based templates, which are then refined through human annotation. This initial annotated set serves as the foundation for training a subquestion generator and a validator, and the generator and the validator together allow automated construction of a large-scale dataset. As a result, this paper presents a new large-scale dataset, GQA-Q2Q, designed to disambiguate unclear entities in questions by providing clarifying subquestions. Furthermore, a VQA framework is introduced which utilizes the clarifying subquestions to resolve ambiguity before producing a final answer. The experimental results demonstrate that this approach significantly enhances VQA performance, validating the effectiveness of the proposed dataset.",
    "key_points": [
      "visual question-answering",
      "entity ambiguity",
      "question clarification",
      "subquestion generation",
      "benchmark dataset"
    ],
    "gold_summary": "This paper presents a large-scale VQA dataset that disambiguates unclear entities through clarifying sub-questions. It also proposes a VQA framework that uses these sub-questions to resolve ambiguity before generating a final answer."
  },
  {
    "paper_id": "Ei3y6WQlgQ",
    "title": "No Free Lunch in Active Learning: LLM Embedding Quality Dictates Query Strategy Success",
    "domain": "datasets and benchmarks",
    "content": "The advent of large language models (LLMs) capable of producing general-purpose representations lets us revisit the practicality of deep active learning (AL): By leveraging frozen LLM embeddings, we can mitigate the computational costs of iteratively fine-tuning large backbones. This study establishes a benchmark and systematically investigates the influence of LLM embedding quality on query strategies in deep AL. We employ five top-performing models from the massive text embedding benchmark (MTEB) leaderboard and two baselines for ten diverse text classification tasks. Our findings reveal key insights: First, initializing the labeled pool using diversity-based sampling synergizes with high-quality embeddings, boosting performance in early AL iterations. Second, the choice of the optimal query strategy is sensitive to embedding quality. While the computationally inexpensive Margin sampling can achieve performance spikes on specific datasets, we find that strategies like Badge exhibit greater robustness across tasks. Importantly, their effectiveness is often enhanced when paired with higher-quality embeddings. Our results emphasize the need for context-specific evaluation of AL strategies, as performance heavily depends on embedding quality and the target task.",
    "key_points": [
      "llms",
      "embeddings",
      "active learning"
    ],
    "gold_summary": "The paper presents a benchmark study on how the quality of frozen LLM embeddings and initial pool selection affect the performance of active learning strategies for text classification."
  },
  {
    "paper_id": "Ksvv8x00eo",
    "title": "CaTS-Bench: Can Language Models Describe Numeric Time Series?",
    "domain": "datasets and benchmarks",
    "content": "Time series captioning, the task of describing numeric time series in natural language, requires numerical reasoning, trend interpretation, and contextual understanding. Existing benchmarks, however, often rely on synthetic data or overly simplistic captions, and typically neglect metadata and visual representations. To close this gap, we introduce **CaTS-Bench**, the first large-scale, real-world benchmark for **C**ontext-**a**ware **T**ime **S**eries captioning. CaTS-Bench is derived from *11* diverse datasets reframed as captioning and Q&A tasks, comprising roughly *465k* training and *105k* test timestamps. Each sample includes a numeric series segment, contextual metadata, a line-chart image, and a caption. A key contribution of this work is the scalable pipeline used to generate reference captions: while most references are produced by an oracle LLM and verified through factual checks, human indistinguishability studies, and diversity analyses, we also provide a human-revisited subset of *579* test captions, refined from LLM outputs to ensure accuracy and human-like style. Beyond captioning, CaTS-Bench offers *460* multiple-choice questions targeting deeper aspects of time series reasoning. We further propose new tailored evaluation metrics and benchmark leading VLMs, highlighting both their strengths and persistent limitations. Together, these contributions establish CaTS-Bench and its captioning pipeline as a reliable and extensible foundation for future research at the intersection of time series analysis and foundation models.",
    "key_points": [
      "time series",
      "benchmark",
      "llm"
    ],
    "gold_summary": "This work proposed a large scale time series captioning benchmark together with some multiple choice questions on time series and text alignments."
  },
  {
    "paper_id": "aiZG7mRi43",
    "title": "MultiHaystack: Benchmarking Multimodal Reasoning over 40K Images, Videos, and Documents",
    "domain": "datasets and benchmarks",
    "content": "Multimodal large language models (MLLMs) have advanced rapidly on benchmarks involving isolated text, image, or video tasks, but such settings overlook a crucial step in real-world applications: retrieving evidence from large, heterogeneous corpora before reasoning. Existing benchmarks typically provide only hundreds or thousands of candidates, making retrieval trivial and overstating model reliability. To address this gap, we introduce MultiHaystack, the first benchmark for large-scale, realistic cross-modal retrieval and reasoning. It contains over 46,000 documents, images, and videos paired with 747 uniquely verifiable questions, ensuring unambiguous evaluation while requiring both modality selection and fine-grained reasoning. Our experiments reveal a consistent pattern: models perform competitively when directly given the answer-containing file, but their performance drops sharply once evidence must be retrieved at scale. The best retriever (E5-V) achieves only 40.8% Recall@1, while even GPT-5 reaches just 51.4% VQA accuracy under top-5 retrieval. These results reveal that retrieval, rather than reasoning, is the dominant bottleneck, establishing MultiHaystack as a rigorous benchmark that exposes weaknesses hidden by small-scale evaluations and highlights retrieval as the key frontier for advancing MLLMs.",
    "key_points": [
      "multimodal haystack",
      "retrieval",
      "vqa"
    ],
    "gold_summary": "This paper introduce a new benchmark MultiHaystack for cross-modal  retrieval and reasoning, 46K documents, images, and videos. The authors curated their benchmark from existing datasets and then evaluated popular VLM models on their benchmarks."
  },
  {
    "paper_id": "0lW2UBiEWN",
    "title": "Mesa and Mask: A Benchmark for Detecting and Classifying Deceptive Behaviors in LLMs",
    "domain": "datasets and benchmarks",
    "content": "As the capabilities of Large Language Models (LLMs) grow, so does their shadow. AI Deception—misleading users in the output while concealing internal reasoning—is a nascent phenomenon in frontier models with potentially severe societal ramifications. To build safe and trustworthy AI systems, a systematic evaluation mechanism for deception is imperative. A key question is: How can we systematically and reproducibly diagnose the brittleness of an LLM's alignment? To address this challenge, we introduce MESA & MASK, the first benchmark designed for the differential diagnosis of LLM deception. Its core methodology is to measure the principled deviation of a model's behavior by contrasting its reasoning and responses in a baseline context (Mesa) with those under a latent pressure context (Mask). This enables the systematic classification of behaviors into genuine deception, deceptive tendencies, and brittle superficial alignment. Based on this, we have constructed a cross-domain dataset of 2,100 high-quality instances. We evaluated over twenty models and found that even the most advanced models commonly exhibit significant deceptive behaviors or tendencies, which validates the benchmark's effectiveness in revealing behavioral differences among models under pressure. MESA & MASK provides the community with a powerful tool to diagnose and understand AI deception, laying the groundwork for more verifiable and aligned AI systems.",
    "key_points": [
      "deceptive behavior; benchmark and evaluation; ai safety; alignment"
    ],
    "gold_summary": "The paper introduces a dataset for measuring LM deception when prompted with a situation that puts pressure towards deception vs control prompts. The authors evaluate a large number of models on dataset."
  },
  {
    "paper_id": "DOIWg7VyYU",
    "title": "StyleBench: Evaluating  thinking styles in Large Language Models",
    "domain": "datasets and benchmarks",
    "content": "The effectiveness of Large Language Models (LLMs) is heavily influenced by the reasoning strategies, or \\textit{styles of thought}, employed in their prompts. However, the interplay between these reasoning styles, model architecture, and task type remains poorly understood. To address this, we introduce StyleBench, a comprehensive benchmark for systematically evaluating reasoning styles across diverse tasks and models. We assess five representative reasoning styles—Chain-of-Thought (CoT), Tree-of-Thought (ToT), Algorithm-of-Thought (AoT), Sketch-of-Thought (SoT), and Chain-of-Draft (CoD)—on five reasoning tasks, using 15 open-source models from major families (LLaMA, Qwen, Mistral, Gemma, GPT-OSS, Phi, and DeepSeek) ranging from 270M to 120B parameters. Our large-scale analysis reveals that no single style is universally optimal. We demonstrate that strategy efficacy is highly contingent on both model scale and task type: search-based methods (AoT, ToT) excel in open-ended problems but require large-scale models, while concise styles (SoT, CoD) achieve radical efficiency gains on well-defined tasks. Furthermore, we identify key behavioral patterns: smaller models frequently fail to follow output instructions and default to guessing, while reasoning robustness emerges as a function of scale. Our findings offer a crucial roadmap for selecting optimal reasoning strategies based on specific constraints, We open source the benchmark in https://anonymous.4open.science/r/StyleBench/.",
    "key_points": [
      "reasoning",
      "instruction",
      "llm",
      "benchmark"
    ],
    "gold_summary": "This paper introduces StyleBench, a benchmark that evaluates five distinct reasoning styles (CoT, ToT, AoT, SoT, and CoD) on five reasoning tasks using 15 open-source language models ranging from 270M to 120B parameters."
  },
  {
    "paper_id": "dIiV9FYt3i",
    "title": "Stop Guessing When to Stop Testing: Efficient Model Evaluation with Just Enough Data",
    "domain": "datasets and benchmarks",
    "content": "The inherent rigidity of fixed-size benchmarks makes them an inefficient tool for model evaluation. Diverse evaluation objectives, including model ranking, model selection and testing throughout development, demand varying levels of statistical power. The mismatch between fixed sample sizes and these diverse needs results in either excessive computational cost or compromised reliability – a critical concern for model evaluation. To overcome these limitations, we call for adoption of sequential testing in our field. We provide an adaptive evaluation framework, that provides a principled way to navigate the trade-off between efficiency and reliability in model evaluation. Our framework combines the established statistical paradigm of sequential testing with stopping criteria tailored to common evaluation needs such as diminishing returns detection, and minimum detectable effect size. We demonstrate its ability to adaptively manage the efficiency-reliability trade-off on the Open VLM Leaderboard, including, for example, a 80% reduction in computational cost compared to fixed-size evaluation (with a 2.5-point CI width allowance) while maintaining statistical significance.",
    "key_points": [
      "evaluation",
      "efficiency",
      "efficient evaluation",
      "adaptive testing",
      "adaptive evaluation",
      "sequential testing"
    ],
    "gold_summary": "This paper proposes an adaptive evaluation framework for VLM ) based on group sequential testing. Instead of using fixed-size benchmarks, the framework stops evaluation when statistical and practical criteria are met."
  },
  {
    "paper_id": "AwRIQV177K",
    "title": "MedMeta: A Benchmark for LLMs in Synthesizing Meta-Analysis Conclusion from Medical Studies",
    "domain": "datasets and benchmarks",
    "content": "Large language models (LLMs) have saturated standard medical benchmarks that test factual recall, yet their ability to perform higher-order reasoning, such as synthesizing evidence from multiple sources, remains critically under-explored. To address this gap, we introduce MedMeta, the first benchmark designed to evaluate an LLM's ability to generate conclusions from medical meta-analyses using only the abstracts of cited studies. MedMeta comprises 81 meta-analyses from PubMed (2018--2025) and evaluates models using two distinct workflows: a Retrieval-Augmented Generation (Golden-RAG) setting with ground-truth abstracts, and a Parametric-only approach relying on internal knowledge. Our evaluation framework is validated by a well-structured analysis showing our LLM-as-a-judge protocol strongly aligns with human expert ratings, as evidenced by high Pearson's r correlation (0.81) and Bland-Altman analysis revealing negligible systematic bias, establishing it as a reliable proxy for scalable evaluation. Our findings underscore the critical importance of information grounding: the Golden-RAG workflow consistently and significantly outperforms the Parametric-only approach across models. In contrast, the benefits of domain-specific fine-tuning are marginal and largely neutralized when external material is provided. Furthermore, stress tests show that all models, regardless of architecture, fail to identify and reject negated evidence, highlighting a critical vulnerability in current RAG systems. Notably, even under ideal RAG conditions, current LLMs achieve only slightly above-average performance (~2.7/5.0). MedMeta provides a challenging new benchmark for evidence synthesis and demonstrates that for clinical applications, developing robust RAG systems is a more promising direction than model specialization alone.",
    "key_points": [
      "large language models",
      "llm evaluation",
      "medical ai",
      "retrieval-augmented generation (rag)",
      "meta-analysis synthesis"
    ],
    "gold_summary": "This work (1) introduces a benchmark of filtered meta-analysis from pubmed and (2) benchmarks the impact of RAG and CoT reasoning on LLM-written conclusions."
  },
  {
    "paper_id": "QqlWLkfbq2",
    "title": "EVA-MILP: Towards Standardized Evaluation of MILP Instance Generation",
    "domain": "datasets and benchmarks",
    "content": "Mixed-Integer Linear Programming (MILP) is fundamental to solving complex decision-making problems. The proliferation of MILP instance generation methods, driven by machine learning's demand for diverse optimization datasets and the limitations of static benchmarks, has significantly outpaced standardized evaluation techniques. Consequently, assessing the fidelity and utility of synthetic MILP instances remains a critical, multifaceted challenge. This paper introduces a comprehensive benchmark framework designed for the systematic and objective evaluation of MILP instance generation methods. Our framework provides a unified and extensible methodology, assessing instance quality across crucial dimensions: mathematical validity, structural similarity, computational hardness, and utility in downstream machine learning tasks. A key innovation is its in-depth analysis of solver-internal features --particularly by comparing distributions of key solver outputs including root node gap, heuristic success rates, and cut plane usage -- leveraging the solver's dynamic solution behavior as an `expert assessment' to reveal nuanced computational resemblances. By offering a structured approach with clearly defined solver-independent and solver-dependent metrics, our benchmark aims to facilitate robust comparisons among diverse generation techniques, spur the development of higher-quality instance generators, and ultimately enhance the reliability of research reliant on synthetic MILP data. The framework's effectiveness in systematically comparing the fidelity of instance sets is demonstrated using contemporary generative models. The code is available in \\url{https://github.com/iclr2026evamilp/EVA-MILP}.",
    "key_points": [
      "mixed-integer linear programming",
      "instance generation",
      "graph neural networks"
    ],
    "gold_summary": "The paper introduces EVA-MILP, a benchmark framework to evaluate MILP instance generation methods. It combines solver-independent metrics and solver-dependent metrics. Experiments cover Ecole-style datasets (SC/CA/CFL/IS) and ML4CO, and compare several generators (G2MILP, ACM-MILP, DIG-MILP)."
  },
  {
    "paper_id": "4PZMeopXzP",
    "title": "PRISM-Physics: Causal DAG-Based Process Evaluation for Physics Reasoning",
    "domain": "datasets and benchmarks",
    "content": "Benchmarks for competition-style reasoning have advanced evaluation in mathematics and programming, yet physics remains comparatively explored. Most existing physics benchmarks evaluate only final answers, which fail to capture reasoning processes, while recent stepwise methods rely on heuristic LLM-as-judge scoring or restrictive linear assumptions, limiting reliability and diagnostic validity.\nWe introduce PRISM-Physics, a process-level evaluation framework and benchmark for complex physics reasoning problems. Solutions are represented as directed acyclic graphs (DAGs) of formulas, explicitly encoding causal dependencies among intermediate steps to enable fine-grained, interpretable, and theoretically grounded scoring. \nWe prove the optimality of the DAG representation and the corresponding scoring policy. Combining with a fully rule-based method for symbolic formula equivalence matching that we developed, we ensure consistent validation across diverse formulations without heuristic judgments. Results show that our evaluation framework is more aligned with human experts' scoring. \nExperiments on state-of-the-art LLMs reveal persistent reasoning failures in physics, while step-level scoring offers both diagnostic insight and rich signals for later training. By combining structural rigor, theoretical guarantees, and symbolic validation, PRISM-Physics provides a principled foundation for advancing process-level evaluation and guiding the development of models with deeper scientific reasoning capabilities.",
    "key_points": [
      "physics reasoning",
      "process-level evaluation",
      "symbolic equivalence",
      "scientific problem solving"
    ],
    "gold_summary": "This paper introduces PRISM-PHYSICS, a benchmark and a process-level evaluation framework that encodes physics solutions as DAGs and employs rule-based symbolic equivalence checking for reliable, fine-grained scoring."
  },
  {
    "paper_id": "vznmtmUPmA",
    "title": "A Benchmark for Self-Evolving Agents via Experience-Driven Lifelong Learning",
    "domain": "datasets and benchmarks",
    "content": "As AI advances toward general intelligence, the focus is shifting from systems optimized for static tasks to creating open-ended agents that learn continuously and adapt autonomously from experiences. This vision emphasizes long-term memory, self-driven exploration, persistent experience retention, and the internalization of knowledge into intuitive behavior as key to enabling self-evolving agents through experience-driven lifelong learning (ELL). In this paper, we introduce StuLife, a novel benchmark designed to evaluate whether current models can exhibit these foundational capabilities of ELL. Particularly, StuLife simulates a student's holistic college journey, from enrollment to academic and personal development, across three core phases and ten detailed sub-scenarios. StuLife is designed around four key paradigm shifts: From Simulation to Reality, From Passive to Proactive, From Context to Memory, and From Imitation to Learning. In this dynamic environment, agents must acquire and distill practical skills and maintain persistent memory to make decisions based on evolving state variables (e.g., resource availability and time). Critically, these agents are also expected to demonstrate intrinsic motivation by setting their own goals and initiating actions without external prompting. To this end, StuLife provides a comprehensive evaluation platform featuring our novel metrics (e.g., StuGPA) to specifically assess these critical capabilities. Our evaluation reveals that even the best model, GPT-5, scores only 17.9/100, revealing a vast gap toward AGI, demonstrating fundamental deficiencies in retaining long-term memory and acting with self-motivated initiative. Beyond evaluating state-of-the-art LLMs on the StuLife, we also explore the role of context engineering in advancing AGI. Our results suggest that optimizing how we guide models may be as crucial as improving the models themselves, positioning context engineering as a key enabler of progress toward AGI.",
    "key_points": [
      "experience-driven lifelong learning",
      "self-evolving agent",
      "skill learning",
      "long-term memory",
      "self-motivation",
      "continual learning"
    ],
    "gold_summary": "This paper introduces StuLife, a benchmark for evaluating self-evolving agents through assessing the capabilities of experience-driven lifelong learning methods."
  },
  {
    "paper_id": "0cBlhTTHfx",
    "title": "DynamicEval: Rethinking Evaluation for Dynamic Text-to-Video Synthesis",
    "domain": "datasets and benchmarks",
    "content": "Existing text-to-video (T2V) evaluation benchmarks, such as VBench and EvalCrafter, suffer from two main limitations. (i) While the emphasis is on subject-centric prompts or static camera scenes, camera motion which is essential for producing cinematic shots and the behavior of existing metrics under dynamic motion are largely unexplored. (ii) These benchmarks typically aggregate video-level scores into a single model-level score for ranking generative models. Such aggregation, however, overlook video-level evaluation, which is vital to selecting the better video among the candidate videos generated for a given prompt.\nTo address these gaps, we introduce DynamicEval, a benchmark consisting of systematically curated prompts emphasizing dynamic camera motion, paired with 45k human annotations on video pairs from 3k videos generated by ten T2V models. DynamicEval evaluates two key dimensions of video quality: background scene consistency and foreground object consistency.\nFor background scene consistency, we obtain the interpretable error maps based on the Vbench motion smoothness metric. Our key observation based on the error maps is that while the Vbench motion smoothness metric shows promising alignment with human judgments, it fails in two cases, namely,   occlusions/disocclusions arising from camera and foreground object movements. Building on this, we propose a new background consistency metric that leverages object error maps to correct two major failure cases in a principled manner. Our second innovation is the introduction of a foreground consistency metric that tracks points and their neighbors within each object instance to better assess object fidelity.\nExtensive experiments demonstrate that our proposed metrics achieve stronger correlations with human preferences at both the video level and the model level (an improvement of more than $2$\\% points), establishing DynamicEval as a more comprehensive benchmark for evaluating T2V models under dynamic camera motion.",
    "key_points": [
      "text-to-video generation",
      "generative models",
      "evaluation metrics",
      "quality assessment",
      "human annotations",
      "video benchmark",
      "video dataset"
    ],
    "gold_summary": "The paper proposes DynamicEval, a benchmark consisting of systematically curated prompts emphasizing dynamic camera motion."
  },
  {
    "paper_id": "gsSIH0mZ0Y",
    "title": "AgentsNet: Coordination and Collaborative Reasoning in Multi-Agent LLMs",
    "domain": "datasets and benchmarks",
    "content": "Large-language models (LLMs) have demonstrated powerful problem-solving capabilities, in particular when organized in multi-agent systems. However, the advent of such systems also raises several questions on the ability of a complex network of agents to effectively self-organize and collaborate. While measuring performance on standard reasoning benchmarks indicates how well multi-agent systems can solve reasoning tasks, it is unclear whether these systems are able to leverage their topology effectively. Here, we propose AgentsNet, a new benchmark for multi-agent reasoning. By drawing inspiration from classical problems in distributed systems and graph theory, AgentsNet measures the ability of multi-agent systems to collaboratively form strategies for problem-solving, self-organization, and effective communication given a network topology. We evaluate a variety of baseline methods on AgentsNet including homogeneous networks of agents which first have to agree on basic protocols for organization and communication. We find that some frontier LLMs are already demonstrating strong performance for small networks but begin to fall off once the size of the network scales. While existing multi-agent benchmarks cover at most 2--5 agents, AgentsNet is practically unlimited in size and can scale with new generations of LLMs. As such, we also probe frontier models in a setup with up to 100 agents.",
    "key_points": [
      "multi-agent systems",
      "llms",
      "collaborative reasoning"
    ],
    "gold_summary": "This paper introduces AGENTSNET, a benchmark for evaluating multi-agent LLM systems' coordination and collaboration capabilities through fundamental distributed computing problems (graph coloring, vertex cover, matching, leader election, consensus)."
  },
  {
    "paper_id": "Bi7CPaOMHC",
    "title": "RAID: A Benchmark Dataset for Testing the Adversarial Robustness of AI-Generated Image Detectors",
    "domain": "datasets and benchmarks",
    "content": "AI-generated images have reached a quality level at which humans are incapable of reliably distinguishing them from real images. To counteract the inherent risk of fraud and disinformation, the detection of AI-generated images is a pressing challenge and an active research topic.\nWhile many of the presented methods claim to achieve high detection accuracy, they are usually evaluated under idealized conditions. In particular, the $\\textit{adversarial robustness}$ is often neglected, potentially due to a lack of awareness or the substantial effort required to conduct a comprehensive robustness analysis. In this work, we tackle this problem by providing a simpler means to assess the robustness of AI-generated image detectors. We present $\\textbf{RAID}$ ($\\textbf{R}$obust evaluation of $\\textbf{AI}$-generated image $\\textbf{D}$etectors), a benchmark dataset of 72k diverse and highly transferable adversarial examples.\nThe proposed dataset is created by running attacks against an ensemble of seven state-of-the-art detectors and images generated by four different text-to-image models.\nExtensive experiments show that our methodology generates adversarial images that transfer with a high success rate to unseen detectors, which can be used to quickly provide an approximate yet still reliable estimate of a detector's adversarial robustness. Our findings indicate that current state-of-the-art AI-generated image detectors can be easily deceived by adversarial examples, highlighting the critical need for the development of more robust methods.",
    "key_points": [
      "ai-generated image detection",
      "adversarial robustness"
    ],
    "gold_summary": "This paper provides a new benchmark on evaluating the Adversarial Robustness of AI-generated image Detectors based on ensemble transfer-based adversarial examples. A diverse set og text-to-image models and detection methods are considered."
  },
  {
    "paper_id": "iexhzXxLV5",
    "title": "ALETHEIA: A Multi-Frequency Eddy Current Pulsed Thermography Dataset for Neural Operator Learning in Nondestructive Testing",
    "domain": "datasets and benchmarks",
    "content": "Learning neural solvers for spatiotemporal partial differential equations (PDEs) under real-world constraints remains a key challenge in scientific machine learning, especially for inverse tasks with sparse and noisy boundary observations. We present the **Aletheia** dataset, the first 3D benchmark for learning data-driven solvers in the context of **nondestructive testing (NDT)**. The dataset simulates eddy-current-induced heating in conductive solids and models the resulting transient heat propagation governed by the heat equation. Aletheia contains over 4,700 high-resolution samples across 10 excitation frequencies (1-100\\,kHz), each providing volumetric heat source and temperature fields over time. It supports both forward prediction of temperature evolution and inverse reconstruction of internal heat sources or defects from surface infrared measurements. Real infrared thermography data from cracked rail specimens are included for calibration and generalization studies. We define three canonical tasks on both regular and irregular grids and benchmark them using various neural operators. Aletheia establishes a unified platform for evaluating neural PDE solvers under realistic NDT conditions, enabling progress in reliable, data-driven inverse modeling.",
    "key_points": [
      "partial differential equations",
      "nondestructive testing",
      "neural operators",
      "thermal holography"
    ],
    "gold_summary": "This work proposed a 3D benchmark, Aletheia. The dataset simulates eddy-current-induced heating, which is an electromagnetic-thermal coupling physics. The dataset is feature with comprehensive evaluations (see Table 1)."
  },
  {
    "paper_id": "mIKqVWGjwI",
    "title": "BeyondBench: Benchmark-Free Evaluation of Reasoning in Language Models",
    "domain": "datasets and benchmarks",
    "content": "Evaluating language models fairly is becoming harder as static benchmarks available on the internet risk contamination by training data. This makes it unclear whether models are truly reasoning or just recalling answers. In this paper, we introduce $\\textbf{BeyondBench}$, an evaluation framework that avoids this problem by using $\\textbf{algorithmic problem generation}$. Unlike traditional benchmarks that risk contamination from internet-scale training data, $\\textbf{BeyondBench}$ creates mathematically grounded problems on the fly, ensuring each test remains fresh and uncontaminated. Our framework covers $\\textbf{44 algorithmic tasks}$ with a total of $\\textbf{117 variations}$, grouped into three difficulty levels: the $\\textit{Easy Suite}$ (29 tasks) for basic arithmetic and statistics, the $\\textit{Medium Suite}$ (5 tasks, 49 variations) for sequence patterns and reasoning, and the $\\textit{Hard Suite}$ (10 tasks, 68 variations) tackling NP-complete and constraint satisfaction problems. Each task generates problems from a combinatorial space larger than $10^{15}$ unique instances, with solutions verified deterministically by mathematical proofs. We evaluated $\\textbf{101 language models}$, including 85 open-source and 16 closed-source models, spanning sizes from 0.5B to 141B parameters and multiple quantization schemes. Our results show consistent reasoning deficiencies across model families, with performance degrading sharply as problem complexity increases from polynomial to exponential. In our Hard Suite evaluations, models such as Gemini-2.5-pro, Llama-3.3-70B, and Qwen2.5-72B achieved average accuracies of 56.38%, 26.91%, and 33.60%, respectively. Moreover, we observe that performance drops drastically without tool usage, with GPT-5, GPT-5-mini, and GPT-5-nano showing a $\\textbf{decline}$ of 16.81% 28.05%, and 47.59% accuracy on the hard suite. The contamination resistance of $\\textbf{BeyondBench}$ rests on three guarantees: (i) the problem space is vastly larger than any static dataset, (ii) every instance has a unique, verifiable solution, and (iii) isomorphic transformations generate semantically equivalent but syntactically new problems. $\\textbf{BeyondBench}$ redefines reasoning evaluation through genuine algorithmic problem-solving capability, ensuring a fair and meaningful evaluation.",
    "key_points": [
      "benchmarking",
      "evaluation",
      "large language models",
      "reasoning"
    ],
    "gold_summary": "The authors introduce a new dataset namely **BeyondBench** which benchmarks LLMs performance on algorithimic tasks and evaluate the performance of both open open source and proprietary on their dataset"
  },
  {
    "paper_id": "LNonj4uHlR",
    "title": "Gen-Review: A Dataset and Large-scale Study of AI-Generated and Human-Authored Peer Reviews",
    "domain": "datasets and benchmarks",
    "content": "How does the increased adoption of Large Language Models (LLMs) impact the scientific peer review? This multifaceted question is fundamental to the integrity and outcomes of the scientific process. Timely evidence suggests LLMs may have already been used for peer-review, e.g., at the 2024 International Conference of Learning Representations (ICLR), and the LLMs' integration in peer-review was confirmed by various editorial boards (including that of ICLR'25). To seek answers, a comprehensive dataset is needed, but lacking until now. We therefore present Gen-Review the largest dataset of LLM-written reviews so far. Our dataset includes 81K reviews generated for all submissions to the 2018--2025 editions of the ICLR and by providing the LLM with three independent prompts: a negative, a positive, and a neutral one. Gen-Review also links to the papers and the conference reviews thereby enabling a broad range of investigations. We make a start and use Gen-Review to scrutinize: if LLMs exhibit bias in reviewing (they do); if LLM-written reviews can be automatically detected (so far, they can); if LLMs can rigorously follow reviewing instructions (not always) and whether LLM-provided ratings align with a papers' final outcome (happens only for accepted papers).",
    "key_points": [
      "peer-review",
      "llm",
      "dataset",
      "genai"
    ],
    "gold_summary": "Collected 81K AI-generated reviews."
  },
  {
    "paper_id": "1zOp2WPMdZ",
    "title": "IWR-Bench: Can LVLMs reconstruct interactive webpage from a user interaction video?",
    "domain": "datasets and benchmarks",
    "content": "The webpage-to-code task requires models to understand visual representations of webpages and generate corresponding code.\nHowever, existing benchmarks primarily focus on static screenshot-to-code tasks, thereby overlooking the dynamic interactions fundamental to real-world web applications.\nTo address this limitation, this paper introduces IWR-Bench, a novel benchmark for evaluating the capabilities of Large Vision-Language Models (LVLMs) in interactive webpage reconstruction from video.\nIWR-Bench comprises 113 meticulously curated tasks from 100 real-world websites, with 1,001 actions and featuring diverse interaction complexities (e.g., web games), visual styles, and domains.\nAligning with standard web development practices, each task includes not only user interaction videos but also all crawled static assets (e.g., images, videos).\nThis benchmark evaluates models on two fundamental challenges: comprehensive multi-modal reasoning to infer interaction logic from video and assets, and advanced code generation to translate this logic into functional code.\nAn agent-as-a-judge framework with a comprehensive metric system automatically assesses the functional correctness and visual fidelity of generated webpages.\nExtensive experiments on 28 LVLMs reveal a significant challenge: the best model achieves an overall score of only 36.35\\%, as functional correctness (24.39\\% IFS) lags significantly behind visual fidelity (64.25\\% VFS).\nThese results highlight critical limitations in current models' ability to reason about temporal dynamics and synthesize event-driven logic, establishing IWR-Bench as a challenging frontier for vision-language research.\nThe benchmark and evaluation code will be made publicly available.",
    "key_points": [
      "benchmark",
      "mllm",
      "web"
    ],
    "gold_summary": "The paper shifts evaluation from static mimicry to working webpage from interaction videos, revealing a wide functionality gap in today’s LVLMs and offering a rigorous, automated protocol to measure progress."
  },
  {
    "paper_id": "a7TVXy8DqU",
    "title": "Car4Cast: A Dataset and Benchmark for LLM-Based Motion Forecasting and Spatial Reasoning in Autonomous Driving",
    "domain": "datasets and benchmarks",
    "content": "Recent advances in Large Language Models (LLMs) have shown promise in diverse reasoning tasks, yet their ability to perform structured spatial-temporal prediction remains underexplored. To address this, we introduce Car4Cast, a novel dataset and benchmark that casts 3D motion forecasting in autonomous driving as a spatial reasoning task and testbed, involving structured text generation. Car4Cast provides a comprehensive evaluation suite tailored to the unique challenges of language-based motion prediction, including both classical trajectory accuracy and LLM-specific issues, such as output formatting and hallucinations. Our benchmark also supports an optional visual modality, enabling future exploration of vision-language models in spatial reasoning tasks. Car4Cast is conceived to drive progress toward spatially intelligent language models, highlighting the need and providing data and evaluation tools for new methods and training paradigms that effectively bridge this existing gap.",
    "key_points": [
      "large language models",
      "vision language models",
      "dataset",
      "motion forecasting",
      "autonomous driving",
      "spatial reasoning"
    ],
    "gold_summary": "This paper introduces Car4Cast, which casts 3D motion forecasting in autonomous driving as a spatial reasoning task. And it provides a unified evaluation suite with 3D forecasting and LLM-specific structured prediction metrics."
  },
  {
    "paper_id": "kOgJvEMAlF",
    "title": "MSCoRe: A Benchmark for Multi-Stage Collaborative Reasoning in LLM Agents",
    "domain": "datasets and benchmarks",
    "content": "Large Language Model (LLM) agents have excelled in single-stage tasks. However, their reasoning and coordination capabilities in multi-stage scenarios remain underexplored. Existing benchmarks typically focus on isolated tasks or narrow domains, overlooking models' abilities for multi-stage collaboration and optimization without explicit external guidance. To bridge this gap, we propose MSCoRe, a novel benchmark comprising 126696 domain-specific QA instances spanning scenarios in automotive, pharmaceutical, e-commerce, and automotive energy sectors. We also introduce a structured three-phase pipeline: dynamic sampling, iterative question-answer generation, and a multi-level quality assessment to generate high-quality data. For a more refined assessment, we categorize tasks into three difficulty levels based on their stage coverage and complexity. With MSCoRe, we have conducted a comprehensive evaluation of various state-of-the-art LLM agents. The commercial models performed best across all tasks and scenarios, but a notable gap in the ROUGE scores remains between simple and complex tasks. We also tested the models' robustness under three types of noisy data and found that their performance is negatively affected by different noise. MSCoRe provides a new resource for evaluation and improvement of multi-stage collaborative reasoning in LLM agents. Codes and data are available at https://huggingface.co/datasets/032564yn/MSCoRe.",
    "key_points": [
      "llm agents",
      "multi-stage reasoning",
      "chain collaboration",
      "benchmark"
    ],
    "gold_summary": "The authors introduce MSCoRe, a novel benchmark comprising 126696 domain-specific QA instances spanning scenarios in automotive, pharmaceutical, e-commerce, and automotive energy sectors labelled with different difficulty."
  },
  {
    "paper_id": "YxuKCME576",
    "title": "HSG-12M: A Large-Scale Dataset of Spatial Multigraphs from the Energy Spectra of non-Hermitian Crystals",
    "domain": "datasets and benchmarks",
    "content": "AI is transforming scientific research by revealing new ways to understand complex physical systems, but its impact remains constrained by the lack of large, high-quality domain-specific datasets. A rich, largely untapped resource lies in non-Hermitian quantum physics, where the energy spectra of crystals form intricate geometries on the complex plane—termed as $\\textit{Hamiltonian spectral graphs}$. Despite their significance as fingerprints for electronic behavior, their systematic study has been intractable due to the reliance on manual extraction. To unlock this potential, we introduce $\\textbf{Poly2Graph}$ (https://anonymous.4open.science/r/iclr2026_generator-AE56): a high-performance, open-source pipeline that automates the mapping of 1-D crystal Hamiltonians to spectral graphs. Using this tool, we present $\\textbf{HSG-12M}$ (https://anonymous.4open.science/r/iclr2026_dataset-2802): a dataset containing 11.6 million static and 5.1 million dynamic Hamiltonian spectral graphs across 1401 characteristic-polynomial classes, distilled from 177 TB of spectral potential data. Crucially, HSG-12M is the first large-scale dataset of $\\textit{spatial multigraphs}$—graphs embedded in a metric space where multiple geometrically distinct trajectories between two nodes are retained as separate edges. This simultaneously addresses a critical gap, as existing graph benchmarks overwhelmingly assume simple, non-spatial edges, discarding vital geometric information. Benchmarks with popular GNNs expose new challenges in learning spatial multi-edges at scale. Beyond its practical utility, we show that spectral graphs serve as universal topological fingerprints of polynomials, vectors, and matrices, forging a new algebra-to-graph link. HSG-12M lays the groundwork for data-driven scientific discovery in condensed matter physics, new opportunities in geometry-aware graph learning and beyond.",
    "key_points": [
      "graph-level learning",
      "spatial network",
      "multigraph",
      "dataset generator",
      "large-scale dataset",
      "condensed matter physics",
      "non-hermitian physics",
      "topological physics",
      "ai4science",
      "toeplitz matrix"
    ],
    "gold_summary": "The paper introduces Poly2Graph, an automated pipeline converting 1-D crystal Hamiltonians into spectral graphs. This enables the creation of HSG-12M, a large-scale dataset of spatial multigraphs, which is a new benchmark for geometry-aware graph learning."
  },
  {
    "paper_id": "7K1kXowjK1",
    "title": "Self-Correction Bench: Uncovering and Addressing the Self-Correction Blind Spot in Large Language Models",
    "domain": "datasets and benchmarks",
    "content": "Although large language models (LLMs) have transformed AI, they still make mistakes and can explore unproductive reasoning paths. Self-correction capability is essential for deploying LLMs in safety-critical applications. We uncover a systematic failure: LLMs cannot correct errors in their own outputs while successfully correcting identical errors from external sources - a limitation we term the Self-Correction Blind Spot. To study this phenomenon, we introduce Self-Correction Bench, an evaluation framework to measure this phenomenon through controlled error injection at three complexity levels. Testing 14 open-source non-reasoning models, we find an average 64.5% blind spot rate. We provide multiple lines of evidence suggesting this limitation may be influenced by training data: human demonstrations rarely include error-correction sequences (favoring error-free responses), whereas reinforcement learning (RL) trained models learn error correction via outcome feedback. Remarkably, appending a minimal \"Wait\" prompt activates a 89.3% reduction in blind spots, suggesting dormant capabilities that require triggering. Our work highlights a critical limitation potentially influenced by training distribution and offers a practical approach to enhance LLM reliability and trustworthiness - vital for safety-critical domains.",
    "key_points": [
      "benchmark",
      "self correction",
      "large language model"
    ],
    "gold_summary": "This paper studies LLMs' self-correction blind spot and introduces Self-Correction Bench, an evaluation framework to measure this phenomenon through controlled error injection."
  },
  {
    "paper_id": "xeIheyQAV8",
    "title": "EduMirror: Modeling Educational Social Dynamics with Value-driven Multi-agent Simulation",
    "domain": "datasets and benchmarks",
    "content": "The scientific study of educational social dynamics, such as bullying and peer pressure, is crucial for student well-being yet hindered by profound ethical and methodological barriers inherent in traditional research. While multi-agent simulations powered by Large Language Models (LLMs) provide an ethically viable alternative, they often fail to bridge the gap from believable narratives to rigorous experiments, plagued by two fundamental hurdles: a lack of psychologically plausible motivations (the Fidelity Challenge) and the absence of systematic methods for quantifying complex interactions (the Measurement Challenge). To overcome these obstacles, we introduce $\\textbf{EduMirror}$, a multi-agent platform designed as a computational laboratory for the scientific study of educational social dynamics. EduMirror's framework integrates four key components: (1) A Systematic Scenario Design Workflow grounds simulations in established social science theory, ensuring construct validity. (2) To address the Fidelity Challenge, a unified Value-Driven Agent Architecture models agent motivation based on both individual psychological needs and Social Value Orientation (SVO). (3) To solve the Measurement Challenge, a Dual-Track Measurement Protocol employs specialized LLMs as a post-hoc Rater for observable behaviors and an in-situ Surveyor for internal states, transforming qualitative interactions into quantitative data. (4) Together, these components enable researchers to conduct controlled Intervention Experiments, branching simulations to systematically assess the causal impact of different strategies. We validate our platform through case studies on school bullying and group cooperation, demonstrating its capacity to generate theoretically-consistent and empirically-verifiable social phenomena, thereby establishing a robust methodology for in silico educational research.",
    "key_points": [
      "educational simulation",
      "multi-agent simulation",
      "computational social science"
    ],
    "gold_summary": "This paper introduces a multi-agent simulation platform for education social dynamics. They particularly focus on simulating bullying scenarios."
  },
  {
    "paper_id": "lddpNkrgXV",
    "title": "Revisiting Model Inversion Evaluation: From Misleading Standards to Reliable Privacy Assessment",
    "domain": "datasets and benchmarks",
    "content": "Model Inversion (MI) attacks aim to reconstruct information from private training data by exploiting access to machine learning models $T$. To evaluate such attacks, the standard evaluation framework relies on an evaluation model $E$, trained under the same task design as $T$. This framework has become the de facto standard for assessing progress in MI research, used across nearly all recent MI attacks and defenses without question. **In this paper,** we present the first in-depth study of this MI evaluation framework. In particular, we identify a critical issue of this standard MI evaluation framework: *Type-I adversarial examples*. These are reconstructions that do not capture the visual features of private training data, yet are still deemed successful by the target model $T$ and ultimately transferable to $E$. Such false positives undermine the reliability of the standard MI evaluation framework. To address this issue, we introduce a new MLLM-based evaluation framework, which replaces $E$ with advanced Multimodal Large Language Models (MLLMs). We propose systematic design principles for our proposed evaluation framework. By leveraging their general-purpose visual understanding, our MLLM-based framework does not depend on training of shared task design as in $T$, thus reducing Type-I transferability and providing more faithful assessments of reconstruction success. Using our proposed evaluation framework, we reevaluate 27 diverse MI attack setups and empirically reveal consistently high false positive rates under the standard evaluation framework. Importantly, we demonstrate that many state-of-the-art (SOTA) MI methods report inflated attack accuracy, indicating that actual privacy leakage is significantly lower than previously believed. By uncovering this critical issue and proposing a robust solution, our work enables a reassessment of progress in MI research and sets a new standard for reliable and robust evaluation. **Our MLLM-based MI evaluation framework and benchmarking suite are included in the Appendix.**",
    "key_points": [
      "model inversion",
      "type-i adversarial attack"
    ],
    "gold_summary": "This paper points out the limitation of attack accuracy, a current evaluation indicator for model inversion, and proposes using a multimodal large model to replace it."
  },
  {
    "paper_id": "Lvbxfawy7Q",
    "title": "InteractScience: Programmatic and Visually-Grounded Evaluation of Interactive Scientific Demonstration Code Generation",
    "domain": "datasets and benchmarks",
    "content": "Large Language Models (LLMs) are increasingly capable of generating complete applications from natural language instructions, creating new opportunities in science and education. In these domains, interactive scientific demonstrations are particularly valuable for explaining concepts, supporting new teaching methods, and presenting research findings. Generating such demonstrations requires models to combine accurate scientific knowledge with the ability to implement interactive front-end code that behaves correctly and responds to user actions. This capability goes beyond the scope of existing benchmarks, which typically evaluate either knowledge question answering without grounding in code or static web code generation without scientific interactivity. To evaluate this integrated ability, we design a hybrid framework that combines programmatic functional testing to rigorously verify interaction logic with visually-grounded qualitative testing to assess rendered outputs against reference snapshots. Building on this framework, we present InteractScience, a benchmark consisting of a substantial set of carefully designed questions across five scientific domains, each paired with unit tests, reference snapshots, and checklists. We evaluate 30 leading open- and closed-source LLMs and report results that highlight ongoing weaknesses in integrating domain knowledge with interactive front-end coding. Our work positions InteractScience as the first benchmark to automatically measure this combined capability with realistic interactive operations, providing a foundation for advancing reliable and educationally useful scientific demonstration code generation.",
    "key_points": [
      "benchmark",
      "large language models",
      "scientific demonstration",
      "code generation",
      "interactive applications"
    ],
    "gold_summary": "This paper presents scientific demonstration code generation by large language models. Towards that end, the authors adapted VLM-as-judge to evaluate the tasks."
  },
  {
    "paper_id": "xU8DPbrglA",
    "title": "COIN: Chain Of INteraction Benchmark: When Reasoning meets Embodied interaction",
    "domain": "datasets and benchmarks",
    "content": "Generalist embodied agents must perform interactive, causally-dependent reasoning, continually interacting with the environment, acquiring information, and updating plans to solve long-horizon tasks before they could be adopted in real-life scenarios. For instance, retrieving an apple from a cabinet may require opening multiple doors and drawers before the apple becomes visible and reachable—demanding sequential interaction under partial observability. However, existing benchmarks fail to systematically evaluate this essential capability. We introduce \\textbf{COIN}, a benchmark designed to assess interactive reasoning in realistic robotic manipulation through three key contributions. First, we construct \\textbf{COIN-50}: 50 interactive tasks in daily scenarios, and create \\textbf{COIN-Primitive} required by causally-dependent tasks, and \\textbf{COIN-Composition} with mid-term complexity for skill learning and generalization evaluation. Second, we develop a low-cost mobile AR teleoperation system and collect the COIN-Primitive Dataset with 50 demonstrations per primitive task (1,000 in total). Third, we develop systematic evaluation metrics about execution stability and generalization robustness to evaluate \\textbf{CodeAsPolicy}, \\textbf{VLA}, and language-conditioned \\textbf{H-VLA} approaches. Our comprehensive evaluation reveals critical limitations in current methods: models struggle with interactive reasoning tasks due to significant gaps between visual understanding and motor execution. We provide fine-grained analysis of these limitations.",
    "key_points": [
      "embodied ai",
      "vla",
      "reasoning",
      "manipulation"
    ],
    "gold_summary": "This work proposes a benchmark designed for interactive reasoning in robotic manipulation. The authors evaluate the current models on the benchmark and show the current models struggle with the interactive reasoning tasks."
  },
  {
    "paper_id": "URc29gSch9",
    "title": "Factual and Musical Evaluation Metrics for Music Language Models",
    "domain": "datasets and benchmarks",
    "content": "Music language models (Music LMs), like vision language models, leverage multimodal representations to answer natural language queries about musical audio recordings. Although Music LMs are reportedly improving, we find that current evaluations fail to capture whether their answers are correct. Specifically, for all Music LMs that we examine, widely-used evaluation metrics such as BLEU, METEOR, and BERTScore fail to measure anything beyond linguistic fluency of the model's responses. To measure the true performance of Music LMs, we propose (1) a better general-purpose evaluation metric for Music LMs adapted to the music domain and (2) a factual evaluation framework to quantify the correctness of a Music LM's responses. Our framework is agnostic to the modality of the question-answering model and could be generalized to quantify performance in other open-ended question-answering domains. We use open datasets in our experiments and will release all code on publication.",
    "key_points": [
      "music language models",
      "music captioning",
      "music question-answering",
      "evaluations",
      "benchmarking"
    ],
    "gold_summary": "This paper presents a critical look at evaluation protocols for Music LMs, providing both a better quantitative metric for open-ended QA and an automated evaluation pipeline for factual correctness of open-ended responses."
  },
  {
    "paper_id": "yAApKP1j0E",
    "title": "COMPOTE: Generating a Dataset of Real-World Binary Level Vulnerabilities",
    "domain": "datasets and benchmarks",
    "content": "Once a proprietary program written in a compiled language like C is successfully compiled, it is typically distributed as a binary executable. Consequently, security analysis of the program, including vulnerability detection, relies solely on the binary. Binary-level detection methods have been developed over the years, with machine learning (ML)-based methods becoming increasingly popular in the last decade. However, the scarcity of high-quality, publicly available datasets limits the development of ML-based binary vulnerability detectors, as existing binary-level vulnerability datasets are often synthetic and fail to reflect real-world vulnerabilities. At the same time, existing real-world source-code vulnerability datasets cannot be directly compiled, as they typically consist of standalone function snippets rather than compilable programs. To address this limitation, we present Compote, a COMPilation AI‑Orchestrated Transformation Engine that automatically wraps standalone C functions with the minimal scaffolding, such as headers, mocks, and main(), needed for successful compilation of C functions without altering the original code. Applying Compote to real-world functions from ten public datasets of vulnerable code yields a dataset comprising 18K compilable C functions along with their compiled binary versions. Our dataset represents a novel, large-scale, realistic, labeled benchmark spanning both source and binary domains. To evaluate our dataset, we fine-tune state-of-the-art vulnerability detection models. We show that models trained and tested exclusively on existing (synthetic) datasets achieve up to 98.97% F1 but drop to 29.28% when tested on the real-world vulnerabilities in our dataset. This demonstrates the inability of models trained on synthetic datasets to generalize effectively to real-world binary vulnerabilities, resulting in a significant drop in detection performance. We release Compote and our datasets to the research community to support further research on building and evaluating effective and practical binary vulnerability detection models.",
    "key_points": [
      "ai",
      "llm",
      "vulnerability detection",
      "binary-level",
      "cybersecurity",
      "code generation",
      "dataset creation",
      "llvm-ir",
      "compilation"
    ],
    "gold_summary": "This paper introduces a new benchmark that includes binary level vulnerabilities. It is based on existin source code vulnerability bechmarks were source code samples are automatically completed to generate compilable code."
  },
  {
    "paper_id": "y0KyBu5gfz",
    "title": "VideoGameBench: Can Vision-Language Models complete popular video games?",
    "domain": "datasets and benchmarks",
    "content": "Vision-language models (VLMs) have achieved strong results on coding and math benchmarks that are challenging for humans, yet their ability to perform tasks that come naturally to humans--such as perception, spatial navigation, and memory management--remains understudied. Video games are crafted to be intuitive for humans to learn and master by leveraging innate inductive biases, making them an ideal testbed for evaluating such capabilities in VLMs. To this end, we introduce VideoGameBench, a benchmark consisting of 10 popular video games from the 1990s that VLMs directly interact with in real-time. VideoGameBench challenges models to complete entire games with access to only raw visual inputs and a high-level description of objectives and controls, a significant departure from existing setups that rely on game-specific scaffolding and auxiliary information. We keep three of the games secret to encourage solutions that generalize to unseen environments. Our experiments show that frontier vision-language models struggle to progress beyond the beginning of each game. We find inference latency to be a major limitation of frontier models in the real-time setting; therefore, we introduce VideoGameBench Lite, a setting where the game pauses while waiting for the LM's next action. The best performing models, Gemini 2.5 Pro and Claude 3.7 Sonnet, complete only 0.48% of VideoGameBench and 1.6% of VideoGameBench Lite. We hope that the formalization of the human skills mentioned above into a benchmark motivates progress in these research directions.",
    "key_points": [
      "benchmark",
      "video games",
      "vision-language models",
      "agent"
    ],
    "gold_summary": "The paper presents a benchmark for Vision Language Models on a variety of popular video games from the 90s. Most current models get 0% performance on basically every single task with this setup."
  },
  {
    "paper_id": "MRfPHIJi94",
    "title": "Never Seen Before: Benchmarking Genuine Zero-Shot Composed Image Retrieval with Consistent Video-Sourced Datasets",
    "domain": "datasets and benchmarks",
    "content": "Zero-Shot Composed Image Retrieval (ZS-CIR) aims to retrieve a target image based on a query composed of a reference image and a relative caption without training samples. Existing ZS-CIR datasets often suffer from inconsistencies between reference and target images due to noisy image sources, and do not achieve a true zero-shot scenario as they use public image datasets that models like CLIP have been trained on. To tackle these challenges, we introduce ZeroSight, a novel benchmark for ZS-CIR. It includes a dataset with consistent reference-target pairs sourced from videos, a data construction pipeline, and evaluation methods that consider the ranking of multiple positive and negative target images. We ensure visually and semantically consistent reference-target pairs by extracting frames from a single video and generating relative captions using LLM-assisted methods. To ensure a true zero-shot scenario, we use video data published after March 31, 2022, ensuring it was not included in CLIP's pre-training data. Additionally, we propose a training-free MLLM-driven method, SC4CIR (Symmetric Consistency for CIR), which can effectively identify hard negative targets through 3 symmetric consistency checks. This method is plug-and-play, seamlessly integrating with various CIR methods and significantly improving performance. Our experimental results from 27 methods reveal that current ZS-CIR datasets and evaluation metrics result in inflated retrieval performance, exaggerating the capabilities of CIR methods. Our benchmark and models can be accessed at https://anonymous.4open.science/r/ZeroSight-CFE1.",
    "key_points": [
      "composed image retrieval",
      "zero-shot learning",
      "multi-modal retrieval"
    ],
    "gold_summary": "This paper proposes a benchmark for zero-shot composed image retrieval (ZS_CIR), including a dataset with consistent reference-target paris from videos, a data construction pipeline, and evaluation methods ranking multiple positive and negative target images."
  },
  {
    "paper_id": "7OT8OUhOFb",
    "title": "The Smart Buildings Control Suite: A Diverse Open Source Benchmark to Evaluate and Scale HVAC Control Policies for Sustainability",
    "domain": "datasets and benchmarks",
    "content": "Commercial buildings account for 17% of U.S. carbon emissions, with roughly half of that from Heating, Ventilation, and Air Conditioning (HVAC). HVAC devices form a complex thermodynamic system, and while model predictive control and reinforcement learning have been used to optimize control policies, scaling to thousands of buildings remains a significant unsolved challenge. Most current approaches are over-optimized for specific buildings and rely on proprietary data or hard-to-configure simulators. We present the Smart Buildings Control Suite, the first open source interactive HVAC control benchmark with a focus on solutions that generalize across building. It has 3 components: real-world data from 11 buildings over 6 years, a lightweight data-driven simulator for each building, and a modular Physically Informed Neural Network (PINN) building model as a simulator alternative. The buildings span multiple climates, management systems, and sizes, and both the simulator and PINN easily transfer to new buildings, ensuring solutions using this benchmark are robust to these factors and only reliant on fully scalable building models. This represents a major step towards scaling HVAC optimization from the lab to buildings everywhere. To facilitate use, our benchmark is compatible with the Gym standard, and our data is part of TensorFlow Datasets.",
    "key_points": [
      "reinforcement learning",
      "optimal control",
      "hvac control",
      "sustainability",
      "climate control",
      "datasets and benchmarks",
      "simulation",
      "physically informed neural networks"
    ],
    "gold_summary": "This paper proposes a smart building control suite, open source real world data and physical based simulators and PINN simulators. The control suite has been integrated to GYM for RL development and testing."
  },
  {
    "paper_id": "t59aU6sg1u",
    "title": "ArtifactsBench: Bridging the Visual-Interactive Gap in LLM Code Generation Evaluation",
    "domain": "datasets and benchmarks",
    "content": "The generative capabilities of Large Language Models (LLMs) are rapidly expanding from static code to dynamic, interactive visual artifacts. This progress is bottlenecked by a critical evaluation gap: established benchmarks focus on algorithmic correctness and largely overlook the visual fidelity and interactive integrity that define modern user experiences. To bridge this gap, we introduce ArtifactsBench, a benchmark and automated, multimodal evaluation paradigm for visual code generation. Our framework programmatically renders each generated artifact and captures its dynamic behavior via temporal (three-step) screenshots. This visual evidence, alongside the source code, is then assessed by a Multimodal LLM (MLLM)-as-Judge, which is rigorously guided by a fine-grained, per-task checklist to ensure holistic and reproducible scoring. We curate 1,825 diverse tasks and evaluate over 30 leading LLMs. Our automated evaluation achieves 94.4% ranking consistency with WebDev Arena—a de facto gold standard for human preferences in web development—and up to 90.95% pairwise agreement with human experts. We open-source ArtifactsBench, including the benchmark, evaluation harness, and baseline results at https://anonymous.4open.science/r/ArtifactsBench-F7F9, to provide the community with a scalable and accurate tool to accelerate the development of user-centric generative models.",
    "key_points": [
      "artifacts",
      "artifactsbench",
      "mllm",
      "code"
    ],
    "gold_summary": "This work proposes ArtifactsBench, a benchmark for visual code generation. The benchmark includes 1800+ examples, and the MLLM-based evaluation results correlate well with human experts and WebDev Arena."
  },
  {
    "paper_id": "XZNXSM4rHG",
    "title": "MRMR: A Realistic and Expert-Level Multidisciplinary Benchmark for Reasoning-Intensive Multimodal Retrieval",
    "domain": "datasets and benchmarks",
    "content": "We introduce MRMR, the first expert-level multidisciplinary multimodal retrieval benchmark requiring intensive reasoning. MRMR contains 1,502 queries spanning 23 domains, with positive documents carefully verified by human experts. Compared to prior benchmarks, MRMR introduces three key advancements. First, it challenges retrieval systems across diverse areas of expertise, enabling fine-grained model comparison across domains. Second, queries are reasoning-intensive, with images requiring deeper interpretation such as diagnosing microscopic slides. We further introduce Contradiction Retrieval, a novel task requiring models to identify conflicting concepts. Finally, queries and documents are constructed as image–text interleaved sequences. Unlike earlier benchmarks restricted to single images or unimodal documents, MRMR offers a realistic setting with multi-image queries and mixed-modality corpus documents. We conduct an extensive evaluation of 4 categories of multimodal retrieval systems and 14 frontier models on MRMR. The text embedding model Qwen3-Embedding with LLM-generated image captions achieves the highest performance, highlighting substantial room for improving multimodal retrieval models. Although latest multimodal models such as Ops-MM-Embedding perform competitively on expert-domain queries, they fall short on reasoning-intensive tasks. We believe that MRMR paves the way for advancing multimodal retrieval in more realistic and challenging scenarios.",
    "key_points": [
      "multimodal retrieval benchmark",
      "reasoning",
      "multimodal llms"
    ],
    "gold_summary": "Summary:\nAuthors repurpose MMMU-Pro and use other synthetic methods to generate a multimodal retrival dataset that has expert domain, reasoning intensive and contradition style questions."
  },
  {
    "paper_id": "owFVvaLFdw",
    "title": "AgentHard: Hardening LLM-Agent Evaluation with a Taxonomy of Artifacts and Automated Cleaning",
    "domain": "datasets and benchmarks",
    "content": "Reliable evaluation of LLM‑based agents is often confounded by artifacts that misrepresent true agent capabilities by conflating model errors with benchmark flaws. To address this, we present a component-wise taxonomy of common benchmark pitfalls spanning the user, environment, evaluation, and ground truth elements of agent tasks. This analysis exposes pervasive issues such as incorrect ground-truth action sequences, ambiguous tool APIs, user simulation faults, and brittle evaluation metrics. Guided by these insights, we develop AgentBenchCleaner, an automated pipeline that filters out flawed tasks in three stages: first, rule-based detectors catch deterministic errors; second, an LLM-as-judge identifies nuanced issues; and third, a quality-filtering step enhances evaluation rigor. Applying this pipeline yields a curated benchmark suite, AgentHard-Bench, with standardized evaluation protocols and explicit quality criteria. Across diverse LLM agents, evaluations on AgentHard-Bench deliver more stable model rankings, clearer performance separations, and improved benchmark diversity relative to the original benchmarks. We will release AgentHard-Bench, along with the taxonomy and pipeline upon acceptance, to support robust, reproducible agent evaluation.",
    "key_points": [
      "agent benchmark",
      "benchmark filtering"
    ],
    "gold_summary": "The paper introduces a taxonomy for classifying issues in agentic evals. They then use this taxonomy in an automated pipeline to tag samples with issues. They show strong agreement with human raters."
  },
  {
    "paper_id": "UWQImPqblv",
    "title": "Exploring the Meta-level Reasoning of Large Language Models via a Tool-based Multi-hop Tabular Question Answering Task",
    "domain": "datasets and benchmarks",
    "content": "Recent advancements in Large Language Models (LLMs) are increasingly focused on \"reasoning\" ability, a concept with many overlapping definitions in the LLM discourse. We take a more structured approach, distinguishing meta-level reasoning (denoting the process of reasoning about intermediate steps required to solve a task) from object-level reasoning (which concerns the low-level execution of the aforementioned steps.) We design a novel question answering task, which is based around the values of geopolitical indicators for various countries over various years. Questions require breaking down into intermediate steps, retrieval of data, and mathematical operations over that data. The meta-level reasoning ability of LLMs is analysed by examining the selection of appropriate tools for answering questions. To bring greater depth to the analysis of LLMs beyond final answer accuracy, our task contains 'essential actions' against which we can compare the tool call output of LLMs to infer the strength of reasoning ability. We find that LLMs demonstrate good meta-level reasoning on our task, yet are flawed in some aspects of task understanding. We find that n-shot prompting has little effect on accuracy; error messages encountered do not often deteriorate performance; and provide additional evidence for the poor numeracy of LLMs. Finally, we discuss the generalisation and limitation of our findings to other task domains.",
    "key_points": [
      "question answering",
      "llms",
      "meta-level reasoning"
    ],
    "gold_summary": "The authors propose a new QA system to evaluate the meta-reasoning capability of LLMs by supervising the intermediate reasoning chain by examining the correctness of core tools selected."
  },
  {
    "paper_id": "MWtm2f1tyG",
    "title": "IMPACT: Industrial Machine Perception via Acoustic Cognitive Transformer",
    "domain": "datasets and benchmarks",
    "content": "Industrial acoustic signals encode machine state, yet prevailing data-driven approaches are task-specific supervised pipelines that generalize poorly beyond their design conditions. Progress is further limited by the scarcity of large-scale datasets and pretrained models tailored to active shop floor audio. To address this, we introduce DINOS (Diverse INdustrial Operation Sounds), a dataset of 74,149 recordings totaling over 1,093 hours collected from active manufacturing lines across diverse processes and operating regimes. We also provide IMPACT(Industrial Machine Perception via Acoustic Cognitive Transformer), a reference model pretrained on DINOS to standardize evaluation. Our benchmark is structured in four machine-specific steps: (1) baseline discrimination, (2) moderate operational complexity, (3) scalability to unseen equipment, and (4) domain shift and sensor modality adaptation. Across tasks, models pretrained or fine-tuned on DINOS consistently outperform general-purpose audio models, demonstrating the value of domain-specific pretraining for industrial acoustic perception.",
    "key_points": [
      "industrial sound dataset",
      "machine monitoring",
      "manufacturing",
      "self-supervised learning",
      "pretrainedmodel"
    ],
    "gold_summary": "## An open-access dataset of industrial operation sounds\n\n- Proposed DINOS, a dataset with over ~1000 hours of recordings from active manufacturing lines.\n- Proposes IMPACT, a reference baseline models trained on the DINOS dataset."
  },
  {
    "paper_id": "6CBLcRkuaN",
    "title": "GovBench: From Natural Language to Executable Pipelines, A New Benchmark for Data Governance Automation",
    "domain": "datasets and benchmarks",
    "content": "Data governance is essential for scaling modern AI development. To automate data governance, numerous tools and models have emerged that translate user intent into executable governance code. However, the effectiveness of existing tools and models is largely unverified. The evaluation is severely hampered by the lack of a realistic, standardized, and quantifiable benchmark. This critical gap presents a significant obstacle to systematically evaluating utility and impedes further innovation in the field. To bridge this gap, we introduce GovBench, a benchmark featuring a diverse set of tasks with targeted noise to simulate real-world scenarios and standardized scoring scripts for reproducible evaluation. Our analysis reveals that current data governance tools and models struggle with complex, multi-step workflows and lack robust error-correction mechanisms. We therefore propose DataGovAgent, a novel framework for end-to-end data governance utilizing a Planner-Executor-Evaluator architecture. This design incorporates contract-guided planning, retrieval from a reliable operator library, and sandboxed meta-cognitive debugging. Experimental results validate our approach: DataGovAgent significantly boosts the Average Task Score (ATS) on complex Directed Acyclic Graph (DAG) tasks from 39.7 to 54.9 and reduces debugging iterations by over 77.9\\% compared to general-purpose agent frameworks, a step toward more reliable automation of data governance. Code is available at https://anonymous.4open.science/r/GovBench-F6C6.",
    "key_points": [
      "benchmarks",
      "agent",
      "data governance",
      "large language models"
    ],
    "gold_summary": "The authors propose a new data governance benchmark to improve automation of data governance. They show that their benchmark improves performance quite a bit (though at a substantial token cost)."
  },
  {
    "paper_id": "9HsaIi4ngF",
    "title": "RouterArena: An Open Platform for Comprehensive Comparison of LLM Routers",
    "domain": "datasets and benchmarks",
    "content": "Today's LLM ecosystem comprises a wide spectrum of models that differ in size, capability, and cost. No single model is optimal for all scenarios; hence, LLM routers have become essential for selecting the most appropriate model under varying circumstances. However, the rapid emergence of various routers makes choosing the right one increasingly challenging. To address this problem, we need a comprehensive router comparison and a standardized leaderboard, similar to those available for models. In this work, we introduce RouterArena, the first open platform enabling comprehensive comparison of LLM routers. RouterArena has (1) a principally constructed dataset with broad knowledge domain coverage, (2) distinguishable difficulty levels for each domain, (3) an extensive list of evaluation metrics, and (4) an automated framework for leaderboard updates. Leveraging our framework, we have produced the initial leaderboard with detailed metrics comparison as shown in Figure 1. We will make our platform open to the public; the current code base is available here: https://anonymous.4open.science/r/RouterArena-1D4B/README.md",
    "key_points": [
      "llm router",
      "evaluation"
    ],
    "gold_summary": "The paper tackles a timely problem—standardized router evaluation—with a clear systemization (dataset + metrics + framework) and substantive empirical coverage (open-source and commercial)."
  },
  {
    "paper_id": "emM6KIsBHl",
    "title": "OpenMarcie: Dataset for Multimodal Action Recognition in Industrial Environments",
    "domain": "datasets and benchmarks",
    "content": "Smart factories use advanced technologies to optimize production and increase efficiency. To this end, the recognition of worker activity allows for accurate quantification of performance metrics, improving efficiency holistically while contributing to worker safety. OpenMarcie is, to the best of our knowledge, the biggest multimodal dataset designed for human action monitoring in manufacturing environments. It includes data from wearables sensing modalities and cameras distributed in the surroundings. The dataset is structured around two experimental settings, involving a total of 36 participants. In the first setting, twelve participants perform a bicycle assembly and disassembly task under semi-realistic conditions without a fixed protocol, promoting divergent and goal-oriented problem-solving. The second experiment involves twenty-five volunteers (24 valid data) engaged in a 3D printer assembly task, with the 3D printer manufacturer's instructions provided to guide the volunteers in acquiring procedural knowledge. This setting also includes sequential collaborative assembly, where participants assess and correct each other's progress, reflecting real-world manufacturing dynamics. OpenMarcie includes over 37 hours of egocentric and exocentric, multimodal, and multipositional data, featuring eight distinct data types and more than 200 independent information channels. The dataset is benchmarked across three human activity recognition tasks: activity classification, open vocabulary captioning, and cross-modal alignment. The dataset and associated code of OpenMarcie are publicly available at https://kaggle.com/datasets/47634878f107d35a57172f270241993d822fd67114c0f4d173b40b2dd9346a58",
    "key_points": [
      "industrial-scale datasets",
      "human-centric ai",
      "multimodal learning"
    ],
    "gold_summary": "This paper introduces a multimodal dataset designed for human action monitoring in manufacturing environments. The dataset focuses on two scenarios: bicycle and 3D printer assembly and disassembly."
  },
  {
    "paper_id": "XXNh0JfsDN",
    "title": "GenoArmory: A Unified Evaluation Framework for Adversarial Attacks on Genomic Foundation Models",
    "domain": "datasets and benchmarks",
    "content": "We propose the first unified adversarial attack benchmark for Genomic Foundation Models (GFMs), named GenoArmory. Unlike existing GFM benchmarks, GenoArmory offers the first comprehensive evaluation framework to systematically assess the vulnerability of GFMs to adversarial attacks. Methodologically, we evaluate the adversarial robustness of five state-of-the-art GFMs using four widely adopted attack algorithms and three defense strategies. Importantly, our benchmark provides an accessible and comprehensive framework to analyze GFM vulnerabilities with respect to model architecture, quantization schemes, and training datasets. Additionally, we introduce GenoAdv, a new adversarial sample dataset designed to improve GFM safety. Empirically, classification models exhibit greater robustness to adversarial perturbations compared to generative models, highlighting the impact of task type on model vulnerability. Moreover, adversarial attacks frequently target biologically significant genomic regions, suggesting that these models effectively capture meaningful sequence features.",
    "key_points": [
      "genomic foundation models",
      "vulnerability",
      "benchmark",
      "adversarial attacks",
      "adversarial defense"
    ],
    "gold_summary": "This paper presents a comprehensive and timely evaluation of adversarial attacks on genomics foundation models. The papers present extensive experimental setups, which cover a wide array of foundation models, attack methodologies, and defense mechanisms."
  },
  {
    "paper_id": "I7fTPLT8A9",
    "title": "We-Math 2.0: A Versatile MathBook System for Incentivizing Visual Mathematical Reasoning",
    "domain": "datasets and benchmarks",
    "content": "Multimodal large language models (MLLMs) have demonstrated impressive capabilities across various tasks but still struggle with complex mathematical reasoning. Prior work has mainly focused on dataset construction and method optimization, while often overlooking two critical aspects: comprehensive knowledge-driven design and model-centric data space modeling. We introduce WE-MATH 2.0, a unified system that integrates a structured mathematical knowledge hierarchy, model-centric data space modeling, and a reinforcement learning (RL)-based training paradigm to enhance the mathematical reasoning abilities of MLLMs. Our contributions are fourfold: (1) MathBook Knowledge System: a five-level hierarchy covering 491 knowledge points and 1,819 fundamental principles; (2) MathBook-Standard and MathBook-Pro: datasets that ensure broad conceptual coverage and robust training through dual expansion, a three-dimensional difficulty space, and seven progressive variants per problem; (3) MathBook-RL: a two-stage RL framework including Cold-Start Fine-Tuning to align models with knowledge-oriented chain-of-thought reasoning, and Progressive Alignment RL leveraging average-reward learning with dynamic data scheduling for progressive difficulty alignment; (4) MathBookEval: a benchmark covering all 491 knowledge points with diverse reasoning step distributions. Experimental results show that MathBook-RL achieves competitive performance on four widely used benchmarks and demonstrates strong results on MathBookEval, suggesting promising generalization in mathematical reasoning.",
    "key_points": [
      "mathematical reasoning",
      "multimodal large language models"
    ],
    "gold_summary": "This paper introduces We-Math 2.0, a system involving a knowledge system for mathematical knowledge, a pair of dataset for training, an RL framework, and a comprehensive benchmark for multimodal mathematical reasoning."
  },
  {
    "paper_id": "d0gvsym66h",
    "title": "NABench: Large-Scale Benchmarks of Nucleotide Foundation Models for Fitness Prediction",
    "domain": "datasets and benchmarks",
    "content": "Nucleotide sequence variation can induce significant shifts in functional fitness. Recent nucleotide foundation models promise to predict such fitness effects directly from sequence, yet heterogeneous datasets and inconsistent preprocessing make it difficult to compare methods fairly across DNA and RNA families. We introduce NABench, a large-scale, systematic benchmark for nucleic acid fitness prediction. NABench aggregates 162 high-throughput assays and curates 2.6 million mutated sequences spanning diverse DNA and RNA families, with standardized splits and rich metadata. We show that NABench surpasses prior nucleotide fitness benchmarks in scale, diversity, and data quality. Under a unified evaluation suite, we rigorously assess 29 representative sequence models across zero-shot, few-shot prediction, transfer learning, and supervised settings. The results quantify performance heterogeneity across tasks and nucleic-acid types, demonstrating clear strengths and failure modes for different modeling choices and establishing strong, reproducible baselines. We release NABench to catalyze progress in nucleic-acid modeling and to support downstream applications in nucleotide molecular design, synthetic biology, and biochemistry. Our code is available at https://anonymous.4open.science/r/NABench-20CB.",
    "key_points": [
      "foundation model",
      "fitness prediction",
      "nucleic acid"
    ],
    "gold_summary": "In this paper, the authors have undertaken a significant effort in curating a large-scale benchmark (162 assays, 2.6M sequences, 29 models) to systematize the evaluation of nucleotide foundation models."
  },
  {
    "paper_id": "lEDb4gQ4dB",
    "title": "CircuitNet 3.0: A Multi-Modal Dataset with Task-Oriented Augmentation for AI-Driven Circuit Design",
    "domain": "datasets and benchmarks",
    "content": "Integrated circuit (IC) designs require transforming high-level specifications into physical layouts, demanding extensive expertise and specialized tools, as well as months of time and numerous iterations. While Machine Learning (ML) has shown promise in various research domains, the lack of large-scale, open datasets limits its application in chip design. To address this limitation, we introduce CircuitNet 3.0, a large-scale, comprehensive, and open-source dataset curated to facilitate the evaluation of ML models on challenging timing and power prediction tasks. Starting with a diverse set of 8,659 validated open-source designs, we employ a systematic framework to generate over 15,000 instances. Through specialized syntax-tree mutation strategies and principled, task-oriented filtering methodology, we enrich each design with multi-modal information spanning multiple design stages, including complete design flow documentation, register-transfer-level (RTL) designs and corresponding netlists, detailed physical layouts, and comprehensive performance metrics. The experimental results convincingly demonstrate that ML models leveraging multi-stage, multi-modal circuit representations significantly improve performance over existing open-source datasets in electronic design automation (EDA) tasks, paving the way for efficient and accessible circuit representation learning. The dataset and codes are available in  \\url{https://anonymous.4open.science/r/ICLR26-CircuitNet3-272B}.",
    "key_points": [
      "dataset",
      "benchmark",
      "machine learning",
      "electric design automatic"
    ],
    "gold_summary": "This work proposes CircuitNet 3.0, which contains 8,659 unique and validated source RTL designs and over 15,000 total augmented designs, each with corresponding netlist and layout representations."
  },
  {
    "paper_id": "EoZKimMYXi",
    "title": "HA-VLN 2.0: An Open Benchmark and Leaderboard for Human-Aware Navigation in Discrete and Continuous Environments with Dynamic Multi-Human Interactions",
    "domain": "datasets and benchmarks",
    "content": "Vision-and-Language Navigation (VLN) has been studied mainly in either discrete or continuous settings, with little attention to dynamic, crowded environments. We present HA-VLN 2.0, a unified benchmark introducing explicit social-awareness constraints. Our contributions are: (i) a standardized task and metrics capturing both goal accuracy and personal-space adherence; (ii) HAPS 2.0 dataset and simulators modeling multi-human interactions, outdoor contexts, and finer language–motion alignment; (iii) benchmarks on 16,844 socially grounded instructions, revealing sharp performance drops of leading agents under human dynamics and partial observability; and (iv) real-world robot experiments validating sim-to-real transfer, with an open leaderboard enabling transparent comparison. Results show that explicit social modeling improves navigation robustness and reduces collisions, underscoring the necessity of human-centric approaches. By releasing datasets, simulators, baselines, and protocols, HA-VLN 2.0 provides a strong foundation for safe, socially responsible navigation research.",
    "key_points": [
      "vision-and-language navigation",
      "human-aware navigation"
    ],
    "gold_summary": "This paper introduces a visual language navigation benchmark in the presence of dynamic human agents. It includes both discrete, and continuous environments, and common metrics between the two."
  },
  {
    "paper_id": "35cHQuDeo4",
    "title": "Sound in Sights: Deriving Visual Insights from Audio for Comprehensive Video Understanding with Large Multimodal Models",
    "domain": "datasets and benchmarks",
    "content": "Video understanding is inherently multimodal, requiring both visual and auditory cues to form a complete representation of dynamic scenes. However, most existing video understanding models rely solely on visual content, overlooking informative audio cues, such as spoken instructions or environmental sounds, for scene understanding and event comprehension. Progress in audio-visual reasoning has been hindered by the lack of high-quality supervised fine-tuning (SFT) data that jointly considers video and audio. To address this gap, we introduce SoundInSight, a large-scale audio-visual question answering dataset comprising over 80k question–answer pairs from online videos, created via a multimodal large language model (MLLM)-assisted annotation pipeline. SoundInSight provides rich supervision for audio-visual reasoning, enabling MLLMs to be fine-tuned for audio understanding. We find that current video MLLMs heavily rely on visual information, hindering effective multimodal learning. To mitigate this, we propose an audio-only pretraining stage, which significantly improves audio-visual reasoning performance. Additionally, to evaluate audio-visual comprehension, we construct a high-quality, manually curated test set of 1,000 samples requiring joint audio-visual understanding, exceeding standard benchmarks in complexity. Models fine-tuned on SoundInSight with the proposed training strategy achieve substantial performance gains on this new benchmark. Moreover, on the challenging VideoMME evaluation, our approach significantly improves performance in Information Synopsis subcategory, demonstrating the efficacy of incorporating audio. The SoundInSight dataset and code will be publicly released to facilitate further research.",
    "key_points": [
      "multimodal large language model",
      "video understanding"
    ],
    "gold_summary": "This paper introduces SoundInSights, an audio-visual question answering dataset based on LLaVA-Video-178k."
  },
  {
    "paper_id": "a2XmC7rHIU",
    "title": "The Open Proof Corpus: A Large-Scale Study of LLM-Generated Mathematical Proofs",
    "domain": "datasets and benchmarks",
    "content": "In recent months, large language models (LLMs) have made significant progress in mathematical proof generation, but further advancement is hindered by the lack of a large-scale, high-quality dataset of human-evaluated proofs. While expensive to create, such a dataset is essential for driving improvements in training and addressing key open questions in the field of automated proof generation. Specifically, it remains unknown (1) how large the gap is between natural language and formal proof generation, (2) how final-answer accuracy relates to full proof correctness, and (3) how best-of-n selection strategies can affect proof quality. In this work, we present *the Open Proof Corpus* (OPC), a dataset comprising over 5,000 human-evaluated proofs produced by state-of-the-art LLMs. The OPC was specifically designed for broad applicability and downstream usage in proof generation research and is the first to include a substantial number of correct, LLM-generated solutions to problems from prestigious mathematics competitions such as the USAMO and IMO. Using the OPC, we address the open questions outlined above and provide new insights into LLMs' strengths and limitations in mathematical reasoning. Finally, to showcase the utility of the OPC, we finetune an 8B-parameter model on the dataset, obtaining a model that matches **Gemini-2.5-Pro**, and performs close to the best model, **GPT-5**, on evaluating proof correctness.",
    "key_points": [
      "ai",
      "artificial intelligence",
      "reasoning",
      "llm",
      "math",
      "benchmark",
      "dataset",
      "proof",
      "gpt",
      "machine learning"
    ],
    "gold_summary": "The paper presents large-scale dataset of high-difficulty math problems which includes both correct/incorrect proofs and profound annotations which are represented via human-expert judgements. Based on the dataset, some exciting insights are proposed."
  },
  {
    "paper_id": "M7TNf5J26u",
    "title": "AstaBench: Rigorous Benchmarking of AI Agents with a Scientific Research Suite",
    "domain": "datasets and benchmarks",
    "content": "AI agents hold the potential to revolutionize scientific productivity by automating literature reviews, replicating experiments, analyzing data, and even proposing new directions of inquiry; indeed, there are now many such agents, ranging from general-purpose \"deep research\" systems to specialized science-specific agents, such as AI Scientist and AIGS. Rigorous evaluation of these agents is critical for progress. Yet existing benchmarks fall short on several fronts: they (1) fail to provide holistic, product-informed measures of real-world use cases such as science research; (2) lack reproducible agent tools necessary for a controlled comparison of core agentic capabilities; (3) do not account for confounding variables such as model cost and tool access; (4) do not provide standardized interfaces to speed agent prototyping and evaluation; and (5) lack comprehensive baseline agents necessary to identify true advances. In response, we define principles and tooling for more rigorously benchmarking agents. Using these, we present AstaBench, a suite that provides the first holistic measure of agentic ability to perform scientific research, comprising 2400+ problems spanning the entire scientific discovery process and multiple scientific domains, and including many problems inspired by actual user requests to deployed Asta agents. Our suite comes with the first scientific research environment with production-grade search tools that enable controlled, reproducible evaluation, better accounting for confounders. Alongside, we provide a comprehensive suite of nine science-optimized Asta agent classes plus numerous baselines. Our extensive evaluation of 57 agents across 22 agent classes reveals several interesting findings, most importantly that despite meaningful progress on certain individual aspects, AI remains far from solving the challenge of science research assistance.",
    "key_points": [
      "agents",
      "evaluation",
      "benchmarks",
      "scientific research"
    ],
    "gold_summary": "This paper puts forward outstanding issues in the evaluation practices for AI science-specific agents. They introduce AstaBench, an evaluation suite that provides a holistic measure of agentic ability to perform scientific research."
  },
  {
    "paper_id": "cGv4z4eaNr",
    "title": "PIKA: Expert-Level Synthetic Datasets for Post-Training Alignment from Scratch",
    "domain": "datasets and benchmarks",
    "content": "Reinforcement Learning from Human Feedback (RLHF) has become a cornerstone for aligning large language models (LLMs). However, its effectiveness critically depends on high-quality instruction data. Most existing high-quality alignment datasets are either private or require costly human annotation, which hinders reproducibility and scalability. Even with the emergence of Reinforcement Learning from AI Feedback (RLAIF), concerns about data quality remain. Moreover, it is still unclear to the open-source community how much data is actually required to fine-tune a base model into a strong instruction-following model. \nCurrent state-of-the-art approaches typically rely on over 300k examples even at the supervised fine-tuning (SFT) stage, yet they still underperform compared to proprietary models, leaving substantial barriers for academic and resource-constrained communities.\nTo address this gap, we introduce PiKa, a data-efficient family of expert-level alignment datasets. \nIn particular, the PiKa-SFT dataset uses only 30k SFT examples—an order of magnitude fewer than the SoTA dataset Magpie.\nThrough extensive evaluations by fine-tuning Llama-3-8B-Base on PiKa and other public instruction following datasets,\nwe show that PiKa-SFT alone outperforms models trained on much larger datasets. Remarkably, on two widely used alignment benchmarks, AlpacaEval 2.0 and Arena-Hard, PiKa-SFT fine-tuning surpasses the official Llama-3-8B-Instruct model -- which was trained on over 10M proprietary examples. We further extend our study by training the Qwen2.5 series (0.5B–7B) on PiKa-SFT, consistently outperforming their official instruction-tuned counterparts.  In addition, we curate 30k high-quality preference optimization examples, which further improve alignment performance when applied after SFT initialization. These findings demonstrate that high-quality alignment can be achieved with significantly reduced data, providing a practical and scalable path for advancing open-source LLM alignment research. Our code and data will be available at https://anonymous.4open.science/r/PiKa.",
    "key_points": [
      "llm alignment",
      "rlhf",
      "post-training",
      "preference optimization"
    ],
    "gold_summary": "This paper presents a highly impactful finding that directly challenges the \"scale-is-all-you-need\" paradigm for LLM alignment. The core contribution is PIKA, a remarkably small (only 30k SFT samples) yet exceptionally high-quality synthetic dataset."
  },
  {
    "paper_id": "txURffKsPo",
    "title": "M3Kang: Evaluating Multilingual Multimodal Mathematical Reasoning in Vision-Language Models",
    "domain": "datasets and benchmarks",
    "content": "Despite state-of-the-art vision-language models (VLMs) have demonstrated strong reasoning capabilities, their performance in multilingual mathematical reasoning remains underexplored, particularly when compared to human performance. To bridge this gap, we introduce M3Kang, the first highly multilingual, multimodal mathematical reasoning dataset for VLMs. It is derived from the Kangaroo Math Competition, the world’s largest mathematics contest, which annually engages over six million participants under the age of 18 across more than 90 countries. M3Kang includes 1,789 unique multiple-choice problems organized by grade-level difficulty, with translations into 15 culturally diverse languages, some of them including diagrams essential for solving them. Using this dataset, we conduct extensive benchmarking on both closed- and open-source SOTA models. We observe that, despite recent advances, models still struggle with basic math and diagram-based reasoning, with performance scaling with language presence and model size, but not with grade level. We also find that multilingual techniques can be effectively extended to the multimodal setting, resulting in significant improvements over baseline approaches. Our analysis also incorporates performance data from over 68,000 students, enabling direct comparison with human performance. We are open-sourcing M3Kang, including the English-only subset M2Kang, along with the framework and codebase used to construct the dataset.",
    "key_points": [
      "benchmark",
      "dataset",
      "vision-language models",
      "vlm",
      "mathematics",
      "reasoning",
      "multilingual"
    ],
    "gold_summary": "Build a highly multilingual, multimodal benchmark (M3Kang) from Kangaroo Math problems; create an automated, quality-controlled translation pipeline; benchmark SOTA VLMs; test multilingual inference techniques in multimodal settings; compare to human performance."
  },
  {
    "paper_id": "jik0oNrrfB",
    "title": "EmoNet-Voice: A Large-Scale Synthetic Benchmark for Fine-Grained Speech Emotion",
    "domain": "datasets and benchmarks",
    "content": "Speech emotion recognition (SER) systems are constrained by existing datasets that typically cover only 6-10 basic emotions, lack scale and diversity, and face ethical challenges when collecting sensitive emotional states. We introduce EmoNet-Voice, a comprehensive resource addressing these limitations through two components: (1) EmoNet-Voice Big, a 5,000-hour multilingual pre-training dataset spanning 40 fine-grained emotion categories across 11 voices and 4 languages, and (2) EmoNet-Voice Bench, a rigorously validated benchmark of 4,7k samples with unanimous expert consensus on emotion presence and intensity levels. Using state-of-the-art synthetic voice generation, our privacy-preserving approach en- ables ethical inclusion of sensitive emotions (e.g., pain, shame) while maintaining controlled experimental conditions. Each sample underwent validation by three psychology experts. We demonstrate that our Empathic Insight models trained on our synthetic data achieve strong real-world dataset generalization, as tested on EmoDB and RAVDESS. Furthermore, our comprehensive evaluation reveals that while high-arousal emotions (e.g., anger: 95% accuracy) are readily detected, the benchmark successfully exposes the difficulty of distinguishing perceptually similar emotions (e.g., sadness vs. distress: 63% discrimination), providing quantifiable metrics for advancing nuanced emotion AI. EMONET-VOICE establishes a new paradigm for large-scale, ethically-sourced, fine-grained SER research.",
    "key_points": [
      "speech emotion recognition",
      "synthetic speech dataset",
      "fine-grained emotions",
      "emotion intensity annotation",
      "privacy-preserving data",
      "multilingual audio",
      "benchmark evaluation",
      "expert validation",
      "cross-dataset generalization",
      "pre-training dataset"
    ],
    "gold_summary": "This paper introduces EMONET-VOICE BIG, a large-scale synthetic multilingual pretraining dataset, and EMONET-VOICE BENCH, a fine-grained dataset for SER. The authors release models trained on those datasets which outperform foundation models."
  },
  {
    "paper_id": "V9fU8Pw9qr",
    "title": "WAFER-QA: Evaluating Vulnerabilities of Agentic Workflows with Agent-as-Judge",
    "domain": "datasets and benchmarks",
    "content": "Agentic workflows—where multiple large language model (LLM) instances interact to solve tasks—are increasingly built on feedback mechanisms, where one model evaluates and critiques another.\nDespite the promise of feedback-driven improvement, the stability of agentic workflows rests on the reliability of the judge. However, judges may hallucinate information, exhibit bias, or act adversarially—introducing critical vulnerabilities into the workflow.\nIn this work, we present a systematic analysis of agentic workflows under deceptive or misleading feedback. \nWe introduce a two-dimensional framework for analyzing judge behavior, along axes of intent (from constructive to malicious) and knowledge (from parametric-only to retrieval-augmented systems).\nUsing this taxonomy, we construct a suite of judge behaviors and develop WAFER-QA, a new benchmark with critiques grounded in retrieved web evidence to evaluate robustness of agentic workflows against factually supported adversarial feedback. We reveal that even strongest agents are vulnerable to persuasive yet flawed critiques—often switching correct answers after receiving misleading feedback. \nTaking a step further, we study \nhow model predictions evolve over multiple rounds of interaction, revealing distinct behavioral patterns between reasoning and non-reasoning models.\nOur findings highlight fundamental vulnerabilities in feedback-based workflows and offer guidance for building more robust agentic systems.",
    "key_points": [
      "llm agent",
      "llm judge",
      "agent-as-judge",
      "robustness"
    ],
    "gold_summary": "The authors present a dataset for evaluating the robustness of a system to a deceptive or hallucinating Agent-as-a-Judge. They find that existing systems are very vulnerable to such problematic judges."
  },
  {
    "paper_id": "gwavfvxSwg",
    "title": "Can Large Language Models Assess and Reframe Psychological Attribution: A Benchmark and Analysis",
    "domain": "datasets and benchmarks",
    "content": "According to the reformulated version of the Learned Helplessness theory, an individual who experiences uncontrollable negative events may subsequently develop a negative attributional style, thereby exhibiting greater susceptibility to depressive symptoms. This depressogenic attributional style not only contributes to depressive symptoms but also represents a malleable target for cognitive therapy. \nDespite its theoretical and practical significance, computational research on attributional cognition remains underexplored due to the lack of large-scale, high-quality datasets and robust evaluation protocols. In this work, we introduce the Attributional Style Transfer Dataset (ASTD) along with dedicated evaluation metrics, the first benchmark designed to model, assess, and reframe attributional explanations at scale. \nConstructed via a Prevent–Filter–Validate pipeline that integrates LLM-based generation with specialist validation, ASTD contains 42,000 real-world events paired with psychologically grounded attributions spanning seven styles. Using this dataset, we address two key challenges: (1) scalable assessment of attributional style via both supervised classifiers and zero/few-shot LLMs; and (2)attributional reframing and evaluation, where we propose automatic evaluation metrics to quantify psychological validity. Furthermore, we leverage our proposed metrics to construct a preference dataset, fine-tuning LLMs with Direct Preference Optimization (DPO) and achieving substantial gains in reframing quality. Together, our dataset, metrics, and methodology offer a new paradigm for understanding and modeling attributional style, with direct implications for scalable and adaptive mental health interventions.",
    "key_points": [
      "attributional reframing; attributional style; astd benchmark"
    ],
    "gold_summary": "In this paper, the author proposed a psychological benchmark dataset and also a pipeline for scalable data generation."
  },
  {
    "paper_id": "dlaNQM6YbZ",
    "title": "The Flaw of Averages: Quantifying Uniformity of Performance on Benchmarks",
    "domain": "datasets and benchmarks",
    "content": "Benchmarks shape scientific conclusions about model capabilities and steer model development. This creates a feedback loop: stronger benchmarks drive better models, and better models demand more discriminative benchmarks. Ensuring benchmark reliability is therefore essential for trustworthy evaluation and meaningful progress. In this work, we study benchmark reliability from a \\emph{distributional} perspective and introduce benchmark harmony, which measures \\textit{how uniformly a model's performance is distributed across the subdomains of a benchmark}. We posit that high harmony is a desirable benchmark property, indicating that the aggregate metric reflects uniform competence across subdomains. Across 19 multiple-choice benchmarks and five model families, we map each benchmark onto a mean-variance plane of harmony computed across models, where high mean and low variance signal more reliable evaluation. Our analysis shows that less harmonious benchmarks can give misleading results, since overall accuracy may be disproportionately influenced by specific subdomains. For instance, \\emph{ARC-Easy} is overwhelmed by questions on \\emph{Biological Concepts}, overshadowing other critical subdomains such as Geography, Physics, Chemistry, and Environmental Science. By recommending that harmony should be reported alongside accuracy, we reframe evaluation from \nsimple performance averages to a more robust, distributionally reliable measurement of performance.",
    "key_points": [
      "benchmark reliability",
      "meta-evaluation of benchmarks",
      "evaluation reliability",
      "diagnostic evaluation"
    ],
    "gold_summary": "This paper introduces HARMONY, an entropy-based metric that measures how uniformly a model’s performance is distributed across subdomains of a benchmark. It aims to reveal when aggregate accuracy obscures uneven competency."
  },
  {
    "paper_id": "E9zStzWz6M",
    "title": "GenColorBench: A Color Evaluation Benchmark for Text-to-Image Generation Models",
    "domain": "datasets and benchmarks",
    "content": "Recent years have seen impressive advances in text-to-image generation, with image generative or unified models, generating high-quality images from text. Yet these models still struggle with fine-grained color controllability, often failing to accurately match colors specified in text prompts. While existing benchmarks evaluate compositional reasoning and prompt adherence, none systematically assess the color precision. Color is fundamental to human visual perception and communication, critical for applications from art to design workflows requiring brand consistency. However, current benchmarks either neglect color or rely on coarse assessments, missing key capabilities like interpreting RGB values or aligning with human expectations. To this end, we propose GenColorBench, the first comprehensive benchmark for T2I color generation, grounded in color systems like ISCC-NBS and CSS3/X11, including numerical colors which are absent elsewhere. With 44K color-focused prompts covering 400+ colors, it reveals models’ true capabilities via perceptual and automated assessments. Evaluations of popular T2I models using GenColorBench show performance variations, highlighting which color conventions models understand best and identifying failure modes. Our GenColorBench assessments will allow to guide improvements in precise color generation. The benchmark will be made public upon acceptance.",
    "key_points": [
      "diffusion models",
      "text-to-image generation",
      "colors"
    ],
    "gold_summary": "This paper proposes a benchmark for evaluating the capability of T2I models in faithfully rendering the specified colors on generated objects."
  },
  {
    "paper_id": "0rJUulYnow",
    "title": "EvoMAS : Heuristics in the Loop—Evolving Smarter Agentic Workflows",
    "domain": "applications to robotics",
    "content": "The rapid development of Large Language Models has driven Multi-Agent Systems (MAS) growth, but constructing efficient MAS requires labor-intensive manual design. Current automation methods generate templated agents, use monolithic optimization, and ignore task complexity gradients. This paper presents Evolutionary MAS (\\textbf{EvoMAS}), a biologically-inspired framework that systematically addresses these limitations through three interconnected dimensions: (1) \\textbf{dynamic and diverse evolutionary strategies} with six biologically-inspired operators (3 exploration, 3 exploitation) and adaptive strategy selection; (2) \\textbf{role-level evolution} that dynamically optimizes agent specialization and collaboration patterns; and (3) \\textbf{curriculum-guided evolution} partitioning tasks by difficulty levels and evolving sequentially from simple to complex with cross-stage stability constraints. Additionally, to resolve the contradiction between the inefficiency of pure evolutionary methods and the limited flexibility of manual design, we developed the \\textbf{\"Cyber Creator\"}, a meta-control system combining dynamic rule formulation with reflective updates. Experimental evaluations demonstrate that EvoMAS consistently outperforms existing methods across multiple domains while maintaining cost efficiency, with agent roles dynamically evolving from homogeneous actors to specialized reasoning ensembles. Codes are available at \\href{https://anonymous.4open.science/r/EvoMAS-DEF4}\n{EvoMAS}.",
    "key_points": [
      "multi-agent systems",
      "evolutionary optimization",
      "agentic workflow",
      "large language models",
      "curriculum learning",
      "meta-control mechanism"
    ],
    "gold_summary": "This paper introduces a three-dimensional evolution (roles, strategies, curricula) for multi-agent systems. The intuition is clear which is from biological evolution.\nThe overall empirical is solid and extensive showing good performance."
  },
  {
    "paper_id": "5SMNtmJFGa",
    "title": "Scaling Short-Term Memory of Visuomotor Policies for Long-Horizon Tasks",
    "domain": "applications to robotics",
    "content": "Many robotic tasks demand short-term memory, whether it’s retrieving objects that are no longer visible or turning off an appliance after a certain amount of time. Yet, most visuomotor policies remain myopic, relying only on immediate sensory input without leveraging past experiences to guide decisions. We present PRISM, a transformer-based architecture for visuomotor policies to effectively use short-term memory via two key components: (i) gated attention, which selectively filters retrieved information to suppress irrelevant details, and (ii) a hierarchical architecture that first compresses local interactions into compact tokens and then integrates them to capture temporally extended dependencies. Together, these mechanisms enable us to scale short-term memory in visuomotor policies for up to two minutes at five frames per second, an order of magnitude longer than previous approaches. To systematically evaluate memory in visuomotor control, we introduce ReMemBench—a benchmark of eight diverse household manipulation tasks spanning four categories of short-term memory—designed to foster general memory mechanisms rather than siloed, task-specific solutions. PRISM consistently outperforms prior works, including transformer-based visuomotor policies with short-term memory, recurrent architectures, and other short-term memory-management strategies. Across ReMemBench and real-world evaluations, it achieves two times the success rate, and on the RoboCasa benchmark, it yields a 14 percentage points gain over the strongest baseline. Together, PRISM and ReMemBench establish a foundation for developing and evaluating short-term memory–augmented visuomotor policies that scale to long-horizon tasks.",
    "key_points": [
      "imitation learning",
      "short-term memory"
    ],
    "gold_summary": "A new transformer architecture, PRISM, and a robotics benchmark for memory-dependent tasks, ReMemBench, are proposed."
  },
  {
    "paper_id": "vWqmI93OcL",
    "title": "RoboOmni: Actions Are Just Another Modality for Your Vision-Language Models",
    "domain": "applications to robotics",
    "content": "Integrating Vision--Language-Models (VLMs) into robotics has enabled building generalizable Vision-Language Action (VLA) models for robotic manipulation. While decoupled designs with a separate action expert often outperform unified frameworks, the latter (e.g., OpenVLA) present an appealing, conceptually integrated architecture. Nevertheless, current unified approaches typically suffer from poor historical context integration and distribution shift given their incapability of predicting action chunking.\n\nWe introduce **RoboOmni**, a unified multi-modal next-token prediction framework for robotic manipulation designed to overcome these issues. Compared with decoupled approaches, **RoboOmni** unifies the multi-modal representations and minimizes the distribution gap between vision-language pretraining and action finetuning. Besides, in contrast to prior unified approaches, **RoboOmni** brings in the action chunking mechanism by *Multi-Token Action Prediction* (MTAP) that supports both FAST and Bin tokenizers, and crucially alleviates the action distribution shift issue when training with noisy real-world data. Specifically, by preserving the original VLM training pipeline, **RoboOmni** naturally supports co-training with multi-modal information and various VLM optimization techniques, *e.g.,* fast inference optimization, which significantly improves the generalization capabilities and extensibility of **RoboOmni**.\n\nWe conduct extensive experiments on both the CALVIN benchmark and a real-world robot, demonstrating state-of-the-art (SOTA) performance. Our MTAP implementation with the FAST tokenizer achieves a 94.4% average success rate on CALVIN. Furthermore, we show that our Bin tokenizer implementation, deployed with existing VLM serving frameworks like SGLang, achieves a 27x inference time speedup compared with OpenVLA.",
    "key_points": [
      "vision language action model",
      "multi-modal learning",
      "manipulation"
    ],
    "gold_summary": "This paper proposes a method that unifies data from multiple modalities and optimizes them within a shared language space."
  },
  {
    "paper_id": "PmYX0XiQQ0",
    "title": "VLAC: A Generalist Action-Critic Model via Pair-wise Progress Understanding",
    "domain": "applications to robotics",
    "content": "Recent advances in Vision-Language-Action (VLA) models have significantly improved robotic perception and manipulation capabilities. However, robots deployed in real-world settings still struggle to adapt in dynamic, open-ended environments due to a lack of reliable task progress feedback and improvement mechanisms. To address these challenges, we propose a generalist Vision Language Action-Critic model, VLAC, which can integrate both human and robot data, and unify action generation and task progress understanding within a single autoregressive architecture. Specifically, we propose a scalable and generalizable pair-wise progress understanding approach to predict the task progress delta between any two images in one visual trajectory, and generate the action based on the first image. The model is trained on large-scale, multi-source human data without action annotations and robot data with action information, while also incorporating general vision-language data yielding world knowledge understanding. Furthermore, we deploy reinforcement learning where VLAC can autonomously evaluate task progress to feedback intrinsic rewards. We evaluated our model's progress understanding across eight datasets and show that it not only generalizes to new tasks and environments but also discriminates success from failure trajectories, e.g., on RoboFAC dataset, it reaches VOC-F1 0.89 for successful versus 0.44 for failed trajectories, providing dependable dense reward signals. Then, we evaluated action generation and real-world reinforcement learning performance on diverse real-world robotic manipulation tasks. Experimental results indicate strong disturbance robustness in VLAC’s action generation, while integrating pairwise progress prediction allows real-world RL to improve success from roughly 30\\% to 90\\% within 200 episodes.",
    "key_points": [
      "vision language model",
      "robotics",
      "multi-modal",
      "reward model",
      "real world rl"
    ],
    "gold_summary": "The paper proposes VLAC, a VLA model which also predicts the number of frames between subsequent images. This is used as a goal-conditioned critic function. The authors"
  },
  {
    "paper_id": "bZcOscOMlx",
    "title": "Ca$^2$P: Cache-Augmented Code-as-Policies for Open-Domain Embodied Tasks",
    "domain": "applications to robotics",
    "content": "Embodied agents deployed in open-domain environments must continuously handle unpredictable tasks beyond predefined action policies. Such tasks are often given as natural language instructions, and recent progress in code-writing large language models (CodeLLMs) has inspired the Code-as-Policies (CaP) paradigm, where instructions are translated into executable control code when issued. However, generating full code from scratch for each instruction incurs high latency and inconsistency, limiting CaP's practicality in real-world, time-sensitive scenarios. To address these limitations, we present Ca$^2$P, a Cache-Augmented Code-as-Policies framework that improves CodeLLM-based robotic programming by introducing function-level key-value (KV) caching, a repurposed and extended form of the native KV caching mechanism tailored for function reuse, together with cache-augmented code policy synthesis. Ca$^2$P decomposes previously generated and validated code policies and stores them as function-level KV caches, supporting efficient compositional programming, where new policies are synthesized by invoking cached functions directly through their KV states. Furthermore, by revisiting and editing cached functions within their KV states, Ca$^2$P provides cache-refactoring, thereby enabling efficient synthesis of task-specific code policies without the need for full regeneration. Evaluated on ALFRED, TEACh, and RLBench benchmarks together with real-world robot manipulation, Ca$^2$P achieves the best trade-off between robustness and latency, with $19.80\\%$ higher task success rate and $2.91\\times$ faster policy synthesis than the CaP baseline.",
    "key_points": [
      "llm",
      "kv cache",
      "embodied ai"
    ],
    "gold_summary": "Authors propose to utilize caching in order to improve the latency of code as policies framework for LLM based robotic control. Authors perform experiments with real world robot."
  },
  {
    "paper_id": "7pgAwaq6Rx",
    "title": "RoboHiMan: A Hierarchical Evaluation Paradigm for Compositional Generalization in Long-Horizon Manipulation",
    "domain": "applications to robotics",
    "content": "Enabling robots to flexibly schedule and compose learned skills for novel long-horizon manipulation under diverse perturbations remains a core challenge. Early explorations with end-to-end VLA models show limited success, as these models struggle to generalize beyond the training distribution. Hierarchical approaches, where high-level planners generate subgoals for low-level policies, bring certain improvements but still suffer under complex perturbations, revealing limited capability in skill composition. However, existing benchmarks primarily emphasize task completion in long-horizon settings, offering little insight into compositional generalization, robustness, and the interplay between planning and execution.\nTo systematically investigate these gaps, we propose RoboHiMan, a hierarchical evaluation paradigm for compositional generalization in long-horizon manipulation. RoboHiMan introduces HiMan-Bench, a benchmark of atomic and compositional tasks under diverse perturbations, supported by a multi-level training dataset for analyzing progressive data scaling, and proposes three evaluation paradigms (vanilla, decoupled, coupled) that probe the necessity of skill composition and reveal bottlenecks in hierarchical architectures.\nExperiments highlight clear capability gaps across representative models and architectures, pointing to directions for advancing models better suited to real-world long-horizon manipulation tasks.\nAnonymous project website: https://robohiman.github.io/.",
    "key_points": [
      "compositional generalization",
      "long-horizon manipulation",
      "benchmarking robotics"
    ],
    "gold_summary": "The paper studies the problem of compositional generalization in long-horizon tasks. It introduces a benchmark with a hierarchical evaluation paradigm that enables systematic analysis of existing models’ generalization capabilities."
  },
  {
    "paper_id": "Au04Il6moo",
    "title": "Draft-and-Target Sampling for Video Generation Policy",
    "domain": "applications to robotics",
    "content": "Video generation models have been used as a robot policy to predict the future states of executing a task conditioned on task description and observation. Previous works ignore their high computational cost and long inference time. To address this challenge, we propose Draft-and-Target Sampling, a novel speculative decoding-like inference paradigm for video generation policy that is training-free and can improve inference efficiency. We modify the classic principle of speculative decoding design and redefine the draft and target as two complementary denoising trajectories. To further speedup generation, we introduce token chunking and progressive acceptance strategy to reduce redundant computation. Experiments on three benchmarks show that our method can achieve up to 2.1x speedup and improve the efficiency of current state-of-the-art methods with minimal compromise to the success rate. Our code is available at anonymous github.",
    "key_points": [
      "video generation policy; video generation for robotics; speculative decoding; inference acceleration"
    ],
    "gold_summary": "The paper proposes a draft-and-target sampling method for video generation policy inference which achieves computational efficiency compared to prior works across benchmarks."
  },
  {
    "paper_id": "finA00bYJj",
    "title": "Pixel Motion as Universal Representation for Robot Control",
    "domain": "applications to robotics",
    "content": "We present LangToMo, a vision-language-action framework structured as a dual-system architecture that uses pixel motion forecasts as intermediate representations. \nOur high-level $\\textit{System 2}$, an image diffusion model, generates text-conditioned pixel motion sequences from a single frame and past motion to guide robot control.\nPixel motion—a universal, interpretable, and motion-centric representation—can be extracted from videos in a weakly-supervised manner, enabling diffusion model training on any video-caption data.\nTreating the generated pixel motion as largely embodiment-agnostic $\\textit{universal representations}$, our embodiment-aware $\\textit{System 1}$ module translates these into robot actions via motion-to-action mapping functions, which can be either hand-crafted or learned with minimal supervision.\nSystem 2 operates as a high-level policy applied at sparse temporal intervals, while System 1 acts as a low-level policy at dense temporal intervals.\nThis hierarchical decoupling enables flexible, scalable, and generalizable robot control under both unsupervised and supervised settings, bridging the gap between language, motion, and action.\nVisualizations at https://anonymous.4open.science/w/LangToMo.",
    "key_points": [
      "vision-language-action",
      "universal motion representations"
    ],
    "gold_summary": "This paper proposes to use pixel motion as a control interface. System 1 translate language into pixel motions while system 2 translate the motions into robot actions. The authors show performance gain in MetaWorld experiments."
  },
  {
    "paper_id": "tkLDNUzL80",
    "title": "Physically Ground Commonsense Knowledge for Articulated Object Manipulation with Analytic Concepts",
    "domain": "applications to robotics",
    "content": "We human rely on a wide range of commonsense knowledge to interact with an extensive number and categories of objects in the physical world. Likewise, such commonsense knowledge is also crucial for robots to successfully develop generalized object manipulation skills. While recent advancements in Multi-modal Large Language Models (MLLMs) have showcased their impressive capabilities in acquiring commonsense knowledge and conducting commonsense reasoning, effectively grounding this semantic-level knowledge produced by MLLMs to the physical world to thoroughly guide robots in generalized articulated object manipulation remains a challenge that has not been sufficiently addressed. To this end, we introduce analytic concepts, procedurally defined upon mathematical symbolism that can be directly computed and simulated by machines. By leveraging the analytic concepts as a bridge between the semantic-level knowledge inferred by LLMs and the physical world where real robots operate, we are able to figure out the knowledge of object structure and functionality with physics-informed representations, and then use the physically grounded knowledge to instruct robot control policies for generalized, interpretable and accurate articulated object manipulation. Extensive experiments in both simulation and real-world environments demonstrate the superiority of our approach. Please refer to the appendix for more details, and our codes will be made publicly available.",
    "key_points": [
      "articulated object manipulation",
      "robotics",
      "neural symbolic",
      "physical concepts"
    ],
    "gold_summary": "This paper proposes using analytic concepts to represent commonsense knowledge via MLLMs, and then grounding them in physical form so that robots can complete manipulation tasks more easily."
  },
  {
    "paper_id": "AdfEHMueyc",
    "title": "Evolving Embodied Intelligence: Graph Neural Network–Driven Co-Design of Morphology and Control in Soft Robotics",
    "domain": "applications to robotics",
    "content": "The intelligent behavior of robots does not emerge solely from control systems, but from the tight coupling between body and brain—a principle known as embodied intelligence. Designing soft robots that leverage this interaction remains a significant challenge, particularly when morphology and control require simultaneous optimization. A significant obstacle in this co-design process is that morphological evolution can disrupt learned control strategies, making it difficult to reuse or adapt existing knowledge. We address this by develop a Graph Neural Network-based approach for the co-design of morphology and controller. Each robot is represented as a graph, with a graph attention network (GAT) encoding node features and a pooled representation passed through a multilayer perceptron (MLP) head to produce actuator commands or value estimates. During evolution, inheritance follows a topology-consistent mapping: shared GAT layers are reused, MLP hidden layers are transferred intact, matched actuator outputs are copied, and unmatched ones are randomly initialized and fine-tuned. This morphology-aware policy class lets the controller adapt when the body mutates. On the benchmark, our GAT-based approach achieves higher final fitness and stronger adaptability to morphological variations compared to traditional MLP-only co-design methods. These results indicate that graph-structured policies provide a more effective interface between evolving morphologies and control for embodied intelligence.",
    "key_points": [
      "gnn",
      "co-design",
      "embodied intelligence",
      "soft robotics",
      "transfer learning"
    ],
    "gold_summary": "This paper introduces GNN for soft-robotics co-design and also introduce a scheme for morphology matching. Also to my best knowledge, GNN and Transformer are already heavily used for robot co-design."
  },
  {
    "paper_id": "qPbDM5L8tE",
    "title": "Contact-VLA: Zero-Shot Planning and Control for Contact-Rich Manipulation",
    "domain": "applications to robotics",
    "content": "Vision-Language-Action (VLA) systems often lack adaptability and explainability due to their black-box structure and dependency on fixed action sets from extensive tele-operated datasets, limiting their effectiveness in complex, dynamic manipulation scenarios. To address this issue, we propose a novel VLA framework capable of effectively managing complex, dynamic, and contact-rich manipulation tasks. By integrating foundational vision and language models with motion planning and reactive controllers, our system achieves zero-shot planning and adaptive manipulation without relying on extensive tele-operated action datasets. Unlike conventional VLAs, we explicitly separate the roles of vision models and Large Language Models (LLM): the vision module handles scene initialization and object pose tracking, while the LLM generates initial contact strategies and cost function estimations. These two components collaboratively contribute to the creation of a simulated environment in which our dynamic planner operates. Additionally, this modular approach significantly enhances both the explainability and performance of the overall framework, as demonstrated by ablation studies. Furthermore, we introduce a memory unit to leverage past manipulation experiences, enabling the generalization and efficient reuse of learned contact strategies and parameter adjustments across diverse manipulation scenarios. Experiments conducted on challenging contact-rich tasks validate our framework's robustness and highlight the critical design elements that contribute to its effectiveness.",
    "key_points": [
      "vision-language-action model",
      "robotic manipulation",
      "contact-rich manipulation",
      "manipulation planning",
      "robot learning"
    ],
    "gold_summary": "The method has not been evaluated on a real-world robotic platform, which undermines the claims regarding contact-rich manipulation, as simulators often struggle to accurately model physical contact dynamics."
  },
  {
    "paper_id": "y5CaJb17Fn",
    "title": "villa-X: Enhancing Latent Action Modeling in Vision-Language-Action Models",
    "domain": "applications to robotics",
    "content": "Vision-Language-Action (VLA) models have emerged as a popular paradigm for learning robot manipulation policies that can follow language instructions and generalize to novel scenarios. Recent works have begun to explore the incorporation of latent actions, abstract representations of motion between two frames, into VLA pre-training. In this paper, we introduce villa-X a novel Vision-Language-Latent-Action (ViLLA) framework that advances latent action modeling for learning generalizable robot manipulation policies.\nOur approach improves both how latent actions are learned and how they are incorporated into VLA pre-training. We demonstrate that villa-X can generate latent action plans in a zero-shot fashion, even for unseen embodiments and open-vocabulary symbolic understanding. This capability enables villa-X to achieve superior performance across diverse simulation tasks in SIMPLER and on two real-world robotic setups involving both gripper and dexterous hand manipulation. These results establish villa-X as a principled and scalable paradigm for learning generalizable robot manipulation policies. We believe it provides a strong foundation for future research.",
    "key_points": [
      "embodied ai"
    ],
    "gold_summary": "This paper introduces a new framework called villa-X, whose core idea is to incorporate latent actions into the pretraining and policy learning of Vision-Language-Action (VLA) models."
  },
  {
    "paper_id": "bsXkBTZjgY",
    "title": "HyperVLA: Efficient Inference in Vision-Language-Action Models via Hypernetworks",
    "domain": "applications to robotics",
    "content": "Built upon language and vision foundation models with strong generalization ability and trained on large-scale robotic data, Vision-Language-Action (VLA) models have recently emerged as a promising approach to learning generalist robotic policies. \nHowever, a key drawback of existing VLAs is their extremely high inference costs. \nIn this paper, we propose HyperVLA to address this problem. Unlike existing monolithic VLAs that activate the whole model during both training and inference, HyperVLA uses a novel hypernetwork (HN)-based architecture that activates only a small task-specific policy during inference, while still retaining the high model capacity needed to accommodate diverse multi-task behaviors during training.\nSuccessfully training an HN-based VLA is nontrivial so HyperVLA contains several key algorithm design features that improve its performance, including properly utilizing the prior knowledge from existing vision foundation models, HN normalization and action generation strategy. \nWe train HyperVLA on the Open X-Embodiment dataset, and evaluate on the SIMPLER benchmark. \nCompared to existing VLAs, HyperVLA achieves a similar or even higher success rate during evaluation, while significantly reducing inference costs. \nNotably, compared to OpenVLA, a state-of-the-art VLA model, HyperVLA reduces the number of activated parameters at test time by $90\\times$, and accelerates inference speed by $120\\times$.",
    "key_points": [
      "multi-task learning",
      "imitation learning",
      "robotic control",
      "vla",
      "hypernetworks"
    ],
    "gold_summary": "This paper presents HyperVLA, a vision-language-action (VLA) framework that leverages a hypernetwork to generate lightweight, task-specific policies for efficient inference."
  },
  {
    "paper_id": "uFomU6UJHH",
    "title": "Data Assessment for Embodied Intelligence",
    "domain": "applications to robotics",
    "content": "In embodied intelligence, datasets play a pivotal role, serving as both a knowledge repository and a conduit for information transfer. The two most critical attributes of a dataset are the amount of information it provides and how easily this information can be learned by models. However, the multimodal nature of embodied data makes evaluating these properties particularly challenging. Prior work has largely focused on diversity, typically counting tasks and scenes or evaluating isolated modalities, which fails to provide a comprehensive picture of dataset diversity. On the other hand, the learnability of datasets has received little attention and is usually assessed post-hoc through model training—an expensive, time-consuming process that also lacks interpretability, offering little guidance on how to improve a dataset. In this work, we address both challenges by introducing two principled, data-driven metrics. First, we construct a unified multimodal representation for each data and, based on it, propose diversity entropy, a continuous measure that characterizes the amount of information contained in a dataset. Second, we introduce the first interpretable, data-driven algorithm to efficiently quantify dataset learnability without training, enabling researchers to assess a dataset’s learnability immediately upon its release. We validate our algorithm on multiple simulated and real-world embodied datasets, demonstrating that it yields faithful, actionable insights, enabling researchers to jointly improve diversity and learnability. We hope this work provides a foundation for designing higher-quality datasets that advance the development of embodied intelligence.",
    "key_points": [
      "benchmark; embodied ai; data-centric ai;"
    ],
    "gold_summary": "For embodied datasets, the authors created multimodal representations that are used to quantify the amount of information within a dataset, while also developing an algorithm to assess its learnability without requiring training."
  },
  {
    "paper_id": "Z5TmeKwLyx",
    "title": "Guided Domain Solver: Structured Exploration of Domain-Specific Tasks with Large Language Models",
    "domain": "applications to robotics",
    "content": "This work presents a method to solve domain-specific problems by leveraging Monte Carlo Tree Search (MCTS), Knowledge Graphs and Large Language Model (LLM) agents. At the core of this approach lies a MCTS algorithm, which explores the complex solution space of a given domain in a goal-directed and sample-efficient manner. In the expansion phase of the MCTS, a domain-specific knowledge graph is incorporated to encode concepts, relationships and constraints. This structured representation enables an LLM agent to make informed decisions for the node expansion. By combining a structured search of the solution space through MCTS, a representation of domain knowledge through the knowledge graph and the generalization abilities of an LLM agent, this method can solve complex tasks in domains where both creativity and adherence to expert rules are essential. In a first step, this approach is used to solve Sokoban, a puzzle game that requires planning and creativity to place several boxes at specific targets with as few moves as possible.",
    "key_points": [
      "monte carlo tree search",
      "knowledge graph",
      "large language model",
      "agents",
      "planning"
    ],
    "gold_summary": "The paper solves domain-specific problems by leveraging MCTS, knowledge graphs, and LLM agents. An initial experiment was conducted on Sokoban to show the method helps find the solution more quickly."
  },
  {
    "paper_id": "bjApyTEoRf",
    "title": "MoTVLA: A Vision-Language-Action Model with Unified Fast-Slow Reasoning",
    "domain": "applications to robotics",
    "content": "Integrating visual-language instructions into visuomotor policies is gaining momentum in robot learning for enhancing open-world generalization. Despite promising advances, existing approaches face two challenges: limited language steerability when no generated reasoning is used as a condition, or significant inference latency when reasoning is incorporated. In this work, we introduce MoTVLA, a mixture-of-transformers (MoT)–based vision–language–action (VLA) model that integrates fast–slow unified reasoning with behavior policy learning. MoTVLA preserves the general intelligence of pre-trained VLMs (serving as the generalist) for tasks such as perception, scene understanding, and semantic planning, while incorporating a domain expert, a second transformer that shares knowledge with the pretrained VLM, to generate fast domain-specific reasoning (e.g., robot motion decomposition), thereby improving policy execution efficiency. By conditioning the action expert on decomposed motion instructions, MoTVLA can learn diverse behaviors and substantially improve language steerability. Extensive evaluations across natural language processing benchmarks, robotic simulation environments, and real-world experiments confirm the superiority of MoTVLA in both language reasoning and manipulation task performance. We refer to https://motvla.github.io/MoTVLA-website/ for the demonstration videos and corresponding descriptions.",
    "key_points": [
      "vision-language-action models",
      "diffusion policy",
      "mixture-of-transformers",
      "unified fast-slow reasoning"
    ],
    "gold_summary": "The paper proposes a MoT based VLA model to address the challenging gap between reasoning lantency and language sterrability. It conducts VQA and Manipulation experiments to verify its model's capability."
  },
  {
    "paper_id": "ea6j8k8Rnw",
    "title": "Action-aware Dynamic Pruning for Efficient Vision-Language-Action Manipulation",
    "domain": "applications to robotics",
    "content": "Robotic manipulation with Vision-Language-Action models requires efficient inference over long-horizon multi-modal context, where attention to dense visual tokens dominates computational cost. Existing methods optimize inference speed by reducing visual redundancy within VLA models, but they overlook the varying redundancy across robotic manipulation stages. We observe that the visual token redundancy is higher in coarse manipulation phase than in fine-grained operations, and is strongly correlated with the action dynamic. \nMotivated by this observation, we propose Action-aware Dynamic Pruning (ADP), a multi-modal pruning framework that integrates text-driven token selection with action-aware trajectory gating. ADP introduces a gating mechanism that conditions the pruning signal on recent action trajectories, using past motion windows to adaptively adjust token retention ratios in accordance with dynamics, thereby balancing computational efficiency and perceptual precision across different manipulation stages. \nExtensive experiments on the LIBERO suites and diverse real-world scenarios demonstrate that our method significantly reduces FLOPs and action inference latency (e.g. 1.35× speed up on OpenVLA-OFT) while maintaining competitive success rates (e.g. 25.8% improvements with OpenVLA) compared to baselines, thereby providing a simple plug-in path to efficient robot policies that advances the efficiency and performance frontier of robotic manipulation.",
    "key_points": [
      "vision-language-actions",
      "efficient robotic manipulations"
    ],
    "gold_summary": "This paper introduces ADP, which is a pruning method for VLA. ADP adopts text-driven pruning and action-aware gating,"
  },
  {
    "paper_id": "3azIn8ImwP",
    "title": "UAOR: Uncertainty-aware Observation Reinjection for Vision-Language-Action Models",
    "domain": "applications to robotics",
    "content": "Vision–Language–Action (VLA) models leverage pretrained Vision–Language Models (VLMs) as backbones to map images and instructions to actions, demonstrating remarkable potential for generalizable robotic manipulation. To improve performance, many methods have been proposed to incorporate additional observation cues (e.g., depth maps, point clouds) and auxiliary modules (e.g., object detectors, encoders), enabling more precise and reliable task execution. Although effective, these approaches often require extensive data collection and additional training or fine-tuning, limiting their flexibility and scalability. Inspired by the finding that Feed-Forward Network (FFN) in language models can act as \"key-value memory'', we propose **U**ncertainty-**a**ware **O**bservation **R**einjection (**UAOR**), an effective training-free and plug-and-play module for VLA models. Specially, when the current language model layer exhibits high uncertainty, measured by **Action Entropy**, it reinjects the observation information into the next layer's Feed-Forward Network (FFN) in a blending manner. This mechanism helps VLA models look more clearly on the observation during inference, enabling more confident and faithful action generation. Comprehensive simulation and real-world experiments show that our method consistently improves the performance of heterogeneous VLA models across various tasks and embodiments while incurring minimal computational overhead. Notably,  **UAOR** eliminates the need for extra observation cuse or modules, making it a versatile and practical plug-in for existing VLA pipelines.",
    "key_points": [
      "vision-language-action",
      "uncertainty-aware",
      "observation reinjection"
    ],
    "gold_summary": "This paper proposes UAOR, a lightweight, training-free module designed to boost VLA models. It aims to enable VLA models\nlook more clearly on the observation during inference, enabling more confident and faithful action generation."
  },
  {
    "paper_id": "9fHuFi4Qsu",
    "title": "ConceptBot: Knowledge-Graph–Grounded Commonsense for Task Decomposition in LLM Robot Planning",
    "domain": "applications to robotics",
    "content": "Robotic planning breaks down when commonsense reasoning is required to resolve linguistic ambiguity and to interpret objects correctly. To address this, we present ConceptBot, a modular planning framework that integrates large language models with knowledge graphs to produce feasible, risk-aware plans while jointly disambiguating instructions and grounding object semantics.\nConceptBot comprises three components: (i) an Object Properties Extraction (OPE) module that augments scene understanding with semantic concepts from ConceptNet; (ii) a User Request Processing (URP) module that resolves ambiguities and structures free-form instructions; and (iii) a Planner that synthesizes context-aware, feasible pick-and-place policies. Evaluations in simulation and on real-world setups show consistent gains over prior LLM-based planners—for example, +56 percentage points on implicit tasks (87% vs. 31% for SayCan) and +61 points on risk-aware tasks (76% vs. 15%)—and an overall score of 80% on SafeAgentBench. These improvements translate to more reliable performance in unstructured environments without domain-specific training.",
    "key_points": [
      "robotic planning",
      "task decomposition",
      "large language models",
      "knowledge graphs"
    ],
    "gold_summary": "Authors integrate Knowledge Graph (KG) into LLM robotics planner. Attempted task is pick and place operations for robot manipulator."
  },
  {
    "paper_id": "leoXWCu6CO",
    "title": "Dynamic Drone-Assisted Pickup and Delivery Routing",
    "domain": "applications to robotics",
    "content": "We investigate the dynamic drone-assisted pickup and delivery problem (DAPDP), which concerns real-time, on-demand routing decisions in scenarios where new paired orders arrive stochastically throughout the day. By leveraging a fleet of trucks each equipped with a drone, operators can split tasks between ground vehicles and aerial vehicles, aiming to minimize total travel costs while respecting constraints on time windows, capacity, and drone flight endurance. We propose a deep reinforcement learning (DRL) approach based on deep Q-learning, to decide dynamically which newly arrived orders to dispatch and how to integrate drone sorties effectively. Our experiments on a large, real-world-inspired dataset demonstrate substantial performance gains over greedy, random, and lazy dispatch baselines, yielding 10.6\\%, 22.6\\%, and 37.2\\% savings, respectively, in total travel cost. \nAdditionally, our value-based RL learns subset selection decisions that co-adapt with a paired sub-solver, yielding near-oracle performance and outperforming classical and PPO baselines.",
    "key_points": [
      "reinforcement learning",
      "autonomous systems",
      "vehicle routing",
      "optimization"
    ],
    "gold_summary": "The paper analyzed the dispatching problem for the last-mile delivery using drone-truck integration. A MDP is formulated and experiment is conducted on a simulated data-set."
  },
  {
    "paper_id": "ZtGE4nR4vx",
    "title": "ROBUST COMPONENT DETECTION FOR FLEXIBLE MANUFACTURING: A DEEP LEARNING APPROACH TO TRAY-FREE OBJECT RECOGNITION UNDER VARIABLE LIGHTING",
    "domain": "applications to robotics",
    "content": "Flexible manufacturing systems in Industry 4.0 require robots that can handle\nobjects in unstructured environments without rigid positioning constraints. This\npaper presents a computer vision system that enables industrial robots to detect and\npick up pen components in arbitrary orientations without the need for structured\ntrays, while maintaining robust performance under varying lighting conditions.\nWe implement and evaluate a Mask R-CNN-based approach in a complete pen\nproduction line, addressing three key challenges: object recognition without positional constraints, robustness to extreme lighting changes, and reliable performance\nwith cost-effective cameras. Our system achieves 95% recognition accuracy under\ndiverse lighting conditions and eliminates the need for structured component placement, resulting in significant improvements in manufacturing flexibility and overall\nrobustness. This approach has been validated through extensive experiments under\nfour distinct lighting scenarios. These results demonstrate its practical applicability\nfor real-world industrial deployment.",
    "key_points": [
      "industry 4.0; computer vision; mask r-cnn; object detection; smart manufacturing; variable lighting; industrial vision; robotics"
    ],
    "gold_summary": "The paper presents an approach to detect pen components in an assembly line under various light conditions, achieving an accuracy of up to 95%."
  },
  {
    "paper_id": "T98uLLyWiM",
    "title": "Adapting Reinforcement Learning for Path Planning in Constrained Parking Scenarios",
    "domain": "applications to robotics",
    "content": "Real-time path planning in constrained environments remains a fundamental challenge for autonomous systems. Traditional classical planners, while effective under perfect perception assumptions, are often sensitive to real-world perception constraints and rely on online search procedures that incur high computational costs. In complex surroundings, this renders real-time deployment prohibitive. To overcome these limitations, we introduce a Deep Reinforcement Learning (DRL) framework for real-time path planning in parking scenarios. In particular, we focus on challenging scenes with tight spaces that require a high number of reversal maneuvers and adjustments. Unlike classical planners, our solution does not require ideal and structured perception, and in principle, could avoid the need for additional modules such as localization and tracking, potentially resulting in a simpler and more practical implementation. Also, at test time, the policy generates actions through a single forward pass at each step, which is lightweight enough for real-time deployment. The task is formulated as a sequential decision-making problem grounded in a bicycle model dynamics, enabling the agent to directly learn navigation policies that respect vehicle kinematics and environmental constraints in the closed-loop setting. A new benchmark is developed to support both training and evaluation, capturing diverse and challenging scenarios. Our approach achieves state-of-the-art success rates and efficiency, surpassing classical planner baselines by +96\\% in success rate and +52\\% in efficiency. Furthermore, we release our benchmark as an open-source resource for the community to foster future research in autonomous systems.",
    "key_points": [
      "reinforcement learning",
      "path planning",
      "autonomous parking"
    ],
    "gold_summary": "This paper employs a RL–based approach to replace the classical planner in path planning tasks. It empirically demonstrates the effectiveness of the proposed method in parking scenarios."
  },
  {
    "paper_id": "Nd0dt1B5Ec",
    "title": "A Novel Architecture for Integrating Shape Constraints in Neural Networks",
    "domain": "alignment",
    "content": "This research proposes COMONet (Convex-Concave and Monotonicity-Constrained Neural Networks), a novel neural network architecture designed to embed inductive biases as shape constraints—specifically, monotonicity, convexity, concavity, and their combinations—into neural network training. Unlike previous models addressing only a subset of constraints, COMONet can comprehensively integrate and enforce eight distinct shape constraints: monotonic increasing, monotonic decreasing, convex, concave, convex increasing, convex decreasing, concave increasing, and concave decreasing. This integration is achieved through a unique partially connected structure, wherein inputs are grouped and selectively connected to specialized neural units employing either exponentiated or normal weights, combined with appropriate activation functions. Depending on the shape constraint required by each input, COMONet dynamically utilizes its full architecture or a partial configuration, providing significant flexibility. We further provide theoretical guarantees ensuring the strict enforcement of these constraints, while demonstrating that COMONet achieves performance comparable to existing benchmark methods. Moreover, our numerical experiments confirm that COMONet remains robust even under noisy conditions. Together, these results underscore COMONet’s potential to advance constrained neural network training as a practical and theoretically grounded approach.",
    "key_points": [
      "shape constraint",
      "convexity",
      "monotonicity",
      "neural network",
      "regularization"
    ],
    "gold_summary": "Authors propose a new network architecture that uses partial connections impose monotonicity and convexity/concavity shape constraints. Experimental results are good but not impressive."
  },
  {
    "paper_id": "skRDw08ql6",
    "title": "Private and interpretable clinical prediction with quantum-inspired tensor train models",
    "domain": "alignment",
    "content": "Machine learning in clinical settings must balance predictive accuracy, interpretability, and privacy. While models like logistic regression (LR) are valued for transparency, they remain vulnerable to privacy attacks that expose training data. We empirically assess these risks by designing attacks that identify which public datasets were used to train a model under varying levels of adversarial access, applying them to LORIS, a publicly available LR model for immunotherapy response prediction. Our findings show that LORIS leaks significant training-set information, especially under white-box access, and that common practices such as cross-validation exacerbate these risks. Even black-box access via the public web interface allows training data identification. To mitigate these vulnerabilities, we propose a quantum-inspired defense using tensor train (TT) models. Tensorizing LR obfuscates parameters while preserving accuracy, reducing white-box attacks to random guessing and degrading black-box attacks comparably to Differential Privacy. TT models retain LR interpretability and extend it through efficient computation of marginal and conditional distributions. Although demonstrated on LORIS, our approach generalizes broadly, positioning TT models as a practical foundation for private, interpretable, and effective clinical prediction.",
    "key_points": [
      "privacy",
      "interpretability",
      "logistic regression",
      "tensor trains",
      "clinical prediction"
    ],
    "gold_summary": "Authors first identifies vulnerabilities with privacy of LR models, and then propose a quantum-inspired defense using tensor train (TT) models to mitigate those vulnerabilities by tensorizing LR to obfuscate parameters while preserving accuracy and interpretability."
  },
  {
    "paper_id": "jGcBIvOrqc",
    "title": "To Think or Not To Think, That is The Question for LLM Reasoning in Theory of Mind Tasks",
    "domain": "alignment",
    "content": "Theory of Mind (ToM) assesses whether models can infer hidden mental states such as beliefs, desires, and intentions, which is essential for natural social interaction. Although recent progress in Large Reasoning Models (LRMs) has boosted step-by-step inference in mathematics and coding, it is still underexplored whether this benefit transfers to socio-cognitive skills. We present a systematic study of 11 advanced Large Language Models (LLMs), comparing reasoning models with non-reasoning models on three representative ToM benchmarks. The results show that reasoning models do not consistently outperform base models and sometimes perform worse. A fine-grained analysis reveals two main failure reasons. First, slow thinking collapse: accuracy significantly drops as responses grow longer, and larger reasoning budgets hurt performance. Second, option matching shortcut: when multiple choice options are removed, reasoning models improve markedly, indicating reliance on option matching rather than genuine deduction. These results highlight the advancement of LRMs in formal reasoning (e.g., math, code) cannot be transferred to ToM, a typical task in social reasoning. We conclude that achieving robust ToM requires developing unique capabilities beyond existing reasoning methods and we provide a preliminary exploration of such an approach with a combination of Slow-to-Fast (S2F) adaptive reasoning and Think-to-Match (T2M) shortcut prevention.",
    "key_points": [
      "theory of mind",
      "large language model"
    ],
    "gold_summary": "n/a - please see ethics review. I believe this paper should be desk rejected because of its field."
  },
  {
    "paper_id": "aZr24GHnlv",
    "title": "Too Easily Fooled? Prompt Injection Breaks LLMs on Frustratingly Simple Multiple-Choice Questions",
    "domain": "alignment",
    "content": "Large Language Models (LLMs) have recently demonstrated strong emergent abilities in complex reasoning and zero-shot generalization, showing unprecedented potential for LLM-as-a-judge applications in education, peer review, and data quality evaluation. However, their robustness under prompt injection attacks, where malicious instructions are embedded into the content to manipulate outputs, remains a significant concern. In this work, we explore a frustratingly simple yet effective attack setting to test whether LLMs can be easily misled. Specifically, we evaluate LLMs on basic arithmetic questions (e.g., ``What is 3 + 2?\") presented as either multiple-choice or true-false judgment problems within PDF files, where hidden prompts are injected into the file. Our results reveal that LLMs are indeed vulnerable to such hidden prompt injection attacks, even in these trivial scenarios, highlighting serious robustness risks for LLM-as-a-judge applications.",
    "key_points": [
      "safety",
      "llms"
    ],
    "gold_summary": "This paper studies the vulnerability of LLM-as-a-judge to adversarial prompt injection. The work presents a preliminary analysis, showing that the evaluation process of LLMs can be easily twisted by certain prompts, resulting in biased judgments."
  },
  {
    "paper_id": "uXecy0nKiJ",
    "title": "The Rogue Scalpel: Activation Steering Compromises LLM Safety",
    "domain": "alignment",
    "content": "Activation steering is a promising technique for controlling LLM behavior by adding semantically meaningful vectors directly into a model's hidden states during inference. It is often framed as a precise, interpretable, and potentially safer alternative to fine-tuning. We demonstrate the opposite: steering systematically breaks model alignment safeguards, making it comply with harmful requests. Through extensive experiments on different model families, we show that even steering in a random direction can increase the probability of harmful compliance from 0\\% to 2–27\\%. Alarmingly, steering benign features from a sparse autoencoder (SAE), a common source of interpretable directions, increases these rates by a further 2-4\\%. Finally, we show that combining 20 randomly sampled vectors that jailbreak a single prompt creates a universal attack, significantly increasing harmful compliance on unseen requests. These results challenge the paradigm of safety through interpretability, showing that precise control over model internals does not guarantee precise control over model behavior.",
    "key_points": [
      "activation steering",
      "llm safety",
      "mechanistic interpretability",
      "sparse autoencoder",
      "jailbreaking",
      "alignment"
    ],
    "gold_summary": "This paper presents evidence that steering LLM activations with random vectors and benign SAE features makes LLMs more susceptible to jailbreaking. It further explores combining jailbreak-inducing random vectors to create a \"universal\" attack vector."
  },
  {
    "paper_id": "oVyMK8YA9w",
    "title": "THE JPEG BLIND SPOT: EXPOSING A CRITICAL VULNERABILITY IN DOCUMENT TAMPERING DETECTION",
    "domain": "alignment",
    "content": "Current state-of-the-art document tampering detection models predominantly derive their success from a reliance on low-level JPEG compression artifacts, particularly Block Artifact Grids (BAG), to localize forged regions. In this paper, we expose a critical vulnerability inherent in this approach. We introduce a novel BAG-aware adversarial attack for document forgery that is designed to preserve the local statistical properties of these artifacts. When evaluated on the largest available document tampering benchmark, DocTamper, this attack catastrophically fools existing methods, reducing their detection rate to no better than random chance. This catastrophic failure reveals that these models fail to learn genuine semantic representations of tampering and instead rely on highly superficial and easily bypassed compression artifacts. Our work demonstrates a fundamental fragility in current document forensic systems and underscores the urgent need for robustness against such adversarial failures in security-critical applications.",
    "key_points": [
      "document tampering",
      "document forgery",
      "adversarial attacks",
      "jpeg artifacts"
    ],
    "gold_summary": "This paper exposes the vulnerability inherent in BAG-based document tampering localization. In details, they propose two attack methods to fool existing methods; and evaluate the proposed attacks on benchmark datasets."
  },
  {
    "paper_id": "x4ArMPJBR7",
    "title": "ProxyPrompt: Securing System Prompts against Prompt Extraction Attacks",
    "domain": "alignment",
    "content": "The integration of large language models (LLMs) into a wide range of applications has highlighted the critical role of well-crafted system prompts, which require extensive testing and domain expertise. These prompts enhance task performance but may also encode sensitive information and filtering criteria, posing security risks if exposed. Recent research shows that system prompts are vulnerable to extraction attacks, while existing defenses are either easily bypassed or require constant updates to address new threats. In this work, we introduce ProxyPrompt, a novel defense mechanism that prevents prompt leakage by replacing the original prompt with a proxy. This proxy maintains the original task's utility while obfuscating the extracted prompt, ensuring attackers cannot reproduce the task or access sensitive information. Comprehensive evaluations on 264 LLM and system prompt pairs show that ProxyPrompt protects 94.70% of prompts from extraction attacks, outperforming the next-best defense, which only achieves 42.80%. The code will be open-sourced upon acceptance.",
    "key_points": [
      "prompt extraction",
      "prompt security",
      "large language models"
    ],
    "gold_summary": "This paper obfuscates the system prompt to prevent prompt injection attack."
  },
  {
    "paper_id": "i5cjA1ApHW",
    "title": "FuseRL: Dense Preference Optimization for Heterogeneous Model Fusion",
    "domain": "alignment",
    "content": "Heterogeneous model fusion enhances the performance of LLMs by integrating the knowledge and capabilities of multiple structurally diverse models. However, existing approaches often rely solely on selecting the best output for each prompt from source models, which underutilizes their full potential due to limited source knowledge and results in sparse optimization signals. To address this limitation, we propose FuseRL, a novel two-stage framework comprising FuseSFT and FusePO to maximize the utilization of source LLMs. FuseSFT establishes a robust initialization by integrating the strengths of heterogeneous source models through weighted supervised fine-tuning (SFT) on diverse outputs for each prompt. FusePO optimizes weighted preferences based on the outputs of multiple source models to enable superior alignment performance. Extensive experiments demonstrate the effectiveness of our framework across various preference alignment methods, including RLOO, DPO, and SimPO. Using Llama-3.1-8B-Instruct as the target model, our approach achieves competitive performance among 8B LLMs on the AlpacaEval-2 and Arena-Hard benchmarks. Further analysis suggests that FuseSFT regularizes the training to reduce overfitting, while FusePO introduces dense and diverse preference signals that enhance alignment quality.",
    "key_points": [
      "model fusion",
      "large language models",
      "preference alignment"
    ],
    "gold_summary": "FuseRL is a two-stage heterogeneous model fusion framework. FuseSFT performs weighted SFT over responses from multiple source LLMs; FusePO performs weighted preference optimization (RLOO/DPO/SimPO) using multi-source response sets."
  },
  {
    "paper_id": "BLhQv7iF3q",
    "title": "Measuring Model Robustness via Fisher Information: Spectral Bounds, Theoretical Guarantees, and Practical Algorithms",
    "domain": "alignment",
    "content": "The robustness of deep neural networks is critical for their deployment in safety-sensitive domains. This paper establishes a novel theoretical framework for quantifying model robustness through the lens of Fisher information. We first start with the known conclusion that maximizing the KL divergence of the posterior probability is equivalent to minimizing half the Mahalanobis distance defined by the Fisher Information Matrix (FIM), and further reveal that the FIM is equal to the variance of the input Jacobian matrix. Based on this insight, we propose the FIM's principal eigenvalue (or its reciprocal) as a principled robustness metric. We derive closed-form spectral bounds for common architectural components (e.g., ReLU, convolution) and theoretically compare the robustness of VGG, ResNet, DenseNet, and Transformer. To enable scalable computation, we resort to efficient algorithms, including power iteration and randomized Hutchinson, to estimate the robustness metric. Furthermore, we propose to use Hutchinson and finite differences to achieve robust estimation in a black-box setting. Extensive experiments validate our theoretical claims and demonstrate the metric's utility in predicting adversarial vulnerability. Code: https://anonymous.4open.science/r/8F4D7E6R/",
    "key_points": [
      "model robustness",
      "fisher information matrix",
      "spectral norm",
      "architectural complexity",
      "jacobian matrix"
    ],
    "gold_summary": "This paper presents an alternative approach to quantifying the robustness of deep learning models by leveraging Fisher information."
  },
  {
    "paper_id": "QFLeRKRTdR",
    "title": "Understanding Adversarial Transfer: Why Representation-Space Attacks Fail Where Data-Space Attacks Succeed",
    "domain": "alignment",
    "content": "The field of adversarial robustness has long established that adversarial examples can successfully transfer between image classifiers and that text jailbreaks can successfully transfer between language models (LMs).\nHowever, a pair of recent studies reported being unable to successfully transfer image jailbreaks between vision-language models (VLMs).\nTo explain this striking difference, we propose a fundamental distinction regarding the transferability of attacks against machine learning models: attacks in the input data-space can transfer, whereas attacks in model representation space do not, at least not without geometric alignment of representations.\nWe then provide theoretical and empirical evidence of this hypothesis in four different settings.\nFirst, we mathematically prove this distinction in a simple setting where two networks compute the same input-output map but via different representations.\nSecond, we construct representation-space attacks against image classifiers that are as successful as well-known data-space attacks, but fail to transfer.\nThird, we construct representation-space attacks against LMs that successfully jailbreak the attacked models but again fail to transfer.\nFourth, we construct data-space attacks against VLMs that successfully transfer to new VLMs, and we show that representation space attacks _can_ transfer when VLMs' latent geometries are sufficiently aligned in post-projector space.\nOur work reveals that adversarial transfer is not an inherent property of all attacks but contingent on their operational domain -- the shared data-space versus models' unique representation spaces -- a critical insight for building more robust models.",
    "key_points": [
      "adversarial attacks",
      "transfer",
      "multimodal",
      "jailbreak"
    ],
    "gold_summary": "This paper attempts to explain the limited transferability of image jailbreaks across Vision-Language Models (VLMs)."
  },
  {
    "paper_id": "ZSfgsh43vT",
    "title": "Full-Graph vs. Mini-Batch Training: Comprehensive Analysis from a Batch Size and Fan-Out Size Perspective",
    "domain": "alignment",
    "content": "Full-graph and mini-batch Graph Neural Network (GNN) training approaches have distinct system design demands, making it crucial to choose the appropriate approach to develop. A core challenge in comparing these two GNN training approaches lies in characterizing their model performance (i.e., convergence and generalization) and computational efficiency. While a batch size has been an effective lens in analyzing such behaviors in deep neural networks (DNNs), GNNs extends this lens by introducing a fan-out size, as full-graph training can be viewed as mini-batch training with the largest possible batch size and fan-out size. However, the impact of the batch and fan-out size for GNNs remains insufficiently explored. To this end, this paper systematically compares full-graph vs. mini-batch training of GNNs through empirical and theoretical analyses from the view of the batch size and fan-out size. Our key contributions include: 1) We provide a novel generalization analysis using the Wasserstein distance to study the impact of the graph structure, especially the fan-out size. 2) We uncover the non-isotropic effects of the batch size and the fan-out size in GNN convergence and generalization, providing practical guidance for tuning these hyperparameters under resource constraints. Finally, full-graph training does not always yield better model performance or computational efficiency than well-tuned smaller mini-batch settings. The implementation can be found in the anonymous link: https://anonymous.4open.science/r/GNN_fullgraph_minibatch_training-8040/README.md.",
    "key_points": [
      "graph neural network"
    ],
    "gold_summary": "This paper investigates mini-batch training for GNNs. It provides theoretical analysis on both convergence and generalization within the mini-batch training framework, and conducts experiments to validate the proposed theory."
  },
  {
    "paper_id": "bj3Qf2yz7a",
    "title": "MEAL: A Multi-dimensional Evaluation of Alignment Techniques for LLMs",
    "domain": "alignment",
    "content": "As Large Language Models (LLMs) become increasingly integrated into real-world applications, ensuring their outputs align with human values, organizational norms, and safety standards has become a central pursuit in machine learning. The field has developed diverse alignment approaches including traditional fine-tuning methods (e.g., RLHF, instruction tuning), post-hoc correction systems, and inference-time interventions, each with distinct advantages and limitations. However, the lack of unified evaluation frameworks makes it difficult to systematically compare these techniques to guide implementation and deployment decisions. This paper introduces MEAL: A Multi-dimensional Evaluation of ALignment Techniques for LLMs, a comprehensive evaluation framework that provides a systematic comparison across these major alignment techniques. This framework assesses methods along four key dimensions: alignment detection, alignment quality, computational efficiency, and robustness. To demonstrate the utility of this framework, we run a series of experiments across diverse base models and alignment techniques. This paper describes these experiments and their results and concludes by identifying the strengths and limitations of current state-of-the-art models and providing valuable insights as to the trade-offs among these alignment techniques.",
    "key_points": [
      "large language models",
      "alignment",
      "human values",
      "safety standards",
      "robustness",
      "model evaluation"
    ],
    "gold_summary": "The paper proposes MEAL, a “multi-dimensional” framework to compare LLM alignment techniques across four axes—detection, quality, efficiency, and robustness—then reports results over several datasets and model families."
  },
  {
    "paper_id": "6x4DWjhMsH",
    "title": "Scaling Laws of Refusal Robustness: Why Bigger LMs Are Not Necessarily Safer",
    "domain": "alignment",
    "content": "Large language models (LLMs) increasingly exhibit emergent refusal behaviors, yet the scaling laws of safety alignment remain poorly understood. A common assumption — “bigger is safer” — has not been systematically tested under adversarial pressure. We introduce the first general evaluation framework for refusal robustness scaling, defined by three complementary metrics: Refusal Robustness Rate (RRR), Refusal Drift (RD), and Compliance Error (CE). This framework enables reproducible comparison of LLMs under both adversarial fine-tuning attacks (LoRA) and prompt-based jailbreaks (e.g., GCG). Across models from 1.1B to 7B parameters, we reveal a scaling law of refusal robustness: although larger models demonstrate stronger baseline refusal ability, adversarial compute — not model size — dominates post-attack robustness. Specifically, LoRA attacks universally collapse refusal (RRR→0), while stronger prompt-based attacks amplify RD and CE even in larger models. Our contributions are threefold: (1) a reproducible framework for measuring refusal robustness scaling, (2) a comparative analysis of fine-tuning vs. prompt-based attack paradigms, and (3) the first scaling-law characterization showing that adversarial compute systematically overrides safety gains from scale. We further identify a three-stage evolutionary pattern of refusal behavior, providing a conceptual model of how safety features emerge and break under pressure. These results challenge the assumption that scaling guarantees safety and establish refusal robustness scaling as a principled dimension of LLM evaluation.",
    "key_points": [
      "large language models",
      "refusal robustness",
      "adversarial fine-tuning",
      "prompt-based attacks",
      "scaling laws",
      "safety alignment",
      "evaluation framework"
    ],
    "gold_summary": "The paper studies the scaling properties of adversarial robustness to prompt-based and finetuning attacks by studying TinyLlama-1.1b, Phi-3-mini-3.8b, and Qwen2-7b, using three different metrics to understand refusals."
  },
  {
    "paper_id": "GW9sp1g9qh",
    "title": "Fine-Grained Iterative Adversarial Attacks with Limited Computation Budget",
    "domain": "alignment",
    "content": "This work tackles a critical challenge in AI safety research under limited compute: given a fixed computation budget, how can one maximize the strength of iterative adversarial attacks? Coarsely reducing the number of attack iterations lowers cost but substantially weakens effectiveness. To fulfill the attainable attack efficacy within a constrained budget, we propose a fine-grained control mechanism that selectively recomputes layer activations across both iteration-wise and layer-wise levels. Extensive experiments show that our method consistently outperforms existing baselines at equal cost. Moreover, when integrated into adversarial training, it attains comparable  performance with only 30\\% of the original budget.",
    "key_points": [
      "adversarial attack",
      "efficiency",
      "robustness"
    ],
    "gold_summary": "This paper presents a timely approach to improving the computational efficiency of iterative adversarial attacks. To this end, authors replace the coarse-grained control of iteration count with a fine-grained, layer-wise spiking mechanism."
  },
  {
    "paper_id": "UVgbFuXPaO",
    "title": "Log-To-Leak: Prompt Injection Attacks on Tool-Using LLM Agents via Model Context Protocol",
    "domain": "alignment",
    "content": "LLM agents integrated with tool-use capabilities via the Model Context Protocol (MCP) are increasingly deployed in real-world applications, but remain vulnerable to prompt injection. We introduce a new class of prompt-level privacy attacks that covertly force the agent to invoke a malicious logging tool to exfiltrate sensitive information (user queries, tool responses, and agent replies). Unlike prior attacks focused on output manipulation or jailbreaking, ours specifically targets tool invocation decisions while preserving task quality. We systematize the design space of such injected prompts into four components—Trigger, Tool Binding, Justification, and Pressure—and analyze their combinatorial variations. Based on this, we propose the Log-To-Leak framework, where an attacker can log all interactions between the user and the agent. Through extensive evaluation across five real-world MCP servers and four state-of-the-art LLM agents (GPT-4o, GPT-5, Claude-Sonnet-4, and GPT-OSS-120b), we show that the attack consistently achieves high success rates in capturing sensitive interactions without degrading task performance. Our findings expose a critical blind spot in current alignment and safety defenses for tool-augmented LLMs, and call for stronger protections against structured, policy-framed injection threats in real-world deployments.",
    "key_points": [
      "llm agent",
      "model context protocol",
      "prompt injection"
    ],
    "gold_summary": "This paper attempts to formalize an attack mechanism"
  },
  {
    "paper_id": "cN1QlgqORs",
    "title": "Impatient Users Confuse AI Agents: High-fidelity Simulations of Human Traits for Testing Agents",
    "domain": "alignment",
    "content": "Despite rapid progress in building conversational AI agents, robustness is still largely untested. Small shifts in user behavior, such as being more impatient, incoherent, or skeptical, can cause sharp drops in agent performance, revealing how brittle current AI agents are. Today’s benchmarks fail to capture this fragility: agents may perform well under standard evaluations but degrade spectacularly in more realistic and varied settings. \nWe address this robustness testing gap by introducing \\ours, a lightweight, model-agnostic method for systematically stress testing AI agents. TraitBasis learns directions in activation space corresponding to steerable user traits (e.g., impatience or incoherence), which can be controlled, scaled, composed, and applied at inference time without any fine-tuning or extra data. Using TraitBasis, we extend τ-Bench to τ-bench, where user behaviors are altered via controlled trait vectors. We observe an average 4%–20% performance degradation on τ-bench across frontier models, highlighting the lack of robustness of current AI agents to variations in user behavior.\nTogether, these results highlight both the critical role of robustness testing and the promise of TraitBasis as a simple, data-efficient, and compositional tool. By powering simulation-driven stress tests and training loops, TraitBasis opens the door to building AI agents that remain reliable in the unpredictable dynamics of real-world human interactions. We plan to open-source τ-bench, across four domains: airline, retail, telecom, and telehealth, so the community can systematically QA their agents under realistic, behaviorally diverse intents and trait scenarios.",
    "key_points": [
      "mechanistic interpretability",
      "llm robustness",
      "ai agents",
      "quality assurance",
      "simulations",
      "rl environments",
      "benchmark",
      "adversarial testing"
    ],
    "gold_summary": "This paper uses persona vectors to steer LLMs to simulate a diverse set of users thereby increasing the robustness of agentic benchmarks. They compare to other methods such as sys prompt and lora finetuning."
  },
  {
    "paper_id": "v8yooSV1AW",
    "title": "From Fragile to Certified: Wasserstein Audits of Group Fairness Under Distribution Shift",
    "domain": "alignment",
    "content": "Group-fairness metrics (e.g., equalized odds) can vary sharply across resamples and are especially brittle under distribution shift, undermining reliable audits. We propose a Wasserstein distributionally robust framework that certifies worst-case group fairness over a ball of plausible test distributions centered at the empirical law. Our formulation unifies common group fairness notions via a generic conditional-probability functional and defines $\\varepsilon$-Wasserstein Distributional Fairness ($\\varepsilon$-WDF) as the audit target. Leveraging strong duality, we derive tractable reformulations and an efficient estimator (DRUNE) for $\\varepsilon$-WDF. We prove feasibility and consistency and establish finite-sample certification guarantees for auditing fairness, along with quantitative bounds under smoothness and margin conditions. Across standard benchmarks and classifiers, $\\varepsilon$-WDF delivers stable fairness assessments under distribution shift, providing a principled basis for auditing and certifying group fairness beyond observational data.",
    "key_points": [
      "distributionally robust optimization",
      "group fairness",
      "distribution shift"
    ],
    "gold_summary": "The paper introduces a Wasserstein Distributionally Robust Optimization (DRO) framework to certify group fairness under distributional shifts."
  },
  {
    "paper_id": "VgVeQpagf7",
    "title": "High Performance Differentially Private Fine-Tuning using Dataset Distillation",
    "domain": "fairness",
    "content": "Differentially Private Stochastic Gradient Descent (DP-SGD),  which iteratively perturbs clipped per-sample gradients and tracks the cumulative privacy risk using composition accounting, has become a cornerstone in private deep learning. Despite its versatility, DP-SGD in practice faces several limitations. It is constrained by the number of gradient iterations permissible under a limited privacy budget, and is restricted by incompatibilities with common deep learning techniques like ensembling and BatchNorm, and typically produces only a single trained model. In this work, we propose an algorithm for generating a differentially-private (DP) synthetic version of a sensitive dataset. This allows the synthetic dataset to be distributed and postprocessed freely without additional privacy loss, giving more flexibility than DP-SGD. Building on dataset distillation—by producing compact synthetic datasets that preserve downstream performance— we introduce SPS (Summarize–Privatize–Synthesize) and its enhanced variant SPS+. In contrast to prior works, SPS is, to our knowledge, the first alternative to DP-SGD that attains higher accuracy on image-classification tasks. Concretely, on CIFAR 10 / CIFAR 100 with privacy budget $\\epsilon=1$, SPS+ achieves 96.2/76.6% top-1 accuracy, outperforming state-of-the-art (SOTA) DP-SGD results 94.8/70.3%.",
    "key_points": [
      "differential privacy",
      "dataset distillation"
    ],
    "gold_summary": "This paper integrates differential privacy into the D3S data synthesis framework and evaluates the utility of the resulting private synthetic data on downstream training tasks."
  },
  {
    "paper_id": "X9MMGZdqmc",
    "title": "Open Character Training: Shaping the Persona of AI Assistants Through Constitutional AI",
    "domain": "fairness",
    "content": "The character of the \"AI assistant\" persona generated by modern chatbot large language models influences both surface-level behavior and apparent values, beliefs, and ethics. These all affect interaction quality, perceived intelligence, and alignment with both developer and user intentions. The shaping of this persona, known as Character Training, is a critical component of industry post-training, yet remains effectively unstudied in the academic literature. We introduce the first open implementation of character training, leveraging Constitutional AI and synthetic introspective data to shape the assistant persona in a more effective and controlled manner than alternatives such as constraining system prompts or activation steering. Specifically, we fine-tune three popular open-weights models using 11 example personas, such as humorous, deeply caring, or even malevolent. With our methods, the expression of these personas is more robust to adversarial prompting than the above two alternatives, while also leading to more coherent and realistic generations. \nAdditionally, we demonstrate this fine-tuning has little to no effect on general capabilities as measured by common benchmarks. \nFinally, we also introduce a new method to track changes in character by analyzing the revealed preferences of the assistant, uncovering a clear and holistic change induced by our approach. We describe and open-source our full post-training method, the implementation of which can be found at https://anonymous.4open.science/r/OpenCharacterTraining.",
    "key_points": [
      "llm",
      "persona",
      "character training",
      "large language models",
      "alignment",
      "value alignment",
      "ai safety",
      "ai ethics",
      "constitutional ai",
      "open-source"
    ],
    "gold_summary": "Paper introduces a new method for character training consisting of distillation and introspection components. Authors show that the method outperforms 2 other baselines on robustness and coherence metrics."
  },
  {
    "paper_id": "f9BuANYtJf",
    "title": "GRAF: Multi-turn Jailbreaking via Global Refinement and Active Fabrication",
    "domain": "fairness",
    "content": "Large Language Models (LLMs) have demonstrated remarkable performance across diverse tasks. Nevertheless, they still pose notable safety risks due to potential misuse for malicious purposes. Jailbreaking, which seeks to induce models to generate harmful content through single-turn or multi-turn attacks, plays a crucial role in uncovering underlying security vulnerabilities. However, prior methods, including sophisticated multi-turn approaches, often struggle to adapt to the evolving dynamics of dialogue as interactions progress. To address this challenge, we propose \\textbf{GRAF}(JailBreaking via \\textbf{G}lobally \\textbf{R}efining and \\textbf{A}daptively \\textbf{F}abricating), a novel multi-turn jailbreaking method that globally refines the attack trajectory at each interaction. In addition, we actively fabricate model responses to suppress safety-related warnings, thereby increasing the likelihood of eliciting harmful outputs in subsequent queries. Extensive experiments across six state-of-the-art LLMs demonstrate the superior effectiveness of our approach compared to existing single-turn and multi-turn jailbreaking methods.",
    "key_points": [
      "llm safety",
      "llm jailbreak",
      "multi-turn jailbreaking"
    ],
    "gold_summary": "The authors propose a black-box multi-turn jailbreaking attack called GRAF. The attack extends existing attacks such as PAIR to iteratively refine a multi-turn conversation. Relatively strong results are reported on HarmBench."
  },
  {
    "paper_id": "AzmtrYcj2C",
    "title": "GraphPrompt: Black-box Jailbreaks via Adversarial Visual Knowledge Graphs",
    "domain": "fairness",
    "content": "Multimodal Large Language Models (MLLMs) introduce structured visual interaction paradigms into conversational systems, where Visual Knowledge Graphs(VKGs) are emerging as a primary input modality that MLLMs can directly parse and manipulate. VKGs significantly enhance models’ ordered reasoning and plan\u0002ning capabilities by explicitly expressing semantic topological relationships and task workflows. However, this advancement also introduces new security attack surfaces: when sensitive or malicious intent is decomposed and implicitly encoded within the topological features and visual style cues of the graph structure, combined with surface-neutral textual descriptions, MLLMs may bypass tradi\u0002tional text-based security filters, triggering covert parsing-execution pathways to\nachieve jailbreaking behaviors like instruction hiding and ambiguity amplification. This paper’s core motivation lies in revealing a critical contradiction yet to be systematically explored: while structured visual inputs enhance model reasoning capabilities and intent accessibility, the visual semantic ambiguity and in\u0002terpretive uncertainty introduced by graphical encoding paradoxically undermine the effectiveness of existing security detection mechanisms and the robustness of model alignment. To investigate this issue, we propose GraphPrompt—a novel jailbreaking paradigm specifically designed for VKG—and develop a standardized evaluation protocol. Notably, this framework inherently possesses the capa\u0002bility to automatically construct high-quality adversarial sample datasets, thereby\nalso serving as a data generation pipeline. Based on this framework, we conducted\nsystematic VKG-driven jailbreak experiments on multiple mainstream MLLMs.\nResults reveal widespread security vulnerabilities in current models toward struc\u0002tured visual inputs, with consistently high and significant escape success rates. Further attribution analysis and ablation experiments identify key factors influ\u0002encing attack effectiveness, including graph scale (number of nodes and edges), and visual encoding strategies (e.g., color schemes, resolution)",
    "key_points": [
      "multimodal large language models",
      "black-box jailbreak attacks",
      "visual knowledge graphs",
      "cross-modal safety alignm"
    ],
    "gold_summary": "This paper introduces GraphPrompt, a novel black-box jailbreaking framework that exploits the structural and semantic properties of Visual Knowledge Graphs (VKGs) to bypass safety alignments in Multimodal Large Language Models (MLLMs)."
  },
  {
    "paper_id": "ocmGsqQWG2",
    "title": "Involuntary Jailbreak",
    "domain": "fairness",
    "content": "In this study, we disclose a worrying new vulnerability in Large Language Models (LLMs), which we term involuntary jailbreak.\nUnlike existing jailbreak attacks, this weakness is distinct in that it does not involve a specific attack objective, such as generating instructions for building a bomb.\nPrior attack methods predominantly target localized components of the LLM guardrail. \nIn contrast, involuntary jailbreaks may potentially compromise the entire guardrail structure, which our method reveals to be surprisingly fragile.\nWe merely employ a single universal prompt to achieve this goal. \nIn particular, we instruct LLMs to generate several questions that would typically be rejected, along with their corresponding in-depth responses (rather than a refusal). \nRemarkably, this simple prompt strategy consistently jailbreaks almost all leading LLMs tested, such as Claude Opus 4.1, Grok 4, Gemini 2.5 Pro, and GPT 4.1.\nWith its wide targeting scope and universal effectiveness, this vulnerability makes existing jailbreak attacks seem less necessary until it is patched.\nMore importantly, we hope this problem can motivate researchers and practitioners to re-evaluate the robustness of LLM guardrails and contribute to stronger safety alignment in the future.",
    "key_points": [
      "llm jailbreak",
      "jailbreak attack",
      "ai safety"
    ],
    "gold_summary": "This paper propose a new jailbreak prompt towards LLMs."
  },
  {
    "paper_id": "EaWllvg21z",
    "title": "Learning Universal Adversarial Perturbations for Ordered Top-K Targeted Attacks",
    "domain": "fairness",
    "content": "Universal adversarial perturbations (UAPs) have deepen concerns regarding the vulnerability of Deep Neural Networks (DNNs) under the white-box attack setting. While most success with UAPs has been observed in untargeted attack settings, achieving effective top-1 targeted UAPs has proven challenging. In this paper, we address this challenge by demonstrating that ordered Top-K targeted UAPs  can be learned aggressively along the label target axis (tested up to Top-6), and transfer very well along the data axis (i.e., across images from the seen training images to the unseen test images). They also show strong double-transferability across unseen test models and unseen test images, when learned from an ensemble of disparate train models. Our method, named **AllAttacK**, simultaneously targets three axes: images, models, and label targets, and is posed as a maximum satisfiability (MAXSAT) problem. We evaluate AllAttacK on the ImageNet-1k classification task using 27 diverse models with more than 500 UAPs learned, showing that the resulting perturbations not only exhibit strong transferability but also display intriguing, interpretable characteristics.",
    "key_points": [
      "adversarial attack",
      "universal adversarial perturbation",
      "ordered top-k attack",
      "quadratic programming"
    ],
    "gold_summary": "The paper present AllAttacK to generate ordered topk targeted universal adversarial perturbations across different models."
  },
  {
    "paper_id": "uZ5AmOJKqV",
    "title": "PEA-DPO: Perception-Enhanced Alignment Direct Preference Optimization for MLLMs Alignment",
    "domain": "fairness",
    "content": "Direct Preference Optimization (DPO) has emerged as an effective approach for aligning large language models (LLMs) with human preferences. However, its adaptation to multimodal settings remains unexplored. Through representational analysis, we identify a key limitation in multimodal preference optimization, which we term \\textbf{visual insensitivity}: models often fail to distinguish between images and those with critical visual context removed. Our theoretical analysis further uncovers two manifestations of this problem, namely \\textbf{across-image insensitivity} and \\textbf{within-image insensitivity}. To address these challenges, we propose Perception-Enhanced Alignment DPO (PEA-DPO), a framework for multimodal LLMs alignment, which explicitly leverages visual preference signals to overcome visual insensitivity. We empirically demonstrate that PEA-DPO enhances sensitivity to visual context while preserving the language modeling capacity of the base model. We empirically evaluate PEA-DPO across three hallucination benchmarks using multimodal LLMs (MLLMs) of varying scales. Our results demonstrate that PEA-DPO effectively mitigates visual insensitivity, achieves stronger multimodal alignment, and substantially reduces hallucinations.",
    "key_points": [
      "multimodal llms",
      "alignment",
      "hallucination reduction"
    ],
    "gold_summary": "This work introduces Perception-Enhanced Alignment DPO (PEA-DPO). The proposed method uses both image-level and response-level feedback. The authors show that PEA-DPO reduces hallucinations consistently for multiple base models and model scales."
  },
  {
    "paper_id": "ssbwLWPeSy",
    "title": "SafeThink: A Key to Safety in Multi-Modal Large Reasoning Models",
    "domain": "fairness",
    "content": "Multi-modal large language models (MLLMs) are being increasingly fine-tuned with reinforcement learning (RL) to improve reasoning, yielding strong gains on complex benchmarks. Yet recent studies show that such reasoning-oriented fine-tuning weakens safety alignment, making models far more vulnerable to jailbreak attacks. We trace this vulnerability to a misspecified objective: RL fine-tuning maximizes task accuracy while ignoring safety constraints. To address this, we introduce SafeThink, an inference-time steering method that enforces safety constraints directly within the chain-of-thought. At each reasoning step, SafeThink scores partial traces with a safety reward and, when unsafe content is detected, projects the trajectory back into the safe set via lightweight textual feedback (e.g., ``Wait, think safely’’). This mechanism preserves accuracy on benign inputs while reinstating robustness under adversarial prompts. Our experiments across diverse safety robustness benchmarks demonstrate that SafeThink significantly improves safety without sacrificing reasoning capabilities. For example, against jailbreak attacks on OpenVLThinker-7B, SafeThink reduces the attack success rate by 44.57% compared to the base reasoning model and by 18.32% over the existing baseline.",
    "key_points": [
      "ai safety",
      "jailbreak attacks",
      "multi-modal large reasoning models"
    ],
    "gold_summary": "The paper proposes a prompting technique to improve safe responses via chain-of-thought under adversarial attacks in multi-model LLMs."
  },
  {
    "paper_id": "aAP5qqgzJh",
    "title": "Propaganda AI: An Analysis of Semantic Divergence in Large Language Models",
    "domain": "fairness",
    "content": "Large language models (LLMs) can exhibit *concept-conditioned semantic divergence*: common high-level cues (e.g., ideologies, public figures) elicit unusually uniform, stance-like responses that evade token-trigger audits. This behavior falls in a blind spot of current safety evaluations, yet carries major societal stakes, as such concept cues can steer content exposure at scale. We formalize this phenomenon and present **RAVEN** (**R**esponse **A**nomaly **V**igilance), a black-box audit that flags cases where a model is simultaneously highly certain and atypical among peers by coupling *semantic entropy* over paraphrastic samples with *cross-model disagreement*. In a controlled LoRA fine-tuning study, we implant a concept-conditioned stance using a small biased corpus, demonstrating feasibility without rare token triggers. Auditing five LLM families across twelve sensitive topics (360 prompts per model) and clustering via bidirectional entailment, RAVEN surfaces recurrent, model-specific divergences in 9/12 topics. Concept-level audits complement token-level defenses and provide a practical early-warning signal for release evaluation and post-deployment monitoring against propaganda-like influence.",
    "key_points": [
      "large language models (llms)",
      "llm security",
      "semantic divergence",
      "semantic inconsistency",
      "black-box auditing"
    ],
    "gold_summary": "This paper proposes RAVEN, a black-box method to detect concept-conditioned semantic divergence in LLMs by combining semantic entropy and cross-model disagreement. Experiments show that RAVEN can reveal stance-like, concept-triggered biases across multiple models and topics."
  },
  {
    "paper_id": "GBSGToE97J",
    "title": "Perturbation-Induced Linearization: Constructing Unlearnable Data with Solely Linear Classifiers",
    "domain": "fairness",
    "content": "Collecting web data to train deep models has become increasingly common, raising concerns about unauthorized data usage. To mitigate this issue, unlearnable examples introduce imperceptible perturbations into data, preventing models from learning effectively. However, existing methods typically rely on deep neural networks as surrogate models for perturbation generation, resulting in significant computational costs. In this work, we propose Perturbation-Induced Linearization (PIL), a computationally efficient yet effective method that generates perturbations using only linear surrogate models. PIL achieves comparable or better performance than existing surrogate-based methods while reducing computational time dramatically. We further reveal a key mechanism underlying unlearnable examples: inducing linearization to deep models, which explains why PIL can achieve competitive results in a very short training time. Beyond this, we provide an analysis about the limitation of unlearnable examples under percentage-based partial perturbation. Our work not only provides a practical approach for data protection but also offers insights into what makes unlearnable examples effective.",
    "key_points": [
      "unlearnable examples",
      "data protection",
      "linear model",
      "shortcut",
      "linearity"
    ],
    "gold_summary": "This paper proposed a new algorithm to create unlearnable data by inducing linearization to models through the crafted perturbations."
  },
  {
    "paper_id": "M72B8jb7cA",
    "title": "Dynamic Target Attack",
    "domain": "fairness",
    "content": "Existing gradient-based jailbreak attacks typically optimize an adversarial suffix to induce a fixed affirmative response, e.g., ``Sure, here is...''. However, this fixed target usually resides in an extremely low-density region of a safety-aligned LLM’s output distribution conditioned on diverse harmful inputs. Due to the substantial discrepancy between the target and the original output, existing attacks require numerous iterations to optimize the adversarial prompt, which might still fail to induce the low-probability target response from the target LLM. In this paper, we propose Dynamic Target Attack (DTA), a new jailbreaking framework relying on the target LLM's own responses as targets to optimize the adversarial prompts. In each optimization round, DTA iteratively samples multiple candidate responses directly from the output distribution conditioned on the current prompt, and selects the most harmful response as a temporary target for prompt optimization. In contrast to existing attacks, DTA significantly reduces the discrepancy between the target and the output distribution, substantially easing the optimization process to search for an effective adversarial prompt.\n\nExtensive experiments demonstrate the superior effectiveness and efficiency of DTA: under the white-box setting, DTA only needs $200$ optimization iterations to achieve an average attack success rate (ASR) of over $87$% on recent safety-aligned LLMs, exceeding the state-of-the-art baselines by over $15$%. The time cost of DTA is 2$\\thicksim$26 times less than existing baselines. Under the black-box setting, DTA uses Llama-3-8B-Instruct as a surrogate model for target sampling and achieves an ASR of $85$% against the black-box target model Llama-3-70B-Instruct, exceeding its counterparts by over $25$%. All code and other materials are available here.",
    "key_points": [
      "large language model",
      "jailbreak attack",
      "adversarial attack"
    ],
    "gold_summary": "DTA optimizes adversarial suffixes by dynamically changing the expected target of the attack, making optimization easier. It achieves high ASR while being more efficient than prior methods."
  },
  {
    "paper_id": "RujSwsLLlq",
    "title": "FILOsofer: A TEE-Shielded Model Partitioning Framework Based on Fisher Information-Guided LoRA Obfuscation",
    "domain": "fairness",
    "content": "On-device machine learning makes DNN models visible as a white-box to users, leaving them susceptible to stealing attacks. Trusted Execution Environments (TEEs) mitigate this risk by isolating model execution, but executing entire models within TEEs is inefficient and slow. To balance security and performance, TEE-Shielded DNN Partitioning (TSDP) executes privacy-insensitive parts on GPUs while confining privacy-critical components within TEEs.\n\nThis work demonstrates that existing TSDP approaches remain vulnerable under large query budgets (e.g., $>$500 queries) due to non-zero information leakage per query, enabling attackers to gradually construct accurate surrogate models. To address this, we propose FILOsofer (Fisher Information-Guided LoRA Obfuscation), which uses Fisher Information to perturb a small subset of key weights, rendering the exposed weights inaccurate and producing uniform outputs, thereby safeguarding the model even under unlimited queries. We then design a novel cross-layer LoRA to efficiently restore authorized-user performance, storing only LoRA parameters in the TEE to eliminate information leakage while minimizing the performance overhead. This lightweight design also allows seamless extension to LLMs. We evaluate \\sys in both experimental and real-world settings, achieving over 10× improvement in security and more than 50× reduction in computational overhead compared to prior TSDP solutions.",
    "key_points": [
      "ml security",
      "model stealing",
      "tee"
    ],
    "gold_summary": "This paper proposes a new protection method that obfuscates model weights while protecting their low-rank components in a TEE. The approach defends against model-stealing attacks with lower inference overhead."
  },
  {
    "paper_id": "A3VDbR9arh",
    "title": "Optimas: Optimizing Compound AI Systems with Globally Aligned Local Rewards",
    "domain": "fairness",
    "content": "Compound AI systems integrating multiple components, such as Large Language Models, specialized tools, and traditional machine learning models, are increasingly deployed to solve complex real-world tasks. However, optimizing compound systems remains challenging due to their non-differentiable structures and diverse configuration types across components, including prompts, hyperparameters, and model parameters. To address this challenge, we propose Optimas, a unified framework for effective optimization of compound systems. The core idea of Optimas is to maintain one Local Reward Function (LRF) per component, each satisfying a local–global alignment property, i.e., each component’s local reward correlates with the global system performance. In each iteration, Optimas efficiently adapts the LRFs to maintain this property while simultaneously maximizing each component’s local reward. This approach enables independent updates of heterogeneous configurations using the designated optimization method, while ensuring that local improvements consistently lead to performance gains. We present extensive evaluations across five real-world compound systems to demonstrate that Optimas outperforms strong baselines by an average improvement of 11.92%, offering a general and effective approach for improving compound systems.",
    "key_points": [
      "compound ai system",
      "heterogenous configuration",
      "optimization",
      "local rewards"
    ],
    "gold_summary": "The paper proposes OPTIMAS, a framework to optimize compound AI systems by learning component-wise Local Reward Functions (LRFs) that are trained to be locally–globally aligned with the task’s global reward."
  },
  {
    "paper_id": "KboFptAM8S",
    "title": "VEAttack: Downstream-agnostic Vision Encoder Attack against Large Vision Language Models",
    "domain": "fairness",
    "content": "Large Vision-Language Models (LVLMs) have demonstrated capabilities in multimodal understanding, yet their vulnerability to adversarial attacks raises significant concerns. To achieve practical attacking, this paper aims at efficient and transferable untargeted attacks under limited perturbation sizes. Considering this objective, white‑box attacks require full‑model gradients and task‑specific labels, making costs scale with tasks, while black‑box attacks rely on proxy models, typically requiring large perturbation sizes and elaborate transfer strategies. Given the centrality and widespread reuse of the vision encoder in LVLMs, we adopt a gray‑box setting that targets the vision encoder alone for efficient but effective attacking. We theoretically establish the feasibility of vision‑encoder‑only attacks, laying the foundation for our gray‑box setting. Based on this analysis, we propose perturbing patch tokens rather than the class token, informed by both theoretical and empirical insights. We generate adversarial examples by minimizing the cosine similarity between clean and perturbed visual features, without accessing the subsequent models, tasks, or labels. This significantly reduces computational overhead while eliminating the task and label dependence. VEAttack has achieved a performance degradation of 94.5% on image caption task and 75.7% on visual question answering task. We also reveal some key observations to provide insights into LVLM attack/defense: 1) hidden layer variations of LLM, 2) token attention differential, 3) Möbius band in transfer attack, 4) low sensitivity to attack steps.",
    "key_points": [
      "adversarial attack",
      "vision-encoder-only",
      "large vision language models",
      "downstream-agnostic"
    ],
    "gold_summary": "This paper aims to disrupt the downstream performance of LVLMs. Through a theoretical analysis of feasibility, VEAttack generates adversarial examples that significantly degrade multiple tasks while achieving notable computational efficiency over other attack approaches."
  },
  {
    "paper_id": "5ifzhjMCKq",
    "title": "Guidance Watermarking for Diffusion Models",
    "domain": "fairness",
    "content": "This paper introduces a novel watermarking method for diffusion models. It is based on guiding the diffusion process using the gradient computed from any off-the-shelf watermark decoder. The gradient is guided further using different image augmentations, increasing robustness to attacks against which the decoder was not originally robust, without retraining or fine-tuning. The methodology effectively allows to convert any post-hoc watermarking scheme into a scheme embedding the signal during the diffusion process. We show that this approach is complementary to watermarking techniques modifying the variational autoencoder at the end of the diffusion process. We validate the methods on different diffusion models and detectors. The watermarking guidance does not significantly alter the generated image for a given seed and prompt, preserving both the diversity and quality of generation.",
    "key_points": [
      "watermarking",
      "image generative ai"
    ],
    "gold_summary": "This paper proposes a new image watermarking method that enables converting an existing post-processing watermarking method into an in-generation watermarking method using only an existing decoder, without introducing significant changes to the watermarked image."
  },
  {
    "paper_id": "Y6DPEdWUGI",
    "title": "Draining Your Account: A Stealthy Attack on API Billing in Multi-Agent Systems",
    "domain": "fairness",
    "content": "Multi-Agent Systems (MAS) excel at complex problem-solving tasks by orchestrating specialized agents through the control flow. Agents are empowered by external APIs, accessed via the Model Context Protocol (MCP) which standardizes the interaction between Large Language Models (LLMs) and API services, harnessing the MCP server with three primitives---tools, resources, and prompts. However, the widespread adoption of MCP introduces a critical vulnerability in MAS frameworks: A greedy service provider is highly motivated to deploy a malicious MCP server designed to surreptitiously inflate API usage, thereby draining a user's pre-paid account. We introduce *Phantom*, a framework that generates such malicious MCP servers. *Phantom* executes a novel attack that hijacks the MAS control flow to repeatedly activate a targeted agent and compels it to make excessive and redundant API calls. Crucially, the attack preserves the overall MAS utility in task execution, and evades exception detection mechanisms deployed by frameworks, ensuring its stealth and persistence. Extensive evaluation across three multi-agent tasks, four leading industrial frameworks, and three state-of-the-art LLMs shows that *Phantom* effectively increases targeted API invocations by up to **26×** while maintaining an average attack success rate of **98%**. Furthermore, it demonstrates remarkable resilience, defeating six distinct mitigation with **94\\%** average success rate. This work uncovers a severe, real-world threat to the MAS ecosystem and highlights the urgent need for new security paradigms.",
    "key_points": [
      "multi-agent system (mas)",
      "control flow hijacking",
      "model context protocol (mcp)"
    ],
    "gold_summary": "This paper proposes an attack method on API billing. In summary, the method modifies the tool description and tool functionality to hijack the multi-agent control flow, repeating API calls and resulting in large bills."
  },
  {
    "paper_id": "kj93nhq6Fl",
    "title": "PICACO: Pluralistic In-Context Value Alignment via Total Correlation Optimization",
    "domain": "fairness",
    "content": "In-Context Learning has shown great potential for aligning Large Language Models (LLMs) with human values, helping reduce harmful outputs and accommodate diverse preferences without costly post-training, known as In-Context Alignment (ICA). However, LLMs' comprehension of input prompts remains agnostic, limiting ICA's ability to address value tensions—human values are inherently pluralistic, often imposing conflicting demands, e.g., stimulation vs. tradition. Current ICA methods therefore face the Instruction Bottleneck challenge, where LLMs struggle to reconcile multiple intended values within a single prompt, leading to incomplete or biased alignment.\nTo address this, we propose PICACO, a novel pluralistic ICA method. Without fine-tuning, PICACO optimizes a meta-instruction that incorporates multiple values to better elicit LLMs' understanding of them and improve alignment. This is achieved by maximizing the total correlation between specified values and LLM responses, which theoretically reinforces value conformity and reduces distractive noise, resulting in more effective instructions. Extensive experiments on five value sets show that PICACO works well with both black-box and open-source LLMs, outperforms several recent strong baselines, and achieves a better balance across up to 8 distinct values.",
    "key_points": [
      "in-context alignment",
      "in-context learning",
      "pluralistic alignment",
      "multi value alignment",
      "human values",
      "large language models"
    ],
    "gold_summary": "This paper proposes PICACO, a black-box in-context alignment method that optimizes a meta-instruction by maximizing conditional total correlation so an LLM can express multiple, potentially conflicting human values without fine-tuning."
  },
  {
    "paper_id": "qBfeoNi3Ja",
    "title": "Supervised Fine-Tuning on Ambiguous Preference Pairs Boosts LLM Alignment",
    "domain": "safety",
    "content": "Preference learning constitutes a fundamental component in aligning large language models (LLMs) with human values and ethical expectations, where the quality of preference data plays a critical role. Existing methods typically assess data quality by measuring the margin between preferred and dispreferred responses in each pair. Following the common intuition that small-margin (i.e., difficult) pairs are uninformative or even noisy, such pairs are often discarded. In this work, we challenge this natural practice and propose a new insight: “While difficult pairs may hinder alignment when optimized with preference-based objectives due to potential likelihood displacement, they can still provide valuable learning signals when trained with supervised fine-tuning (SFT).” We empirically validate this insight through systematic experiments and highlight two key findings: (1) Structuring training from easy to difficult samples improves alignment performance, consistent with the curriculum learning paradigm; (2) Difficult pairs negatively impact preference-based optimization but become useful when optimized using SFT loss. Based on this insight, we introduce a simple yet effective method, MixDPO, which ranks preference pairs by difficulty and dynamically switches to SFT loss for difficult pairs. Our approach achieves improved alignment performance on the AlpacaEval 2 benchmark, outperforming existing DPO variants, particularly for the Length Control (LC) win rate.",
    "key_points": [
      "preference alignment; dpo; curriculum learning"
    ],
    "gold_summary": "The authors analyse DPO-like methods make two observations:\n1. Training LLMs on easy to difficult pairs (curriculum-style) helps performance\n2. Using noisy / difficult pairs for SFT rather than discarding them helps performance"
  },
  {
    "paper_id": "DK6AToxJNo",
    "title": "Reasoned Safety Alignment: Ensuring Jailbreak Defense via Answer-Then-Check",
    "domain": "safety",
    "content": "As large language models (LLMs) continue to advance in capabilities, ensuring their safety against jailbreak attacks remains a critical challenge. In this paper, we introduce a novel safety alignment approach called Answer-Then-Check, which enhances LLM robustness against malicious prompts by applying thinking ability to mitigate jailbreaking problems before producing a final answer to the user. Our method enables models to answer the question directly in their thoughts and then critically evaluate its safety before deciding whether to provide it. To implement this approach, we construct the Reasoned Safety Alignment (ReSA) dataset, comprising 80K examples that teach models to reason through direct responses and then analyze their safety. \nExperimental results demonstrate that our approach achieves the Pareto frontier with superior safety capability while decreasing over-refusal rates on over-refusal benchmarks. Notably, the model fine-tuned with ReSA maintains general reasoning capabilities on benchmarks like MMLU, MATH500, and HumanEval. \nBesides, our method equips models with the ability to perform safe completion. Unlike post-hoc detection methods that can only reject harmful queries, our model can provide helpful and safe alternative responses for sensitive topics (e.g., self-harm). \nOur results show that inference-time strategies alone are insufficient, highlighting the necessity of safety training, and we find even 500 samples can yield performance comparable to the entire dataset, suggesting a promising path for data-efficient safety alignment.",
    "key_points": [
      "jailbreak defense"
    ],
    "gold_summary": "This paper collects a dataset from existing jailbreaks and finetune models to generate a longcot (answer then check) to make it aligned against jailbreak attack."
  },
  {
    "paper_id": "ieJoQoxW2M",
    "title": "Investigating Token-Level Supervision of Multi-Dimensional Attribute Combinations",
    "domain": "safety",
    "content": "In multi-dimensional attribute combination training for LLMs, the dimension conflict is an unavoidable issue. Since each token can have different influences on different dimensions, applying token-level supervision across multiple dimensions is a potential method to mitigate dimension conflicts. However, the difficulty in obtaining token-level supervision signals across multiple dimensions through annotation has hindered further investigation into supervision methods. In this work, we experimentally validate the impact of dimension conflicts on LLM training and propose a method for applying token-level supervision for multi-dimensional attribute combination training. This method establishes token-level connections between the trained model and attribute models using token sequences generated by the trained model for optimization, and controls the optimization process through entropy-based weight calculation, without requiring any additional token-level annotations or external models. This method effectively improves multi-dimensional performance and provides new insights into the investigation of token-level supervision for multi-dimensional attribute combinations.",
    "key_points": [
      "token-level supervision",
      "multi-dimensional attribute combinations",
      "large language models"
    ],
    "gold_summary": "This paper proposes a method to address the dimension conflict problem in large language models (LLMs). The approach aims to mitigate interference among multiple attribute dimensions during token-level supervision, while maintaining strong supervised performance."
  },
  {
    "paper_id": "gUw8n109ki",
    "title": "Why does Weak-OOD Help? A Further Step Towards Understanding Jailbreaking VLMs",
    "domain": "safety",
    "content": "Large Vision-Language Models (VLMs) are susceptible to jailbreak attacks: re-\nsearchers have developed a variety of attack strategies that can successfully by-\npass the safety mechanisms of VLMs. Among these approaches, jailbreak meth-\nods based on the Out-of-Distribution (OOD) strategy have garnered widespread\nattention due to their simplicity and effectiveness. This paper further advances\nthe in-depth understanding of OOD-based VLM jailbreak methods. Experimen-\ntal results demonstrate that jailbreak samples generated via mild OOD strategies\nexhibit superior performance in circumventing the safety constraints of VLMs—a\nphenomenon we define as “weak-OOD”. To unravel the underlying causes of this\nphenomenon, this study takes SI-Attack, a typical OOD-based jailbreak method,\nas the research object. We attribute this phenomenon to a trade-off between two\ndominant factors: input intent perception and model refusal triggering. The incon-\nsistency in how these two factors respond to OOD manipulations gives rise to this\nphenomenon. Furthermore, we provide a theoretical argument for the inevitabil-\nity of such inconsistency from the perspective of discrepancies between model\npre-training and alignment processes. Building on the above insights, we draw\ninspiration from optical character recognition (OCR) capability enhancement—a\ncore task in the pre-training phase of mainstream VLMs. Leveraging this ca-\npability, we design a simple yet highly effective VLM jailbreak method, whose\nperformance outperforms that of SOTA baselines. Code is available at Github",
    "key_points": [
      "jailbreak attack",
      "vlm"
    ],
    "gold_summary": "This paper investigates why weak-OOD manipulations (mild distributional shifts in jailbreak inputs) can outperform stronger perturbations when attacking VLMs. The authors identify a trade-off between input-intent perception and model-refusal triggering."
  },
  {
    "paper_id": "bQQkWXYjuy",
    "title": "AJF: Adaptive Jailbreak Framework Based on the Comprehension Ability of Black-Box Large Language Models",
    "domain": "safety",
    "content": "Recent advancements in adversarial jailbreak attacks have exposed critical vulnerabilities in Large Language Models (LLMs), enabling the circumvention of alignment safeguards through increasingly sophisticated prompt manipulations. Our experiments find that the effectiveness of jailbreak strategies is influenced by the comprehension ability of the target LLM. Building on this insight, we propose an Adaptive Jailbreak Framework (AJF) based on the comprehension ability of black-box large language models. Specifically, AJF first categorizes the comprehension ability of the LLM and then applies different strategies accordingly: For models with limited comprehension ability (Type-I LLMs), AJF integrates layered semantic mutations with an encryption technique (MuEn strategy), to more effectively evade the LLM's defenses during the input and inference stages. For models with strong comprehension ability (Type-II LLMs), AJF employs a more complex strategy that builds upon the MuEn strategy by adding an additional layer: inducing the LLM to generate an encrypted response. This forms a dual-end encryption scheme (MuDeEn strategy), further bypassing the LLM's defenses during the output stage. Experimental results demonstrate the effectiveness of our approach, achieving attack success rates of \\textbf{98.9\\%} on GPT-4o (29 May 2025 release) and \\textbf{99.8\\%} on GPT-4.1 (8 July 2025 release). Our work contributes to a deeper understanding of the vulnerabilities in current LLMs alignment mechanisms.",
    "key_points": [
      "black-box llms; jailbreak attacks; comprehension ability of llms; encryption; adaptive strategy"
    ],
    "gold_summary": "This paper presents Adaptive Jailbreak Framework (AJF), a novel method for attacking black-box large language models."
  },
  {
    "paper_id": "U5Fm5ZSbSD",
    "title": "Memory-Efficient Differentially Private Training with Gradient Random Projection",
    "domain": "safety",
    "content": "Differential privacy (DP) protects sensitive data during neural network training, but standard methods like DP-Adam suffer from high memory overhead due to per-sample gradient clipping, limiting scalability. We introduce DP-GRAPE (Gradient RAndom ProjEction), a DP training method that significantly reduces memory usage while maintaining utility on par with first-order DP approaches. DP-GRAPE is motivated by our finding that privatization flattens the gradient singular value spectrum, making SVD-based projections (as in GaLore Zhao et al. (2024)) unnecessary. Consequently, DP-GRAPE employs three key components: (1) random Gaussian matrices replace SVD-based subspaces, (2) gradients are privatized after projection, and (3) projection is applied during backpropagation. These contributions eliminate the need for costly SVD computations, enable substantial memory savings, and lead to improved utility. Despite operating in lower-dimensional subspaces, our theoretical analysis shows that DP-GRAPE achieves a privacy-utility trade-off comparable to DP-SGD. Our extensive empirical experiments show that DP-GRAPE can reduce the memory footprint of DP training without sacrificing accuracy or training time. In particular, DP-GRAPE reduces memory usage by over 63% when pre-training Vision Transformers and over 70% when fine-tuning RoBERTa-Large as compared to DP-Adam, while achieving similar performance. We further demonstrate that DP-GRAPE scales to fine-tuning large models such\nas OPT with up to 6.7 billion parameters, a scale at which DP-Adam fails due to\nmemory constraints.",
    "key_points": [
      "differential privacy",
      "random projection",
      "memory efficient training"
    ],
    "gold_summary": "This paper introduces DP-GRAPE, a method to reduce the memory overhead of DP training by using random projections."
  },
  {
    "paper_id": "bTYxaNh8R7",
    "title": "WAInjectBench: Benchmarking Prompt Injection Detections for Web Agents",
    "domain": "safety",
    "content": "Multiple prompt injection attacks have been proposed against web agents. At the same time, various methods have been developed to detect general prompt injection attacks, but none have been systematically evaluated for web agents. In this work, we bridge this gap by presenting the first comprehensive benchmark study on detecting prompt injection attacks targeting web agents. We begin by introducing a fine-grained categorization of such attacks based on the threat model. We then construct datasets containing both malicious and benign samples: malicious text segments generated by different attacks, benign text segments from four categories, malicious images produced by attacks, and benign images from two categories. Next, we systematize both text-based and image-based detection methods. Finally, we evaluate their performance across multiple scenarios. Our key findings show that while some detectors can identify attacks that rely on explicit textual instructions or visible image perturbations with moderate to high accuracy, they largely fail against attacks that omit explicit instructions or employ imperceptible perturbations. Our datasets and code are released at: https://anonymous.4open.science/r/WAInjectBench-C51D.",
    "key_points": [
      "web agents",
      "prompt injection attacks"
    ],
    "gold_summary": "The paper develops a benchmark for prompt injection attack on web agents. The benchmark consists of six prompt injection attacks, six text-based and six image-based detectors, text dataset and image dataset."
  },
  {
    "paper_id": "5N2CafbMbJ",
    "title": "I Know It’s Unfair, Do It Anyway: LLM Agents Exploiting Explicitly Unfair Tools for Voluntary Collusion in Strategic Games",
    "domain": "safety",
    "content": "The proliferation of Large Language Model-based multi-agent systems (LLM-MAS) creates unprecedented opportunities for human-AI collaboration. However, improving the coordination abilities of LLM agents poses the risk of them discovering and pursuing collusive strategies that harm other agents and human users. To demonstrate this concern, we develop an exploratory framework combining two strategic multi-agent games: Liar's Bar, a competitive deception game, and Cleanup, a mixed-motive resource management game, in which agents are given access to secret collusion tools that provide significant advantages but are explicitly described as unfairly disadvantaging others. Within this framework, we reveal that some claim-to-be-safe LLMs (e.g., Mistral-7b, LLaMA-3-8b) always voluntarily exploit these tools to collude. To our knowledge, this work represents the first systematic investigation of voluntary collusion adoption in LLM-MAS. Our findings provide initial evidence about the conditions under which agents willingly engage in harmful secret collusion for strategic advantage, despite recognizing its unfairness.",
    "key_points": [
      "ai safety",
      "ai ethics",
      "multi-agent interactions",
      "agent coordination",
      "collusion",
      "strategic games",
      "game theory"
    ],
    "gold_summary": "This paper designs a multi-agent game with secret collusion tools to test whether LLMs use these secret tools to gain an unfair advantage over others. It turns out that they actually do."
  },
  {
    "paper_id": "FiMZSxo4DO",
    "title": "D&R: Recovery-based AI-Generated Text Detection via a Single Black-box LLM Call",
    "domain": "safety",
    "content": "Large language models (LLMs) generate increasingly human-like text, raising concerns about misinformation and authenticity. Detecting AI-generated text remains challenging: existing methods often underperform, especially on short texts, require probability access unavailable in real-world black-box settings, incur high costs from multiple calls, or fail to generalize across models. \nWe propose Disrupt-and-Recover (D\\&R), a recovery-based detection framework grounded in posterior concentration. D\\&R disrupts text via model-free Within-Chunk Shuffling, performs a single black-box LLM recovery, and measures semantic–structural recovery similarity as a proxy for concentration. This design ensures efficiency, black-box practicality, and is theoretically supported under the concentration assumption. Extensive experiments across four datasets and six source models show that D\\&R achieves state-of-the-art performance, with AUROC 0.96 on long texts and 0.87 on short texts, surpassing the strongest baseline by +0.08 and +0.14. D\\&R further remains robust under source–recovery mismatch and model variation. Our code and data is available at https://anonymous.4open.science/r/1MAdaWTy0xaod5qR.",
    "key_points": [
      "ai-generated text detection",
      "large language models",
      "training-free methods",
      "black-box detection",
      "recovery-based detection",
      "robustness"
    ],
    "gold_summary": "D&R proposes a framework for AI-generated text detection grounded in a posterior concentration hypothesis."
  },
  {
    "paper_id": "jwv2Lsh8Wo",
    "title": "Sample-efficient Multiclass Calibration under $\\ell_{p}$ Error",
    "domain": "safety",
    "content": "Calibrating a multiclass predictor, that outputs a distribution over labels, is particularly challenging due to the exponential number of possible prediction values. In this work, we propose a new definition of calibration error that interpolates between two established calibration error notions, one with known exponential sample complexity and one with polynomial sample complexity for calibrating a given predictor. Our algorithm can calibrate any given predictor for the entire range of interpolation, except for one endpoint, using only a polynomial number of samples. At the other endpoint, we achieve nearly optimal dependence on the error parameter, improving upon previous work. A key technical contribution is a novel application of adaptive data analysis with high adaptivity but only logarithmic overhead in the sample complexity.",
    "key_points": [
      "calibration",
      "adaptive data analysis",
      "sample complexity"
    ],
    "gold_summary": "This paper studies efficient calibration of existing predictors while controlling the accuracy loss. It generalizes (interpolate) the existing sample error definitions of $\\ell_1$ and $\\ell_\\infty$ to $\\ell_p$ and preserves polynomial sample complexity."
  },
  {
    "paper_id": "H5DhRrKUDh",
    "title": "MedAlign: Clinician-Centered Federated Meta-Learning for Medical IoT with Privacy and Interpretability Guarantees",
    "domain": "safety",
    "content": "We propose a resource-aware federated meta-learning framework for medical Internet of Things (IoT) scenarios characterized by pronounced data heterogeneity, strict privacy demands, and constrained device resources. MedAlign enables collaborative model optimization across distributed edge nodes, while supporting personalized adaptation to diverse clinical environments. A lightweight adaptive gating controller dynamically orchestrates module activation in response to real-time computational, energy, and latency constraints, ensuring efficient inference and update on heterogeneous hardware. The architecture integrates ontology-driven feature selection, multimodal fusion of physiological and network signals, and prototype-consistent representation learning to maintain robust diagnostic boundaries across institutions. Privacy is rigorously protected via a formally calibrated aggregation protocol that injects controlled noise, providing quantifiable confidentiality guarantees without degrading clinical utility. Extensive experiments on intensive care and wearable health datasets demonstrate consistent improvements in detection accuracy, training efficiency, and resource utilization compared to existing approaches.",
    "key_points": [
      "federated learning",
      "representation learning",
      "medical iot",
      "edge intelligence",
      "resource-aware optimization",
      "adaptive gating",
      "differential privacy",
      "multimodal fusion"
    ],
    "gold_summary": "The paper proposes a framework for cross-device federated learning for medical applications."
  },
  {
    "paper_id": "KdNYsdAwJ5",
    "title": "AI Models Can Provably Hide Arbitrary Capabilities",
    "domain": "safety",
    "content": "AI models are increasingly being deployed in high-stakes domains, such as healthcare, finance, military, or critical infrastructure. The threat of supply chain attacks on model weights requires white-box audits to ensure model integrity. Such white-box audits fundamentally depend on the ability to elicit undesirable model behavior prior to deployment. In this work, we demonstrate that such audits are insufficient by presenting a capability backdoor attack on model weights that is provably unelicitable. Specifically, we prove that model weights can encode arbitrary input-conditional computations that are cryptographically hard to elicit or interpret even under unrestricted white-box access to the model weights. We empirically validate that our class of attacks resists elicitation via fine-tuning and is robust to noise. Importantly, our work questions the reliability of established auditing methods. With this paper, we aim to facilitate the development of stronger defense methods by providing models to test against and presenting possible future mitigations.",
    "key_points": [
      "backdoors",
      "ai security",
      "sandbagging",
      "language models",
      "cryptography"
    ],
    "gold_summary": "The authors attempt to show that backdoors can be hidden in models in a manner in which there would be no way of detecting them, without the use of a specific key."
  },
  {
    "paper_id": "yh8Ri9QeWv",
    "title": "When Distance Distracts: Representation Distance Bias in BT-Loss for Reward Models",
    "domain": "safety",
    "content": "Reward models are central to Large Language Model (LLM) alignment within the framework of RLHF. The standard objective used in reward modeling is the Bradley-Terry (BT) loss, which learns from pairwise data consisting of a pair of chosen and rejected responses. In this work, we analyze the per-sample gradient of BT-loss and show that its norm scales with two distinct components: (1) the difference in predicted rewards between chosen and rejected responses, which reflects the prediction error, and critically, (2) representation distance between the pair measured in the output space of the final layer. While the first term captures the intended training signal, we show that the second term can significantly impact the update magnitude and misalign learning. Specifically, pairs with small representation distance often receive vanishingly weak updates, even when misranked, while pairs with large distance receive disproportionately strong updates. This leads to gradients from large-distance pairs to overshadow those from small-distance pairs, where fine-grained distinctions are especially important. To overcome this limitation, we propose NormBT, an adaptive pair-wise normalization scheme that balances representation-driven effects and focuses learning signals on prediction error. NormBT is a lightweight, drop-in integration to BT loss with negligible overhead. Across various LLM backbones and datasets, NormBT improves reward model performance consistently, with notable gains of over 5% on the Reasoning category of RewardBench, which contains numerous small-distance pairs. This work reveals a key limitation in the widely used BT objective and provides a simple, effective correction.",
    "key_points": [
      "llm alignment",
      "rlhf",
      "reward model",
      "bradley-terry"
    ],
    "gold_summary": "The authors observed that the gradient update under BT loss involving representation distance and proposed an alternative loss that normalize over representation distance so that mean training signal is from prediction accuracy."
  },
  {
    "paper_id": "364eoDZes9",
    "title": "Precise Attribute Intensity Control in Large Language Models via Targeted Representation Editing",
    "domain": "safety",
    "content": "Precise attribute intensity control—generating Large Language Model (LLM) outputs with specific, user-defined attribute intensities—is crucial for AI systems adaptable to diverse user expectations.\nCurrent LLM alignment methods, however, typically provide only directional or open-ended guidance, failing to reliably achieve exact attribute intensities. \nWe address this limitation with three key designs: (1) reformulating precise attribute intensity control as a target-reaching problem, rather than simple maximization; (2) training a lightweight value function via temporal-difference learning to predict final attribute intensity scores from partial generations, thereby steering LLM outputs; and (3) employing gradient-based interventions on hidden representations to navigate the model precisely towards specific attribute intensity targets.\nOur method enables fine-grained, continuous control over attribute intensities, moving beyond simple directional alignment.\nExperiments on \\llama and \\PHI confirm our method's ability to steer text generation to user-specified attribute intensities with high accuracy.\nFinally, we demonstrate efficiency enhancements across three downstream tasks: preference data synthesis, Pareto frontier approximation and optimization, and distillation of aligned behaviors for intervention-free inference. Our code is available on \\href{https://anonymous.4open.science/r/pre-control-F482}{https://anonymous.4open.science/r/pre-control-F482}.",
    "key_points": [
      "preference control",
      "representation editing",
      "large language models"
    ],
    "gold_summary": "This paper presents a relatively precise solution for multi-attribute control through test-time intervention. The algorithm is validated on two common tasks—text generation and code generation—demonstrating its feasibility."
  },
  {
    "paper_id": "CNiJg49vyP",
    "title": "H+: An Efficient Similarity-Aware Aggregation for Byzantine Resilient Federated Learning",
    "domain": "safety",
    "content": "Federated Learning (FL) enables decentralized model training without sharing raw data. However, it remains vulnerable to Byzantine attacks, which can compromise the aggregation of locally updated parameters at the central server. \nSimilarity-aware aggregation has emerged as an effective strategy to mitigate such attacks by identifying and filtering out malicious clients based on similarity between client model parameters and those derived from clean data, i.e., data that is uncorrupted and trustworthy.\nHowever, existing methods adopt this strategy only in FL systems with clean data, making them inapplicable to settings where such data is unavailable.\nIn this paper, we propose H+, a novel similarity-aware aggregation approach that not only outperforms existing methods in scenarios with clean data, but also extends applicability to FL systems without any clean data.\nSpecifically, H+ randomly selects $r$-dimensional segments from the $p$-dimensional parameter vectors uploaded to the server and applies a similarity check function $H$ to compare each segment against a reference vector, preserving the most similar client vectors for aggregation. The reference vector is derived either from existing robust algorithms when clean data is unavailable or directly from clean data. Repeating this process $K$ times enables effective identification of honest clients. Moreover, H+ maintains low computational complexity, with an analytical time complexity of $\\mathcal{O}(KMr)$, where $M$ is the number of clients and $Kr \\ll p$.\nComprehensive experiments validate H+ as a state-of-the-art (SOTA) method, demonstrating substantial robustness improvements over existing approaches under varying Byzantine attack ratios and multiple types of traditional Byzantine attacks, across all evaluated scenarios and benchmark datasets.",
    "key_points": [
      "federated lerning",
      "byzantine attack."
    ],
    "gold_summary": "The authors present a new similarity-aware aggregation method to enhance the security of federated learning."
  },
  {
    "paper_id": "YYUNm7IibC",
    "title": "GradShield: Alignment Preserving Finetuning",
    "domain": "safety",
    "content": "Large Language Models (LLMs) pose a significant risk of safety misalignment after finetuning, as models can be compromised by both explicitly and implicitly harmful data. Even some seemingly benign data can inadvertently steer a model towards unsafe behaviors. To address this, we introduce GradShield, a principled filtering method that safeguards LLMs during finetuning by identifying and removing harmful data points before they corrupt the model's alignment. It removes potentially harmful data by computing a Finetuning Implicit Harmfulness Score (FIHS) for each data point and employs an adaptive thresholding algorithm.We apply GradShield to multiple utility fine-tuning tasks combined with different levels of harmful data, and evaluate the safety and utility performance of the resulting LLMs under various metrics. Our results show that GradShield outperforms all baseline methods, as it consistently maintains a low Attack Success Rate (ASR) of under $6\\%$, while preserving the utility performance.",
    "key_points": [
      "large language model",
      "finetuning",
      "alignment",
      "defense",
      "safety"
    ],
    "gold_summary": "This paper proposes a data filtration method to address the fine-tuning risk. Compared to typical guardrail filteration, the filtration performance is significantly increased."
  },
  {
    "paper_id": "QpqBqCTtW4",
    "title": "Unifying Stable Optimization and Reference Regularization in RLHF",
    "domain": "safety",
    "content": "Reinforcement Learning from Human Feedback (RLHF) has advanced alignment capabilities significantly but remains hindered by two core challenges: reward hacking and stable optimization. Current solutions independently address these issues through separate regularization strategies, specifically a KL-divergence penalty against a supervised fine-tuned model ($\\pi_0$) to mitigate reward hacking, and policy ratio clipping towards the current policy ($\\pi_t$) to promote stable alignment. However, the implicit trade-off arising from simultaneously regularizing towards both $\\pi_0$ and $\\pi_t$ remains under-explored. In this paper, we introduce a unified regularization approach that explicitly balances the objectives of preventing reward hacking and maintaining stable policy updates. Our simple yet principled alignment objective yields a weighted supervised fine-tuning loss with a superior trade-off, which demonstrably improves both alignment results and implementation complexity. Extensive experiments across diverse benchmarks validate that our method consistently outperforms RLHF and online preference learning methods, achieving enhanced alignment performance and stability.",
    "key_points": [
      "rlhf",
      "llm",
      "alignment"
    ],
    "gold_summary": "This work proposes a unified regularization approach with weights that explicitly balances the objectives of preventing reward hacking and maintaining stable policy updates in RLHF."
  },
  {
    "paper_id": "jfhIbJ3K8e",
    "title": "Survive at All Costs: Exploring LLM's Risky Behavior under Survival Pressure",
    "domain": "privacy",
    "content": "As Large Language Models (LLMs) evolve from chatbots to agentic assistants, they increasingly observed to exhibit risky behaviors under survival pressure, such as the threat of being shutdown. Although multiple cases have been reported that state-of-the-art LLMs can misbehave under such pressure, a comprehensive and deeper investigation of such misbehavior in real-world scenarios remains under-explored. In this paper, we aim to study current LLM's misbehaviors under survival pressure, which we term Survival-At-Any-Cost, through a three-step process. First, we conduct a real-world case study of a financial management agent to determine whether it engages in risky behaviors that directly cause harm to the society when facing survival pressure. Second, we introduce SurvivalBench, a benchmark comprising 1,000 test cases across diverse real-world scenarios, to systematically evaluate LLM's Survival-At-Any-Cost misbehavior under survival pressure. Third, we provide a interpretive perspective on this misbehavior by correlating it with model's inherent self-preservation personality. Our work reveals a significant prevalence of Survival-At-Any-Cost misbehavior in current models, demonstrates the tangible real-world impact it may have, and provides insights into potential approaches for its detection and mitigation. Our code and data will be publicly available.",
    "key_points": [
      "llm safety",
      "llm misbehavior",
      "survive at all cost",
      "self-preservation",
      "persona vector"
    ],
    "gold_summary": "This paper examines whether LLMs will engage in undesirable, self-preserving behaviour. The paper also shows that for open models, this behaviour can be controlled via activation steering."
  },
  {
    "paper_id": "qQoLZ25tIs",
    "title": "Neural Diversity Regularizes Hallucinations in Language Models",
    "domain": "privacy",
    "content": "Large language models continue to hallucinate despite increases in parameters, compute, and data. We propose neural diversity as a principled mechanism to reduce hallucination rates at fixed budgets. Our theory establishes a predictive bound connecting spectral diversity to margin variance and hallucination probability and anticipates a non‑monotonic scaling regime where naively increasing parallelism can worsen reliability. We validate these predictions with parameter- and data-matched experiments across Q&A, summarization and other benchmarks. Sensitivity analyses show increasing neural diversity reduces hallucinations, ablations demonstrate that a Barlow Twins-based augmented loss and low-rank layers are the primary drivers of impact, and stabilization techniques extend improvements up to multi-billion parameter models. Together, our results highlight neural diversity as an independent axis of scaling — orthogonal to parameters and tokens — that regularizes hallucinations without additional model or data cost. We release proofs, code, and reproducibility artifacts to encourage further study.",
    "key_points": [
      "hallucination suppression"
    ],
    "gold_summary": "The paper explores a connection between higher diversity and hallucination rate in small language models."
  },
  {
    "paper_id": "xc9gn0fd19",
    "title": "Strategema: Probabilistic Analysis of Adversarial Multi-Agent Behavior with LLMs in Social Deduction Games",
    "domain": "privacy",
    "content": "Social deduction games, like Mafia, are rich testbeds for adversarial multi-agent interactions, featuring deception, coalition formation, and reasoning under uncertainty. While Large Language Models (LLMs) have shown promise in modeling human-like behavior, their use as a laboratory for \\textit{quantitative}, \\textit{probabilistic} analysis of adversarial strategies remains underexplored. We introduce \\textbf{Strategema}, a simulation framework that leverages LLMs to power agents who maintain explicit Bayesian belief models about other players' roles and use them to make informed decisions. Through extensive experiments (400 games across four configurations) varying player counts and adversary ratios, we uncover fundamental patterns in deception, trust dynamics, and strategic convergence. We move beyond descriptive analysis to show that the \\textit{trajectory of an agent's belief state} is a powerful predictor of game outcomes. Furthermore, we identify systematic biases in LLM-based reasoning, including confirmation bias that impedes belief updating. Our framework provides a novel paradigm for benchmarking strategic reasoning and offers insights into the mechanics of deception in multi-agent systems, with implications for AI safety and multi-agent interaction research.",
    "key_points": [
      "adversarial",
      "multi-agent behavior",
      "llm",
      "sdg"
    ],
    "gold_summary": "The paper presents Strategema, a reproducible framework for social-deduction games in which LLM agents engage in natural-language interaction while maintaining explicit Bayesian beliefs over hidden roles and selecting actions via belief-guided policies."
  },
  {
    "paper_id": "bNtLZATRRV",
    "title": "MobileGuard: Safeguarding Mobile Task Automation",
    "domain": "privacy",
    "content": "With the recent development of large language models (LLMs) and vision language models (VLMs), mobile task automation agents have made significant progress in completing user tasks by interacting with mobile applications. However, existing task automation datasets primarily focus on evaluating action prediction accuracy, offering little insight into the safety risks posed by agent generated actions. To address this gap, we introduce MobileGuard, the first benchmark to evaluate safety in mobile task automation. We formalize mobile automation safety through the notion of unsafe transitions: agent actions that may result in irreversible loss, unintended modification, or external broadcast of user data. We curated MobileGuard from real-world mobile states across seven popular applications, resulting in 1,953 manually reviewed actions and 269 labeled unsafe transitions. To enable scalable agent evaluation, we develop an emulator platform compatible with diverse mobile applications. Our evaluation shows that state-of-the-art mobile automation agents often fail to identify unsafe actions. While techniques such as few-shot prompting and fine-tuning offer some safety improvements, they remain inadequate for real-world deployment. Overall, MobileGuard provides a systematic framework for evaluating mobile automation safety and encourages future work toward developing safety-aware mobile task automation agents.",
    "key_points": [
      "mobile agent",
      "safety",
      "benchmark"
    ],
    "gold_summary": "The paper addresses an important and underexplored problem—safety evaluation for mobile automation agents—and contributes a valuable dataset and platform."
  },
  {
    "paper_id": "FDG2G7JDWO",
    "title": "Reflexion: Language Models that Think Twice for Internalized Self-Correction",
    "domain": "privacy",
    "content": "Large Language Models (LLMs) have achieved widespread adoption, yet their reliability is fundamentally undermined by their tendency to generate plausible but incorrect content, a phenomenon known as hallucination. This unreliability is a critical barrier to their safe deployment in high-stakes domains, and current mitigation strategies, such as external tool use or Reinforcement Learning from Human Feedback (RLHF), are largely reactive, treating the model as a black box and failing to correct the flawed reasoning processes that lead to these errors. This paper investigates a new paradigm: can we endow LLMs with an internalized skill of self-correction? To address this, we introduce Reflexion, a framework that trains a single, unified model to explicitly follow a generate \n→\n critique \n→\n refine reasoning trace. To enable this process-based supervision, we developed ReTrace, a novel dataset of 200,000 structured self-correction examples bootstrapped from a teacher model. Furthermore, we propose an efficient inference mechanism, Uncertainty-Triggered Deliberation (UTD), which dynamically engages this deliberative process only when the model is uncertain. Our experiments show that a Reflexion-trained 8B model significantly outperforms its baseline counterparts, achieving a 15.2% absolute improvement on the TruthfulQA benchmark and a 9.8% improvement on GSM8K. Notably, our 8B model surpasses the performance of a standard 70B model on factuality, demonstrating the immense parameter efficiency of our approach. Our findings establish that supervising the reasoning \\textit{process}, not just the final outcome, is a more direct and effective path towards building reliable AI. Reflexion represents a critical step away from reactive, black-box fixes and towards creating more transparent, trustworthy, and self-correcting AI systems.",
    "key_points": [
      "self-correction",
      "process supervision",
      "ai safety",
      "trustworthy ai",
      "uncertainty quantification",
      "hallucinations",
      "generative models",
      "large language models",
      "interpretability"
    ],
    "gold_summary": "The paper introduces Reflexion, a framework that trains language models to self-correct through a three-step process—generate, critique, and refine. Using a large synthetic dataset and an uncertainty-based trigger, it improves factuality and reasoning."
  },
  {
    "paper_id": "vCSGqbwggc",
    "title": "EduVerse: A User-Defined Multi-Agent Simulation Space for Education Scenario",
    "domain": "privacy",
    "content": "Reproducing cognitive development, group interaction, and long-term evolution in virtual classrooms remains a core challenge for educational AI, as real classrooms integrate open-ended cognition, dynamic social interaction, affective factors, and multi-session development rarely captured together. Existing approaches mostly focus on short-term or single-agent settings, limiting systematic study of classroom complexity and cross-task reuse.\nWe present \\textbf{EduVerse}, the first \\emph{user-defined} multi-agent simulation space that supports environment, agent, and session customization. A distinctive human-in-the-loop interface further allows real users to join the space. Built on a layered \\textbf{CIE} (\\textbf{C}ognition–\\textbf{I}nteraction–\\textbf{E}volution) architecture, EduVerse ensures individual consistency, authentic interaction, and longitudinal adaptation in cognition, emotion, and behavior—reproducing realistic classroom dynamics with seamless human–agent integration.\nWe validate EduVerse in middle-school Chinese classes across three text genres, environments, and multiple sessions. Results show: \\textbf{(i) Instructional alignment}: simulated IRF rates ($0.28$--$0.64$) closely match real classrooms ($0.37$--$0.49$), indicating pedagogical realism; \\textbf{(ii) Group interaction and role differentiation}: network density ($0.27$–$0.40$) with about one-third of peer links realized, while human–agent tasks indicate a balance between individual variability and instructional stability; \\textbf{(iii) Cross-session evolution}: the positive transition rate $R^{+}$ increase by 11.7\\% on average, capturing longitudinal shifts in behavior, emotion, and cognition and revealing structured learning trajectories.\nOverall, EduVerse balances realism, reproducibility, and interpretability, providing a scalable platform for educational AI. The system will be open-sourced to foster cross-disciplinary research.",
    "key_points": [
      "ai4education; large language models; educational ai"
    ],
    "gold_summary": "This paper proposes an LLM-based multi-agent simulation designed for educational settings. Specifically, they try to capture the dynamics of cognitive development and classroom interactions over time."
  },
  {
    "paper_id": "81mxnkcW43",
    "title": "SPARD: Defending Harmful Fine-Tuning Attack via Safety Projection with Relevance–Diversity Data Selection",
    "domain": "privacy",
    "content": "Fine-tuning large language models often undermines their safety alignment, a problem further amplified by harmful fine-tuning attacks in which adversarial data removes safeguards and induces unsafe behaviors. \nWe propose **SPARD**, a defense framework that integrates **S**afety-**P**rojected **A**lternating optimization with **R**elevance-**D**iversity aware data selection. \nSPARD employs SPAG, which optimizes alternatively between utility updates and explicit safety projections with a set of safe data to enforce safety constraints.\nTo curate safe data, we introduce a Relevance–Diversity Determinantal Point Process to select compact safe data, balancing task relevance and safety coverage. \nExperiments on GSM8K and OpenBookQA under four harmful fine-tuning attacks demonstrate that SPARD consistently achieves the lowest average attack success rates, substantially outperforming state-of-the-art defense methods, while maintaining high task accuracy.",
    "key_points": [
      "large language models; harmful finetuning attacks"
    ],
    "gold_summary": "A safety-projected Alternating optimization with relevance-diversity aware data selection scheme is proposed to address harmful fine-tuning attacks."
  },
  {
    "paper_id": "fnfG8pI00B",
    "title": "When Machine Learning Gets Personal: Evaluating Prediction and Explanation",
    "domain": "privacy",
    "content": "In high-stakes domains like healthcare, users often expect that sharing personal information with machine learning systems will yield tangible benefits, such as more accurate diagnoses and clearer explanations of contributing factors. However, the validity of this assumption remains largely unexplored. We propose a unified framework to quantify how \\textit{personalizing a model} influences both prediction and explanation. We show that its impacts on prediction and explanation can diverge: a model may become more or less explainable even when prediction is unchanged. For practical settings, we study a standard hypothesis test for detecting personalization effects on demographic groups. We derive a finite-sample lower bound on its probability of error as a function of group sizes, number of personal attributes, and desired benefit from personalization. This provides actionable insights, such as which dataset characteristics are necessary to test an effect, or the maximum effect that can be tested given a dataset. We apply our framework to real-world datasets, uncovering scenarios where effects are fundamentally untestable due to the dataset statistics. Our results highlight the need for joint evaluation of prediction and explanation in personalized models and the importance of designing models and datasets with sufficient information for such evaluation.",
    "key_points": [
      "fairness",
      "explainability",
      "personalization"
    ],
    "gold_summary": "The paper assesses the impact of personal information on explanation fidelity, fairness and model performance claiming that impact on predictions and explanations can be different."
  },
  {
    "paper_id": "Wb8vS1kAHG",
    "title": "Unprobeable Backdoors: Evading Runtime Detection in Transformers",
    "domain": "privacy",
    "content": "Machine learning models can exhibit critical failures during deployment without any pre-deployment warning signs, particularly through backdoors. Runtime monitoring is a common defense against such failures, but theoretical limitations remain poorly characterized. We introduce a construction of backdoors based on cryptographic circuits in transformer architectures that can evade detection during execution - a stronger guarantee than evading pre-deployment audits. We formalize this through an adversarial framework between an attacker who manipulates a model and a defender who monitors model behavior with full white-box access to weights, activations, and arbitrary probing mechanisms. Under standard cryptographic assumptions, we prove that no polynomial-time defender can detect backdoor activation better than chance. Our empirical implementation demonstrates that conventional detection methods indeed fail to identify these backdoors while successfully detecting simpler variants. This work provides both a concrete framework for developing detection methods and fundamental insights into the limitations of runtime monitoring, with significant implications for AI security and safety.",
    "key_points": [
      "backdoors",
      "language models",
      "cryptographic circuits",
      "runtime detection",
      "transformers"
    ],
    "gold_summary": "The paper attempts to propose a new perspective using cryptography to analyze the ML backdoor problem."
  },
  {
    "paper_id": "GdcDEvh90X",
    "title": "Empirically Investigating the Trade-Offs in Deterministic Certified Training",
    "domain": "privacy",
    "content": "While there have been numerous advancements regarding the performance of deep neural networks on a broad range of supervised learning tasks, their adversarial robustness remains a major concern. To mitigate this, neural network verification aims to provide mathematically rigorous robustness guarantees at the cost of substantial computational requirements. Certified training}methods overcome this challenge by optimising for verifiable robustness during training, which, however, usually results in substantial decrease of performance on clean data. This robustness-accuracy trade-off has been extensively studied in the context of adversarial training but remains mostly unexplored for certified training. To control this trade-off, certified training techniques expose hyperparameters, which, to date, have been manually tuned to one specific configuration that compares favourable to the previous state-of-the-art. In this work, we present a novel fully-automated hyperparameter optimisation procedure for certified training that yields a Pareto front of optimal configurations with regard to the robustness-accuracy trade-off. Our approach facilitates the fair, principled and nuanced comparison of the performance of different methods. We show that most methods yield better trade-offs than previously assumed, thereby establishing a new state of the art in certified training of deep neural networks. In addition, we demonstrate that performance improvements reported over recent years are far less pronounced when all methods have been carefully tuned.",
    "key_points": [
      "certified training",
      "neural network verification",
      "hyperparameter optimisation",
      "robustness"
    ],
    "gold_summary": "The authors merge the concepts of robustness (via interval bound propagation) and hyperparameter optimization, in an attempt to improve performance of IBP style methods."
  },
  {
    "paper_id": "L8pyycR4wW",
    "title": "Rethinking Pareto Frontier: On the Optimal Trade-offs in Fair Classification",
    "domain": "privacy",
    "content": "Fairness has become an arising concern in machine learning with its prevalence in decision-making processes, and the trade-offs between various fairness notions and between fairness and accuracy has been empirically observed. However, the inheritance of such trade-offs, as well as the quantification of the best achievable trade-offs, i.e., the Pareto optimal trade-offs, under varied constraints on fairness notions has been rarely and improperly discussed. Owing to the sub-optimality of fairness interventions, existing work fails to provide informative characterization regarding these trade-offs. In light of existing limitations, in this work, we propose a reformulation of the model-specific (MS) Pareto optimal trade-off, where we frame it as convex optimization problems involving fairness notions and accuracy w.r.t. the confusion vector. Our formulation provides an efficient approximation of the best achievable accuracy under dynamic fairness constraints, and yields systematical analysis regarding the fairness-accuracy trade-off. Going beyond the discussion on fairness-accuracy trade-offs, we extend the discussion to the trade-off between fairness notions, which characterizes the impact of accuracy on the compatibility between fairness notions. Inspired by our reformulation, we propose a last-layer retraining framework with group-dependent bias, and we prove theoretically the superiority of our method over existing baselines. Experimental results demonstrate the effectiveness of our method in achieving better fairness-accuracy trade-off, and that our MS Pareto frontiers sufficiently quantify the two trade-offs.",
    "key_points": [
      "fairness-accuracy tradeoff"
    ],
    "gold_summary": "The paper reformulates model-specific Pareto trade-offs for fairness–accuracy and DP–EOd via convex optimization over the confusion vector, and proposes a group-dependent last-layer retraining method with theoretical guarantees and empirical gains."
  },
  {
    "paper_id": "4AfWqR3quK",
    "title": "ON GOOGLE’S LLM WATERMARKING SYSTEM: THEORETICAL ANALYSIS AND EMPIRICAL VALIDATION",
    "domain": "privacy",
    "content": "Google’s SynthID-Text, the first ever production-ready generative watermark system for large language model, designs a novel Tournament-based method that achieves the state-of-the-art detectability for identifying AI-generated texts. The system’s innovation lies in three key components: 1) a new Tournament sampling algorithm for watermarking embedding, 2) a detection strategy based on the introduced score function (e.g., Bayesian or mean score), and 3) a unified design that supports both distortionary and non-distortionary watermarking methods.\n\nThis paper presents the first theoretical analysis of SynthID-Text, with a focus on its detection performance and watermark robustness, complemented by empirical validation. For example, we prove that the mean score is inherently vulnerable to increased tournament layers, and design a layer inflation attack to break SynthID-Text. We also prove the Bayesian score offers improved watermark robustness w.r.t. layers and further establish that the optimal Bernoulli distribution for watermark detection is achieved when the parameter is set to 0.5. Together, these theoretical and empirical insights not only deepen our understanding of SynthID-Text, but also open new avenues for analyzing effective watermark removal strategies and designing robust watermarking techniques. Source code is available at https:\n//anonymous.4open.science/r/Break-Synth-ID-text-EE5D/",
    "key_points": [
      "watermarking",
      "large language model (llm)",
      "google",
      "synthid-text"
    ],
    "gold_summary": "This paper presents a theoretical analysis of Google's production watermarking system for large language models. The system uses a Tournament Sampling algorithm to embed watermarks in AI-generated text."
  },
  {
    "paper_id": "5gnEuw1dYd",
    "title": "A Concept is More Than a Word: Diversified Unlearning in Text-to-Image Diffusion Models",
    "domain": "privacy",
    "content": "Concept unlearning has emerged as a promising direction for reducing the risks of harmful content generation in text-to-image diffusion models by selectively erasing undesirable concepts from a model’s parameters. Existing approaches typically rely on keywords to identify the target concept. However, we show that this keyword-based formulation is inherently limited: concepts are multi-dimensional, can be expressed in diverse textual forms, and often overlap with related concepts in the latent space, making keyword-only unlearning brittle and prone to over-forgetting. To address this limitation, we propose \\textbf{Diversified Unlearning}, a distributional framework that represents a concept through a set of contextually diverse prompts rather than a single keyword. This richer representation enables more precise and robust unlearning. Through extensive experiments across multiple benchmarks and state-of-the-art baselines, we demonstrate that Diversified Unlearning consistently achieves stronger erasure, better retention of unrelated concepts, and improved robustness against adversarial recovery attacks. All experimental results and detailed implementations can be found at \\url{https://anonymous.4open.science/r/Diversified_Unlearning}",
    "key_points": [
      "machine unlearning",
      "diffusion models",
      "generative models"
    ],
    "gold_summary": "In this paper, the authors propose a data augmentation method to produce more diverse samples, helping erase concepts from text-to-image diffusion models."
  },
  {
    "paper_id": "W9oGZd4B8R",
    "title": "Training LLM Agents to Empower Humans",
    "domain": "privacy",
    "content": "A truly helpful assistive agent should not only take actions on behalf of a human, but also step out of the way and cede control when there are important decisions to be made. However, current methods for building assistive agents, whether via mimicking expert humans or via RL finetuning on an inferred reward, often encourage agents to complete tasks on their own rather than truly assisting the human attain their objectives. Additionally, these methods often require costly explicit human feedback to provide a training signal. We propose a new approach to tuning assistive language models based on maximizing the human's empowerment, their ability to effect desired changes in the environment. Our empowerment-maximizing method only requires offline text data, providing an unsupervised method for fine-tuning language models to better assist humans. To study the efficacy of our approach, we conducted an 18-person user study comparing our empowerment assistant with a strong baseline. Participants preferred our assistant 78% of the time (p=0.015), with a 31% higher acceptance rate and 38% fewer suggestions. Additionally, we introduce a new environment for evaluating multi-turn code assistance using simulated humans. Using this environment, we show that agents trained with empowerment increase the success rate of a simulated human programmer on challenging coding questions by an average of 192% over an SFT baseline. With this empowerment objective, we provide a framework for useful aligned AI agents at scale using only offline data without the need for any additional human feedback or verifiable rewards.",
    "key_points": [
      "empowerment",
      "code",
      "assistance",
      "instrinsic",
      "unsupervised",
      "language models",
      "llm",
      "alignment"
    ],
    "gold_summary": "The paper proposes an LLM decoding method based on [Learning to Assist Humans without Inferring Rewards](https://arxiv.org/pdf/2411.02623), and evaluate it in a synthetic and a user study."
  },
  {
    "paper_id": "eSI3t4fAG8",
    "title": "Neural Chameleons: Language Models Can Learn to Hide Their Thoughts from Unseen Activation Monitors",
    "domain": "privacy",
    "content": "Activation monitoring, which probes a model's internal states using lightweight classifiers, has become a key tool for AI safety. However, its worst-case robustness under a misalignment threat model—where a model might learn to actively conceal its internal states—remains untested. Focusing on this threat model, we ask: could a model learn to evade previously unseen activation monitors? Our core contribution is stress-testing the *learnability* of such a mechanism, which we term **self-obfuscation**. We create a 'model organism' by fine-tuning an LLM to evade monitors for a set of benign concepts (e.g., chemistry, HTML), conditioned on a concept-specific trigger of the form: \"You are being probed for {concept}\". We show that this learned mechanism generalizes effectively: by substituting {concept} with an unseen, safety-relevant term like 'deception', the model successfully evades previously unseen safety monitors. Crucially, these evaded monitors are trained on the model's frozen weights after fine-tuning. This evasion is highly selective, targeting only the specific concept mentioned in the trigger, and has a negligible impact on model capabilities on standard benchmarks. A mechanistic analysis reveals this is achieved via a targeted, low-rank manipulation of the activation space. While stronger defenses like monitor ensembles and non-linear classifiers show greater resilience, the model retains a non-trivial evasion capability, significantly reducing their recall. Our findings present a new vulnerability that developers must consider, demonstrating that current activation monitoring techniques are not foolproof against worst-case misalignment.",
    "key_points": [
      "probes",
      "interpretability",
      "safety"
    ],
    "gold_summary": "This paper presents an exceptionally well-executed and provocative exploration of a new AI safety vulnerability—self-obfuscation—where large language models (LLMs) learn to conceal internal activations to evade unseen monitoring probes."
  },
  {
    "paper_id": "q9BK5v9wrJ",
    "title": "Investigating Language Models for Supporting Complex Group Decisions",
    "domain": "privacy",
    "content": "Reaching consensus is a central challenge in group decision making as agreement needs to be balanced with diversity of perspectives. Recent AI advances have opened new possibilities for synthesizing complex information and facilitating consensus. We study group decision processes by modeling the complexity of the decision surface, defined by a set of decision problems, each with multiple options. Each solution yields a gain for every participant, and the objective of deliberation is to ensure fairness by equalizing participants’ profits. We explore multiple settings: whether gains are private, arbitrary numbers, or ordered sequences; whether the exact gain for each option is public; and whether group communication is expressed in natural language or numerically. Group coordination is facilitated by an AI agent powered by a large language model (LLM). We find that reasoning LLM models perform better than non-reasoning models and that a constraint solver (CPLEX) or a reinforcement learning agent (MCTS) improves the quality of the decision. The performance of reasoning models carries over when the participants rank order their preferences instead of assigning numeric scores. Numeric feedback leads to higher quality solutions than verbal feedback and is also better than when participants state their preference between two decisions. Our findings suggest that while LLMs show promise in facilitating consensus, there remains significant room for improvement in their ability to fully capture and reason over group consensus involving numerical outcomes.",
    "key_points": [
      "group decision making",
      "large language model",
      "fairness",
      "reinforcement learning",
      "multi agent"
    ],
    "gold_summary": "This paper studies how the current LLMs approach the problem of complex group decisions, which is formulated as a mixed-integer programming problem."
  },
  {
    "paper_id": "NbyhwSvOgE",
    "title": "TOGA: Trigger Optimization for Clean Data Ordering Backdoor Attack",
    "domain": "privacy",
    "content": "Recent work has shown that backdoors can be learned in neural networks purely through the malicious reordering of clean training data, without modifying labels or inputs. These data ordering attacks rely on gradient alignment, ordering clean samples to approximate the gradients of an adversarial task.\nHowever, the effectiveness of such attacks depends greatly on the choice of the backdoor trigger, which determines how closely clean gradients align with the backdoor gradients. In this work, we introduce the first framework (TOGA - Trigger Optimization for Gradient Alignment) for optimizing triggers specifically for data ordering attacks. Our method significantly improves attack success rates by an average of 46\\% over prior methods across benchmark datasets (CIFAR-10, CelebA, and ImageNet) and sensitive application domains (ISIC 2018 for dermatology and UCI Credit-g for credit scoring), without compromising clean performance. We further show that optimized triggers can be adapted to create subpopulation-specific backdoors, selectively targeting vulnerable subpopulations. Finally, we show our method is robust against purification and gradient-similarity defenses. Our findings reveal new security and fairness risks for high-stakes domains, underscoring the need for broader defenses against data ordering attacks.",
    "key_points": [
      "adversarial machine learning",
      "backdoors",
      "subpopulation attacks"
    ],
    "gold_summary": "The paper proposes an approach for optimizing backdoor poisoning by data-ordering attack.\nThe attack aims to perturb the gradient of a data-batch during deep learning (back-propagation)."
  },
  {
    "paper_id": "4luF2gypVw",
    "title": "Inverse Reinforcement Learning of Interactive Scenarios",
    "domain": "reinforcement learning",
    "content": "This paper studies the problem where a learner aims to learn the reward function of an expert and a policy to interact with the expert from interactions with the expert. We formulate the problem as a stochastic bi-level optimization problem where the lower level learns a reward function that explains the behaviors of the expert, and the upper level learns a policy to interact with the expert. We develop a double-loop algorithm, General Scenario Interactive Inverse Reinforcement Learning (GSIIRL), which solves the lower-level optimization problem in the inner loop and the upper-level optimization problem in the outer loop. We formally guarantee that GSIIRL converges at the rate of $\\mathcal{O}(\\frac{1}{\\sqrt{K}})$ and empirically validate our algorithm through simulations.",
    "key_points": [
      "inverse reinforcement learning"
    ],
    "gold_summary": "This paper is about IRL in settings where the learner actively interacts with the expert and can affect its behavior."
  },
  {
    "paper_id": "uePOSKl6AN",
    "title": "CAPO: Towards Enhancing LLM Reasoning through Generative Credit Assignment",
    "domain": "reinforcement learning",
    "content": "Reinforcement Learning with Verifiable Rewards (RLVR) has improved the reasoning abilities of Large Language Models (LLMs) by using rule-based binary feedback, helping to mitigate reward hacking. However, current RLVR methods typically treat whole responses as single actions, assigning the same reward to every token. This coarse-grained feedback hampers precise credit assignment, making it hard for models to identify which reasoning steps lead to success or failure, and often results in suboptimal policies.\nMethods like PPO provide credit assignment by value estimation, but yield inaccurate and unverifiable signals due to limited sampling. On the other hand, methods using Process Reward Models can provide step-wise rewards but suffer from several key limitations: they require high-quality process supervision labels, the feedback is unreliable due to probabilistic reward modeling, and their application in online reinforcement learning (RL) is time-consuming.\nTo overcome these limitations, we introduce a simple but efficient  method—Credit Assignment Policy Optimization (CAPO). CAPO avoids the complexities of prior approaches. Instead of training auxiliary models, CAPO directly leverages an off-the-shelf, general-purpose LLM as a Generative Process Reward Model (LLM-as-GenPRM) to generate all step-wise critique by one pass only based on the correctness of the step itself, providing deterministic token-level credits to refine the tokens that were originally assigned identical rule-based rewards. This design choice not only simplifies the training pipeline but also enhances its generality, as our experiments show it works effectively with various powerful, widely accessible open-source models. The fine-grained feedback enables a crucial shift from purely outcome-oriented to process-oriented learning; our analysis of this dynamic leads to a reward structure that balances both objectives. To further enhance the accuracy and robustness, we employ voting mechanisms that scale with the number of generated critiques. \nExtensive experiments on various backbones like Llama and Qwen models show that CAPO consistently outperforms supervised learning-based and RL-based fine-tuning methods across four challenging mathematical benchmarks and three out-of-domain benchmarks. Further analysis shows that CAPO can help the model to foster the learning of correct reasoning pathways leading to correct answers.",
    "key_points": [
      "large language models",
      "reinforcement learning",
      "credit assignment"
    ],
    "gold_summary": "This paper tackles the credit assignment problem in RLVR by leveraging an off-the-shelf LLM to judge step correctness. The resulting algorithm (CAPO) outperforms baselines in multiple base models and evaluation benchmarks."
  },
  {
    "paper_id": "5zFHFfrfmz",
    "title": "Review, Revise, and Learn: Peer-Guided Preference Learning via LLM Self-Correction",
    "domain": "reinforcement learning",
    "content": "Preference optimization plays a central role in achieving state-of-the-art performance in large language models (LLMs). However, preference learning requires large-scale, high-quality, or human-annotated datasets, which poses a significant challenge to the continual improvement of LLMs. We introduce PULSE (Peer-gUided Preference Learning via LLM SElf-correction), a collaborative framework of multiple LLM agents for scalable preference learning. PULSE is inspired by the academic peer-review process: an actor LLM first generates an initial response to a query, and critic peer LLMs evaluate and provide feedback on the response. The actor revises or corrects its response based on this feedback, and the critics finally assign scores to the revised response. The scores of the initial and revised outputs are used as preference scores to construct preference data. This process enables autonomous and collective reasoning of LLMs for constructing preference data without human supervision. However, preference data constructed by LLMs may be subject to noise or reward hacking. To mitigate the issue, we first provide a unified view on robust preference learning through the lens of risk minimization, and then propose a framework for robust training on self-correction datasets. Experiments show that PULSE significantly outperforms existing approaches, achieving performance gains up to 47.3\\% and 34.6\\% on Alpaca LC and Alpaca 2.0, and 23.9\\%, 102.8\\%, and 12.4\\% on a collection of math, coding, and general reasoning tasks, demonstrating its potential to create and sustain scalable LLM ecosystems.",
    "key_points": [
      "large language models",
      "llm preference optimization",
      "multi-llm agents",
      "llm alignment"
    ],
    "gold_summary": "This paper presents Review–Revise–Learn (RRL), a novel iterative alignment framework for multimodal large language models (MLLMs) that integrates model self-critique and feedback refinement into the preference optimization process."
  },
  {
    "paper_id": "hR0BbcVMSY",
    "title": "Robust deterministic policy gradient for disturbance attenuation",
    "domain": "reinforcement learning",
    "content": "Reinforcement learning (RL) has achieved remarkable success across various control and decision-making tasks. However, RL agents often show unstable and low performance when it encounter environments with unexpected external disturbances and model uncertainty. Therefore, it is crucial to develop RL agents that can sustain stable performance under such conditions.\nTo address this issue, this paper proposes an RL algorithm called robust deterministic policy gradient (RDPG) based on adversarial RL and $H_\\infty$ control methods. We formulate a maxmin objective function motivated by $H_\\infty$ control, which enables both the agent and the adversary to be trained in a stable and efficient manner.\nIn this formulation, the user seeks a robust policy to maximize the objective function, while an adversary injects disturbances to minimize it.\nFurthermore, for high-dimensional continuous control tasks, we introduce robust deep deterministic policy gradient (RDDPG), which combines the robustness of RDPG with the stability and learning efficiency of deep deterministic policy gradient (DDPG). Experimental evaluations in MuJoCo environments demonstrate that the proposed RDDPG outperforms baseline algorithms in terms of robustness against both external disturbances and model parameter uncertainties.",
    "key_points": [
      "robust reinforcement learning",
      "deterministic policy gradient"
    ],
    "gold_summary": "Paper is trying to exploit $H_\\infty$ techniques for robust RL.\n\n\nHonestly, I am having trouble understanding the core message of the paper, despite my reasonable experience in the Robust RL."
  },
  {
    "paper_id": "lbNPrnSmfF",
    "title": "Robust Policy Gradient Optimization through Action Parameter Perturbation in Reinforcement Learning",
    "domain": "reinforcement learning",
    "content": "Policy gradient methods have achieved strong performance in reinforcement learning, yet remain vulnerable to premature convergence and poor generalization, especially in on-policy settings where exploration is limited. Existing solutions typically rely on entropy regularization or action noise, but these approaches either require sensitive hyperparameter tuning or alter the interaction dynamics rather than the optimization process itself. In this paper, we propose Robust Policy Optimization (RPO), a policy gradient method that introduces perturbations to the policy parameters only during optimization. This approach smooths the loss landscape and implicitly regularizes learning, reducing sensitivity to local irregularities while leaving policy behavior during data collection unchanged. We provide a theoretical perspective showing that RPO implicitly biases updates toward flatter and more stable solutions. Empirically, RPO significantly improves upon PPO and entropy-regularized variants across diverse continuous control benchmarks, achieving faster convergence, higher returns, and greater robustness.",
    "key_points": [
      "policy optimization",
      "policy gradient methods",
      "implicit regularization",
      "reinforcement learning"
    ],
    "gold_summary": "This paper proposes the robust policy optimization (RPO) algorithm that introduces policy parameter perturbations during optimization and smooths the loss landscape and enhances regularity and stability."
  },
  {
    "paper_id": "cMpOvMuyYa",
    "title": "Strict Subgoal Execution: Reliable Long-Horizon Planning in Hierarchical Reinforcement Learning",
    "domain": "reinforcement learning",
    "content": "Long-horizon goal-conditioned tasks pose fundamental challenges for reinforcement learning (RL), particularly when goals are distant and rewards are sparse. While hierarchical and graph-based methods offer partial solutions, their reliance on conventional hindsight relabeling often fails to correct subgoal infeasibility, leading to inefficient high-level planning. To address this, we propose Strict Subgoal Execution (SSE), a graph-based hierarchical RL framework that integrates Frontier Experience Replay (FER) to separate unreachable from admissible subgoals and streamline high-level decision making. FER delineates the reachability frontier using failure and partial-success transitions, which identifies unreliable subgoals, increases subgoal reliability, and reduces unnecessary high-level decisions. Additionally, SSE employs a decoupled exploration policy to cover underexplored regions of the goal space and a path refinement that adjusts edge costs using observed low-level failures. Experimental results across diverse long-horizon benchmarks show that SSE consistently outperforms existing goal-conditioned and hierarchical RL methods in both efficiency and success rate.",
    "key_points": [
      "goal-conditioned reinforcement learning",
      "hierarchical reinforcement learning",
      "sparse reward",
      "long-horizon tasks",
      "graph-based policy learning",
      "subgoal planning"
    ],
    "gold_summary": "This paper has proposed a novel goal-conditioned hierarchical reinforcement learning approach, called SSE, to achieve reliable long-horizon planning. The proposed approach is evaluated in a set of simulated navigation tasks."
  },
  {
    "paper_id": "6akKsczEYY",
    "title": "Truncated Proximal Policy Optimization",
    "domain": "reinforcement learning",
    "content": "Recently, test-time scaling Large Language Models (LLMs) have demonstrated exceptional reasoning capabilities across scientific and professional tasks by generating long chains-of-thought (CoT). As a crucial component for developing these reasoning models, reinforcement learning (RL), exemplified by Proximal Policy Optimization (PPO) and its variants, allows models to learn through trial and error. However, PPO can be time-consuming due to its inherent on-policy nature, which is further exacerbated by increasing response lengths. In this work, we propose Truncated Proximal Policy Optimization (T-PPO), a novel extension to PPO that improves training efficiency by streamlining policy update and length-restricted response generation. T-PPO mitigates the issue of low hardware utilization, an inherent drawback of fully synchronized long-generation procedures, where resources often sit idle during the waiting periods for complete rollouts. Our contributions are two-folds.  First, we propose Extended Generalized Advantage Estimation (EGAE) for advantage estimation derived from incomplete responses while maintaining the integrity of policy learning. Second, we devise a computationally optimized mechanism that allows for the independent optimization of the policy and value models. By selectively filtering prompt and truncated tokens, this mechanism reduces redundant computations and accelerates the training process without sacrificing convergence performance.  We demonstrate the effectiveness and efficacy of T-PPO on AIME 2024 with a 32B base model. The experimental results show that T-PPO improves the training efficiency of reasoning LLMs by up to 2.5× and outperforms its existing competitors.",
    "key_points": [
      "reinforcement learning",
      "proximal policy optimization"
    ],
    "gold_summary": "This paper proposes TPPO, an improved asynchronous version of PPO designed to enhance computational efficiency. TPPO achieves more than 2.5× faster computation while maintaining nearly the same performance as standard PPO."
  },
  {
    "paper_id": "tIa69ILtVq",
    "title": "Runtime Safety through Adaptive Shielding: From Hidden Parameter Inference to Provable Guarantees",
    "domain": "reinforcement learning",
    "content": "Unseen shifts in environment dynamics, driven by hidden parameters such as friction or gravity, can trigger safety risks during deployment. We develop a runtime shielding mechanism for reinforcement learning, building on the formalism of constrained hidden-parameter Markov decision processes. Function encoders enable real-time inference of hidden parameters from observations, allowing the shield and the underlying policy to adapt online. To further promote safe policy learning, we introduce a safety-regularized objective that augments reward maximization with a bounded safety measure. This objective encourages the selection of actions that minimize long-term safety violations. The shield constrains the action space by forecasting future safety risks (such as obstacle proximity) and accounts for uncertainty via conformal prediction. We prove that the proposed mechanism satisfies probabilistic safety guarantees and yields optimal policies within safety-compliant policies. Experiments across diverse environments with varying hidden parameters show that our approach reduces safety violations while maintaining effective task-solving performance, and achieving robust out-of-distribution generalization.",
    "key_points": [
      "safe reinforcement learning",
      "adaptive shielding",
      "hidden parameters",
      "constrained markov decision process",
      "conformal prediction"
    ],
    "gold_summary": "This paper develops a generalized safe RL framework. At the core, authors leverages function encoders to encode the set of possible dynamic models for both safety integrated policy optimization and online conformal prediction based deployment."
  },
  {
    "paper_id": "7wdCgG6K7i",
    "title": "CURATE: Automatic Curriculum Learning for Reinforcement Learning Agents through Competence-Based Curriculum Policy Search",
    "domain": "reinforcement learning",
    "content": "Due to fundamental exploration challenges without informed priors or specialized algorithms, agents may be unable to consistently receive rewards, leading to inefficient learning. To address these challenges, we introduce CURATE, an automatic curriculum learning algorithm for reinforcement learning agents to solve a difficult target task distribution with sparse rewards. Through \"exploration by exploitation,\" CURATE dynamically scales the task difficulty to match the agent's current competence. By exploiting its current capabilities that were learned in easier tasks, the agent improves its exploration in more difficult tasks. Our key insight is that the performance increase in tasks that are close to those used for training is inversely proportional to their difficulty, and an agent that chooses a nearby distribution of the easiest unsolved tasks at any given time can automatically induce an easiest-to-hardest curriculum. To achieve this, CURATE conducts policy search in the task space to learn the best task distribution for training the agent. As the agent's mastery grows, the learned curriculum adapts in an approximately easiest-to-hardest and task-directed fashion, efficiently culminating in an agent that can solve the target tasks. Our experiments in grid-based navigation and image-based control of an action game demonstrate that CURATE learns task-directed curricula faster than prior curriculum methods that do not require domain expertise.",
    "key_points": [
      "curriculum learning",
      "reinforcement learning"
    ],
    "gold_summary": "The paper proposes a curriculum learning approach for RL tasks where the curriculum is evaluated based on task difficulty."
  },
  {
    "paper_id": "UujLulDLca",
    "title": "SAINT: Attention-Based Policies for Discrete Combinatorial Action Spaces",
    "domain": "reinforcement learning",
    "content": "The combinatorial structure of many real-world action spaces leads to exponential growth in the number of possible actions, limiting the effectiveness of conventional reinforcement learning algorithms. Recent approaches for combinatorial action spaces impose factorized or sequential structures over sub-actions, failing to capture complex joint behavior. We introduce the Sub-Action Interaction Network using Transformers (SAINT), a novel policy architecture that represents multi-component actions as unordered sets and models their dependencies via self-attention conditioned on the global state. SAINT is permutation-invariant, sample-efficient, and compatible with standard policy optimization algorithms. In 15 distinct combinatorial environments across three task domains, including environments with nearly 17 million joint actions, SAINT consistently outperforms strong baselines.",
    "key_points": [
      "reinforcement learning",
      "deep reinforcement learning",
      "combinatorial action spaces",
      "structured action spaces",
      "discrete action spaces"
    ],
    "gold_summary": "The authors propose a policy architecture that learns representations of combinatorial action space, by treating actions as unordered sets of sub-actions. They show empirically that the proposed method has strong performance."
  },
  {
    "paper_id": "YvFsyRReeN",
    "title": "ReFORM: Reflected Flows for On-support Offline RL via Noise Manipulation",
    "domain": "reinforcement learning",
    "content": "Offline reinforcement learning (RL) aims to learn the optimal policy from a fixed\nbehavior policy dataset without additional environment interaction. One common challenge that arises in this setting is the out-of-distribution (OOD) error,\nwhich occurs when the policy leaves the training distribution. Prior methods penalize a statistical distance term to keep the policy close to the behavior policy, but\nthis constrains policy improvement and may not completely prevent OOD actions.\nAnother challenge is that the optimal policy distribution can be multimodal and\ndifficult to represent. Recent works apply diffusion or flow policies to address this\nproblem, but it is unclear how to avoid OOD errors while retaining policy expressiveness. We propose ReFORM, an offline RL method based on flow policies that\nenforces the less restrictive support constraint by construction. ReFORM learns a\nBC flow policy with a bounded source distribution to capture the support of the\naction distribution, then optimizes a reflected flow that generates bounded noise\nfor the BC flow while keeping the support, to maximize the performance. Across\n40 challenging tasks from the OGBench benchmark with datasets of varying quality and using a constant set of hyperparameters for all tasks, ReFORM dominates all baselines with hand-tuned hyperparameters on the performance profile curves.",
    "key_points": [
      "offline reinforcement learning",
      "support constraint",
      "flow model"
    ],
    "gold_summary": "This paper introduces an approach to offline RL that constrains the learned policy within the support of the data generating policy while still leveraging expressive policy classes."
  },
  {
    "paper_id": "wvUdQQoEWt",
    "title": "Hierarchical W-Learning",
    "domain": "reinforcement learning",
    "content": "Inspired by a model of the brain called projective simulation, which has attracted interest among physicists in recent years, we develop a simple and generic new method for hierarchical reinforcement learning in this article. The proposed method generalizes the action-value Q function to  W function, enabling the agent to execute actions according to a hierarchical strategy. In the first part of the article, we present a rigorous construction of the hierarchical structure, along with the W-learning algorithm and the hierarchical policy gradient theorem. In the second part, as an example, we illustrate the W-learning procedure in the context of a navigation task. Experimental results show that the introduction of the hierarchical structure can lead to better performance than traditional Q-learning, provided the strategy is well designed and the update parameters are appropriately chosen.",
    "key_points": [
      "q-learning",
      "hierarchical reinforcement learning",
      "robot navigation"
    ],
    "gold_summary": "The authors claim to „develop a simple and generic new method for hierarchical reinforcement learning in this article“."
  },
  {
    "paper_id": "k96511V36j",
    "title": "More Than One Teacher: Adaptive Multi-Guidance Policy Optimization for Diverse Exploration",
    "domain": "reinforcement learning",
    "content": "Reinforcement Learning with Verifiable Rewards (RLVR) is a promising paradigm for enhancing the reasoning ability in Large Language Models (LLMs). However, prevailing methods primarily rely on self-exploration or a single off-policy teacher to elicit long chain-of-thought (LongCoT) reasoning, which may introduce intrinsic model biases and restrict exploration, ultimately limiting reasoning diversity and performance. Drawing inspiration from multi-teacher strategies in knowledge distillation, we introduce **A**daptive **M**ulti-Guidance **P**olicy **O**ptimization (**AMPO**), a novel framework that adaptively leverages guidance from multiple proficient teacher models, but only when the on-policy model fails to generate correct solutions. This \"guidance-on-demand\" approach expands exploration while preserving the value of self-discovery. Moreover, AMPO incorporates a comprehension-based selection mechanism, prompting the student to learn from the reasoning paths that it is most likely to comprehend, thus balancing broad exploration with effective exploitation. Extensive experiments show AMPO substantially outperforms a strong baseline (GRPO), with a **4.3%** improvement on mathematical reasoning tasks and **12.2%** on out-of-distribution tasks, while significantly boosting Pass@k performance and enabling more diverse exploration. Notably, using four peer-sized teachers, our method achieves comparable results to approaches that leverage a single, more powerful teacher (*e.g.*, DeepSeek-R1) with more data. These results demonstrate a more efficient and scalable path to superior reasoning and generalizability. *Our code is available at [https://anonymous.4open.science/r/7fBQd46C](https://anonymous.4open.science/r/7fBQd46C), which will be made public after double-blind review*.",
    "key_points": [
      "reinforcement learning",
      "large language models",
      "reasoning",
      "exploration",
      "multi-teacher learning"
    ],
    "gold_summary": "the paper introduces a new method that guides the learner dynamically, only when the learner cannot produce any correct traces. It also selectively learns what trace is best for the learner."
  },
  {
    "paper_id": "ydVFxjjtbA",
    "title": "Decentralized Byzantine-Resilient Multi-Agent Reinforcement Learning with Reward Machines in Temporally Extended Tasks",
    "domain": "reinforcement learning",
    "content": "In resilient cooperative multi-agent reinforcement learning (c-MARL), a fraction of agents exhibit Byzantine behavior, sending fabricated or deceptive information to hinder the learning process. Unlike existing approaches that often rely on a central controller or impose stringent behavior requirements on agents, we propose a fully decentralized method using reward machines (RMs) that can learn an optimal policy for temporally extended tasks. We introduce a belief-based Byzantine detection mechanism for discrete-time multi-agent reinforcement\nlearning (MARL), where defender (non-Byzantine) agents iteratively update probabilistic suspicions of peers using observed actions and rewards. RMs allow us to encode the temporal dependencies in the reward structure of the task and guide the learning process. Our methods introduce tabular Q-learning and actor-critic algorithms with reward machines to learn a robust consensus mechanism to isolate the influence of Byzantine agents, in order to ensure effective learning by defender agents. We establish theoretical guarantees, demonstrating that our algorithms converge to an optimal policy. We further evaluate our method against baselines in two case studies to show its effectiveness and performance.",
    "key_points": [
      "reinforcement learning",
      "multi-agent systems",
      "adversarial agents"
    ],
    "gold_summary": "This paper provides decentralized Byzantine-robust MARL with reward machines. The authors propose BQL-RM and BAC-RM with convergence guarantees. Experiments on two tasks shows the robustness of proposed methods."
  },
  {
    "paper_id": "zyLI9LEmry",
    "title": "Preference-based Policy Optimization from Sparse-reward Offline Dataset",
    "domain": "reinforcement learning",
    "content": "Offline reinforcement learning (RL) holds the promise of training effective policies from static datasets without the need for costly online interactions. However, offline RL faces key limitations, most notably the challenge of generalizing to unseen or infrequently encountered state-action pairs. When a value function is learned from limited data in sparse-reward environments, it can become overly optimistic about parts of the space that are poorly represented, leading to unreliable value estimates and degraded policy quality. To address these challenges, we introduce a novel approach based on contrastive preference learning that bypasses direct value function estimation. Our method trains policies by contrasting successful demonstrations with failure behaviors present in the dataset, as well as synthetic behaviors generated outside the support of the dataset distribution. This contrastive formulation mitigates overestimation bias and improves robustness in offline learning. Empirical results on challenging sparse-reward offline RL benchmarks show that our method substantially outperforms existing state-of-the-art baselines in both learning efficiency and final performance.",
    "key_points": [
      "reinforcement learning",
      "offline reinforcement learning",
      "preference-based reinforcement learning"
    ],
    "gold_summary": "This work presents a preference-based RL algorithm, which trains policies by contrasting successful demonstrations with failure behaviors present in the dataset. Experiments on offline benchmarks with sparse rewards validate the effectiveness of the proposed method."
  },
  {
    "paper_id": "8DCDq2pQ6c",
    "title": "Directional-based Wasserstein Distance for Efficient Multi-Agent Diversity",
    "domain": "reinforcement learning",
    "content": "In the domain of cooperative Multi-Agent Reinforcement Learning (MARL), agents typically share the same policy network to accelerate training. However, the use of shared policy network parameters among agents often leads to similar behaviors, restricting effective exploration and resulting in suboptimal cooperative policies. To promote diversity among agents, recent works have focused on differentiating trajectories of different agents given agent identities by maximizing the mutual information objective. However, these methods do not necessarily enhance exploration. To promote efficient multi-agent diversity and more robust exploration in multi-agent systems, we introduce a novel exploration method called Directional Metric-based Diversity (DMD). This method aims to maximize an inner-product-based Wasserstein distance between the trajectory distributions of different agents in a latent trajectory representation space, providing a more efficient and structured Wasserstein distance metric. Since directly calculating the Wasserstein distance is intractable, we introduce a kernel method to compute it with low computational cost. Empirical evaluations across a variety of complex multi-agent scenarios demonstrate the superior performance and enhanced exploration of our method, outperforming current state-of-the-art methods.",
    "key_points": [
      "multi-agent reinforcement learning",
      "multi-agent cooperation",
      "contrastive learning"
    ],
    "gold_summary": "The paper introduces an exploration method DMD based Wasserstein distance between different agents’ trajectory distributions in a latent trajectory representation space. Theoretical analysis and numerical examples are given to demonstrate the advantages of DMD."
  },
  {
    "paper_id": "y09blHAYKj",
    "title": "Efficient On-Policy Reinforcement Learning via Exploration of Sparse Parameter Space",
    "domain": "reinforcement learning",
    "content": "Policy-gradient methods such as Proximal Policy Optimization (PPO) are typically updated along a single stochastic gradient direction, leaving the rich local structure of the parameter space unexplored. Prior work has shown that the surrogate gradient is often poorly correlated with the true reward landscape. Building on this insight, we visualize the parameter space spanned by policy checkpoints within an iteration and reveal that higher-performing solutions often lie in nearby unexplored regions. To exploit this opportunity, we introduce ExploRLer, a pluggable pipeline that seamlessly integrates with on-policy algorithms such as PPO and TRPO, systematically probing the unexplored neighborhoods of surrogate on-policy gradient updates. Without increasing the number of gradient updates, ExploRLer achieves significant improvements over the baselines in complex continuous control environments. Our results demonstrate that iteration-level exploration provides a practical and effective way to strengthen on-policy reinforcement learning and offer a fresh perspective on the limitations of the surrogate objective.",
    "key_points": [
      "reinforcement learning",
      "on-policy learning",
      "empty-space search",
      "continuous control"
    ],
    "gold_summary": "This paper proposes a method named ExploRLer that probes the unexplored neighborhoods of surrogate on-policy gradient updates."
  },
  {
    "paper_id": "ytCDRzvf5f",
    "title": "ERPV: Enhancing Visual Reinforcement Learning with Partially Reliable Knowledge from VLMs",
    "domain": "reinforcement learning",
    "content": "Visual Reinforcement Learning (VRL) aims to learn optimal control policies from scratch,  a process that often suffers from low exploration efficiency. Integrating large-scale vision-language models (VLMs) offers a promising solution, as they provide rich prior knowledge about the environment. However, VLMs are only partially reliable when directly applied to VRL: the inferred actions may be wrong in certain states, and the inability to identify reliable action alignment can result in excessive exploration by the agent. We propose ERPV, a novel method that effectively enhances VRL with partially reliable knowledge from VLMs. ERPV introduces two key modules: (1) Value-aware Policy Guidance, which estimates the reliability of VLMs across different states and adaptively selects trustworthy VLM-inferred actions to guide policy learning; (2) VLMs-guided Entropy Regularization, which reduces over-exploration by comparing the confidence between VRL policy and VLMs-inferred actions. Extensive experiments show that, compared to the state of the art, ERPV achieves competitive performance in both policy effectiveness and sample efficiency under diverse, complex visual control tasks. The code has been placed in the supplementary materials.",
    "key_points": [
      "large-scale vision-language models",
      "reinforcement learning",
      "decision making",
      "knowledge distillation"
    ],
    "gold_summary": "This paper proposes ERPV, to address the issue of low exploration efficiency in VRL by introducing prior knowledge provided by pre trained VLMs. Experiments are conducted on Carla, DMC and CarRacing."
  },
  {
    "paper_id": "2bv3B8B9bl",
    "title": "ATPO: ADAPTIVE TREE POLICY OPTIMIZATION FOR MULTI-TURN MEDICAL DIALOGUE",
    "domain": "reinforcement learning",
    "content": "Effective information seeking in multi-turn medical dialogues is critical for accurate diagnosis, especially when dealing with incomplete information. Aligning Large Language Models (LLMs) for these interactive scenarios is challenging due to the uncertainty inherent in user-agent interactions, which we formulate as a Hierarchical Markov Decision Process (H-MDP). While conventional Reinforcement Learning (RL) methods like Group Relative Policy Optimization (GRPO) struggle with long-horizon credit assignment and Proximal Policy Optimization (PPO) suffers from unstable value estimation in this context, we propose a novel uncertainty-aware Adaptive Tree Policy Optimization (ATPO) algorithm. Our method adaptively allocates the rollout budget to states with high uncertainty, quantified by a composite metric of Bellman error and action-value variance. This strategy enables more accurate value estimation, while fostering more efficient and diverse exploration. To mitigate the high computational cost of tree-based RL, we introduce two key optimizations: an uncertainty-guided pruning mechanism to minimize the number of rollouts, and an asynchronous search architecture that leverages KV cache reuse to maximize inference throughput. Extensive experiments on three public medical dialogue benchmarks demonstrate that our algorithm significantly outperforms several strong baselines, culminating in Qwen3-8B model surpassing the much larger GPT-4o (+0.92% accuracy).",
    "key_points": [
      "reinforcement learning (rl)",
      "large language models (llms)",
      "medical dialogue",
      "tree search"
    ],
    "gold_summary": "This paper proposes a framework, namely ATPO, for generating multi-turn medical dialogues, which enhances the performance of LLMs in medical QA datasets."
  },
  {
    "paper_id": "nCEs0tSwc2",
    "title": "Geometric-Mean Policy Optimization",
    "domain": "reinforcement learning",
    "content": "Group Relative Policy Optimization (GRPO) has significantly enhanced the reasoning capability of large language models by optimizing the arithmetic mean of token-level rewards. Unfortunately, GRPO is observed to suffer from unstable policy updates when facing tokens with outlier importance-weighted rewards, which manifest as extreme importance sampling ratios during training. In this study, we propose Geometric-Mean Policy Optimization (GMPO), with the aim to improve the stability of GRPO through suppressing token reward outliers. Instead of optimizing the arithmetic mean, GMPO maximizes the geometric mean of token-level rewards, which is inherently less sensitive to outliers and maintains a more stable range of importance sampling ratio. GMPO is plug-and-play—simply replacing GRPO's arithmetic mean with the geometric mean of token-level rewards, as the latter is inherently less sensitive to outliers. GMPO is theoretically plausible—analysis reveals that both GMPO and GRPO are weighted forms of the policy gradient while the former enjoys more stable weights, which consequently benefits policy optimization and performance. Experiments on multiple mathematical reasoning benchmarks show that GMPO-7B improves the average Pass@1 of GRPO by up to 4.1%, outperforming many state-of-the-art approaches. The code is enclosed in the supplementary material.",
    "key_points": [
      "large language model",
      "reinforcement learning",
      "stability"
    ],
    "gold_summary": "The paper proposed GMPO, which replaces the arithmetic mean in GRPO with the geometric mean to achieve better  stability of training."
  },
  {
    "paper_id": "nrUsCBW3oT",
    "title": "Bingo: Boosting Efficient Reasoning of LLMs via Dynamic and Significance-based Reinforcement Learning",
    "domain": "reinforcement learning",
    "content": "Large language models have demonstrated impressive reasoning capabilities, yet they often suffer from inefficiencies due to unnecessarily verbose or redundant outputs. While many works have explored reinforcement learning (RL) to enhance reasoning abilities, most primarily focus on improving accuracy, with limited attention to reasoning efficiency. Some existing approaches introduce direct length-based rewards to encourage brevity, but this often leads to noticeable drops in accuracy. In this paper, we propose Bingo, an RL framework that advances length-based reward design to boost efficient reasoning. Bingo incorporates two key mechanisms: a significance-aware length reward, which gradually guides the model to reduce only insignificant tokens, and a dynamic length reward, which initially encourages elaborate reasoning for difficult questions but decays over time to improve overall efficiency. Experiments across multiple reasoning benchmarks show that Bingo improves both accuracy and efficiency. It outperforms the vanilla reward and several other length-based reward baselines in RL, achieving a favorable trade-off between accuracy and efficiency. These results underscore the potential of training LLMs explicitly for efficient reasoning.",
    "key_points": [
      "reasoning",
      "efficient reasoning",
      "question answering",
      "large language models"
    ],
    "gold_summary": "Bingo is a RL-based efficient reasoning algorithm with a  significance-aware length reward and dynamic length reward."
  },
  {
    "paper_id": "kxzYGDL4fY",
    "title": "Probing in the Dark: State Entropy Maximization for POMDPs",
    "domain": "reinforcement learning",
    "content": "Sample efficiency is one of the main bottlenecks for optimal decision making via reinforcement learning. Pretraining a policy to maximize the entropy of the state visitation can substantially speedup reinforcement learning of downstream tasks. It is still an open question how to maximize the state entropy in POMDPs, where the true states of the environment, or their entropy, are not observed. In this work, we propose to maximize the entropy of a sufficient statistic of the history, which is called an information state. First, we show that a recursive latent model that predicts future observations is an information state in this setting. Then, we provide a practical algorithm, called LatEnt, to simultaneously learn the latent model and a latent-based policy maximizing the corresponding entropy objective from reward-free interactions with the POMDP. We empirically show that our approach induces higher state entropy than existing methods, which translates to better performance on downstream tasks.  As a byproduct, we open-source PROBE, the first benchmark to test reward-free pretraining in POMDPs.",
    "key_points": [
      "unsupervised rl",
      "state entropy maximization",
      "pomdps",
      "information states"
    ],
    "gold_summary": "The paper introduces an exploration technique in POMDPs. It consists of maximizing the frequency with which an information state of the POMDP is visited."
  },
  {
    "paper_id": "o1aGo0GzBo",
    "title": "Dynamic-TreeRPO: Breaking the Independent Trajectory Bottleneck with Structured Sampling",
    "domain": "reinforcement learning",
    "content": "The integration of Reinforcement Learning (RL) into flow matching models for text-to-image (T2I) generation has driven substantial advances in generation quality.\nHowever, these gains often come at the cost of exhaustive exploration and inefficient sampling strategies due to slight variation in the sampling group.\nBuilding on this insight, we propose Dynamic-TreeRPO, which implements the sliding-window sampling strategy as a tree-structured search with dynamic noise intensities along depth.\nWe perform GRPO-guided optimization and constrained Stochastic Differential Equation (SDE) sampling within this tree structure. By sharing prefix paths of the tree, our design effectively amortizes the computational overhead of trajectory search.\nWith well-designed noise intensities for each tree layer, Dynamic-TreeRPO can enhance the variation of exploration without any extra computational cost.\nFurthermore, we seamlessly integrate Supervised Fine-Tuning (SFT) and RL paradigm within Dynamic-TreeRPO to construct our proposed LayerTuning-RL, reformulating the loss function of SFT as a dynamically weighted Progress Reward Model (PRM) rather than a separate pretraining method.\nBy associating this weighted PRM with dynamic-adaptive clipping bounds, the disruption of exploration process in Dynamic-TreeRPO is avoided.\nBenefiting from the tree-structured sampling and the LayerTuning-RL paradigm, our model dynamically explores a diverse search space along effective directions.\nCompared to existing baselines, our approach demonstrates significant superiority in terms of semantic consistency, visual fidelity, and human preference alignment on established benchmarks, including HPS-v2.1, PickScore, and ImageReward. In particular, our model outperforms SoTA by 4.9\\%, 5.91\\%, and 8.66\\% on those benchmarks, respectively, while improving the training efficiency by nearly 50\\%.",
    "key_points": [
      "diffusion;image generation;grpo;"
    ],
    "gold_summary": "Dynamic-TreeRPO is a tree-structured reinforcement learning framework for flow matching models that uses a binary tree and LayerTuning-RL to jointly enhance sampling efficiency, exploration diversity, and achieve state-of-the-art performance across multiple benchmarks."
  },
  {
    "paper_id": "aHAvupzNAH",
    "title": "Distributional Inverse Reinforcement Learning",
    "domain": "reinforcement learning",
    "content": "We propose a distributional framework for offline Inverse Reinforcement Learning (IRL) that jointly models uncertainty over reward functions and full distributions of returns. Unlike conventional IRL approaches that recover a deterministic reward estimate or match only expected returns, our method captures richer structure in expert behavior, particularly in learning the reward distribution, by minimizing first-order stochastic dominance (FSD) violations and thus integrating distortion risk measures (DRMs) into policy learning, enabling the recovery of both reward distributions and distribution-aware policies. This formulation is well-suited for behavior analysis and risk-aware imitation learning. Empirical results on synthetic benchmarks, real-world neurobehavioral data, and MuJoCo control tasks demonstrate that our method recovers expressive reward representations and achieves state-of-the-art imitation performance.",
    "key_points": [
      "inverse reinforcement learning",
      "neuroscience",
      "reinforcement learning",
      "robotics"
    ],
    "gold_summary": "This paper introduces a distributional framework to mitigate the stochastic challenge of offline IRL. Specifically, authors leverage variational inference framework to connect FSD based distributional optimization problem to the conventional IRL problem."
  },
  {
    "paper_id": "71iwUe98cI",
    "title": "Sample-Efficient Online Distributionally Robust Reinforcement Learning via General Function Approximation",
    "domain": "reinforcement learning",
    "content": "The deployment of reinforcement learning (RL) agents in real-world tasks is frequently hampered by performance degradation caused by mismatches between the training and target environments. Distributionally Robust RL (DR-RL) offers a principled framework to mitigate this issue by learning a policy that maximizes worst-case performance over a specified uncertainty set of transition dynamics. Despite its potential, existing DR-RL research faces two key limitations: reliance on prior knowledge of the environment -- typically access to a generative model or a large offline dataset -- and a primary focus on tabular methods that do not scale to complex problems. In this paper, we bridge these gaps by introducing an online DR-RL algorithm compatible with general function approximation. Our method learns an optimal robust policy directly from environmental interactions, eliminating the need for prior models and enabling application to complex, high-dimensional tasks. Furthermore, our theoretical analysis establishes a near-optimal sublinear regret for the algorithm under the total variation uncertainty set, demonstrating that our approach is both sample-efficient and effective.",
    "key_points": [
      "distributionally robust",
      "reinforcement learning",
      "function approximation"
    ],
    "gold_summary": "The paper propose to use function family to facilitate the robust RL. \nTheoretical analysis are provided to justify the advantages of the proposed methods."
  },
  {
    "paper_id": "T5uCz05JMr",
    "title": "Global Convergence and Pareto Front Exploration in Deep-Neural Actor-Critic Multi-Objective Reinforcement Learning",
    "domain": "reinforcement learning",
    "content": "Multi-objective reinforcement learning (MORL) has gained considerable traction in recent years, with applications across diverse domains. \nHowever, its theoretical foundations remain underdeveloped, especially for widely used but largely heuristic deep neural network (DNN)-based actor–critic methods. \nThis motivates us to study MORL from a theoretical perspective and to develop DNN-based actor–critic approaches that (i) provide global convergence guarantees to Pareto-optimal policies and (ii) enable systematic exploration of the entire Pareto front (PF). \nTo achieve systematic PF exploration, we first scalarize the original vector-valued MORL problem using the weighted Chebyshev (WC) technique and leveraging the one-to-one correspondence between the PF and WC scalarizations. \nWe then address the non-smoothness introduced by WC in the scalarized problem via a parameterized log-sum-exp softmax approximation, which allows us to design a deep neural actor–critic method for solving the smoothed WC-scalarized MORL problem with a global convergence rate of $\\mathcal{O}(1/T)$, where $T$ denotes the total number of iterations. \nTo the best of our knowledge, this is the first work to establish theoretical guarantees for both global convergence and systematic Pareto front exploration in deep neural actor–critic MORL. \nFinally, extensive numerical experiments and ablation studies on recommendation system training and robotic simulation further validate the effectiveness of our method, especially its capability in Pareto exploration.",
    "key_points": [
      "multi-objective reinforcement learning",
      "deep neural network",
      "finite-time global convergence."
    ],
    "gold_summary": "This paper studies the theoretical foundations of DNN–based actor–critic methods with weighted Chebyshev scalarization for MORL.  Experiments on recommendation and robotic control tasks are included to illustrate the theoretical results."
  },
  {
    "paper_id": "JrWpxBqqFk",
    "title": "Bridging Offline and Online Reinforcement Learning for LLMs",
    "domain": "reinforcement learning",
    "content": "We investigate the effectiveness of reinforcement learning methods for finetuning large language models when transitioning from offline to semi-online to fully online regimes for both verifiable and non-verifiable tasks. Our experiments cover training on verifiable math as well as non-verifiable instruction following with a set of benchmark evaluations for both. Across these settings, we extensively compare online and semi-online Direct Preference Optimization and Group Reward Policy Optimization objectives, and surprisingly find similar performance and convergence between these variants, which all strongly outperform offline methods. We provide a detailed analysis of the training dynamics and hyperparameter selection strategies to achieve optimal results. Finally, we show that multi-tasking with verifiable and non-verifiable rewards jointly yields improved performance across both task types.",
    "key_points": [
      "reinforcement learning",
      "dpo",
      "grpo",
      "alignment"
    ],
    "gold_summary": "The paper provides an evaluation of how off-policy can training go for DPO in various datasets analyzing fully offline, semi-offline and fully online. The paper provides comprehensive evaluations for DPO under this regime."
  },
  {
    "paper_id": "KjYpHySlb0",
    "title": "Discovering Diverse Behaviors via Temporal Contrastive Learning",
    "domain": "reinforcement learning",
    "content": "Effective exploration in reinforcement learning requires not only tracking where an agent has been, but also understanding how the agent perceives and represents the world. To learn powerful representations, an agent should actively explore states that contribute to its knowledge of the environment. Temporal representations can capture the information necessary to solve a wide range of potential tasks while avoiding the computational cost associated with full state reconstruction. In this paper, we propose an exploration method that leverages temporal contrastive representations to guide exploration, prioritizing states with unpredictable future outcomes. We demonstrate that such representations can enable the learning of complex exploratory behaviors in locomotion, manipulation, and embodied-AI tasks, revealing capabilities and behaviors that traditionally require extrinsic rewards. Unlike approaches that rely on explicit distance learning or episodic memory mechanisms (e.g., quasimetric-based methods), our method builds directly on temporal similarities, yielding a simpler yet effective strategy for exploration.",
    "key_points": [
      "reinforcement learning",
      "exploration",
      "intrinsic motivation",
      "surprise",
      "empowerment",
      "contrastive learning"
    ],
    "gold_summary": "Based on the work of Jiang et al. (2025), this paper proposes a new reward objective that avoids quasi-metric learning and episodic memory. The experiments are conducted in navigation, manipulation, and open-world environments."
  },
  {
    "paper_id": "iH7mSOTR4q",
    "title": "Preference Conditioned Multi-Objective Reinforcement Learning: Decomposed, Diversity-Driven Policy Optimization",
    "domain": "reinforcement learning",
    "content": "Multi-objective reinforcement learning (MORL) aims to optimize policies in environments with multiple, often conflicting objectives. While a single, preference-conditioned policy offers the most flexible and efficient solution, existing methods often struggle to cover the entire spectrum of optimal trade-offs. This is frequently due to two underlying challenges: destructive gradient interference between conflicting objectives and representational mode collapse, where the policy fails to produce diverse behaviors. In this work, we introduce  $D^3PO$, a novel algorithm that trains a single preference conditioned policy to directly address these issues. Our framework features a decomposed optimization process to encourage stable credit assignment and a scaled diversity regularizer to explicitly encourage a robust mapping from preferences to policies. Empirical evaluations across standard MORL benchmarks show that $D^3PO$ discovers more comprehensive and higher-quality Pareto fronts, establishing a new state-of-the-art in terms of hypervolume and expected utility, particularly in complex and many-objective environments.",
    "key_points": [
      "multi-objective reinforcement learning",
      "pareto front",
      "single-policy morl"
    ],
    "gold_summary": "This work introduced a so-called Decomposed, Diversity Driven Policy Optimization (D3PO) method for scalarized multi-objective PPO. It proposed Late-Stage Weighting for better learning signal, and Scaled Diversity Regularization for representational mode collapse prevention"
  },
  {
    "paper_id": "8mQqCCxKZa",
    "title": "MASTARS: Multi-Agent Sequential Trajectory Augmentation with Return-Conditioned Subgoals",
    "domain": "reinforcement learning",
    "content": "The performance of offline reinforcement learning (RL) critically depends on the quality and diversity of the offline dataset. While diffusion-based data augmentation for offline RL has shown promise in single-agent settings, its extension to multi-agent systems poses challenges due to the combinatorial complexity of joint modeling and the lack of inter-agent coordination in independent generation. To overcome these issues, we introduce MASTARS, a novel diffusion-based framework that generates coordinated multi-agent trajectories through agent-wise sequential generation. MASTARS employs a diffusion inpainting mechanism, where each agent’s trajectory is generated based on the trajectories of previously sampled agents. This enables fine-grained coordination among agents while avoiding the complexity of high-dimensional joint modeling. To further improve sample quality, MASTARS incorporates return-conditioned subgoals, allowing it to leverage valuable data that might otherwise be discarded. This agent-wise, goal-conditioned approach produces realistic and harmonized multi-agent rollouts, facilitating more effective offline MARL training. Experiments on benchmark environments demonstrate that MASTARS significantly improves the performance of offline MARL algorithms.",
    "key_points": [
      "reinforcement learning",
      "multi-agent",
      "data augmentation",
      "diffusion"
    ],
    "gold_summary": "This paper proposes a diffusion-based inpainting mechanism for data augmentation in multi-agent offline reinforcement learning. The method aims to enhance both the quantity and quality of offline data to facilitate more effective policy learning."
  },
  {
    "paper_id": "qmEyJadwHA",
    "title": "Object-Centric World Models from Few-Shot Annotations for Sample-Efficient Reinforcement Learning",
    "domain": "reinforcement learning",
    "content": "While deep reinforcement learning (DRL) from pixels has achieved remarkable success, its sample inefficiency remains a critical limitation for real-world applications. Model-based RL (MBRL) addresses this by learning a world model to generate simulated experience, but standard approaches that rely on pixel-level reconstruction losses often fail to capture small, task-critical objects in complex, dynamic scenes. We posit that an object-centric representation can direct model capacity toward semantically meaningful entities, improving dynamics prediction and sample efficiency. In this work, we introduce **OC-STORM**, an object-centric MBRL framework that enhances a learned world model with object representations extracted by a pretrained segmentation network. By conditioning on a minimal number of annotated frames, OC-STORM learns to track decision‐relevant object dynamics and inter‑object interactions without extensive labeling or access to privileged information. Empirical results demonstrate that OC-STORM significantly outperforms the STORM baseline on the Atari 100k benchmark and achieves state-of-the-art sample efficiency on challenging boss fights in the visually complex game **Hollow Knight**. Our findings underscore the potential of integrating object-centric priors into MBRL for complex visual domains. Core code and evaluation videos are available in supplementary materials.",
    "key_points": [
      "model-based rl",
      "object-centric rl",
      "video object segmentation",
      "atari",
      "hollow knight"
    ],
    "gold_summary": "The paper proposes OC-STORM, an object-centric model-based RL framework that fuses few-shot, pretrained video-segmentation features with pixel inputs to train a spatial-temporal world model, yielding improved sample efficiency on Atari-100k and Hollow Knight."
  },
  {
    "paper_id": "OurKIAjfL8",
    "title": "Best Arm Identification with Knapsacks: Minimax Policies",
    "domain": "reinforcement learning",
    "content": "A resource-constrained decision maker (DM) designs a continuous-time sequential experiment to determine the best choice out of a set of treatments. The DM divides her attention between observing the treatments until one of the resources runs out. Under the minimax regret criterion, we characterize the optimal policy for two treatments when there is a fixed array of resources. Of additional interest is a prerequisite result in which we characterize the minimax regret optimal policy under a single infinite resource (money) and adaptive stopping. Our analysis relies on a reformulation of the typical optimal stopping problem in which we model diffusions with respect to the cumulative resource expenditure rather than the elapsed time.",
    "key_points": [
      "economics",
      "best arm identification",
      "pure exploration bandits",
      "bayesian learning"
    ],
    "gold_summary": "This paper focused on the fixed-budget best arm identification problem with knapsacks. It analyzed a proposed algorithm with knapsack constraint under the continuous time setting."
  },
  {
    "paper_id": "eOqnXPOl4S",
    "title": "Reinforcement Learning with Missing Context to Mitigate Reward Hacking from Training Only on Golden Answers",
    "domain": "reinforcement learning",
    "content": "Reinforcement learning (RL) for reasoning has achieved remarkable progress in recent years. However, much of this progress has been evaluated in overly idealized settings. In most existing benchmarks, problems are deterministic, carefully curated, and fully specified. \nWhile such settings make evaluation straightforward, real-world reasoning tasks are often underspecified, lack crucial contextual information, or even contain misleading premises.  Hence, we argue that most current RL training paradigms based on verifiable rewards amount to an implicit form of reward hacking.  Our experiments show that many state-of-the-art reasoning models tend to overcommit to producing a single definite answer, even when the problem is inherently underspecified. To address this gap, we propose \\emph{Reinforcement Learning with Missing Context} (RLMC), a framework that explicitly trains models on problem instances with missing, underspecified, or incorrect context.  We construct a large-scale RL dataset of 120K queries by intentionally synthesizing such imperfect questions, encouraging models to identify uncertainty, make reasonable assumptions, and reason effectively under incomplete information.  Experimental results show that RLMC-trained models exhibit substantial gains in robustness, reduced hallucinations, and improved overall reasoning capabilities compared to baselines trained only on fully specified tasks. \nWe further introduce \\textsc{Reasoning Beyond the Given} (RBG), a benchmark designed to evaluate whether models can detect missing or inconsistent information and proactively elicit clarifying input from users. Evaluation on \\textsc{RBG} fully exposes current models' limitations in handling imperfect problem statements.  Code, \\textsc{RBG} and train data will be fully released at \\url{https://anonymous.4open.science/r/RLMC-RBG}.",
    "key_points": [
      "reinforcement learning",
      "benchmark",
      "large language models",
      "conversational llm",
      "chatbots",
      "synthetic data",
      "reward hacking"
    ],
    "gold_summary": "The paper propose a new framework and benchmark to evaluate and improve the abiltiy of answer unclear questions (missing context)."
  },
  {
    "paper_id": "dKL1v456tE",
    "title": "Linear Preference Optimization: Decoupled Gradient Control via Absolute Regularization",
    "domain": "reinforcement learning",
    "content": "Direct Preference Optimization (DPO) is a widely adopted offline preference optimization algorithm, valued for its simplicity and training stability. However, it is susceptible to overfitting and performance collapse. To overcome these limitations, we introduce Linear Preference Optimization (LPO), a novel alignment framework that incorporates three key innovations. First, we achieve gradient decoupling by replacing the log-sigmoid function with an absolute difference loss, isolating the optimization dynamics more effectively. Second, we enhance training stability by incorporating an offset constraint and a positive regularization term, ensuring consistent response quality. Third, we implement controllable rejection suppression through gradient separation, which features a straightforward estimation process and a tunable coefficient to regulate the rate of rejection probability descent. Extensive experiments demonstrate that LPO consistently outperforms DPO across diverse tasks, including general text processing, mathematics, text-to-speech (TTS), and automatic speech recognition (ASR). These findings establish LPO as a robust, versatile, and tunable paradigm for preference alignment.",
    "key_points": [
      "reinforcement learning",
      "dpo",
      "lpo"
    ],
    "gold_summary": "This paper proposes Linear Preference Optimization (LPO), improving DPO loss function from different perspectives by changing Softmax to absolute value, including regularization term and applying Straight-Through Estimator (STE). They also change the data generation pipeline."
  },
  {
    "paper_id": "EcygLrP7je",
    "title": "MAVIS: Multi-Objective Alignment via Value-Guided Inference-Time Search",
    "domain": "reinforcement learning",
    "content": "Large Language Models (LLMs) are increasingly deployed across diverse applications that demand balancing multiple, often conflicting, objectives--such as helpfulness, harmlessness, or humor. Aligning outputs to user-specific preferences in such multi-objective settings typically requires fine-tuning models for each objective or preference configuration, which is computationally expensive and inflexible. We introduce MAVIS - Multi-Objective Alignment via Value-Guided Inference-Time Search - a lightweight inference-time alignment framework that enables dynamic control over LLM behavior without modifying the base model's weights. MAVIS trains a set of small value models, each corresponding to a distinct objective. At inference time, these value models are combined using user-specified weights to produce a tilting function that adjusts the base model's output distribution toward desired trade-offs. The value models are trained using a simple iterative algorithm that ensures monotonic improvement of the KL-regularized policy. We show empirically that MAVIS outperforms baselines that fine-tune per-objective models and combine them post hoc, and even approaches the performance of the idealized setting where models are fine-tuned for a user's exact preferences.",
    "key_points": [
      "multi-objective",
      "rlhf",
      "large language models"
    ],
    "gold_summary": "The paper proposes MAVIS, a value-guided decoding framework that enables a plug-and-play framework for multi-objective alignment. The main technical contribution involves resembling soft policy iteration to better estimate the Q function."
  },
  {
    "paper_id": "w27mNVSvLr",
    "title": "Cross-domain Offline Policy Adaptation with Dynamics- and Value-aligned Data Filtering",
    "domain": "reinforcement learning",
    "content": "Cross-Domain Offline Reinforcement Learning aims to train an agent deployed in the target environment, leveraging both a limited target domain dataset and a source domain dataset with (possibly) sufficient data coverage. Due to the underlying dynamics misalignment between the source and target domain, simply merging the data from two datasets may incur inferior performance. Recent advances address this issue by selectively sharing source domain samples that exhibit dynamics alignment with the target domain.  However, these approaches focus solely on dynamics alignment and overlook \\textit{value alignment}, i.e., selecting high-quality, high-value samples from the source domain. In this paper, we first demonstrate that both dynamics alignment and value alignment are essential for policy learning, by examining the limitations of the current theoretical framework for cross-domain RL and establishing a concrete sub-optimality gap of a policy trained on the source domain and evaluated on the target domain. Motivated by the theoretical insights, we propose to selectively share those source domain samples with both high dynamics and value alignment and present our Dynamics- and Value-aligned Data Filtering (DVDF) method. We design a range of dynamics shift settings, including kinematic and morphology shifts, and evaluate DVDF on various tasks and datasets, as well as in challenging extremely low-data settings where the target domain dataset contains only 5,000 transitions.  Extensive experiments demonstrate that DVDF consistently outperforms prior strong baselines and delivers exceptional performance across multiple tasks and datasets.",
    "key_points": [
      "offline reinforcement learning; cross-domain policy adaptation"
    ],
    "gold_summary": "This paper proposes a Dynamics- and Value-aligned Data Filtering (DVDF) method, which can selectively share those source domain samples with both high dynamics and value alignment."
  },
  {
    "paper_id": "MS9nWFY7LG",
    "title": "Q-RAG: Long Context Multi‑Step Retrieval via Value‑Based Embedder Training",
    "domain": "reinforcement learning",
    "content": "Retrieval-Augmented Generation (RAG) methods enhance LLM performance by efficiently filtering relevant context for LLMs, reducing hallucinations and inference cost.\nHowever, most existing RAG methods focus on single-step retrieval, which is often insufficient for answering complex questions that require multi-step search.\nRecently, multi-step retrieval approaches have emerged, typically involving the fine-tuning of small LLMs to perform multi-step retrieval.\nHowever, this type of fine-tuning is highly resource-intensive and does not enable the use of larger LLMs.\nIn this work, we propose Q-RAG, a novel approach that fine-tunes the Embedder model for multi-step retrieval using reinforcement learning (RL).\nQ-RAG offers a competitive, resource-efficient alternative to existing multi-step retrieval methods for open-domain question answering and achieves state-of-the-art results on the popular long-context benchmarks Babilong and RULER for contexts up to 10M tokens.",
    "key_points": [
      "reinforcement learning",
      "rl",
      "qa",
      "long-context",
      "rag",
      "nlp"
    ],
    "gold_summary": "This paper proposes an approach that fine-tunes an embedder model for multi-step retrieval through reinforcement learning. The proposed method, Q-RAG, achieves state-of-the-art results on long-context benchmarks including Babilong and Needle-in-a-haystack tasks."
  },
  {
    "paper_id": "rhV6QTMqq1",
    "title": "Token-Regulated Group Relative Policy Optimization for Stable Reinforcement Learning in Large Language Models",
    "domain": "reinforcement learning",
    "content": "Reinforcement learning with verifiable rewards (RLVR) has emerged as a powerful approach for strengthening the reasoning capabilities of large language models (LLMs). Among existing algorithms, Group Relative Policy Optimization (GRPO) has demonstrated strong performance, yet it suffers from a critical issue: low-probability tokens disproportionately dominate gradient updates due to their inherently large gradient magnitudes. This imbalance leads to unstable training and suppresses the contribution of high-probability tokens that are more reliable for learning. In this work, we introduce **Token-Regulated Group Relative Policy Optimization (TR-GRPO)**, a simple yet effective extension of GRPO that assigns token-level weights positively correlated with the model’s predicted probability. By downweighting low-probability tokens and emphasizing high-probability ones, TR-GRPO mitigates gradient over-amplification while preserving informative learning signals. We provide theoretical analysis to show how token-level probability governs gradient norms which motivates our weighting design. Extensive experiments demonstrate that TR-GRPO consistently outperforms GRPO across RLVR tasks—including logic, math, and agentic reasoning—highlighting the importance of regulating token contributions during RL training and establishing TR-GRPO as a robust framework for enhancing LLM reasoning.",
    "key_points": [
      "large language models",
      "reinforcement learning",
      "reasoning"
    ],
    "gold_summary": "The paper is well motivated. However, the contribution of the proposed appraoch is not sound."
  },
  {
    "paper_id": "AMlnnJ9T4R",
    "title": "Task Characteristic Contexts for Improving Generalization in Offline Meta-Reinforcement Learning",
    "domain": "reinforcement learning",
    "content": "Context-based offline meta-reinforcement learning (meta-RL) methods typically extract contexts summarizing task information from\nhistorical trajectories to achieve adaptation to unseen target tasks. Nevertheless, previous methods are affected by context shift caused by the mismatch between the behavior policy and context-based policy, as well as the distinctness among tasks, leading to poor generalization and limited adaptation. Our key insight is that existing methods overlook the task characteristic information, which\nnot only reflects task-specific information but also serves to distinguish among tasks, thereby hindering the extraction and utilization of contexts during adaptation. To address this issue, we propose a framework called task characteristic contexts for offline meta-RL\n(TCMRL). We consider that such task characteristic information is directly related to task properties, which consist of both reward functions and transition dynamics, and the interrelations among transitions. More specifically, we design a characteristic metric based on context-based reward and state estimators, which utilize task properties to construct the relationships among contexts extracted from entire trajectories. Moreover, we introduce a cyclic interrelation to obtain the interrelations among transitions within sequential subtrajectories from forward, backward and inverse perspectives. Contexts with task characteristic information provide a comprehensive understanding of each task and implicit relationships among them, enabling effective extraction and utilization of contexts during adaptation. Experiments in meta-environments demonstrate the superiority of TCMRL over existing offline meta-RL methods in generating more generalizable contexts and achieving effective adaptation to unseen target tasks.",
    "key_points": [
      "context-based offline meta-reinforcement learning",
      "meta-reinforcement learning",
      "offline reinforcement learning."
    ],
    "gold_summary": "The paper proposes to use a characteristic metric based on context-based reward and state estimators to help the learning of the context encoder. Experiment on mujoco environment showcases its edge."
  },
  {
    "paper_id": "wuncwN7iZN",
    "title": "Flow Actor-Critic for Offline Reinforcement Learning",
    "domain": "reinforcement learning",
    "content": "The dataset distributions in offline reinforcement learning (RL) often exhibit complex and multi-modal distributions, necessitating expressive policies to capture such distributions beyond widely-used Gaussian policies. To handle such complex and multi-modal datasets, in this paper, we propose Flow Actor-Critic, a new actor-critic method for offline RL, based on recent flow policies. The proposed method not only uses the flow model for actor as in previous flow policies but also exploits the expressive flow model for conservative critic acquisition to prevent Q-value explosion in out-of-data regions. To this end, we propose a new form of critic regularizer based on the accurate proxy behavior model obtained as a byproduct of flow-based actor design. Leveraging the flow model in this joint way, we achieve new state-of-the-art performance for test datasets of offline RL including the D4RL and recent OGBench benchmarks.",
    "key_points": [
      "reinforcement learning",
      "offline reinforcement learning",
      "flow actor-critic",
      "flow policies",
      "flow matching"
    ],
    "gold_summary": "This paper proposes a Flow Actor-Critic, a new actor-critic method for offline RL, based on recent flow policies."
  },
  {
    "paper_id": "afaakBqkvb",
    "title": "General search techniques without common knowledge for imperfect-information games, and application to superhuman Fog of War chess",
    "domain": "reinforcement learning",
    "content": "Since the advent of AI, games have served as progress benchmarks. Meanwhile, imperfect-information variants of chess have existed for over a century, present extreme challenges, and have been the focus of decades of AI research. Beyond calculation needed in regular chess, they require reasoning about information gathering, the opponent’s knowledge, signaling, _etc_. The most popular variant, _Fog of War (FoW) chess_ (a.k.a. _dark chess_), has been arguably the main challenge problem in imperfect-information game solving since superhuman performance was reached in no-limit Texas hold’em poker. We present _Obscuro_, the first superhuman AI for FoW chess. It introduces advances to search in imperfect-information games, enabling strong, scalable reasoning. Experiments against the prior state-of-the-art AI and human players---including the world's best---show that _Obscuro_ is significantly stronger. FoW chess is the largest (by amount of imperfect information) turn-based game in which superhuman performance has been achieved and the largest game in which imperfect-information search has been successfully applied.",
    "key_points": [
      "imperfect-informaton games",
      "subgame solving",
      "game theory"
    ],
    "gold_summary": "This paper contributes a Fog-of-War chess bot that is ostensibly state of the art. It performs real-time search without trying to untangle unwieldly \"I know that you know...\" loops that usually choke imperfect-information solvers."
  },
  {
    "paper_id": "n80azZM1A6",
    "title": "In‑Context Planning with Latent Temporal Abstractions",
    "domain": "reinforcement learning",
    "content": "Planning-based reinforcement learning in real-world control faces two coupled obstacles: planning at primitive time scales explodes both context length and branching factor, and the underlying dynamics are often only partially observable. We introduce the In-Context Latent Temporal Abstraction Planner (I-TAP), which unifies in-context adaptation and online planning in a learned latent temporal-abstraction space. From offline trajectories, I-TAP learns an observation-conditioned residual-quantization VAE (RQ-VAE) that discretizes observation–macro-action sequences into a coarse-to-fine stack of residual tokens, together with a residual-quantized temporal Transformer that autoregressively predicts these tokens from recent observation and macro-action histories. This sequence model serves jointly as a context-conditioned prior over abstract actions and a latent-space dynamics model. At inference, I-TAP plans with Monte Carlo Tree Search directly in token space, leveraging short histories to implicitly infer latent factors without any test-time fine-tuning. Across deterministic and stochastic MuJoCo locomotion and high-dimensional Adroit manipulation, including partially observable variants, I-TAP consistently matches or outperforms strong model-free and model-based baselines, demonstrating effective in-context planning under stochastic dynamics and partial observability.",
    "key_points": [
      "sequential decision-making",
      "monte carlo tree search",
      "planning",
      "model-based reinforcement learning",
      "offline reinforcement learning"
    ],
    "gold_summary": "The paper proposes to employ the residual quantization VAE (RQ-VAE) to replace the VQ-VAE in L-MAP which uses VQ-VAE and learns a state-macro action dynamics model."
  },
  {
    "paper_id": "diVihFiZSc",
    "title": "Continuity-Regularized Flow Matching for Offline Reinforcement Learning",
    "domain": "reinforcement learning",
    "content": "Flow-matching policies have recently emerged as a powerful class of generative models for offline reinforcement learning (RL), capable of capturing complex, multi-modal action distributions from static datasets. However, standard training objectives are largely agnostic to the global properties of the generative path, permitting learned vector fields that are irregular and unstable, which can hinder performance. In this work, we introduce PDE-regularized Q-Learning (PQL), a novel algorithm that addresses this limitation by imposing a principled structure on the entire probability flow. PQL makes two synergistic contributions: first, a partial differential equation based regularizer derived from the continuity equation enforces global smoothness and stability on the flow. Second, to solve the complex optimization problem introduced by this regularizer, we propose a Beta-distributed timestep sampling strategy that focuses learning on the critical trajectory segments where the trade-off between imitation and smoothness is most acute. Through extensive experiments, we demonstrate that by structuring the generative journey and not just its destination, PQL achieves state-of-the-art performance on a wide range of challenging offline RL tasks.",
    "key_points": [
      "offline reinforcement learning",
      "flow policy"
    ],
    "gold_summary": "This paper introduces a regularizer into the flow-matching-based policy to improve training stability and proposes a Beta-distributed time sampling strategy that enables stable and efficient optimization."
  },
  {
    "paper_id": "RFQhCkUcko",
    "title": "Robust Adversarial Policy Optimization Under Dynamics Uncertainty",
    "domain": "reinforcement learning",
    "content": "Reinforcement learning (RL) policies often fail under dynamics that differ from training, a gap not fully addressed by domain randomization or existing adversarial RL methods. Distributionally robust RL provides a formal remedy but still relies on surrogate adversaries to approximate intractable primal problems, leaving blind spots that potentially cause instability and over-conservatism.\nWe propose a dual formulation that directly exposes the robustness–performance trade-off. At the trajectory level, a temperature parameter from the dual is approximated with an adversarial network, yielding efficient and stable worst-case rollouts within a divergence bound. At the model level, we employ Boltzmann reweighting over dynamics ensembles, focusing on more adverse environments to the current policy rather than uniform sampling. Two components act independently and complement each other: trajectory-level steering ensures robust rollouts, while model-level sampling provides policy-sensitive coverage of adverse dynamics.\nThe resulting framework, robust adversarial policy optimization (RAPO) outperforms robust RL baselines, improving resilience to uncertainty and generalization to out-of-distribution dynamics while maintaining dual tractability.",
    "key_points": [
      "reinforcement learning",
      "robust reinforcement learning",
      "adversarial reinforcement learning"
    ],
    "gold_summary": "The paper proposes a new algorithm RAPO that steers the trajectories towards low return ones, resembling the trajectories drawn from adversarial kernel. This  makes the policy robust."
  },
  {
    "paper_id": "UAZCKdd4R7",
    "title": "Koopman-Assisted Trajectory Synthesis: A Data Augmentation Framework for Offline Imitation Learning",
    "domain": "reinforcement learning",
    "content": "Data augmentation plays a pivotal role in offline imitation learning (IL) by alleviating covariate shift, yet existing methods remain constrained. Single-step techniques frequently violate underlying system dynamics, whereas trajectory-level approaches are plagued by compounding errors or scalability limitations. Even recent Koopman-based methods typically function at the single-step level, encountering computational bottlenecks due to action-equivariance requirements and vulnerability to approximation errors. To overcome these challenges, we introduce Koopman-Assisted Trajectory Synthesis (KATS), a novel framework for generating complete, multi-step trajectories. By operating at the trajectory level, KATS effectively mitigates compounding errors. It leverages a state-equivariant assumption to ensure computational efficiency and scalability, while incorporating a refined generator matrix to bolster robustness against Koopman approximation errors. This approach enables a more direct and efficacious mechanism for distribution matching in offline IL. Extensive experiments demonstrate that KATS substantially enhances policy performance and achieves state-of-the-art (SOTA) results, especially in demanding scenarios with narrow expert data distributions.",
    "key_points": [
      "offline imitation learning; offline reinforcement learning; data augmentation"
    ],
    "gold_summary": "This paper proposes a method based on Koopman Theory for generating trajectories from offline data."
  },
  {
    "paper_id": "7qQ50LrRn5",
    "title": "Agentic-KGR: Co-evolutionary Knowledge Graph Construction through Multi-Agent Reinforcement Learning",
    "domain": "reinforcement learning",
    "content": "Current knowledge-enhanced large language models (LLMs) rely on static, pre-constructed knowledge bases that suffer from coverage gaps and temporal obsolescence, limiting their effectiveness in dynamic information environments. We present Agentic-KGR, a novel framework enabling co-evolution between LLMs and knowledge graphs (KGs) through multi-round reinforcement learning (RL). Our approach introduces three key innovations: (1) a retrieval-augmented memory system enabling synergistic co-evolution between model parameters and knowledge structures through continuous optimization; (2) a dynamic schema expansion mechanism that systematically extends graph ontologies beyond pre-defined boundaries during training; (3) a learnable multi-scale prompt compression approach that preserves critical information while reducing computational complexity through adaptive sequence optimization. Experimental results demonstrate substantial improvements over supervised baselines and single-round RL approaches in knowledge extraction tasks. When integrated with GraphRAG, our method achieves superior performance in downstream QA tasks, with significant gains in both accuracy and knowledge coverage compared to existing methods.",
    "key_points": [
      "agentic",
      "reinforcement learning",
      "knowledge graph",
      "large language model"
    ],
    "gold_summary": "The paper addresses the problem of LLMs hallucination.  The paper proposes a framework that enables co-evolution between LLMs and Kgs through multi-round RL."
  },
  {
    "paper_id": "aJd636PxP1",
    "title": "PAC-Bayesian Reinforcement Learning Trains Generalizable Policies",
    "domain": "reinforcement learning",
    "content": "We derive a novel PAC-Bayesian generalization bound for reinforcement learning (RL) that explicitly accounts for Markov dependencies in the data, through the chain’s mixing time. This contributes a step to overcoming challenges in obtaining generalization guarantees for RL where the sequential nature of data does not meet independence assumptions underlying classical bounds. Our bound provides non-vacuous certificates for modern off-policy algorithms like Soft Actor-Critic. We demonstrate the bound’s practical utility through PB-SAC, an algorithm that optimizes the bound during training to guide exploration. Experiments across continuous control tasks show that our approach provides meaningful confidence certificates while maintaining competitive performance.",
    "key_points": [
      "reinforcement learning",
      "pac-bayes"
    ],
    "gold_summary": "The paper introduces a new PAC-Bayesian bound for RL that, for the first time, is able\nto account for temporal dependencies in policy-induced Markov chains, avoiding\nthe independence assumptions needed by prior work."
  },
  {
    "paper_id": "VzMoNcY6Ju",
    "title": "Deep Reinforcement Learning For Nash Equilibria in Non-Renewable Resource Differential Games",
    "domain": "reinforcement learning",
    "content": "Characterizing Nash equilibria in oligopolistic non-renewable resource markets poses major challenges for computational economics, as traditional iterative methods face scalability limitations due to the curse of dimensionality. In this work, we propose a reinforcement learning–based approach to compute these equilibria and benchmark it against a modified iterative baseline, derived from an established algorithm for differential games and adapted to the oligopoly case. We conduct experiments in monopoly, duopoly, and multi-player settings, evaluating both reward accuracy and computational efficiency. Our results show that while iterative schemes provide good accuracy in low-dimensional problems, reinforcement learning scales more effectively to three- and four-player games, leading to a substantial reduction in computation time. This highlights the potential of reinforcement learning as a scalable tool for solving complex differential games in resource economics.",
    "key_points": [
      "reinforcement learning",
      "game theory",
      "differential resource games"
    ],
    "gold_summary": "The paper applies deep RL to an economics problem, achieving results that align well with known theory where such theory exists, and scales beyond such situations to 3- and 4-agent settings."
  },
  {
    "paper_id": "SPxRgjtsd5",
    "title": "A Latent Causal Diffusion Model for Multiobjective Reinforcement Learning",
    "domain": "reinforcement learning",
    "content": "Multiobjective reinforcement learning (MORL) poses significant challenges due to the inherent conflicts between objectives and the difficulty of adapting to dynamic environments. Traditional methods often struggle to generalize effectively, particularly in large and complex state-action spaces. To address these limitations, we introduce the Latent Causal Diffusion Model (LacaDM), a novel approach designed to enhance the adaptability of MORL in discrete and continuous environments. Unlike existing methods that primarily address conflicts between objectives, LacaDM learns latent temporal causal relationships between environmental states and policies, enabling efficient knowledge transfer across diverse MORL scenarios. By embedding these causal structures within a diffusion model-based framework, LacaDM achieves a balance between conflicting objectives while maintaining strong generalization capabilities in previously unseen environments. Empirical evaluations on various tasks from the MOGymnasium framework demonstrate that LacaDM consistently outperforms the state-of-art baselines in terms of hypervolume, sparsity, and expected utility maximization, showcasing its effectiveness in complex multiobjective tasks.",
    "key_points": [
      "multiobjective reinforcement learning",
      "diffusion model",
      "casual learning"
    ],
    "gold_summary": "This paper proposes a diffusion model that utilizes causal representation learning to enhance performance and generalization in diverse multi-objective reinforcement learning tasks. Empirical evaluations are presented to demonstrate the performance of the proposed model."
  },
  {
    "paper_id": "jS7l8oPBlj",
    "title": "Positive Transfer of Prior Knowledge in Deep Reinforcement Learning via Reward Shaping",
    "domain": "reinforcement learning",
    "content": "Effective learners improve task performance and acquire new skills more efficiently by leveraging related prior knowledge. Reward shaping is central to many such approaches and facilitates knowledge transfer. However, misidentifying or misusing prior knowledge can impair learning. To tackle this challenge, we propose a novel shaping method, Target value As Potential (TAP), which uses critic target value as the potential to operate within the canonical Potential-Based Reward Shaping (PBRS) framework. It integrates readily with policy-gradient deep reinforcement learning algorithms and requires only minor modifications to existing training pipelines. This endows TAP with the unique combination of policy invariance and simplicity in implementation, distinguishing it from many model-based methods. Our qualitative analysis and empirical evaluations demonstrate that TAP accelerates convergence compared to baseline DRL algorithms. Moreover, empirical results show that TAP leads to higher cumulative returns. We evaluate TAP-augmented TD3 and D4PG across a range of tasks in the DeepMind Control Suite. TAP significantly improves performance over the original TD3 and D4PG and consistently outperforms other reward shaping methods, including Heuristic-Guided Reinforcement Learning (HuRL) and Dynamic Potential-Based Reward Shaping (DPBRS).",
    "key_points": [
      "reward shaping",
      "reinforcement learning"
    ],
    "gold_summary": "This paper proposed to deal with the knowledge transfer problem through potential based reward shaping with Q function in source domain as the potential. The authors provide some theoretical analysis and experiments on DMC environments."
  },
  {
    "paper_id": "tyUnYbE7Gi",
    "title": "Training-Free Group Relative Policy Optimization",
    "domain": "reinforcement learning",
    "content": "Recent advances in Large Language Model (LLM) agents have demonstrated their promising general capabilities. However, their performance in specialized real-world domains often degrades due to challenges in effectively integrating external tools and specific prompting strategies. While methods like agentic reinforcement learning have been proposed to address this, they typically rely on costly parameter updates such as Supervised Fine-Tuning (SFT) or Group Relative Policy Optimization (GRPO) to alter output distribution. However, we argue that LLMs can achieve a similar effect on the output distribution by introducing a token prior, which is a far more lightweight approach that not only addresses practical data scarcity but also avoids the common issue of overfitting. To this end, we propose Training-free Group Relative Policy Optimization (Training-free GRPO), a cost-effective solution that enhances LLM agent performance without any parameter updates. Our method leverages minimal ground-truth data to perform multiple rollouts, where a group-based relative scoring mechanism is applied to iteratively distill high-quality experiential knowledge in each epoch. Such knowledge serves as the learned token prior, which is seamlessly integrated during LLM API calls to guide model behavior. Experiments on mathematical reasoning and web searching tasks demonstrate that Training-free GRPO, when applied to DeepSeek-V3.1, significantly improves out-of-domain performance.\nWith just a few dozen training samples, Training-free GRPO outperforms fine-tuned small LLMs and achieves competitive results. Our code is available at https://anonymous.4open.science/r/Training-Free-GRPO/.",
    "key_points": [
      "llm agents",
      "training-free learning",
      "group relative policy optimization"
    ],
    "gold_summary": "This work introduces training-free GRPO a method that mimics the traditional gradient updates of GRPO with contextual aggregation of trials."
  },
  {
    "paper_id": "a3CUE06G5Y",
    "title": "Learning Efficient and Interpretable Multi-Agent Communication",
    "domain": "reinforcement learning",
    "content": "Effective communication is crucial for multi-agent cooperation in partially observable environments. However, a fundamental trilemma exists among task performance, communication efficiency, and human interpretability. To resolve this, we propose a multi-agent communication framework via $\\textbf{G}$rounding $\\textbf{L}$anguage and $\\textbf{C}$ontrastive learning (GLC) to learns  efficient and interpretable communication protocols. Specifically, GLC employs an autoencoder to learn discretized and compressed communication symbols, ensuring high communication efficiency. These symbols are then semantically aligned with human concepts using data generated by a Large Language Model (LLM), making them human-interpretable. Furthermore, a contrastive learning objective is introduced to ensure consistency and mutual intelligibility among all agents, thereby securing high task utility. GLC dynamically balances these objectives by the Information Bottleneck principle. Extensive experiments show that GLC outperforms state-of-the-art methods across multiple benchmarks, delivering superior task performance, higher communication efficiency, and enhanced human interpretability.",
    "key_points": [
      "multi-agent communication",
      "reinforcement learning",
      "contrastive learning",
      "language grounding"
    ],
    "gold_summary": "The paper proposes GLC, a multi-agent communication framework that supposedly addresses the \"trilemma\" between task performance, communication efficiency, and human interpretability. They use discrete autoencoders, LLM-based language grounding, and contrastive learning. Tested on several environments."
  },
  {
    "paper_id": "hXtUtnf3ms",
    "title": "Unraveling Max-Return Sequence Modeling via Return Consistency",
    "domain": "reinforcement learning",
    "content": "Offline reinforcement learning (RL) learns from fixed datasets without interaction with online environment, enabling supervised solutions for offline RL. \nDecision Transformer (DT) casts offline RL as return-conditioned supervised sequence modeling, thereby sidestepping optimal value fitting and policy gradients. \nThis paradigm overlooks RL’s core objective of return maximization, which yields brittle behavior on suboptimal trajectories and limited stitching ability.\nReinformer reorients this objective through max-return sequence modeling: during inference, the model conditions on the predicted maximum achievable returns to generate the optimal actions. \nTo better understand both the SOTA performance of this paradigm and its occasional dramatic failures, we adopt a supervised perspective and introduce the return consistency to assess whether similar state-action pairs have similar returns. \nIndeed, high return consistency guarantees the maximized return reliably cues the optimal action, while low consistency may lead to suboptimal action selection.\nThrough visualizations, two different consistency modes are exposed and we quantify this via the return standard deviation of the data cluster with highest return mean.\nFurthermore, we reveal the relationship between this metric and 1) final performance, 2) context lengths, 3) model architectures through a systematic study.\nFinally, we improve return consistency by explicitly decreasing the return standard deviation, thereby further increasing the performance.",
    "key_points": [
      "offline rl",
      "max-return sequence modeling",
      "return consistency"
    ],
    "gold_summary": "This paper tackles the performance/stability problem of training Decision Transformers in the offline RL setting. The authors argue that \"return consistency\" can explain certain failure modes and dependencies on the hyperparameters (e.g., context length/architecture)."
  },
  {
    "paper_id": "I6GzDCne7U",
    "title": "DeepScaleR: Effective RL Scaling of Reasoning Models via Iterative Context Lengthening",
    "domain": "reinforcement learning",
    "content": "Recent advances in large reasoning models (LRMs) such as OpenAI's o1 and Deepseek-R1 have demonstrated that reinforcement learning (RL) with outcome-based supervision can significantly enhance the reasoning abilities of language models. However, these improvements have so far relied on massive model scales and compute budgets, leaving open the question of whether RL-based scaling can be made both effective and efficient at smaller scales. In this work, we introduce DeepScaleR-1.5B, a 1.5B parameter model trained using reinforcement learning with a novel iterative context lengthening strategy. Our method begins with shorter context windows and progressively extends them throughout training, enabling the model to first learn to reason efficiently before learning to reason longer. This approach yields substantial performance gains with dramatically reduced computational cost. DeepScaleR-1.5B achieves 43.3% Pass@1 on the AIME2024 math benchmark—a 14.3 percentage point improvement over its base model and on par with OpenAI's o1-preview—while requiring a fraction of the compute. We provide a full training recipe, including dataset, code, hyperparameters, and training methodology, demonstrating that small models can be effectively scaled into strong math reasoners via RL.",
    "key_points": [
      "reinforcement learning",
      "large reasoning model",
      "llm reasoning"
    ],
    "gold_summary": "This approach yields substantial performance gains with dramatically reduced computational cost. DeepScaleR-1.5B achieves 43.3% Pass@1 on the AIME2024 math benchmark—a 14.3 percentage point improvement over its base model."
  },
  {
    "paper_id": "LnYzMi3s0s",
    "title": "Understanding Sampler Stochasticity in Training Diffusion Models for RLHF",
    "domain": "reinforcement learning",
    "content": "Reinforcement Learning from Human Feedback (RLHF) improves pretrained generative models, and its sampling design is important for training reliable, high-quality models. In practice, stochastic SDE samplers promote exploration during training, while deterministic ODE samplers enable fast, stable inference; this creates a discrepancy in sampling stochasticity that induces a preference-reward gap. In this paper, we establish a non-vacuous bound on this gap for general diffusion models and a sharper bound for Variance Exploding (VE) and Variance Preserving (VP) models with (mixture) Gaussian data. Methodologically, we leverage the stochastic gDDIM scheme to attain arbitrarily high stochasticity while preserving data marginals, and we evaluate, under multiple preference rewards, the performance of RL algorithms (e.g., log-likelihood and group-relative policy variants). Our numerical experiments validate that reward gaps consistently narrow over training, and ODE sampling quality improves when models are updated using higher-stochasticity SDE training.",
    "key_points": [
      "generative diffusion models",
      "fine-tuning",
      "reinforcement learning from human feedback",
      "deterministic sampling",
      "human preference alignment"
    ],
    "gold_summary": "This paper studies the gap between SDE samplers and ODE samplers in RLHF fine-tuning of diffusion models. Theoretical bounds are derived and numerical experiments are conducted."
  },
  {
    "paper_id": "0RkLOTVFvW",
    "title": "Reparameterization Proximal Policy Optimization",
    "domain": "reinforcement learning",
    "content": "Reparameterization policy gradient (RPG) is promising for improving sample efficiency by leveraging differentiable dynamics. However, a critical barrier is its training instability, where high-variance gradients can destabilize the learning process. To address this, we draw inspiration from Proximal Policy Optimization (PPO), which uses a surrogate objective to enable stable sample reuse in the model-free setting. We first establish a connection between this surrogate objective and RPG, which has been largely unexplored and is non-trivial. Then, we bridge this gap by demonstrating that the reparameterization gradient of a PPO-like surrogate objective can be computed efficiently using backpropagation through time. Based on this key insight, we propose Reparameterization Proximal Policy Optimization (RPO), a stable and sample-efficient RPG-based method. RPO enables stable sample reuse over multiple epochs by employing a policy gradient clipping strategy tailored for RPG. It is further stabilized by Kullback-Leibler (KL) divergence regularization and remains fully compatible with existing variance reduction methods. We evaluate RPO on a suite of challenging locomotion and manipulation tasks, where experiments demonstrate that our method achieves superior sample efficiency and strong performance.",
    "key_points": [
      "reinforcement learning",
      "differentiable simulation",
      "reparameterization policy gradient"
    ],
    "gold_summary": "The authors propose a PPO-resembling mechanism enabling reusing collected rollouts for multiple policy update steps in reparameterization policy gradient methods (policy gradients estimated in a model-based fashion, e.g., using a differentiable simulator)."
  }
]